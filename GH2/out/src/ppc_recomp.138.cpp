#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_823F8DB4"))) PPC_WEAK_FUNC(sub_823F8DB4);
PPC_FUNC_IMPL(__imp__sub_823F8DB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_823F8DB8"))) PPC_WEAK_FUNC(sub_823F8DB8);
PPC_FUNC_IMPL(__imp__sub_823F8DB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// mr r20,r6
	r20.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r29,r8
	r29.u64 = ctx.r8.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rlwinm. r11,r11,0,13,13
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823f8f30
	if (!cr0.eq) goto loc_823F8F30;
	// rlwinm r3,r29,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r22,r3
	r22.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// beq 0x823f8f40
	if (cr0.eq) goto loc_823F8F40;
	// rlwinm. r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f8e28
	if (cr0.eq) goto loc_823F8E28;
	// mr r11,r22
	r11.u64 = r22.u64;
	// li r9,-1
	ctx.r9.s64 = -1;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x823f8e28
	if (cr0.eq) goto loc_823F8E28;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_823F8E1C:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823f8e1c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823F8E1C;
loc_823F8E28:
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// rlwinm r26,r29,2,0,29
	r26.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// li r11,2
	r11.s64 = 2;
loc_823F8E38:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r26
	ctx.r10.u64 = ctx.r10.u64 + r26.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823f8e38
	if (!cr0.eq) goto loc_823F8E38;
	// li r8,4
	ctx.r8.s64 = 4;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x823f8e98
	if (cr6.eq) goto loc_823F8E98;
	// lwz r9,8(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// mr r11,r29
	r11.u64 = r29.u64;
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
loc_823F8E6C:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// and r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 & ctx.r8.u64;
	// rlwinm r8,r8,0,29,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x4;
	// bne 0x823f8e6c
	if (!cr0.eq) goto loc_823F8E6C;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x823f8ea8
	if (cr6.eq) goto loc_823F8EA8;
loc_823F8E98:
	// clrlwi r30,r29,12
	r30.u64 = r29.u32 & 0xFFFFF;
	// li r8,0
	ctx.r8.s64 = 0;
	// oris r5,r30,4096
	ctx.r5.u64 = r30.u64 | 268435456;
	// b 0x823f8eb4
	goto loc_823F8EB4;
loc_823F8EA8:
	// clrlwi r30,r29,12
	r30.u64 = r29.u32 & 0xFFFFF;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// oris r5,r30,8272
	ctx.r5.u64 = r30.u64 | 542113792;
loc_823F8EB4:
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// blt cr6,0x823f90e8
	if (cr6.lt) goto loc_823F90E8;
	// lwz r28,84(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x823f90e8
	if (cr0.lt) goto loc_823F90E8;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x823f8f20
	if (cr6.eq) goto loc_823F8F20;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_823F8F20:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x823f90e4
	if (cr6.eq) goto loc_823F90E4;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// b 0x823f90d8
	goto loc_823F90D8;
loc_823F8F30:
	// mulli r3,r29,12
	ctx.r3.s64 = r29.s64 * 12;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r22,r3
	r22.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// bne 0x823f8f4c
	if (!cr0.eq) goto loc_823F8F4C;
loc_823F8F40:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x823f90e8
	goto loc_823F90E8;
loc_823F8F4C:
	// mulli r10,r29,3
	ctx.r10.s64 = r29.s64 * 3;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x823f8f78
	if (cr6.eq) goto loc_823F8F78;
	// mr r11,r22
	r11.u64 = r22.u64;
	// li r9,-1
	ctx.r9.s64 = -1;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x823f8f78
	if (cr0.eq) goto loc_823F8F78;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_823F8F6C:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823f8f6c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823F8F6C;
loc_823F8F78:
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// rlwinm r23,r29,2,0,29
	r23.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// li r11,3
	r11.s64 = 3;
loc_823F8F88:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r23
	ctx.r10.u64 = ctx.r10.u64 + r23.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823f8f88
	if (!cr0.eq) goto loc_823F8F88;
	// clrlwi r28,r29,12
	r28.u64 = r29.u32 & 0xFFFFF;
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r9,0
	ctx.r9.s64 = 0;
	// oris r26,r28,4112
	r26.u64 = r28.u64 | 269484032;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x823f90e8
	if (cr0.lt) goto loc_823F90E8;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// lwz r30,84(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// oris r5,r28,8208
	ctx.r5.u64 = r28.u64 | 537919488;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x823f90e8
	if (cr0.lt) goto loc_823F90E8;
	// lwz r28,88(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x823f90e8
	if (cr0.lt) goto loc_823F90E8;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x823f90b4
	if (cr6.eq) goto loc_823F90B4;
	// mr r11,r30
	r11.u64 = r30.u64;
	// subf r7,r30,r25
	ctx.r7.s64 = r25.s64 - r30.s64;
	// subf r6,r30,r28
	ctx.r6.s64 = r28.s64 - r30.s64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_823F9044:
	// lwz r9,8(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r8,r7,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwzx r9,r5,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r5,0(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r4,0(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// clrlwi r5,r5,27
	ctx.r5.u64 = ctx.r5.u32 & 0x1F;
	// rlwinm r5,r5,0,29,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// or r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 | ctx.r4.u64;
	// stw r5,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r5.u32);
	// lwz r9,8(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwzx r5,r6,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,0,27,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x1E;
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// rlwinm r8,r8,0,30,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF3;
	// lwzx r9,r5,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// or r8,r8,r5
	ctx.r8.u64 = ctx.r8.u64 | ctx.r5.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// bne 0x823f9044
	if (!cr0.eq) goto loc_823F9044;
loc_823F90B4:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x823f90cc
	if (cr6.eq) goto loc_823F90CC;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_823F90CC:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x823f90e4
	if (cr6.eq) goto loc_823F90E4;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
loc_823F90D8:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_823F90E4:
	// li r31,0
	r31.s64 = 0;
loc_823F90E8:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_823F9100"))) PPC_WEAK_FUNC(sub_823F9100);
PPC_FUNC_IMPL(__imp__sub_823F9100) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x823f913c
	if (!cr0.eq) goto loc_823F913C;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x823f91a0
	goto loc_823F91A0;
loc_823F913C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823f6248
	sub_823F6248(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823f9190
	if (cr6.eq) goto loc_823F9190;
	// mr r11,r31
	r11.u64 = r31.u64;
	// subf r8,r31,r27
	ctx.r8.s64 = r27.s64 - r31.s64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_823F9160:
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r9,r7,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// or r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 | ctx.r6.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// bne 0x823f9160
	if (!cr0.eq) goto loc_823F9160;
loc_823F9190:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_823F91A0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_823F91A8"))) PPC_WEAK_FUNC(sub_823F91A8);
PPC_FUNC_IMPL(__imp__sub_823F91A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd0
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r24,0
	r24.s64 = 0;
	// mr r19,r4
	r19.u64 = ctx.r4.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r18,r5
	r18.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r23,r7
	r23.u64 = ctx.r7.u64;
	// stw r24,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r24.u32);
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// stw r24,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r24.u32);
	// mr r21,r9
	r21.u64 = ctx.r9.u64;
	// mr r20,r10
	r20.u64 = ctx.r10.u64;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x823f9480
	if (cr6.eq) goto loc_823F9480;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x823f9208
	if (!cr6.eq) goto loc_823F9208;
	// lwz r11,324(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x823f9208
	if (cr6.eq) goto loc_823F9208;
	// mr r21,r11
	r21.u64 = r11.u64;
	// addi r20,r1,100
	r20.s64 = ctx.r1.s64 + 100;
	// li r23,1
	r23.s64 = 1;
loc_823F9208:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x823f944c
	if (!cr6.eq) goto loc_823F944C;
	// lwz r22,332(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x823f944c
	if (cr6.eq) goto loc_823F944C;
	// lwz r11,136(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 136);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823f944c
	if (!cr6.eq) goto loc_823F944C;
loc_823F9228:
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// mr r27,r24
	r27.u64 = r24.u64;
	// mr r30,r24
	r30.u64 = r24.u64;
	// mr r29,r24
	r29.u64 = r24.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,18
	cr6.compare<int32_t>(ctx.r10.s32, 18, xer);
	// bne cr6,0x823f92a0
	if (!cr6.eq) goto loc_823F92A0;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r31,24(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// beq 0x823f929c
	if (cr0.eq) goto loc_823F929C;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// lwz r3,24(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f92a0
	if (cr0.lt) goto loc_823F92A0;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x823f9288
	if (!cr6.eq) goto loc_823F9288;
	// mr r27,r31
	r27.u64 = r31.u64;
	// b 0x823f92a0
	goto loc_823F92A0;
loc_823F9288:
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x823f92a0
	if (!cr6.eq) goto loc_823F92A0;
	// mr r30,r31
	r30.u64 = r31.u64;
	// b 0x823f92a0
	goto loc_823F92A0;
loc_823F929C:
	// mr r29,r31
	r29.u64 = r31.u64;
loc_823F92A0:
	// lwz r22,12(r22)
	r22.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x823f92c4
	if (!cr6.eq) goto loc_823F92C4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// mr r27,r30
	r27.u64 = r30.u64;
	// bne cr6,0x823f92bc
	if (!cr6.eq) goto loc_823F92BC;
	// mr r27,r29
	r27.u64 = r29.u64;
loc_823F92BC:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x823f9444
	if (cr6.eq) goto loc_823F9444;
loc_823F92C4:
	// lwz r3,8(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// bge cr6,0x823f92e4
	if (!cr6.lt) goto loc_823F92E4;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x823f92e8
	goto loc_823F92E8;
loc_823F92E4:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
loc_823F92E8:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x823f94a0
	if (cr6.eq) goto loc_823F94A0;
	// bl 0x8243e4e0
	sub_8243E4E0(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r25,r10
	cr6.compare<uint32_t>(r25.u32, ctx.r10.u32, xer);
	// bge cr6,0x823f9318
	if (!cr6.lt) goto loc_823F9318;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r11,r10
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x823f931c
	goto loc_823F931C;
loc_823F9318:
	// mr r28,r24
	r28.u64 = r24.u64;
loc_823F931C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x823f94ac
	if (cr6.eq) goto loc_823F94AC;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm. r10,r11,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x823f9398
	if (!cr0.eq) goto loc_823F9398;
	// ori r11,r11,2112
	r11.u64 = r11.u64 | 2112;
	// stw r27,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r27.u32);
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f9440
	if (cr0.eq) goto loc_823F9440;
	// rlwinm. r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x823f9440
	if (!cr0.eq) goto loc_823F9440;
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f936c
	if (cr0.eq) goto loc_823F936C;
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r10,112(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 112);
	// rlwinm. r10,r10,0,10,10
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f936c
	if (cr0.eq) goto loc_823F936C;
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
loc_823F936C:
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x823f9440
	if (!cr0.eq) goto loc_823F9440;
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r10,112(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 112);
	// rlwinm. r10,r10,0,11,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f9440
	if (cr0.eq) goto loc_823F9440;
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// stw r11,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r11.u32);
	// b 0x823f9440
	goto loc_823F9440;
loc_823F9398:
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_823F93A0:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x823f93a0
	if (!cr6.eq) goto loc_823F93A0;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// mr r11,r27
	r11.u64 = r27.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rotlwi r30,r10,0
	r30.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_823F93C4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x823f93c4
	if (!cr6.eq) goto loc_823F93C4;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r29,r11,0
	r29.u64 = __builtin_rotateleft32(r11.u32, 0);
	// add r11,r29,r30
	r11.u64 = r29.u64 + r30.u64;
	// addi r4,r11,3
	ctx.r4.s64 = r11.s64 + 3;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x823f94ac
	if (cr0.eq) goto loc_823F94AC;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// add r11,r31,r30
	r11.u64 = r31.u64 + r30.u64;
	// li r10,59
	ctx.r10.s64 = 59;
	// li r9,32
	ctx.r9.s64 = 32;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r11,2
	ctx.r3.s64 = r11.s64 + 2;
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// stb r9,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r9.u8);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// add r11,r31,r29
	r11.u64 = r31.u64 + r29.u64;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// stb r24,2(r11)
	PPC_STORE_U8(r11.u32 + 2, r24.u8);
	// stw r31,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r31.u32);
loc_823F9440:
	// li r28,1
	r28.s64 = 1;
loc_823F9444:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// bne cr6,0x823f9228
	if (!cr6.eq) goto loc_823F9228;
loc_823F944C:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r10,r20
	ctx.r10.u64 = r20.u64;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x823f6438
	sub_823F6438(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f9498
	if (cr0.lt) goto loc_823F9498;
loc_823F9480:
	// lwz r11,340(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x823f9494
	if (cr6.eq) goto loc_823F9494;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_823F9494:
	// li r3,0
	ctx.r3.s64 = 0;
loc_823F9498:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8239bd20
	return;
loc_823F94A0:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x823f9498
	goto loc_823F9498;
loc_823F94AC:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x823f9498
	goto loc_823F9498;
}

__attribute__((alias("__imp__sub_823F94B8"))) PPC_WEAK_FUNC(sub_823F94B8);
PPC_FUNC_IMPL(__imp__sub_823F94B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r25,r8
	r25.u64 = ctx.r8.u64;
	// mr r30,r9
	r30.u64 = ctx.r9.u64;
	// mr r24,r10
	r24.u64 = ctx.r10.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x823f94f0
	if (!cr6.eq) goto loc_823F94F0;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x823f9600
	goto loc_823F9600;
loc_823F94F0:
	// li r28,0
	r28.s64 = 0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r28.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bge cr6,0x823f9518
	if (!cr6.lt) goto loc_823F9518;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x823f951c
	goto loc_823F951C;
loc_823F9518:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
loc_823F951C:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x823f9530
	if (!cr6.eq) goto loc_823F9530;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x823f9600
	goto loc_823F9600;
loc_823F9530:
	// bl 0x8243e4e0
	sub_8243E4E0(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// bge cr6,0x823f9558
	if (!cr6.lt) goto loc_823F9558;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x823f955c
	goto loc_823F955C;
loc_823F9558:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_823F955C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x823f9570
	if (!cr6.eq) goto loc_823F9570;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x823f9600
	goto loc_823F9600;
loc_823F9570:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,64
	ctx.r10.u64 = ctx.r10.u64 | 64;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// rlwinm. r9,r10,0,27,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x823f95d4
	if (cr0.eq) goto loc_823F95D4;
	// rlwinm. r9,r10,0,24,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x823f95d4
	if (!cr0.eq) goto loc_823F95D4;
	// rlwinm. r9,r10,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x823f95ac
	if (cr0.eq) goto loc_823F95AC;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,112(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 112);
	// rlwinm. r9,r9,0,10,10
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x823f95ac
	if (cr0.eq) goto loc_823F95AC;
	// ori r10,r10,1024
	ctx.r10.u64 = ctx.r10.u64 | 1024;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_823F95AC:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r9,r10,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x823f95d4
	if (!cr0.eq) goto loc_823F95D4;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,112(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 112);
	// rlwinm. r9,r9,0,11,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x823f95d4
	if (cr0.eq) goto loc_823F95D4;
	// oris r10,r10,16
	ctx.r10.u64 = ctx.r10.u64 | 1048576;
	// ori r10,r10,1024
	ctx.r10.u64 = ctx.r10.u64 | 1024;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_823F95D4:
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// stw r24,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r24.u32);
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f91a8
	sub_823F91A8(ctx, base);
loc_823F9600:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8239bd38
	return;
}

__attribute__((alias("__imp__sub_823F9608"))) PPC_WEAK_FUNC(sub_823F9608);
PPC_FUNC_IMPL(__imp__sub_823F9608) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x823f96e4
	if (cr6.eq) goto loc_823F96E4;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
loc_823F9638:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// b 0x823f96a0
	goto loc_823F96A0;
loc_823F9654:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x823f96a8
	if (!cr6.eq) goto loc_823F96A8;
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r6,52(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r6,96(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 96);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x823f9690
	if (!cr6.eq) goto loc_823F9690;
	// lwz r6,96(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// stw r6,96(r10)
	PPC_STORE_U32(ctx.r10.u32 + 96, ctx.r6.u32);
	// lwz r6,100(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// stw r6,100(r10)
	PPC_STORE_U32(ctx.r10.u32 + 100, ctx.r6.u32);
loc_823F9690:
	// lwz r6,52(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// stw r6,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r6.u32);
	// lwz r10,52(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 52);
loc_823F96A0:
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x823f9654
	if (!cr6.eq) goto loc_823F9654;
loc_823F96A8:
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f96d4
	if (cr0.eq) goto loc_823F96D4;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823f96d8
	if (cr6.eq) goto loc_823F96D8;
loc_823F96D4:
	// li r7,0
	ctx.r7.s64 = 0;
loc_823F96D8:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823f9638
	if (!cr0.eq) goto loc_823F9638;
loc_823F96E4:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x823f9798
	if (cr6.eq) goto loc_823F9798;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x823f9798
	if (cr6.eq) goto loc_823F9798;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x823f9768
	if (cr6.eq) goto loc_823F9768;
	// mr r31,r26
	r31.u64 = r26.u64;
loc_823F9704:
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lfd f1,32(r30)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// beq cr6,0x823f97a4
	if (cr6.eq) goto loc_823F97A4;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,96(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 96);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r29,r27
	cr6.compare<uint32_t>(r29.u32, r27.u32, xer);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r9,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r9.u32);
	// lwz r10,100(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// stw r10,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r10.u32);
	// blt cr6,0x823f9704
	if (cr6.lt) goto loc_823F9704;
loc_823F9768:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r6,120(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 120);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823f94b8
	sub_823F94B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f979c
	if (cr0.lt) goto loc_823F979C;
loc_823F9798:
	// li r3,0
	ctx.r3.s64 = 0;
loc_823F979C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd3c
	return;
loc_823F97A4:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x823f979c
	goto loc_823F979C;
}

__attribute__((alias("__imp__sub_823F97B0"))) PPC_WEAK_FUNC(sub_823F97B0);
PPC_FUNC_IMPL(__imp__sub_823F97B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce0
	// stfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r23,r6
	r23.u64 = ctx.r6.u64;
	// mr r22,r7
	r22.u64 = ctx.r7.u64;
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x823f9898
	if (cr6.eq) goto loc_823F9898;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f31,-31360(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_823F97E0:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823f9898
	if (cr6.eq) goto loc_823F9898;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x823f9888
	if (cr6.eq) goto loc_823F9888;
	// lis r10,8272
	ctx.r10.s64 = 542113792;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x823f98a8
	if (!cr6.eq) goto loc_823F98A8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x823f5390
	sub_823F5390(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f9860
	if (cr0.lt) goto loc_823F9860;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x823f9860
	if (!cr6.eq) goto loc_823F9860;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x823f9890
	goto loc_823F9890;
loc_823F9860:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bl 0x823f5390
	sub_823F5390(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f9898
	if (cr0.lt) goto loc_823F9898;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
loc_823F9888:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_823F9890:
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// bne cr6,0x823f97e0
	if (!cr6.eq) goto loc_823F97E0;
loc_823F9898:
	// li r3,0
	ctx.r3.s64 = 0;
loc_823F989C:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x8239bd30
	return;
loc_823F98A8:
	// lis r10,8224
	ctx.r10.s64 = 538968064;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x823f99b4
	if (!cr6.eq) goto loc_823F99B4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x823f5390
	sub_823F5390(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f9898
	if (cr0.lt) goto loc_823F9898;
	// clrldi r11,r24,32
	r11.u64 = r24.u64 & 0xFFFFFFFF;
	// lfd f13,96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lfd f0,88(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f9898
	if (cr0.lt) goto loc_823F9898;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823f993c
	if (cr6.eq) goto loc_823F993C;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x823f989c
	goto loc_823F989C;
loc_823F993C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r7,r7,0,30,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x823f9898
	if (cr0.eq) goto loc_823F9898;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r11,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x823f9898
	if (!cr0.eq) goto loc_823F9898;
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f9898
	if (cr0.eq) goto loc_823F9898;
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823f9898
	if (cr0.eq) goto loc_823F9898;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x823f99a8
	if (cr6.eq) goto loc_823F99A8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
loc_823F99A8:
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r8,0(r22)
	PPC_STORE_U32(r22.u32 + 0, ctx.r8.u32);
	// b 0x823f989c
	goto loc_823F989C;
loc_823F99B4:
	// lis r10,12288
	ctx.r10.s64 = 805306368;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r8,20(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r9,r8
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x823f9898
	if (cr0.eq) goto loc_823F9898;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
	// lfd f13,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31368(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,20(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r9,r8
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x823f9898
	if (cr0.eq) goto loc_823F9898;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
	// lfd f0,32(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r10,r8
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f9898
	if (cr0.eq) goto loc_823F9898;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lis r8,8256
	ctx.r8.s64 = 541065216;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwzx r27,r11,r10
	r27.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bne cr6,0x823f9898
	if (!cr6.eq) goto loc_823F9898;
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x823f9af4
	if (cr0.eq) goto loc_823F9AF4;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
loc_823F9AD8:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x823f9af4
	if (cr6.eq) goto loc_823F9AF4;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// blt cr6,0x823f9ad8
	if (cr6.lt) goto loc_823F9AD8;
loc_823F9AF4:
	// li r26,0
	r26.s64 = 0;
	// li r25,1
	r25.s64 = 1;
loc_823F9AFC:
	// lwz r8,12(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mullw r10,r8,r26
	ctx.r10.s64 = int64_t(ctx.r8.s32) * int64_t(r26.s32);
	// lwz r7,8(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + r28.u64;
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r11,r7
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f9c80
	if (cr0.eq) goto loc_823F9C80;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x823f9c80
	if (!cr6.eq) goto loc_823F9C80;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x823f9c80
	if (!cr6.eq) goto loc_823F9C80;
	// lwz r5,12(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq 0x823f9ba4
	if (cr0.eq) goto loc_823F9BA4;
	// lwz r11,16(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_823F9B88:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r4,r6
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r6.u32, xer);
	// beq cr6,0x823f9ba4
	if (cr6.eq) goto loc_823F9BA4;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// blt cr6,0x823f9b88
	if (cr6.lt) goto loc_823F9B88;
loc_823F9BA4:
	// mullw r11,r8,r25
	r11.s64 = int64_t(ctx.r8.s32) * int64_t(r25.s32);
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwzx r31,r10,r9
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwzx r29,r11,r7
	r29.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x823f5390
	sub_823F5390(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f9c80
	if (cr0.lt) goto loc_823F9C80;
	// clrldi r11,r24,32
	r11.u64 = r24.u64 & 0xFFFFFFFF;
	// lfd f13,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f0,96(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x823f9c80
	if (!cr6.eq) goto loc_823F9C80;
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f9c80
	if (cr0.lt) goto loc_823F9C80;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823f9c34
	if (cr6.eq) goto loc_823F9C34;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x823f9c80
	if (!cr6.eq) goto loc_823F9C80;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x823f989c
	goto loc_823F989C;
loc_823F9C34:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,20(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r8,r8,0,30,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x823f9c80
	if (cr0.eq) goto loc_823F9C80;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r11,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x823f9c80
	if (!cr0.eq) goto loc_823F9C80;
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823f9c80
	if (cr0.eq) goto loc_823F9C80;
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823f9c94
	if (!cr0.eq) goto loc_823F9C94;
loc_823F9C80:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r25,r25,-1
	r25.s64 = r25.s64 + -1;
	// cmplwi cr6,r26,2
	cr6.compare<uint32_t>(r26.u32, 2, xer);
	// blt cr6,0x823f9afc
	if (cr6.lt) goto loc_823F9AFC;
	// b 0x823f9898
	goto loc_823F9898;
loc_823F9C94:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x823f9cb4
	if (cr6.eq) goto loc_823F9CB4;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
loc_823F9CB4:
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r9,0(r22)
	PPC_STORE_U32(r22.u32 + 0, ctx.r9.u32);
	// b 0x823f989c
	goto loc_823F989C;
}

__attribute__((alias("__imp__sub_823F9CC0"))) PPC_WEAK_FUNC(sub_823F9CC0);
PPC_FUNC_IMPL(__imp__sub_823F9CC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r14,r4
	r14.u64 = ctx.r4.u64;
	// addi r11,r31,44
	r11.s64 = r31.s64 + 44;
	// li r17,0
	r17.s64 = 0;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r18,r8
	r18.u64 = ctx.r8.u64;
	// mr r23,r6
	r23.u64 = ctx.r6.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r21,r7
	r21.u64 = ctx.r7.u64;
	// mr r16,r17
	r16.u64 = r17.u64;
	// stw r17,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r17.u32);
	// stw r4,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, ctx.r4.u32);
	// mr r15,r17
	r15.u64 = r17.u64;
	// stw r17,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r17.u32);
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// stw r17,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r17.u32);
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r11.u32);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// stw r17,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r17.u32);
	// stw r17,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r17.u32);
	// stw r17,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r17.u32);
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r11.u32);
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// stw r11,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, r11.u32);
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// stw r11,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r11.u32);
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// stw r11,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r11.u32);
	// bne cr6,0x823f9d44
	if (!cr6.eq) goto loc_823F9D44;
	// lwz r18,24(r31)
	r18.u64 = PPC_LOAD_U32(r31.u32 + 24);
loc_823F9D44:
	// addi r5,r1,208
	ctx.r5.s64 = ctx.r1.s64 + 208;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823f9db4
	if (cr0.lt) goto loc_823F9DB4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f12,208(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// lfd f0,-31368(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// bgt cr6,0x823f9dac
	if (cr6.gt) goto loc_823F9DAC;
	// lfd f13,216(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 216);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x823f9dac
	if (cr6.lt) goto loc_823F9DAC;
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// bne cr6,0x823f9db4
	if (!cr6.eq) goto loc_823F9DB4;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x823f9db4
	if (!cr6.eq) goto loc_823F9DB4;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
loc_823F9D8C:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r29,24(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r18,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r18.u32);
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r29,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r29.u32);
	// b 0x823facd0
	goto loc_823FACD0;
loc_823F9DAC:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// b 0x823f9d8c
	goto loc_823F9D8C;
loc_823F9DB4:
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,420
	ctx.r5.s64 = ctx.r1.s64 + 420;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// li r19,-1
	r19.s64 = -1;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r6,420(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// stw r17,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r17.u32);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r19,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r19.u32);
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r29,r11,r10
	r29.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823f9fc4
	if (cr6.eq) goto loc_823F9FC4;
	// lwz r8,24(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,8240
	ctx.r10.s64 = 540016640;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,0,0,11
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// bne cr6,0x823f9fc4
	if (!cr6.eq) goto loc_823F9FC4;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x823f9e4c
	if (cr0.eq) goto loc_823F9E4C;
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_823F9E30:
	// lwz r5,0(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// beq cr6,0x823f9e4c
	if (cr6.eq) goto loc_823F9E4C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x823f9e30
	if (cr6.lt) goto loc_823F9E30;
loc_823F9E4C:
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r7,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r6,r10,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r6,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r6.u32);
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823f9fc4
	if (cr6.eq) goto loc_823F9FC4;
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823f9fc4
	if (cr0.eq) goto loc_823F9FC4;
	// lwz r11,24(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,4112
	ctx.r7.s64 = 269484032;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// bne cr6,0x823f9fc4
	if (!cr6.eq) goto loc_823F9FC4;
	// lwz r7,12(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mr r11,r17
	r11.u64 = r17.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x823f9ee4
	if (cr0.eq) goto loc_823F9EE4;
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_823F9EC8:
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r5,r8
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r8.u32, xer);
	// beq cr6,0x823f9ee4
	if (cr6.eq) goto loc_823F9EE4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x823f9ec8
	if (cr6.lt) goto loc_823F9EC8;
loc_823F9EE4:
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bne cr6,0x823f9fc4
	if (!cr6.eq) goto loc_823F9FC4;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,172
	ctx.r5.s64 = ctx.r1.s64 + 172;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// stw r19,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r19.u32);
	// li r9,23
	ctx.r9.s64 = 23;
	// stw r19,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r19.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,172
	ctx.r7.s64 = ctx.r1.s64 + 172;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// li r9,23
	ctx.r9.s64 = 23;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,420
	ctx.r7.s64 = ctx.r1.s64 + 420;
	// addi r6,r1,132
	ctx.r6.s64 = ctx.r1.s64 + 132;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r20,r17
	r20.u64 = r17.u64;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r9,r11,0,27,27
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x823fa108
	if (cr0.eq) goto loc_823FA108;
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fa108
	if (cr0.eq) goto loc_823FA108;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_823F9FB4:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x823fa108
	if (!cr6.eq) goto loc_823FA108;
	// li r28,1
	r28.s64 = 1;
	// b 0x823fa10c
	goto loc_823FA10C;
loc_823F9FC4:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addi r7,r1,420
	ctx.r7.s64 = ctx.r1.s64 + 420;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// stw r19,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r19.u32);
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// stw r19,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r19.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r19,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r19.u32);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fa094
	if (cr0.eq) goto loc_823FA094;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,16
	ctx.r9.s64 = 16;
	// li r8,0
	ctx.r8.s64 = 0;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// li r9,23
	ctx.r9.s64 = 23;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,420
	ctx.r7.s64 = ctx.r1.s64 + 420;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lis r5,8240
	ctx.r5.s64 = 540016640;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r8,r1,420
	ctx.r8.s64 = ctx.r1.s64 + 420;
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// addi r6,r1,132
	ctx.r6.s64 = ctx.r1.s64 + 132;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r20,1
	r20.s64 = 1;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823fa108
	if (cr0.eq) goto loc_823FA108;
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fa108
	if (cr0.eq) goto loc_823FA108;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// b 0x823f9fb4
	goto loc_823F9FB4;
loc_823FA094:
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r19,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r19.u32);
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lis r5,8224
	ctx.r5.s64 = 538968064;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lis r5,8240
	ctx.r5.s64 = 540016640;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// addi r6,r1,132
	ctx.r6.s64 = ctx.r1.s64 + 132;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// li r20,1
	r20.s64 = 1;
loc_823FA108:
	// mr r28,r17
	r28.u64 = r17.u64;
loc_823FA10C:
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r22,1
	r22.s64 = 1;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r29,r17
	r29.u64 = r17.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fa1a8
	if (cr0.eq) goto loc_823FA1A8;
	// li r4,98
	ctx.r4.s64 = 98;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x8239d9f0
	sub_8239D9F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x823fa188
	if (!cr0.eq) goto loc_823FA188;
	// li r4,66
	ctx.r4.s64 = 66;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x8239d9f0
	sub_8239D9F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823fa1a8
	if (cr0.eq) goto loc_823FA1A8;
loc_823FA188:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,84(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x823fa258
	if (cr6.eq) goto loc_823FA258;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x823fa258
	if (cr6.eq) goto loc_823FA258;
	// mr r22,r17
	r22.u64 = r17.u64;
	// b 0x823fa254
	goto loc_823FA254;
loc_823FA1A8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fa214
	if (cr0.eq) goto loc_823FA214;
	// li r4,99
	ctx.r4.s64 = 99;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x8239d9f0
	sub_8239D9F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x823fa1dc
	if (!cr0.eq) goto loc_823FA1DC;
	// li r4,67
	ctx.r4.s64 = 67;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x8239d9f0
	sub_8239D9F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823fa214
	if (cr0.eq) goto loc_823FA214;
loc_823FA1DC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x823fa204
	if (!cr6.eq) goto loc_823FA204;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x823fa20c
	if (cr6.eq) goto loc_823FA20C;
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x823fa20c
	if (!cr6.eq) goto loc_823FA20C;
loc_823FA204:
	// li r22,1
	r22.s64 = 1;
	// li r29,1
	r29.s64 = 1;
loc_823FA20C:
	// mr r28,r17
	r28.u64 = r17.u64;
	// b 0x823fa258
	goto loc_823FA258;
loc_823FA214:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x823fa250
	if (!cr6.eq) goto loc_823FA250;
	// lwz r10,84(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x823fa238
	if (cr6.eq) goto loc_823FA238;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x823fa250
	if (!cr6.eq) goto loc_823FA250;
loc_823FA238:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x823fa258
	if (cr6.eq) goto loc_823FA258;
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x823fa258
	if (!cr6.eq) goto loc_823FA258;
loc_823FA250:
	// li r22,1
	r22.s64 = 1;
loc_823FA254:
	// li r29,1
	r29.s64 = 1;
loc_823FA258:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x823fa290
	if (!cr6.eq) goto loc_823FA290;
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x823fa2a8
	if (cr6.eq) goto loc_823FA2A8;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x823fa290
	if (cr6.eq) goto loc_823FA290;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x823fa354
	if (cr6.eq) goto loc_823FA354;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
loc_823FA284:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x823fa290
	if (cr6.lt) goto loc_823FA290;
	// mr r29,r17
	r29.u64 = r17.u64;
loc_823FA290:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x823fa2a8
	if (cr6.eq) goto loc_823FA2A8;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fa2a8
	if (cr0.eq) goto loc_823FA2A8;
	// mr r29,r17
	r29.u64 = r17.u64;
loc_823FA2A8:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x823fa2c0
	if (cr6.eq) goto loc_823FA2C0;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fa2c0
	if (cr0.eq) goto loc_823FA2C0;
	// mr r22,r17
	r22.u64 = r17.u64;
loc_823FA2C0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r25,r17
	r25.u64 = r17.u64;
	// lwz r24,28(r11)
	r24.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// rlwinm r27,r24,2,0,29
	r27.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r16,r3
	r16.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r16.s32, 0, xer);
	// beq 0x823facc8
	if (cr0.eq) goto loc_823FACC8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r15,r3
	r15.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r15.s32, 0, xer);
	// beq 0x823facc8
	if (cr0.eq) goto loc_823FACC8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// stw r26,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r26.u32);
	// beq 0x823facc8
	if (cr0.eq) goto loc_823FACC8;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x823fa6bc
	if (cr6.eq) goto loc_823FA6BC;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// lwz r26,12(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x823fa36c
	if (!cr6.eq) goto loc_823FA36C;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x823fa360
	if (cr6.eq) goto loc_823FA360;
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
	// b 0x823fa36c
	goto loc_823FA36C;
loc_823FA354:
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// b 0x823fa284
	goto loc_823FA284;
loc_823FA360:
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
loc_823FA36C:
	// lis r5,4336
	ctx.r5.s64 = 284164096;
	// stw r19,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r19.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// addi r6,r1,136
	ctx.r6.s64 = ctx.r1.s64 + 136;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x823fa3b4
	if (cr6.eq) goto loc_823FA3B4;
	// lwz r10,144(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 144);
	// b 0x823fa3b8
	goto loc_823FA3B8;
loc_823FA3B4:
	// lwz r10,160(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 160);
loc_823FA3B8:
	// lwz r9,136(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// beq cr6,0x823fa444
	if (cr6.eq) goto loc_823FA444;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// stw r20,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r20.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,168(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// stw r17,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r17.u32);
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// stw r17,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r17.u32);
	// stw r11,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r11.u32);
	// b 0x823fa454
	goto loc_823FA454;
loc_823FA444:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_823FA454:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x823fa4d8
	if (cr6.eq) goto loc_823FA4D8;
	// cntlzw r11,r20
	r11.u64 = r20.u32 == 0 ? 32 : __builtin_clz(r20.u32);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r10.u32);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// lwz r30,140(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,168(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// stw r17,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r17.u32);
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r11.u32);
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// stw r17,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r17.u32);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
	// b 0x823fa4ec
	goto loc_823FA4EC;
loc_823FA4D8:
	// lwz r30,140(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_823FA4EC:
	// mr r25,r17
	r25.u64 = r17.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fa534
	if (cr6.eq) goto loc_823FA534;
	// mr r11,r30
	r11.u64 = r30.u64;
	// subf r9,r30,r18
	ctx.r9.s64 = r18.s64 - r30.s64;
	// subf r8,r30,r15
	ctx.r8.s64 = r15.s64 - r30.s64;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_823FA508:
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// beq cr6,0x823fa528
	if (cr6.eq) goto loc_823FA528;
	// lwzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fa528
	if (cr6.eq) goto loc_823FA528;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
loc_823FA528:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823fa508
	if (!cr0.eq) goto loc_823FA508;
loc_823FA534:
	// lwz r11,188(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
	// lwz r11,192(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
	// beq cr6,0x823fa5d4
	if (cr6.eq) goto loc_823FA5D4;
	// cmplwi cr6,r25,16
	cr6.compare<uint32_t>(r25.u32, 16, xer);
	// bgt cr6,0x823fa568
	if (cr6.gt) goto loc_823FA568;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// subf r11,r26,r11
	r11.s64 = r11.s64 - r26.s64;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// ble cr6,0x823fa56c
	if (!cr6.gt) goto loc_823FA56C;
loc_823FA568:
	// mr r22,r17
	r22.u64 = r17.u64;
loc_823FA56C:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x823fa5d4
	if (cr6.eq) goto loc_823FA5D4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r26,r10
	cr6.compare<uint32_t>(r26.u32, ctx.r10.u32, xer);
	// bge cr6,0x823fa5cc
	if (!cr6.lt) goto loc_823FA5CC;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
loc_823FA594:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lis r8,24576
	ctx.r8.s64 = 1610612736;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// beq cr6,0x823fa5c8
	if (cr6.eq) goto loc_823FA5C8;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x823fa594
	if (cr6.lt) goto loc_823FA594;
	// b 0x823fa5cc
	goto loc_823FA5CC;
loc_823FA5C8:
	// mr r22,r17
	r22.u64 = r17.u64;
loc_823FA5CC:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// bne cr6,0x823fa640
	if (!cr6.eq) goto loc_823FA640;
loc_823FA5D4:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x823fa638
	if (!cr6.eq) goto loc_823FA638;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fa638
	if (cr0.eq) goto loc_823FA638;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r29,r26
	r29.u64 = r26.u64;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// bge cr6,0x823fa638
	if (!cr6.lt) goto loc_823FA638;
	// rlwinm r30,r26,2,0,29
	r30.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
loc_823FA600:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// bl 0x8243d5d8
	sub_8243D5D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x823fa634
	if (!cr0.eq) goto loc_823FA634;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x823fa600
	if (cr6.lt) goto loc_823FA600;
	// b 0x823fa638
	goto loc_823FA638;
loc_823FA634:
	// li r22,1
	r22.s64 = 1;
loc_823FA638:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x823fa8e0
	if (cr6.eq) goto loc_823FA8E0;
loc_823FA640:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r29,r26
	r29.u64 = r26.u64;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// bge cr6,0x823fa6a0
	if (!cr6.lt) goto loc_823FA6A0;
	// rlwinm r30,r26,2,0,29
	r30.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
loc_823FA658:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r28,r11,r30
	r28.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x823fa67c
	if (cr0.eq) goto loc_823FA67C;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
loc_823FA67C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stwx r17,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, r17.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x823fa658
	if (cr6.lt) goto loc_823FA658;
loc_823FA6A0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// stw r26,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r26.u32);
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r26,140(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
loc_823FA6BC:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x823fa8e0
	if (cr6.eq) goto loc_823FA8E0;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x823fa768
	if (cr6.eq) goto loc_823FA768;
	// addi r29,r31,44
	r29.s64 = r31.s64 + 44;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// stw r19,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r19.u32);
	// bne cr6,0x823fa6e4
	if (!cr6.eq) goto loc_823FA6E4;
	// addi r8,r1,132
	ctx.r8.s64 = ctx.r1.s64 + 132;
loc_823FA6E4:
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r7,r1,156
	ctx.r7.s64 = ctx.r1.s64 + 156;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,156(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// stw r17,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r17.u32);
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// stw r17,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r17.u32);
	// stw r11,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r11.u32);
	// b 0x823fa778
	goto loc_823FA778;
loc_823FA768:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_823FA778:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x823fa81c
	if (cr6.eq) goto loc_823FA81C;
	// addi r29,r31,44
	r29.s64 = r31.s64 + 44;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// addi r8,r1,132
	ctx.r8.s64 = ctx.r1.s64 + 132;
	// stw r19,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r19.u32);
	// bne cr6,0x823fa798
	if (!cr6.eq) goto loc_823FA798;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
loc_823FA798:
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r7,r1,156
	ctx.r7.s64 = ctx.r1.s64 + 156;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,156(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// stw r17,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r17.u32);
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r11.u32);
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// stw r17,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r17.u32);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
	// b 0x823fa82c
	goto loc_823FA82C;
loc_823FA81C:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_823FA82C:
	// mr r25,r17
	r25.u64 = r17.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fac00
	if (cr6.eq) goto loc_823FAC00;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// mr r11,r15
	r11.u64 = r15.u64;
	// subf r4,r15,r26
	ctx.r4.s64 = r26.s64 - r15.s64;
	// subf r5,r15,r18
	ctx.r5.s64 = r18.s64 - r15.s64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
loc_823FA84C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwzx r8,r4,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + r11.u32);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// beq cr6,0x823fa8d0
	if (cr6.eq) goto loc_823FA8D0;
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x823fa8b8
	if (cr6.eq) goto loc_823FA8B8;
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r30,r9,2,0,29
	r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,20(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// lwz r7,116(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 116);
	// lwzx r30,r30,r6
	r30.u64 = PPC_LOAD_U32(r30.u32 + ctx.r6.u32);
	// lwz r30,4(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplw cr6,r7,r30
	cr6.compare<uint32_t>(ctx.r7.u32, r30.u32, xer);
	// beq cr6,0x823fa8b8
	if (cr6.eq) goto loc_823FA8B8;
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x823fa8a8
	if (cr6.eq) goto loc_823FA8A8;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r6
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r6.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// beq cr6,0x823fa8a8
	if (cr6.eq) goto loc_823FA8A8;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// b 0x823fa8d0
	goto loc_823FA8D0;
loc_823FA8A8:
	// stwx r9,r4,r11
	PPC_STORE_U32(ctx.r4.u32 + r11.u32, ctx.r9.u32);
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stwx r9,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r9.u32);
	// b 0x823fa8c4
	goto loc_823FA8C4;
loc_823FA8B8:
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stwx r8,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r8.u32);
loc_823FA8C4:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// stwx r9,r5,r11
	PPC_STORE_U32(ctx.r5.u32 + r11.u32, ctx.r9.u32);
loc_823FA8D0:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823fa84c
	if (!cr0.eq) goto loc_823FA84C;
loc_823FA8E0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x823fac00
	if (cr6.eq) goto loc_823FAC00;
	// li r11,1
	r11.s64 = 1;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mulli r3,r25,24
	ctx.r3.s64 = r25.s64 * 24;
	// stw r11,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r10,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r10.u32);
	// beq 0x823facc8
	if (cr0.eq) goto loc_823FACC8;
	// addi r9,r1,208
	ctx.r9.s64 = ctx.r1.s64 + 208;
	// rlwinm r8,r25,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,6
	r11.s64 = 6;
loc_823FA914:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fa914
	if (!cr0.eq) goto loc_823FA914;
	// lwz r25,216(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// mr r26,r17
	r26.u64 = r17.u64;
	// lwz r28,212(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// lwz r8,208(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	// beq cr6,0x823faa10
	if (cr6.eq) goto loc_823FAA10;
	// lwz r10,140(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r9,r15
	ctx.r9.u64 = r15.u64;
	// subf r30,r15,r18
	r30.s64 = r18.s64 - r15.s64;
	// subf r5,r28,r8
	ctx.r5.s64 = ctx.r8.s64 - r28.s64;
	// subf r4,r15,r10
	ctx.r4.s64 = ctx.r10.s64 - r15.s64;
	// subf r6,r28,r25
	ctx.r6.s64 = r25.s64 - r28.s64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
loc_823FA964:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwzx r7,r9,r4
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// beq cr6,0x823faa04
	if (cr6.eq) goto loc_823FAA04;
	// lwzx r10,r9,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823faa04
	if (cr6.eq) goto loc_823FAA04;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// bne cr6,0x823fa990
	if (!cr6.eq) goto loc_823FA990;
	// lwz r10,132(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
loc_823FA990:
	// stwx r10,r5,r11
	PPC_STORE_U32(ctx.r5.u32 + r11.u32, ctx.r10.u32);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823fa9c0
	if (cr6.eq) goto loc_823FA9C0;
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r29,r10,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r27,20(r7)
	r27.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// lwz r7,116(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 116);
	// lwzx r29,r29,r27
	r29.u64 = PPC_LOAD_U32(r29.u32 + r27.u32);
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmplw cr6,r7,r29
	cr6.compare<uint32_t>(ctx.r7.u32, r29.u32, xer);
	// bne cr6,0x823fa9c4
	if (!cr6.eq) goto loc_823FA9C4;
loc_823FA9C0:
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
loc_823FA9C4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwzx r10,r9,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823fa9f4
	if (cr6.eq) goto loc_823FA9F4;
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r29,r10,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r27,20(r7)
	r27.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// lwz r7,116(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 116);
	// lwzx r29,r29,r27
	r29.u64 = PPC_LOAD_U32(r29.u32 + r27.u32);
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmplw cr6,r7,r29
	cr6.compare<uint32_t>(ctx.r7.u32, r29.u32, xer);
	// bne cr6,0x823fa9f8
	if (!cr6.eq) goto loc_823FA9F8;
loc_823FA9F4:
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
loc_823FA9F8:
	// stwx r10,r6,r11
	PPC_STORE_U32(ctx.r6.u32 + r11.u32, ctx.r10.u32);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
loc_823FAA04:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fa964
	if (!cr0.eq) goto loc_823FA964;
loc_823FAA10:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x823faa3c
	if (cr6.eq) goto loc_823FAA3C;
	// lwz r29,220(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f8108
	sub_823F8108(ctx, base);
	// b 0x823fab74
	goto loc_823FAB74;
loc_823FAA3C:
	// clrlwi r27,r26,12
	r27.u64 = r26.u32 & 0xFFFFF;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r20,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r20.u32);
	// oris r29,r27,4096
	r29.u64 = r27.u64 | 268435456;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x823faaa4
	if (cr6.eq) goto loc_823FAAA4;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_823FAA7C:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r9,152(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// stw r9,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r9.u32);
	// bne 0x823faa7c
	if (!cr0.eq) goto loc_823FAA7C;
loc_823FAAA4:
	// cntlzw r11,r20
	r11.u64 = r20.u32 == 0 ? 32 : __builtin_clz(r20.u32);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// stw r10,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r10.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x823fab18
	if (cr6.eq) goto loc_823FAB18;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// mr r11,r26
	r11.u64 = r26.u64;
loc_823FAAF0:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r9,152(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r9,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r9.u32);
	// bne 0x823faaf0
	if (!cr0.eq) goto loc_823FAAF0;
loc_823FAB18:
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// lwz r29,220(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,168(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// beq cr6,0x823fab54
	if (cr6.eq) goto loc_823FAB54;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r19
	ctx.r10.u64 = r19.u64;
	// cmplwi r26,0
	cr0.compare<uint32_t>(r26.u32, 0, xer);
	// beq 0x823fab54
	if (cr0.eq) goto loc_823FAB54;
	// mtctr r26
	ctr.u64 = r26.u64;
loc_823FAB48:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fab48
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FAB48;
loc_823FAB54:
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r27,8304
	ctx.r5.u64 = r27.u64 | 544210944;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
loc_823FAB74:
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823facd0
	if (cr0.lt) goto loc_823FACD0;
	// mr r27,r17
	r27.u64 = r17.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fabfc
	if (cr6.eq) goto loc_823FABFC;
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// mr r30,r18
	r30.u64 = r18.u64;
	// subf r25,r18,r15
	r25.s64 = r15.s64 - r18.s64;
	// subf r26,r15,r11
	r26.s64 = r11.s64 - r15.s64;
loc_823FAB98:
	// add r11,r25,r30
	r11.u64 = r25.u64 + r30.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwzx r11,r26,r11
	r11.u64 = PPC_LOAD_U32(r26.u32 + r11.u32);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x823fabec
	if (cr6.eq) goto loc_823FABEC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823fabec
	if (cr6.eq) goto loc_823FABEC;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwzx r28,r9,r11
	r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r4,r8,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8243de18
	sub_8243DE18(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// stw r27,48(r28)
	PPC_STORE_U32(r28.u32 + 48, r27.u32);
loc_823FABEC:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r27,r24
	cr6.compare<uint32_t>(r27.u32, r24.u32, xer);
	// blt cr6,0x823fab98
	if (cr6.lt) goto loc_823FAB98;
loc_823FABFC:
	// stw r17,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r17.u32);
loc_823FAC00:
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r9,152(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// lwz r8,160(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// beq cr6,0x823fac24
	if (cr6.eq) goto loc_823FAC24;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x823fac28
	if (!cr6.eq) goto loc_823FAC28;
loc_823FAC24:
	// mr r11,r17
	r11.u64 = r17.u64;
loc_823FAC28:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r11.u32);
	// beq cr6,0x823fac44
	if (cr6.eq) goto loc_823FAC44;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x823fac5c
	if (!cr6.eq) goto loc_823FAC5C;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x823fac5c
	if (!cr6.eq) goto loc_823FAC5C;
loc_823FAC44:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x823fac64
	if (cr6.eq) goto loc_823FAC64;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x823fac5c
	if (!cr6.eq) goto loc_823FAC5C;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x823fac64
	if (cr6.eq) goto loc_823FAC64;
loc_823FAC5C:
	// li r11,1
	r11.s64 = 1;
	// b 0x823fac68
	goto loc_823FAC68;
loc_823FAC64:
	// mr r11,r17
	r11.u64 = r17.u64;
loc_823FAC68:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// beq cr6,0x823fac84
	if (cr6.eq) goto loc_823FAC84;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x823fac8c
	if (!cr6.eq) goto loc_823FAC8C;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x823fac9c
	if (cr6.eq) goto loc_823FAC9C;
loc_823FAC84:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x823facc0
	if (cr6.eq) goto loc_823FACC0;
loc_823FAC8C:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x823facc0
	if (!cr6.eq) goto loc_823FACC0;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne cr6,0x823facc0
	if (!cr6.eq) goto loc_823FACC0;
loc_823FAC9C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3042
	ctx.r5.s64 = 3042;
	// addi r6,r11,31832
	ctx.r6.s64 = r11.s64 + 31832;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// lis r30,-32768
	r30.s64 = -2147483648;
	// ori r30,r30,16385
	r30.u64 = r30.u64 | 16385;
	// b 0x823facd0
	goto loc_823FACD0;
loc_823FACC0:
	// mr r30,r17
	r30.u64 = r17.u64;
	// b 0x823facd0
	goto loc_823FACD0;
loc_823FACC8:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
loc_823FACD0:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,140(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,184(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r11,r31,44
	r11.s64 = r31.s64 + 44;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,168(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// lwz r11,188(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
	// lwz r11,192(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_823FAD38"))) PPC_WEAK_FUNC(sub_823FAD38);
PPC_FUNC_IMPL(__imp__sub_823FAD38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-448(r1)
	ea = -448 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r6,492(r1)
	PPC_STORE_U32(ctx.r1.u32 + 492, ctx.r6.u32);
	// li r26,0
	r26.s64 = 0;
	// stw r4,476(r1)
	PPC_STORE_U32(ctx.r1.u32 + 476, ctx.r4.u32);
	// mr r15,r7
	r15.u64 = ctx.r7.u64;
	// subf r11,r26,r5
	r11.s64 = ctx.r5.s64 - r26.s64;
	// mr r20,r8
	r20.u64 = ctx.r8.u64;
	// lwz r9,48(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stw r26,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r26.u32);
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r26.u32);
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// stw r26,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r26.u32);
	// stw r9,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r9.u32);
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// stw r26,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r26.u32);
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r26.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r9,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r9.u32);
	// lwz r9,108(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r9,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r9.u32);
	// lwz r9,112(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// stw r9,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r9.u32);
	// lwz r9,92(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x823fadcc
	if (cr6.lt) goto loc_823FADCC;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x823fbf00
	goto loc_823FBF00;
loc_823FADCC:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// stw r10,68(r31)
	PPC_STORE_U32(r31.u32 + 68, ctx.r10.u32);
	// lwz r22,28(r9)
	r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	// lwz r17,8(r11)
	r17.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r24,r22,2,0,29
	r24.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r18,12(r11)
	r18.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// stw r3,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823fbe80
	if (cr0.eq) goto loc_823FBE80;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r23,r3
	r23.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r23.s32, 0, xer);
	// stw r23,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r23.u32);
	// beq 0x823fbe80
	if (cr0.eq) goto loc_823FBE80;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// stw r21,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r21.u32);
	// beq 0x823fbe80
	if (cr0.eq) goto loc_823FBE80;
	// rlwinm r27,r22,4,0,27
	r27.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 4) & 0xFFFFFFF0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r25,r3
	r25.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// stw r25,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r25.u32);
	// beq 0x823fbe80
	if (cr0.eq) goto loc_823FBE80;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r19,r3
	r19.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r19.s32, 0, xer);
	// stw r19,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r19.u32);
	// beq 0x823fbe80
	if (cr0.eq) goto loc_823FBE80;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x823faf00
	if (cr6.eq) goto loc_823FAF00;
	// mr r30,r26
	r30.u64 = r26.u64;
	// mr r29,r25
	r29.u64 = r25.u64;
	// mr r28,r22
	r28.u64 = r22.u64;
loc_823FAE78:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r4,r30,r11
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x823fae9c
	if (cr6.eq) goto loc_823FAE9C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x823faeac
	if (!cr0.lt) goto loc_823FAEAC;
loc_823FAE9C:
	// lfd f0,168(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// stfd f0,0(r29)
	PPC_STORE_U64(r29.u32 + 0, f0.u64);
	// lfd f0,176(r31)
	f0.u64 = PPC_LOAD_U64(r31.u32 + 176);
	// stfd f0,8(r29)
	PPC_STORE_U64(r29.u32 + 8, f0.u64);
loc_823FAEAC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r30,r11
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823faee8
	if (cr6.eq) goto loc_823FAEE8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r8,116(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// lwzx r11,r9,r10
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// beq cr6,0x823faee8
	if (cr6.eq) goto loc_823FAEE8;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// b 0x823faeec
	goto loc_823FAEEC;
loc_823FAEE8:
	// li r11,31
	r11.s64 = 31;
loc_823FAEEC:
	// stwx r11,r30,r23
	PPC_STORE_U32(r30.u32 + r23.u32, r11.u32);
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r29,r29,16
	r29.s64 = r29.s64 + 16;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x823fae78
	if (!cr0.eq) goto loc_823FAE78;
loc_823FAF00:
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r19,-1
	r19.s64 = -1;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r14,1
	r14.s64 = 1;
	// mr r23,r14
	r23.u64 = r14.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r19,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r19.u32);
	// stw r19,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r19.u32);
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r14.u32);
	// lfd f30,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// lwz r11,104(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 104);
	// stfd f30,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, f30.u64);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// mr r16,r11
	r16.u64 = r11.u64;
	// bne 0x823faf64
	if (!cr0.eq) goto loc_823FAF64;
	// li r16,255
	r16.s64 = 255;
loc_823FAF64:
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// beq cr6,0x823fbe6c
	if (cr6.eq) goto loc_823FBE6C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// b 0x823faf84
	goto loc_823FAF84;
loc_823FAF80:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_823FAF84:
	// addi r25,r10,1
	r25.s64 = ctx.r10.s64 + 1;
	// lwz r29,492(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// stw r10,108(r31)
	PPC_STORE_U32(r31.u32 + 108, ctx.r10.u32);
	// stw r25,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r25.u32);
	// beq cr6,0x823fafe4
	if (cr6.eq) goto loc_823FAFE4;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823fafe4
	if (cr6.eq) goto loc_823FAFE4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fb410
	if (!cr6.eq) goto loc_823FB410;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe6c
	if (!cr6.eq) goto loc_823FBE6C;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe6c
	if (!cr6.eq) goto loc_823FBE6C;
loc_823FAFE4:
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// stw r19,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r19.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x823fb070
	if (cr6.eq) goto loc_823FB070;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r19,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r19.u32);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fb410
	if (!cr6.eq) goto loc_823FB410;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe6c
	if (!cr6.eq) goto loc_823FBE6C;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe6c
	if (!cr6.eq) goto loc_823FBE6C;
loc_823FB070:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5390
	sub_823F5390(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823fb11c
	if (cr0.lt) goto loc_823FB11C;
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x823fb11c
	if (cr6.eq) goto loc_823FB11C;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x823fb224
	if (cr6.eq) goto loc_823FB224;
	// lwz r29,100(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r30,0
	r30.s64 = 0;
	// subf r26,r21,r20
	r26.s64 = r20.s64 - r21.s64;
	// mr r27,r22
	r27.u64 = r22.u64;
loc_823FB0AC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r28,r30,r21
	r28.u64 = r30.u64 + r21.u64;
	// lwzx r4,r30,r11
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwzx r11,r26,r28
	r11.u64 = PPC_LOAD_U32(r26.u32 + r28.u32);
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// beq cr6,0x823fb108
	if (cr6.eq) goto loc_823FB108;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x823fb0e8
	if (!cr0.lt) goto loc_823FB0E8;
	// lfd f0,168(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// stfd f0,0(r29)
	PPC_STORE_U64(r29.u32 + 0, f0.u64);
	// lfd f0,176(r31)
	f0.u64 = PPC_LOAD_U64(r31.u32 + 176);
	// stfd f0,8(r29)
	PPC_STORE_U64(r29.u32 + 8, f0.u64);
loc_823FB0E8:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_823FB108:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r29,r29,16
	r29.s64 = r29.s64 + 16;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x823fb0ac
	if (!cr0.eq) goto loc_823FB0AC;
	// b 0x823fb224
	goto loc_823FB224;
loc_823FB11C:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x823fb224
	if (cr6.eq) goto loc_823FB224;
	// lwz r29,100(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r30,0
	r30.s64 = 0;
	// subf r26,r21,r20
	r26.s64 = r20.s64 - r21.s64;
	// mr r27,r22
	r27.u64 = r22.u64;
loc_823FB134:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r28,r30,r21
	r28.u64 = r30.u64 + r21.u64;
	// lwzx r4,r30,r11
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwzx r11,r28,r26
	r11.u64 = PPC_LOAD_U32(r28.u32 + r26.u32);
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// beq cr6,0x823fb214
	if (cr6.eq) goto loc_823FB214;
	// lfd f0,0(r29)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r29.u32 + 0);
	// lfd f13,176(r31)
	ctx.f13.u64 = PPC_LOAD_U64(r31.u32 + 176);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x823fb16c
	if (cr6.gt) goto loc_823FB16C;
	// lfd f0,168(r31)
	f0.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// lfd f13,8(r29)
	ctx.f13.u64 = PPC_LOAD_U64(r29.u32 + 8);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x823fb1b8
	if (!cr6.lt) goto loc_823FB1B8;
loc_823FB16C:
	// addi r5,r1,240
	ctx.r5.s64 = ctx.r1.s64 + 240;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823fb1a8
	if (cr0.lt) goto loc_823FB1A8;
	// lfd f13,0(r29)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r29.u32 + 0);
	// lfd f0,240(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 240);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x823fb194
	if (!cr6.gt) goto loc_823FB194;
	// stfd f0,0(r29)
	PPC_STORE_U64(r29.u32 + 0, f0.u64);
loc_823FB194:
	// lfd f13,8(r29)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r29.u32 + 8);
	// lfd f0,248(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 248);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x823fb1b8
	if (!cr6.lt) goto loc_823FB1B8;
	// b 0x823fb1b4
	goto loc_823FB1B4;
loc_823FB1A8:
	// lfd f0,168(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// stfd f0,0(r29)
	PPC_STORE_U64(r29.u32 + 0, f0.u64);
	// lfd f0,176(r31)
	f0.u64 = PPC_LOAD_U64(r31.u32 + 176);
loc_823FB1B4:
	// stfd f0,8(r29)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r29.u32 + 8, f0.u64);
loc_823FB1B8:
	// lfd f0,0(r29)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r29.u32 + 0);
	// lfd f13,8(r29)
	ctx.f13.u64 = PPC_LOAD_U64(r29.u32 + 8);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x823fb1ec
	if (cr6.eq) goto loc_823FB1EC;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,25,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_823FB1EC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_823FB214:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r29,r29,16
	r29.s64 = r29.s64 + 16;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x823fb134
	if (!cr0.eq) goto loc_823FB134;
loc_823FB224:
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x823fb2a0
	if (cr6.eq) goto loc_823FB2A0;
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823fb270
	if (cr0.lt) goto loc_823FB270;
	// lfd f0,256(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 256);
	// lfd f13,264(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 264);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x823fb25c
	if (!cr6.eq) goto loc_823FB25C;
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x823fb410
	if (cr6.eq) goto loc_823FB410;
loc_823FB25C:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f31.f64);
	// bgt cr6,0x823fb270
	if (cr6.gt) goto loc_823FB270;
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// blt cr6,0x823fb270
	if (cr6.lt) goto loc_823FB270;
	// li r23,0
	r23.s64 = 0;
loc_823FB270:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stfd f30,32(r11)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + 32, f30.u64);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stfd f30,40(r11)
	PPC_STORE_U64(r11.u32 + 40, f30.u64);
loc_823FB2A0:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x823fb370
	if (cr6.eq) goto loc_823FB370;
	// lwz r29,120(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// mr r28,r22
	r28.u64 = r22.u64;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r30,108(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// subf r26,r29,r20
	r26.s64 = r20.s64 - r29.s64;
	// subf r27,r29,r11
	r27.s64 = r11.s64 - r29.s64;
loc_823FB2C0:
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwzx r11,r29,r26
	r11.u64 = PPC_LOAD_U32(r29.u32 + r26.u32);
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// beq cr6,0x823fb360
	if (cr6.eq) goto loc_823FB360;
	// lfd f0,0(r30)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// lfd f13,176(r31)
	ctx.f13.u64 = PPC_LOAD_U64(r31.u32 + 176);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x823fb2f0
	if (cr6.gt) goto loc_823FB2F0;
	// lfd f0,8(r30)
	f0.u64 = PPC_LOAD_U64(r30.u32 + 8);
	// lfd f13,168(r31)
	ctx.f13.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x823fb33c
	if (!cr6.lt) goto loc_823FB33C;
loc_823FB2F0:
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823fb32c
	if (cr0.lt) goto loc_823FB32C;
	// lfd f13,0(r30)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// lfd f0,176(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x823fb318
	if (!cr6.gt) goto loc_823FB318;
	// stfd f0,0(r30)
	PPC_STORE_U64(r30.u32 + 0, f0.u64);
loc_823FB318:
	// lfd f13,8(r30)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r30.u32 + 8);
	// lfd f0,184(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x823fb33c
	if (!cr6.lt) goto loc_823FB33C;
	// b 0x823fb338
	goto loc_823FB338;
loc_823FB32C:
	// lfd f0,168(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// stfd f0,0(r30)
	PPC_STORE_U64(r30.u32 + 0, f0.u64);
	// lfd f0,176(r31)
	f0.u64 = PPC_LOAD_U64(r31.u32 + 176);
loc_823FB338:
	// stfd f0,8(r30)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r30.u32 + 8, f0.u64);
loc_823FB33C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r29,r27
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r27.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// stwx r11,r29,r27
	PPC_STORE_U32(r29.u32 + r27.u32, r11.u32);
loc_823FB360:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r30,r30,16
	r30.s64 = r30.s64 + 16;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// bne 0x823fb2c0
	if (!cr0.eq) goto loc_823FB2C0;
loc_823FB370:
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823fb3b4
	if (cr6.eq) goto loc_823FB3B4;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x823fb3ac
	if (!cr6.eq) goto loc_823FB3AC;
	// addi r7,r1,148
	ctx.r7.s64 = ctx.r1.s64 + 148;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r6,r1,136
	ctx.r6.s64 = ctx.r1.s64 + 136;
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f97b0
	sub_823F97B0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x823fb3ac
	if (cr0.eq) goto loc_823FB3AC;
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r14.u32);
	// b 0x823fb3b4
	goto loc_823FB3B4;
loc_823FB3AC:
	// li r11,0
	r11.s64 = 0;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
loc_823FB3B4:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fb404
	if (cr6.eq) goto loc_823FB404;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fb404
	if (!cr6.eq) goto loc_823FB404;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fb410
	if (!cr6.eq) goto loc_823FB410;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe6c
	if (!cr6.eq) goto loc_823FBE6C;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe6c
	if (!cr6.eq) goto loc_823FBE6C;
loc_823FB404:
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// cmplw cr6,r25,r16
	cr6.compare<uint32_t>(r25.u32, r16.u32, xer);
	// blt cr6,0x823faf80
	if (cr6.lt) goto loc_823FAF80;
loc_823FB410:
	// lwz r28,84(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// ble cr6,0x823fbe6c
	if (!cr6.gt) goto loc_823FBE6C;
	// cmplw cr6,r28,r16
	cr6.compare<uint32_t>(r28.u32, r16.u32, xer);
	// bge cr6,0x823fb44c
	if (!cr6.lt) goto loc_823FB44C;
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe6c
	if (!cr6.eq) goto loc_823FBE6C;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823fbe6c
	if (!cr0.eq) goto loc_823FBE6C;
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fb44c
	if (!cr6.eq) goto loc_823FB44C;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
loc_823FB44C:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x823fb4b4
	if (!cr6.eq) goto loc_823FB4B4;
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fb4b4
	if (!cr6.eq) goto loc_823FB4B4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,112(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rlwinm. r10,r10,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823fbe6c
	if (cr0.eq) goto loc_823FBE6C;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r29,r18
	r29.u64 = r18.u64;
	// cmplw cr6,r18,r11
	cr6.compare<uint32_t>(r18.u32, r11.u32, xer);
	// bge cr6,0x823fb4b4
	if (!cr6.lt) goto loc_823FB4B4;
	// rlwinm r30,r18,2,0,29
	r30.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
loc_823FB484:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// bl 0x8243d5d8
	sub_8243D5D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x823fbe6c
	if (!cr0.eq) goto loc_823FBE6C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x823fb484
	if (cr6.lt) goto loc_823FB484;
loc_823FB4B4:
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823fb4d0
	if (cr6.eq) goto loc_823FB4D0;
	// mr r28,r16
	r28.u64 = r16.u64;
	// li r11,0
	r11.s64 = 0;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
loc_823FB4D0:
	// cmplw cr6,r28,r16
	cr6.compare<uint32_t>(r28.u32, r16.u32, xer);
	// bne cr6,0x823fb500
	if (!cr6.eq) goto loc_823FB500;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5390
	sub_823F5390(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823fb4fc
	if (cr0.lt) goto loc_823FB4FC;
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x823fbe6c
	if (!cr6.eq) goto loc_823FBE6C;
loc_823FB4FC:
	// cmplw cr6,r28,r16
	cr6.compare<uint32_t>(r28.u32, r16.u32, xer);
loc_823FB500:
	// bge cr6,0x823fb5f0
	if (!cr6.lt) goto loc_823FB5F0;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x823fb5f0
	if (cr6.eq) goto loc_823FB5F0;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823fb5f0
	if (!cr0.eq) goto loc_823FB5F0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r9,r18
	ctx.r9.u64 = r18.u64;
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r18,r7
	cr6.compare<uint32_t>(r18.u32, ctx.r7.u32, xer);
	// bge cr6,0x823fb5e8
	if (!cr6.lt) goto loc_823FB5E8;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// rlwinm r10,r18,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r8,8208
	ctx.r8.s64 = 537919488;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
loc_823FB53C:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bgt cr6,0x823fb594
	if (cr6.gt) goto loc_823FB594;
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,4096
	ctx.r6.s64 = 268435456;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,4112
	ctx.r6.s64 = 269484032;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,4128
	ctx.r6.s64 = 270532608;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,4160
	ctx.r6.s64 = 272629760;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,8192
	ctx.r6.s64 = 536870912;
	// b 0x823fb5c8
	goto loc_823FB5C8;
loc_823FB594:
	// lis r6,8224
	ctx.r6.s64 = 538968064;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,8240
	ctx.r6.s64 = 540016640;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,8256
	ctx.r6.s64 = 541065216;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,8272
	ctx.r6.s64 = 542113792;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x823fb5d0
	if (cr6.eq) goto loc_823FB5D0;
	// lis r6,12288
	ctx.r6.s64 = 805306368;
loc_823FB5C8:
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bne cr6,0x823fb5e8
	if (!cr6.eq) goto loc_823FB5E8;
loc_823FB5D0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x823fb53c
	if (cr6.lt) goto loc_823FB53C;
loc_823FB5E8:
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// beq cr6,0x823fbe6c
	if (cr6.eq) goto loc_823FBE6C;
loc_823FB5F0:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x823fb630
	if (cr6.eq) goto loc_823FB630;
	// li r11,0
	r11.s64 = 0;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
loc_823FB604:
	// lwzx r10,r11,r20
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823fb624
	if (cr6.eq) goto loc_823FB624;
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// beq cr6,0x823fb624
	if (cr6.eq) goto loc_823FB624;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_823FB624:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823fb604
	if (!cr0.eq) goto loc_823FB604;
loc_823FB630:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mulli r3,r30,36
	ctx.r3.s64 = r30.s64 * 36;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// stw r3,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823fbe80
	if (cr0.eq) goto loc_823FBE80;
	// mulli r10,r30,9
	ctx.r10.s64 = r30.s64 * 9;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x823fb674
	if (cr6.eq) goto loc_823FB674;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x823fb674
	if (cr0.eq) goto loc_823FB674;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_823FB668:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fb668
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FB668;
loc_823FB674:
	// addi r9,r1,192
	ctx.r9.s64 = ctx.r1.s64 + 192;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r11,9
	r11.s64 = 9;
loc_823FB684:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fb684
	if (!cr0.eq) goto loc_823FB684;
	// lwz r23,200(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	// li r24,0
	r24.s64 = 0;
	// lwz r29,196(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r21,192(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x823fb74c
	if (cr6.eq) goto loc_823FB74C;
	// li r11,0
	r11.s64 = 0;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// subf r7,r23,r21
	ctx.r7.s64 = r21.s64 - r23.s64;
	// subf r6,r29,r23
	ctx.r6.s64 = r23.s64 - r29.s64;
loc_823FB6C8:
	// lwzx r10,r11,r20
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823fb73c
	if (cr6.eq) goto loc_823FB73C;
	// lwz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r5,r5,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x823fb73c
	if (cr6.eq) goto loc_823FB73C;
	// add r10,r6,r9
	ctx.r10.u64 = ctx.r6.u64 + ctx.r9.u64;
	// stwx r8,r10,r7
	PPC_STORE_U32(ctx.r10.u32 + ctx.r7.u32, ctx.r8.u32);
	// lwzx r5,r11,r20
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// stw r5,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r5.u32);
	// lwzx r5,r11,r20
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// stw r5,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r5.u32);
	// lwzx r10,r11,r20
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823fb72c
	if (cr6.eq) goto loc_823FB72C;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r5,r11,r20
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,20(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r10,116(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 116);
	// lwzx r5,r4,r5
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x823fb734
	if (!cr6.eq) goto loc_823FB734;
loc_823FB72C:
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
loc_823FB734:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
loc_823FB73C:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r22
	cr6.compare<uint32_t>(ctx.r8.u32, r22.u32, xer);
	// blt cr6,0x823fb6c8
	if (cr6.lt) goto loc_823FB6C8;
loc_823FB74C:
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5458
	sub_823F5458(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// li r10,0
	ctx.r10.s64 = 0;
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f1,f0
	ctx.f1.f64 = double(f0.s64);
	// stw r10,108(r31)
	PPC_STORE_U32(r31.u32 + 108, ctx.r10.u32);
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lis r5,4368
	ctx.r5.s64 = 286261248;
	// stw r3,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r3.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r19,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r19.u32);
	// addi r7,r1,164
	ctx.r7.s64 = ctx.r1.s64 + 164;
	// addi r6,r1,116
	ctx.r6.s64 = ctx.r1.s64 + 116;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// clrlwi r25,r24,12
	r25.u64 = r24.u32 & 0xFFFFF;
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r30,20(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// lwz r11,164(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 164);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// oris r5,r25,4384
	ctx.r5.u64 = r25.u64 | 287309824;
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r14,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r14.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// lwz r22,224(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// oris r5,r25,4400
	ctx.r5.u64 = r25.u64 | 288358400;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fb924
	if (cr6.eq) goto loc_823FB924;
	// mr r11,r23
	r11.u64 = r23.u64;
	// subf r6,r23,r21
	ctx.r6.s64 = r21.s64 - r23.s64;
	// subf r5,r23,r22
	ctx.r5.s64 = r22.s64 - r23.s64;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
loc_823FB860:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r7,108(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwzx r9,r11,r6
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// rlwinm r9,r9,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// lfd f0,0(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// lfd f13,8(r9)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x823fb8c4
	if (cr6.gt) goto loc_823FB8C4;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stfd f0,32(r10)
	PPC_STORE_U64(ctx.r10.u32 + 32, f0.u64);
	// lfd f0,8(r9)
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// rlwimi r7,r14,8,23,24
	ctx.r7.u64 = (__builtin_rotateleft32(r14.u32, 8) & 0x180) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFE7F);
	// stfd f0,40(r10)
	PPC_STORE_U64(ctx.r10.u32 + 40, f0.u64);
	// stw r7,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r7.u32);
	// lfd f0,0(r9)
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// lfd f13,8(r9)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x823fb8c4
	if (!cr6.eq) goto loc_823FB8C4;
	// ori r9,r7,128
	ctx.r9.u64 = ctx.r7.u64 | 128;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
loc_823FB8C4:
	// lwzx r9,r11,r6
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwzx r9,r9,r4
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r10,152(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 152);
	// lwzx r9,r7,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// stw r10,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r9,r5,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r10,172(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 172);
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// stw r10,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r10.u32);
	// bne 0x823fb860
	if (!cr0.eq) goto loc_823FB860;
loc_823FB924:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fb950
	if (cr6.eq) goto loc_823FB950;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823fb950
	if (cr6.eq) goto loc_823FB950;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
loc_823FB950:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,492(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r19,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r19.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fb9a4
	if (cr6.eq) goto loc_823FB9A4;
	// mr r11,r23
	r11.u64 = r23.u64;
	// subf r9,r23,r21
	ctx.r9.s64 = r21.s64 - r23.s64;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_823FB984:
	// lwzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823fb984
	if (!cr0.eq) goto loc_823FB984;
loc_823FB9A4:
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// lwz r26,216(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x823fba4c
	if (cr0.lt) goto loc_823FBA4C;
	// lfd f0,176(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bgt cr6,0x823fb9d8
	if (cr6.gt) goto loc_823FB9D8;
	// lfd f0,184(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x823fba4c
	if (!cr6.lt) goto loc_823FBA4C;
loc_823FB9D8:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fba04
	if (cr6.eq) goto loc_823FBA04;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fba04
	if (!cr6.eq) goto loc_823FBA04;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
loc_823FBA04:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fbc68
	if (cr6.eq) goto loc_823FBC68;
	// mr r11,r26
	r11.u64 = r26.u64;
	// subf r8,r26,r21
	ctx.r8.s64 = r21.s64 - r26.s64;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
loc_823FBA18:
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bne cr6,0x823fba3c
	if (!cr6.eq) goto loc_823FBA3C;
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_823FBA3C:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823fba18
	if (!cr0.eq) goto loc_823FBA18;
	// b 0x823fbc68
	goto loc_823FBC68;
loc_823FBA4C:
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// bge cr6,0x823fba68
	if (!cr6.lt) goto loc_823FBA68;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rlwinm. r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fbe6c
	if (cr0.eq) goto loc_823FBE6C;
loc_823FBA68:
	// lis r5,4416
	ctx.r5.s64 = 289406976;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r19,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r19.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r1,104
	ctx.r6.s64 = ctx.r1.s64 + 104;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,160(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 160);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// stw r14,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r14.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// beq cr6,0x823fbaec
	if (cr6.eq) goto loc_823FBAEC;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbaec
	if (!cr6.eq) goto loc_823FBAEC;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
loc_823FBAEC:
	// lwz r7,204(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fbb24
	if (cr6.eq) goto loc_823FBB24;
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
	// subf r9,r7,r21
	ctx.r9.s64 = r21.s64 - ctx.r7.s64;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_823FBB04:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r6
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r6.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823fbb04
	if (!cr0.eq) goto loc_823FBB04;
loc_823FBB24:
	// lwz r27,208(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	// oris r28,r25,4096
	r28.u64 = r25.u64 | 268435456;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fbb88
	if (cr6.eq) goto loc_823FBB88;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_823FBB60:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r9,152(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// stw r9,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r9.u32);
	// bne 0x823fbb60
	if (!cr0.eq) goto loc_823FBB60;
loc_823FBB88:
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r29,212(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fbbfc
	if (cr6.eq) goto loc_823FBBFC;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_823FBBD4:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r9,152(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// stw r9,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r9.u32);
	// bne 0x823fbbd4
	if (!cr0.eq) goto loc_823FBBD4;
loc_823FBBFC:
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// stw r14,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r14.u32);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r25,8320
	ctx.r5.u64 = r25.u64 | 545259520;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fbc68
	if (cr6.eq) goto loc_823FBC68;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_823FBC40:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r9,152(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// stw r9,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r9.u32);
	// bne 0x823fbc40
	if (!cr0.eq) goto loc_823FBC40;
loc_823FBC68:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r25,4096
	ctx.r5.u64 = r25.u64 | 268435456;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fbcc8
	if (cr6.eq) goto loc_823FBCC8;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_823FBCA0:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r9,152(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r9,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r9.u32);
	// bne 0x823fbca0
	if (!cr0.eq) goto loc_823FBCA0;
loc_823FBCC8:
	// lwz r29,220(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r25,8336
	ctx.r5.u64 = r25.u64 | 546308096;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fbd2c
	if (cr6.eq) goto loc_823FBD2C;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_823FBD04:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r9,152(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 152);
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// stw r9,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r9.u32);
	// bne 0x823fbd04
	if (!cr0.eq) goto loc_823FBD04;
loc_823FBD2C:
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,476(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// oris r5,r25,4432
	ctx.r5.u64 = r25.u64 | 290455552;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fbe88
	if (cr0.lt) goto loc_823FBE88;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x823fbe04
	if (cr6.eq) goto loc_823FBE04;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// subf r6,r21,r23
	ctx.r6.s64 = r23.s64 - r21.s64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
loc_823FBD78:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r5,100(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lwzx r8,r6,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lfd f0,0(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// lfd f13,8(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x823fbddc
	if (cr6.gt) goto loc_823FBDDC;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stfd f0,32(r10)
	PPC_STORE_U64(ctx.r10.u32 + 32, f0.u64);
	// lfd f0,8(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// ori r8,r8,256
	ctx.r8.u64 = ctx.r8.u64 | 256;
	// stfd f0,40(r10)
	PPC_STORE_U64(ctx.r10.u32 + 40, f0.u64);
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// lfd f0,0(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// lfd f13,8(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x823fbddc
	if (!cr6.eq) goto loc_823FBDDC;
	// ori r11,r8,128
	r11.u64 = ctx.r8.u64 | 128;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
loc_823FBDDC:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// lwz r5,124(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// bne 0x823fbd78
	if (!cr0.eq) goto loc_823FBD78;
loc_823FBE04:
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x823fbe78
	if (cr6.eq) goto loc_823FBE78;
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823fbe78
	if (cr6.eq) goto loc_823FBE78;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe78
	if (!cr6.eq) goto loc_823FBE78;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fbe78
	if (!cr6.eq) goto loc_823FBE78;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,492(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,148
	ctx.r7.s64 = ctx.r1.s64 + 148;
	// add r6,r11,r10
	ctx.r6.u64 = r11.u64 + ctx.r10.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x823fbe78
	if (!cr0.lt) goto loc_823FBE78;
loc_823FBE6C:
	// lis r30,-32768
	r30.s64 = -2147483648;
	// ori r30,r30,16389
	r30.u64 = r30.u64 | 16389;
	// b 0x823fbe88
	goto loc_823FBE88;
loc_823FBE78:
	// li r30,0
	r30.s64 = 0;
	// b 0x823fbe88
	goto loc_823FBE88;
loc_823FBE80:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
loc_823FBE88:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,124(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,108(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,152(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lwz r10,140(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r10,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r10.u32);
	// lwz r10,144(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// stw r11,68(r31)
	PPC_STORE_U32(r31.u32 + 68, r11.u32);
	// stw r10,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r10.u32);
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r10,108(r31)
	PPC_STORE_U32(r31.u32 + 108, ctx.r10.u32);
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// stw r10,112(r31)
	PPC_STORE_U32(r31.u32 + 112, ctx.r10.u32);
loc_823FBF00:
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// lfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_823FBF10"))) PPC_WEAK_FUNC(sub_823FBF10);
PPC_FUNC_IMPL(__imp__sub_823FBF10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -176, f29.u64);
	// stfd f30,-168(r1)
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r4,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, ctx.r4.u32);
	// li r22,0
	r22.s64 = 0;
	// stw r7,452(r1)
	PPC_STORE_U32(ctx.r1.u32 + 452, ctx.r7.u32);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r14,r6
	r14.u64 = ctx.r6.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r19,r8
	r19.u64 = ctx.r8.u64;
	// stw r22,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r22.u32);
	// mr r21,r22
	r21.u64 = r22.u64;
	// stw r22,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r22.u32);
	// mr r18,r22
	r18.u64 = r22.u64;
	// stw r22,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r22.u32);
	// stw r22,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r22.u32);
	// lwz r20,28(r11)
	r20.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// rlwinm r15,r20,2,0,29
	r15.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// stw r11,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r11.u32);
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r11.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r11,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r25,r3
	r25.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// beq 0x823fc6c8
	if (cr0.eq) goto loc_823FC6C8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// stw r3,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823fc6c8
	if (cr0.eq) goto loc_823FC6C8;
	// rlwinm r29,r20,4,0,27
	r29.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 4) & 0xFFFFFFF0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// beq 0x823fc6c8
	if (cr0.eq) goto loc_823FC6C8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// stw r3,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823fc6c8
	if (cr0.eq) goto loc_823FC6C8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r18,r3
	r18.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r18.s32, 0, xer);
	// beq 0x823fc6c8
	if (cr0.eq) goto loc_823FC6C8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// stw r3,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823fc6c8
	if (cr0.eq) goto loc_823FC6C8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// stw r3,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823fc6c8
	if (cr0.eq) goto loc_823FC6C8;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r22,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r22.u32);
	// beq cr6,0x823fc070
	if (cr6.eq) goto loc_823FC070;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fc6d0
	if (cr0.lt) goto loc_823FC6D0;
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823fc058
	if (cr6.eq) goto loc_823FC058;
	// li r11,1
	r11.s64 = 1;
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r11.u32);
loc_823FC058:
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc6c0
	if (!cr6.eq) goto loc_823FC6C0;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc6c0
	if (!cr6.eq) goto loc_823FC6C0;
loc_823FC070:
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x823fc12c
	if (cr6.eq) goto loc_823FC12C;
	// mr r30,r22
	r30.u64 = r22.u64;
	// mr r29,r21
	r29.u64 = r21.u64;
	// mr r28,r20
	r28.u64 = r20.u64;
loc_823FC0A4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r4,r11,r30
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x823fc0c8
	if (cr6.eq) goto loc_823FC0C8;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x823fc0d8
	if (!cr0.lt) goto loc_823FC0D8;
loc_823FC0C8:
	// lfd f0,168(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// stfd f0,0(r29)
	PPC_STORE_U64(r29.u32 + 0, f0.u64);
	// lfd f0,176(r31)
	f0.u64 = PPC_LOAD_U64(r31.u32 + 176);
	// stfd f0,8(r29)
	PPC_STORE_U64(r29.u32 + 8, f0.u64);
loc_823FC0D8:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r11,r30
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x823fc114
	if (cr6.eq) goto loc_823FC114;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r8,116(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// lwzx r11,r9,r10
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// beq cr6,0x823fc114
	if (cr6.eq) goto loc_823FC114;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// b 0x823fc118
	goto loc_823FC118;
loc_823FC114:
	// li r11,31
	r11.s64 = 31;
loc_823FC118:
	// stwx r11,r30,r18
	PPC_STORE_U32(r30.u32 + r18.u32, r11.u32);
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r29,r29,16
	r29.s64 = r29.s64 + 16;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x823fc0a4
	if (!cr0.eq) goto loc_823FC0A4;
loc_823FC12C:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r26,-1
	r26.s64 = -1;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r17,r22
	r17.u64 = r22.u64;
	// mr r16,r22
	r16.u64 = r22.u64;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r11.u32);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
	// stw r26,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r26.u32);
	// stw r26,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r26.u32);
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_823FC15C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r3,132(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r24,8(r11)
	r24.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r23,12(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// rlwinm r5,r20,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 4) & 0xFFFFFFF0;
	// lwz r3,136(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// lwz r3,140(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// stw r26,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r26.u32);
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x823fc280
	if (cr6.eq) goto loc_823FC280;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r25,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r25.u32);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// stw r26,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r26.u32);
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// stw r22,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r22.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r22,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r22.u32);
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fc6d0
	if (cr0.lt) goto loc_823FC6D0;
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// addi r7,r1,156
	ctx.r7.s64 = ctx.r1.s64 + 156;
	// addi r6,r1,156
	ctx.r6.s64 = ctx.r1.s64 + 156;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fc6d0
	if (cr0.lt) goto loc_823FC6D0;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r19,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r19.u32);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// stw r22,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r22.u32);
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// stw r22,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r22.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r26,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r26.u32);
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fc6d0
	if (cr0.lt) goto loc_823FC6D0;
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fc6d0
	if (cr0.lt) goto loc_823FC6D0;
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc278
	if (!cr6.eq) goto loc_823FC278;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc594
	if (!cr6.eq) goto loc_823FC594;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc594
	if (!cr6.eq) goto loc_823FC594;
loc_823FC278:
	// stw r22,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r22.u32);
	// stw r22,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r22.u32);
loc_823FC280:
	// addi r5,r1,208
	ctx.r5.s64 = ctx.r1.s64 + 208;
	// lwz r4,144(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3650
	sub_823F3650(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x823fc2ac
	if (!cr0.lt) goto loc_823FC2AC;
	// lfd f30,176(r31)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(r31.u32 + 176);
	// lfd f29,168(r31)
	f29.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// stfd f30,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, f30.u64);
	// stfd f29,216(r1)
	PPC_STORE_U64(ctx.r1.u32 + 216, f29.u64);
	// b 0x823fc2b4
	goto loc_823FC2B4;
loc_823FC2AC:
	// lfd f29,216(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + 216);
	// lfd f30,208(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
loc_823FC2B4:
	// fcmpu cr6,f30,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f31.f64);
	// bgt cr6,0x823fc2c4
	if (cr6.gt) goto loc_823FC2C4;
	// fcmpu cr6,f29,f31
	cr6.compare(f29.f64, f31.f64);
	// bge cr6,0x823fc2c8
	if (!cr6.lt) goto loc_823FC2C8;
loc_823FC2C4:
	// li r17,1
	r17.s64 = 1;
loc_823FC2C8:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x823fc3ac
	if (cr6.eq) goto loc_823FC3AC;
	// mr r30,r19
	r30.u64 = r19.u64;
	// mr r29,r21
	r29.u64 = r21.u64;
	// subf r28,r19,r18
	r28.s64 = r18.s64 - r19.s64;
	// mr r27,r20
	r27.u64 = r20.u64;
loc_823FC2E0:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x823fc39c
	if (cr6.eq) goto loc_823FC39C;
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3650
	sub_823F3650(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x823fc314
	if (!cr0.lt) goto loc_823FC314;
	// lfd f0,168(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// lfd f13,176(r31)
	ctx.f13.u64 = PPC_LOAD_U64(r31.u32 + 176);
	// stfd f0,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, f0.u64);
	// stfd f13,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.f13.u64);
	// b 0x823fc31c
	goto loc_823FC31C;
loc_823FC314:
	// lfd f13,200(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// lfd f0,192(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
loc_823FC31C:
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// beq cr6,0x823fc358
	if (cr6.eq) goto loc_823FC358;
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// ld r11,8(r11)
	r11.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// std r10,0(r29)
	PPC_STORE_U64(r29.u32 + 0, ctx.r10.u64);
	// std r11,8(r29)
	PPC_STORE_U64(r29.u32 + 8, r11.u64);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// b 0x823fc398
	goto loc_823FC398;
loc_823FC358:
	// lfd f12,0(r29)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r29.u32 + 0);
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// ble cr6,0x823fc368
	if (!cr6.gt) goto loc_823FC368;
	// stfd f0,0(r29)
	PPC_STORE_U64(r29.u32 + 0, f0.u64);
loc_823FC368:
	// lfd f0,8(r29)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r29.u32 + 8);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x823fc378
	if (!cr6.lt) goto loc_823FC378;
	// stfd f13,8(r29)
	PPC_STORE_U64(r29.u32 + 8, ctx.f13.u64);
loc_823FC378:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r28,r30
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r30.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
loc_823FC398:
	// stwx r11,r28,r30
	PPC_STORE_U32(r28.u32 + r30.u32, r11.u32);
loc_823FC39C:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r29,r29,16
	r29.s64 = r29.s64 + 16;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x823fc2e0
	if (!cr0.eq) goto loc_823FC2E0;
loc_823FC3AC:
	// fcmpu cr6,f30,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f31.f64);
	// bne cr6,0x823fc3bc
	if (!cr6.eq) goto loc_823FC3BC;
	// fcmpu cr6,f29,f31
	cr6.compare(f29.f64, f31.f64);
	// beq cr6,0x823fc594
	if (cr6.eq) goto loc_823FC594;
loc_823FC3BC:
	// fcmpu cr6,f30,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f31.f64);
	// bgt cr6,0x823fc3d4
	if (cr6.gt) goto loc_823FC3D4;
	// fcmpu cr6,f29,f31
	cr6.compare(f29.f64, f31.f64);
	// blt cr6,0x823fc3d4
	if (cr6.lt) goto loc_823FC3D4;
	// li r11,1
	r11.s64 = 1;
	// stw r11,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r11.u32);
loc_823FC3D4:
	// lwz r11,148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823fc418
	if (cr6.eq) goto loc_823FC418;
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// bne cr6,0x823fc414
	if (!cr6.eq) goto loc_823FC414;
	// addi r7,r1,164
	ctx.r7.s64 = ctx.r1.s64 + 164;
	// lwz r4,128(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f97b0
	sub_823F97B0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x823fc414
	if (cr0.eq) goto loc_823FC414;
	// li r11,1
	r11.s64 = 1;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// b 0x823fc418
	goto loc_823FC418;
loc_823FC414:
	// stw r22,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r22.u32);
loc_823FC418:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x823fc498
	if (cr6.eq) goto loc_823FC498;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// subf r6,r25,r19
	ctx.r6.s64 = r19.s64 - r25.s64;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
loc_823FC42C:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwzx r10,r6,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x823fc48c
	if (cr6.eq) goto loc_823FC48C;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823fc48c
	if (cr6.eq) goto loc_823FC48C;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r5,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,0,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFE0;
	// rlwinm r9,r9,0,25,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFE7F;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// andi. r5,r5,415
	ctx.r5.u64 = ctx.r5.u64 & 415;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// or r9,r5,r9
	ctx.r9.u64 = ctx.r5.u64 | ctx.r9.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lfd f0,32(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// stfd f0,32(r11)
	PPC_STORE_U64(r11.u32 + 32, f0.u64);
	// lfd f0,40(r10)
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 40);
	// stfd f0,40(r11)
	PPC_STORE_U64(r11.u32 + 40, f0.u64);
loc_823FC48C:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x823fc42c
	if (!cr0.eq) goto loc_823FC42C;
loc_823FC498:
	// lwz r29,452(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x823fc524
	if (cr6.eq) goto loc_823FC524;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r25.u32);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// stw r22,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r22.u32);
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// stw r22,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r22.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f9cc0
	sub_823F9CC0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fc6d0
	if (cr0.lt) goto loc_823FC6D0;
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r19,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r19.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// stw r22,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r22.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r22,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r22.u32);
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x823fc6d0
	if (cr0.lt) goto loc_823FC6D0;
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc51c
	if (!cr6.eq) goto loc_823FC51C;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc594
	if (!cr6.eq) goto loc_823FC594;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc594
	if (!cr6.eq) goto loc_823FC594;
loc_823FC51C:
	// stw r22,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r22.u32);
	// stw r22,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r22.u32);
loc_823FC524:
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc540
	if (!cr6.eq) goto loc_823FC540;
	// addi r16,r16,1
	r16.s64 = r16.s64 + 1;
	// cmplwi cr6,r16,1024
	cr6.compare<uint32_t>(r16.u32, 1024, xer);
	// blt cr6,0x823fc15c
	if (cr6.lt) goto loc_823FC15C;
	// b 0x823fc594
	goto loc_823FC594;
loc_823FC540:
	// mr r11,r25
	r11.u64 = r25.u64;
	// lwz r25,132(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// lwz r21,136(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r9,r18
	ctx.r9.u64 = r18.u64;
	// lwz r18,140(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r11.u32);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// stw r10,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r10.u32);
	// stw r9,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r9.u32);
	// bl 0x823f5458
	sub_823F5458(ctx, base);
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// stw r22,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r22.u32);
	// stw r22,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r22.u32);
	// stw r22,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r22.u32);
	// bne cr6,0x823fc594
	if (!cr6.eq) goto loc_823FC594;
	// li r11,1
	r11.s64 = 1;
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r11.u32);
loc_823FC594:
	// cmplwi cr6,r16,1024
	cr6.compare<uint32_t>(r16.u32, 1024, xer);
	// bne cr6,0x823fc5bc
	if (!cr6.eq) goto loc_823FC5BC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,428(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// li r7,1024
	ctx.r7.s64 = 1024;
	// addi r6,r11,31896
	ctx.r6.s64 = r11.s64 + 31896;
	// li r5,3511
	ctx.r5.s64 = 3511;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x823fc6b4
	goto loc_823FC6B4;
loc_823FC5BC:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x823fc63c
	if (cr6.eq) goto loc_823FC63C;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// subf r7,r25,r18
	ctx.r7.s64 = r18.s64 - r25.s64;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
loc_823FC5D4:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823fc62c
	if (cr6.eq) goto loc_823FC62C;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// lwz r8,20(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stfd f0,32(r11)
	PPC_STORE_U64(r11.u32 + 32, f0.u64);
	// lfd f0,8(r10)
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 8);
	// stfd f0,40(r11)
	PPC_STORE_U64(r11.u32 + 40, f0.u64);
	// lwzx r8,r7,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lfd f0,32(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// rlwinm r8,r8,0,25,22
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFE7F;
	// lfd f13,40(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// bne cr6,0x823fc624
	if (!cr6.eq) goto loc_823FC624;
	// ori r8,r8,128
	ctx.r8.u64 = ctx.r8.u64 | 128;
	// b 0x823fc628
	goto loc_823FC628;
loc_823FC624:
	// ori r8,r8,256
	ctx.r8.u64 = ctx.r8.u64 | 256;
loc_823FC628:
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
loc_823FC62C:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fc5d4
	if (!cr0.eq) goto loc_823FC5D4;
loc_823FC63C:
	// lwz r3,168(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x823fc6c0
	if (cr6.eq) goto loc_823FC6C0;
	// lwz r11,148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823fc6c0
	if (cr6.eq) goto loc_823FC6C0;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc6c0
	if (!cr6.eq) goto loc_823FC6C0;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fc6c0
	if (!cr6.eq) goto loc_823FC6C0;
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,164
	ctx.r7.s64 = ctx.r1.s64 + 164;
	// add r6,r11,r10
	ctx.r6.u64 = r11.u64 + ctx.r10.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x823fc6c0
	if (!cr0.lt) goto loc_823FC6C0;
loc_823FC6B4:
	// lis r30,-32768
	r30.s64 = -2147483648;
	// ori r30,r30,16389
	r30.u64 = r30.u64 | 16389;
	// b 0x823fc6d0
	goto loc_823FC6D0;
loc_823FC6C0:
	// mr r30,r22
	r30.u64 = r22.u64;
	// b 0x823fc6d0
	goto loc_823FC6D0;
loc_823FC6C8:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
loc_823FC6D0:
	// lwz r11,168(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,132(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,172(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,136(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,140(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r11.u32);
	// lwz r11,152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// lfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -176);
	// lfd f30,-168(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_823FC754"))) PPC_WEAK_FUNC(sub_823FC754);
PPC_FUNC_IMPL(__imp__sub_823FC754) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_823FC758"))) PPC_WEAK_FUNC(sub_823FC758);
PPC_FUNC_IMPL(__imp__sub_823FC758) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-1696(r1)
	ea = -1696 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r4
	r19.u64 = ctx.r4.u64;
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// mr r15,r5
	r15.u64 = ctx.r5.u64;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// stw r19,1724(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1724, r19.u32);
	// stw r14,1716(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1716, r14.u32);
	// stw r15,1732(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1732, r15.u32);
	// bne cr6,0x823fc798
	if (!cr6.eq) goto loc_823FC798;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// bne cr6,0x824034d4
	if (!cr6.eq) goto loc_824034D4;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x824034dc
	goto loc_824034DC;
loc_823FC798:
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x824034d4
	if (!cr6.eq) goto loc_824034D4;
	// lwz r9,28(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 28);
	// lwz r10,36(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 36);
	// cmpwi cr6,r9,32
	cr6.compare<int32_t>(ctx.r9.s32, 32, xer);
	// lwz r11,20(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r9,24(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// mullw r30,r11,r9
	r30.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// stw r10,524(r1)
	PPC_STORE_U32(ctx.r1.u32 + 524, ctx.r10.u32);
	// bne cr6,0x824034d4
	if (!cr6.eq) goto loc_824034D4;
	// li r22,0
	r22.s64 = 0;
	// lwz r27,8(r10)
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// lis r25,3584
	r25.s64 = 234881024;
	// cmplwi r27,0
	cr0.compare<uint32_t>(r27.u32, 0, xer);
	// std r22,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r22.u64);
	// std r22,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r22.u64);
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// std r22,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r22.u64);
	// std r22,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r22.u64);
	// std r22,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r22.u64);
	// std r22,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, r22.u64);
	// stw r11,532(r1)
	PPC_STORE_U32(ctx.r1.u32 + 532, r11.u32);
	// lwz r11,100(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 100);
	// stw r11,528(r1)
	PPC_STORE_U32(ctx.r1.u32 + 528, r11.u32);
	// beq 0x823fc8c4
	if (cr0.eq) goto loc_823FC8C4;
	// mr r28,r22
	r28.u64 = r22.u64;
loc_823FC810:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x823fc8a8
	if (cr6.eq) goto loc_823FC8A8;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r31,r1,128
	r31.s64 = ctx.r1.s64 + 128;
	// addi r26,r1,160
	r26.s64 = ctx.r1.s64 + 160;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// stwx r11,r28,r31
	PPC_STORE_U32(r28.u32 + r31.u32, r11.u32);
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// stwx r10,r28,r26
	PPC_STORE_U32(r28.u32 + r26.u32, ctx.r10.u32);
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// stwx r29,r28,r11
	PPC_STORE_U32(r28.u32 + r11.u32, r29.u32);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwzx r4,r28,r31
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + r31.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwzx r11,r28,r26
	r11.u64 = PPC_LOAD_U32(r28.u32 + r26.u32);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x823fc8a8
	if (cr0.eq) goto loc_823FC8A8;
	// lwz r10,8(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
loc_823FC888:
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// and r25,r9,r25
	r25.u64 = ctx.r9.u64 & r25.u64;
	// bne 0x823fc888
	if (!cr0.eq) goto loc_823FC888;
loc_823FC8A8:
	// lwz r27,12(r27)
	r27.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplwi r27,0
	cr0.compare<uint32_t>(r27.u32, 0, xer);
	// bne 0x823fc810
	if (!cr0.eq) goto loc_823FC810;
	// lis r11,3584
	r11.s64 = 234881024;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// bne cr6,0x823fc8c8
	if (!cr6.eq) goto loc_823FC8C8;
loc_823FC8C4:
	// mr r25,r22
	r25.u64 = r22.u64;
loc_823FC8C8:
	// stw r25,100(r14)
	PPC_STORE_U32(r14.u32 + 100, r25.u32);
	// lwz r11,32(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,134
	cr6.compare<uint32_t>(r11.u32, 134, xer);
	// bgt cr6,0x82403474
	if (cr6.gt) goto loc_82403474;
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,31328
	r12.s64 = r12.s64 + 31328;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32192
	r12.s64 = -2109734912;
	// addi r12,r12,-14072
	r12.s64 = r12.s64 + -14072;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_823FC908;
	case 1:
		goto loc_823FC9C4;
	case 2:
		goto loc_823FCA20;
	case 3:
		goto loc_823FCD58;
	case 4:
		goto loc_823FCDE4;
	case 5:
		goto loc_823FCE2C;
	case 6:
		goto loc_823FCE88;
	case 7:
		goto loc_823FCED8;
	case 8:
		goto loc_823FCFEC;
	case 9:
		goto loc_823FD0B8;
	case 10:
		goto loc_823FD0DC;
	case 11:
		goto loc_823FD138;
	case 12:
		goto loc_823FD3F4;
	case 13:
		goto loc_823FD558;
	case 14:
		goto loc_823FD5B0;
	case 15:
		goto loc_823FD600;
	case 16:
		goto loc_823FD6A8;
	case 17:
		goto loc_82403474;
	case 18:
		goto loc_823FDFDC;
	case 19:
		goto loc_823FE15C;
	case 20:
		goto loc_823FE1BC;
	case 21:
		goto loc_823FE264;
	case 22:
		goto loc_823FE39C;
	case 23:
		goto loc_823FE3E4;
	case 24:
		goto loc_823FE60C;
	case 25:
		goto loc_823FE6F0;
	case 26:
		goto loc_823FE92C;
	case 27:
		goto loc_823FE97C;
	case 28:
		goto loc_823FEDC0;
	case 29:
		goto loc_823FF04C;
	case 30:
		goto loc_823FF2FC;
	case 31:
		goto loc_823FF57C;
	case 32:
		goto loc_823FF824;
	case 33:
		goto loc_823FF8D8;
	case 34:
		goto loc_823FF9D4;
	case 35:
		goto loc_823FFA24;
	case 36:
		goto loc_82403474;
	case 37:
		goto loc_823FFCEC;
	case 38:
		goto loc_823FFE10;
	case 39:
		goto loc_823FFF18;
	case 40:
		goto loc_823FFF5C;
	case 41:
		goto loc_823FFFB4;
	case 42:
		goto loc_8240000C;
	case 43:
		goto loc_82400470;
	case 44:
		goto loc_82400470;
	case 45:
		goto loc_82400470;
	case 46:
		goto loc_82400508;
	case 47:
		goto loc_82400590;
	case 48:
		goto loc_82400590;
	case 49:
		goto loc_82400508;
	case 50:
		goto loc_82400590;
	case 51:
		goto loc_82400590;
	case 52:
		goto loc_82400BCC;
	case 53:
		goto loc_82400C04;
	case 54:
		goto loc_82400E18;
	case 55:
		goto loc_82400E58;
	case 56:
		goto loc_82403474;
	case 57:
		goto loc_82403474;
	case 58:
		goto loc_82403474;
	case 59:
		goto loc_82400EF0;
	case 60:
		goto loc_82401090;
	case 61:
		goto loc_8240152C;
	case 62:
		goto loc_824016FC;
	case 63:
		goto loc_82401740;
	case 64:
		goto loc_82401854;
	case 65:
		goto loc_82401A3C;
	case 66:
		goto loc_82401A84;
	case 67:
		goto loc_82401B24;
	case 68:
		goto loc_82401E30;
	case 69:
		goto loc_82402160;
	case 70:
		goto loc_82402218;
	case 71:
		goto loc_8240227C;
	case 72:
		goto loc_824023C4;
	case 73:
		goto loc_8240277C;
	case 74:
		goto loc_82403474;
	case 75:
		goto loc_82403474;
	case 76:
		goto loc_82403474;
	case 77:
		goto loc_82403474;
	case 78:
		goto loc_824028E8;
	case 79:
		goto loc_82403474;
	case 80:
		goto loc_82403474;
	case 81:
		goto loc_82403474;
	case 82:
		goto loc_82403474;
	case 83:
		goto loc_8240299C;
	case 84:
		goto loc_82402A18;
	case 85:
		goto loc_82402A94;
	case 86:
		goto loc_82403474;
	case 87:
		goto loc_82403474;
	case 88:
		goto loc_82403474;
	case 89:
		goto loc_82403474;
	case 90:
		goto loc_82403474;
	case 91:
		goto loc_82402B10;
	case 92:
		goto loc_82403474;
	case 93:
		goto loc_82403474;
	case 94:
		goto loc_82403474;
	case 95:
		goto loc_82403474;
	case 96:
		goto loc_82402B88;
	case 97:
		goto loc_82403474;
	case 98:
		goto loc_82403474;
	case 99:
		goto loc_82403474;
	case 100:
		goto loc_82403474;
	case 101:
		goto loc_82402C60;
	case 102:
		goto loc_82402CDC;
	case 103:
		goto loc_82402D58;
	case 104:
		goto loc_82403474;
	case 105:
		goto loc_82403474;
	case 106:
		goto loc_82403474;
	case 107:
		goto loc_82403474;
	case 108:
		goto loc_82403474;
	case 109:
		goto loc_82402DD4;
	case 110:
		goto loc_82403474;
	case 111:
		goto loc_82403474;
	case 112:
		goto loc_82402E4C;
	case 113:
		goto loc_82403474;
	case 114:
		goto loc_82403474;
	case 115:
		goto loc_82402F24;
	case 116:
		goto loc_82402FA0;
	case 117:
		goto loc_8240301C;
	case 118:
		goto loc_82403474;
	case 119:
		goto loc_82403474;
	case 120:
		goto loc_82403098;
	case 121:
		goto loc_82403474;
	case 122:
		goto loc_82403474;
	case 123:
		goto loc_82403110;
	case 124:
		goto loc_82403474;
	case 125:
		goto loc_82403474;
	case 126:
		goto loc_824031E8;
	case 127:
		goto loc_82403264;
	case 128:
		goto loc_824032E0;
	case 129:
		goto loc_82403474;
	case 130:
		goto loc_82403474;
	case 131:
		goto loc_82403474;
	case 132:
		goto loc_8240335C;
	case 133:
		goto loc_82403474;
	case 134:
		goto loc_824033E0;
	default:
		__builtin_unreachable();
	}
loc_823FC908:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fc980
	if (cr6.eq) goto loc_823FC980;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fc95c
	if (cr0.eq) goto loc_823FC95C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FC950:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fc950
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FC950;
loc_823FC95C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fc980
	if (cr6.eq) goto loc_823FC980;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fc980
	if (cr0.eq) goto loc_823FC980;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FC974:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fc974
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FC974;
loc_823FC980:
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// oris r5,r30,8208
	ctx.r5.u64 = r30.u64 | 537919488;
	// b 0x82402760
	goto loc_82402760;
loc_823FC9C4:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fca00
	if (cr6.eq) goto loc_823FCA00;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fca00
	if (cr0.eq) goto loc_823FCA00;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FC9F4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fc9f4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FC9F4;
loc_823FCA00:
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// li r6,0
	ctx.r6.s64 = 0;
loc_823FCA08:
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f7120
	sub_823F7120(ctx, base);
	// b 0x82402770
	goto loc_82402770;
loc_823FCA20:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r31,160(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// cmplwi cr6,r31,1
	cr6.compare<uint32_t>(r31.u32, 1, xer);
	// bne cr6,0x823fca8c
	if (!cr6.eq) goto loc_823FCA8C;
	// li r29,-1
	r29.s64 = -1;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r6,r1,412
	ctx.r6.s64 = ctx.r1.s64 + 412;
	// addi r5,r1,404
	ctx.r5.s64 = ctx.r1.s64 + 404;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r29,404(r1)
	PPC_STORE_U32(ctx.r1.u32 + 404, r29.u32);
	// stw r29,412(r1)
	PPC_STORE_U32(ctx.r1.u32 + 412, r29.u32);
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r8,r1,404
	ctx.r8.s64 = ctx.r1.s64 + 404;
	// addi r7,r1,412
	ctx.r7.s64 = ctx.r1.s64 + 412;
loc_823FCA7C:
	// lis r5,8224
	ctx.r5.s64 = 538968064;
loc_823FCA80:
	// li r9,23
	ctx.r9.s64 = 23;
loc_823FCA84:
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// b 0x82402760
	goto loc_82402760;
loc_823FCA8C:
	// cmplwi cr6,r31,2
	cr6.compare<uint32_t>(r31.u32, 2, xer);
	// bne cr6,0x823fcb00
	if (!cr6.eq) goto loc_823FCB00;
	// li r29,-1
	r29.s64 = -1;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r7,4
	ctx.r8.s64 = ctx.r7.s64 + 4;
	// addi r6,r1,420
	ctx.r6.s64 = ctx.r1.s64 + 420;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// stw r29,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, r29.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r29,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, r29.u32);
	// stw r29,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, r29.u32);
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r7,r1,420
	ctx.r7.s64 = ctx.r1.s64 + 420;
	// addi r6,r1,384
	ctx.r6.s64 = ctx.r1.s64 + 384;
	// addi r5,r1,428
	ctx.r5.s64 = ctx.r1.s64 + 428;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r8,r1,428
	ctx.r8.s64 = ctx.r1.s64 + 428;
	// addi r7,r1,384
	ctx.r7.s64 = ctx.r1.s64 + 384;
	// b 0x823fca7c
	goto loc_823FCA7C;
loc_823FCB00:
	// cmplwi cr6,r31,3
	cr6.compare<uint32_t>(r31.u32, 3, xer);
	// bne cr6,0x823fcbb0
	if (!cr6.eq) goto loc_823FCBB0;
	// li r29,-1
	r29.s64 = -1;
	// lwz r30,144(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addi r10,r1,496
	ctx.r10.s64 = ctx.r1.s64 + 496;
	// mr r11,r29
	r11.u64 = r29.u64;
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r28,r5,1
	r28.u64 = ctx.r5.u64 | 1;
	// stw r29,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, r29.u32);
	// addi r8,r30,4
	ctx.r8.s64 = r30.s64 + 4;
	// stw r29,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, r29.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// addi r6,r1,496
	ctx.r6.s64 = ctx.r1.s64 + 496;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r30,8
	ctx.r8.s64 = r30.s64 + 8;
	// addi r7,r1,496
	ctx.r7.s64 = ctx.r1.s64 + 496;
	// addi r6,r1,500
	ctx.r6.s64 = ctx.r1.s64 + 500;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r7,r1,500
	ctx.r7.s64 = ctx.r1.s64 + 500;
	// addi r6,r1,316
	ctx.r6.s64 = ctx.r1.s64 + 316;
	// addi r5,r1,356
	ctx.r5.s64 = ctx.r1.s64 + 356;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r8,r1,356
	ctx.r8.s64 = ctx.r1.s64 + 356;
	// addi r7,r1,316
	ctx.r7.s64 = ctx.r1.s64 + 316;
	// b 0x823fca7c
	goto loc_823FCA7C;
loc_823FCBB0:
	// mulli r4,r31,3
	ctx.r4.s64 = r31.s64 * 3;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// rlwinm r8,r31,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,3
	r11.s64 = 3;
loc_823FCBCC:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fcbcc
	if (!cr0.eq) goto loc_823FCBCC;
	// lwz r27,128(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x823fcc14
	if (cr6.eq) goto loc_823FCC14;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x823fcc14
	if (cr0.eq) goto loc_823FCC14;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_823FCC08:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fcc08
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCC08;
loc_823FCC14:
	// lwz r26,132(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x823fcc40
	if (cr6.eq) goto loc_823FCC40;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x823fcc40
	if (cr0.eq) goto loc_823FCC40;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_823FCC34:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fcc34
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCC34;
loc_823FCC40:
	// lwz r28,136(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x823fcc6c
	if (cr6.eq) goto loc_823FCC6C;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x823fcc6c
	if (cr0.eq) goto loc_823FCC6C;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_823FCC60:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fcc60
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCC60;
loc_823FCC6C:
	// lwz r8,144(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r30,r31,12
	r30.u64 = r31.u32 & 0xFFFFF;
	// li r9,4
	ctx.r9.s64 = 4;
	// stw r29,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, r29.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// stw r29,424(r1)
	PPC_STORE_U32(ctx.r1.u32 + 424, r29.u32);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,8272
	ctx.r5.u64 = r30.u64 | 542113792;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r30,8240
	ctx.r5.u64 = r30.u64 | 540016640;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,6
	ctx.r9.s64 = 6;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// addi r6,r1,292
	ctx.r6.s64 = ctx.r1.s64 + 292;
	// oris r5,r30,20480
	ctx.r5.u64 = r30.u64 | 1342177280;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,10
	ctx.r9.s64 = 10;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,292
	ctx.r7.s64 = ctx.r1.s64 + 292;
	// addi r6,r1,424
	ctx.r6.s64 = ctx.r1.s64 + 424;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r8,r1,292
	ctx.r8.s64 = ctx.r1.s64 + 292;
	// addi r7,r1,424
	ctx.r7.s64 = ctx.r1.s64 + 424;
	// lis r5,8240
	ctx.r5.s64 = 540016640;
	// b 0x823fca80
	goto loc_823FCA80;
loc_823FCD58:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// li r29,-1
	r29.s64 = -1;
	// lwz r8,144(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lwz r5,160(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r11,5
	r11.s64 = 5;
	// li r9,4
	ctx.r9.s64 = 4;
	// rlwimi r5,r11,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// addi r6,r1,284
	ctx.r6.s64 = ctx.r1.s64 + 284;
	// stw r29,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, r29.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r29,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, r29.u32);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,284
	ctx.r7.s64 = ctx.r1.s64 + 284;
	// addi r6,r1,324
	ctx.r6.s64 = ctx.r1.s64 + 324;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r8,r1,284
	ctx.r8.s64 = ctx.r1.s64 + 284;
	// addi r7,r1,324
	ctx.r7.s64 = ctx.r1.s64 + 324;
	// b 0x823fca7c
	goto loc_823FCA7C;
loc_823FCDE4:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fce20
	if (cr6.eq) goto loc_823FCE20;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fce20
	if (cr0.eq) goto loc_823FCE20;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FCE14:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fce14
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCE14;
loc_823FCE20:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// b 0x823fca08
	goto loc_823FCA08;
loc_823FCE2C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fce68
	if (cr6.eq) goto loc_823FCE68;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fce68
	if (cr0.eq) goto loc_823FCE68;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FCE5C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fce5c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCE5C;
loc_823FCE68:
	// li r6,0
	ctx.r6.s64 = 0;
loc_823FCE6C:
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f77a8
	sub_823F77A8(ctx, base);
	// b 0x82402770
	goto loc_82402770;
loc_823FCE88:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fced0
	if (cr6.eq) goto loc_823FCED0;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fced0
	if (cr0.eq) goto loc_823FCED0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FCEC4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fcec4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCEC4;
loc_823FCED0:
	// lwz r6,148(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// b 0x823fce6c
	goto loc_823FCE6C;
loc_823FCED8:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// rlwinm r4,r30,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// add r27,r11,r28
	r27.u64 = r11.u64 + r28.u64;
	// li r29,-1
	r29.s64 = -1;
	// beq cr6,0x823fcf80
	if (cr6.eq) goto loc_823FCF80;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fcf34
	if (cr0.eq) goto loc_823FCF34;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FCF28:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fcf28
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCF28;
loc_823FCF34:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fcf80
	if (cr6.eq) goto loc_823FCF80;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fcf5c
	if (cr0.eq) goto loc_823FCF5C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FCF50:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fcf50
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCF50;
loc_823FCF5C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fcf80
	if (cr6.eq) goto loc_823FCF80;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fcf80
	if (cr0.eq) goto loc_823FCF80;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FCF74:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fcf74
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FCF74;
loc_823FCF80:
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,20
	ctx.r9.s64 = 20;
	// oris r5,r30,4160
	ctx.r5.u64 = r30.u64 | 272629760;
loc_823FCFB8:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_823FCFE4:
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// b 0x82402760
	goto loc_82402760;
loc_823FCFEC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd07c
	if (cr6.eq) goto loc_823FD07C;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd058
	if (cr0.eq) goto loc_823FD058;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD04C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd04c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD04C;
loc_823FD058:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd07c
	if (cr6.eq) goto loc_823FD07C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd07c
	if (cr0.eq) goto loc_823FD07C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD070:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd070
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD070;
loc_823FD07C:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,8208
	ctx.r5.u64 = r30.u64 | 537919488;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r8,152(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// oris r5,r30,8192
	ctx.r5.u64 = r30.u64 | 536870912;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FD0B8:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// lwz r6,160(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// bl 0x823f8be8
	sub_823F8BE8(ctx, base);
	// b 0x82402770
	goto loc_82402770;
loc_823FD0DC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd118
	if (cr6.eq) goto loc_823FD118;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd118
	if (cr0.eq) goto loc_823FD118;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD10C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd10c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD10C;
loc_823FD118:
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// li r6,0
	ctx.r6.s64 = 0;
loc_823FD120:
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
loc_823FD124:
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f6740
	sub_823F6740(ctx, base);
	// b 0x82402770
	goto loc_82402770;
loc_823FD138:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r31,8(r14)
	r31.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lfd f1,264(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 264);
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fdiv f1,f0,f1
	ctx.f1.f64 = f0.f64 / ctx.f1.f64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lfd f1,-28592(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + -28592);
	// lwz r4,120(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mulli r4,r30,7
	ctx.r4.s64 = r30.s64 * 7;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,7
	r11.s64 = 7;
loc_823FD1C4:
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r3,r3,r9
	ctx.r3.u64 = ctx.r3.u64 + ctx.r9.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x823fd1c4
	if (!cr0.eq) goto loc_823FD1C4;
	// lwz r22,184(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwz r8,180(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// beq cr6,0x823fd20c
	if (cr6.eq) goto loc_823FD20C;
	// mr r11,r22
	r11.u64 = r22.u64;
	// subf r9,r22,r8
	ctx.r9.s64 = ctx.r8.s64 - r22.s64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_823FD1F8:
	// stwx r31,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, r31.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823fd1f8
	if (!cr0.eq) goto loc_823FD1F8;
loc_823FD20C:
	// lwz r25,160(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd23c
	if (cr6.eq) goto loc_823FD23C;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd23c
	if (cr0.eq) goto loc_823FD23C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD230:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd230
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD230;
loc_823FD23C:
	// lwz r23,164(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd268
	if (cr6.eq) goto loc_823FD268;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd268
	if (cr0.eq) goto loc_823FD268;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD25C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd25c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD25C;
loc_823FD268:
	// lwz r24,168(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd294
	if (cr6.eq) goto loc_823FD294;
	// mr r11,r24
	r11.u64 = r24.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd294
	if (cr0.eq) goto loc_823FD294;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD288:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd288
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD288;
loc_823FD294:
	// lwz r26,172(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd2c0
	if (cr6.eq) goto loc_823FD2C0;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd2c0
	if (cr0.eq) goto loc_823FD2C0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD2B4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd2b4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD2B4;
loc_823FD2C0:
	// lwz r27,176(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd310
	if (cr6.eq) goto loc_823FD310;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd2ec
	if (cr0.eq) goto loc_823FD2EC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD2E0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd2e0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD2E0;
loc_823FD2EC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd310
	if (cr6.eq) goto loc_823FD310;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd310
	if (cr0.eq) goto loc_823FD310;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD304:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd304
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD304;
loc_823FD310:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// oris r28,r30,8272
	r28.u64 = r30.u64 | 542113792;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r29,r30,4176
	r29.u64 = r30.u64 | 273678336;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// b 0x82402760
	goto loc_82402760;
loc_823FD3F4:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r29,-1
	r29.s64 = -1;
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// clrlwi r25,r30,12
	r25.u64 = r30.u32 & 0xFFFFF;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r31,r29
	r31.u64 = r29.u64;
	// mr r30,r29
	r30.u64 = r29.u64;
	// lwz r23,4(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r28,r1,808
	r28.s64 = ctx.r1.s64 + 808;
	// addi r27,r1,824
	r27.s64 = ctx.r1.s64 + 824;
	// addi r26,r1,752
	r26.s64 = ctx.r1.s64 + 752;
	// oris r24,r25,8272
	r24.u64 = r25.u64 | 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r23,568(r1)
	PPC_STORE_U32(ctx.r1.u32 + 568, r23.u32);
	// addi r8,r1,584
	ctx.r8.s64 = ctx.r1.s64 + 584;
	// lwz r23,8(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r7,r1,568
	ctx.r7.s64 = ctx.r1.s64 + 568;
	// addi r6,r1,808
	ctx.r6.s64 = ctx.r1.s64 + 808;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r23,572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 572, r23.u32);
	// lwz r23,0(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r23,576(r1)
	PPC_STORE_U32(ctx.r1.u32 + 576, r23.u32);
	// lwz r23,8(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r23,584(r1)
	PPC_STORE_U32(ctx.r1.u32 + 584, r23.u32);
	// lwz r23,0(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r23,588(r1)
	PPC_STORE_U32(ctx.r1.u32 + 588, r23.u32);
	// lwz r23,4(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r23,592(r1)
	PPC_STORE_U32(ctx.r1.u32 + 592, r23.u32);
	// lwz r23,8(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r23,600(r1)
	PPC_STORE_U32(ctx.r1.u32 + 600, r23.u32);
	// lwz r23,0(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r23,604(r1)
	PPC_STORE_U32(ctx.r1.u32 + 604, r23.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,608(r1)
	PPC_STORE_U32(ctx.r1.u32 + 608, r11.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r11,616(r1)
	PPC_STORE_U32(ctx.r1.u32 + 616, r11.u32);
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r11,620(r1)
	PPC_STORE_U32(ctx.r1.u32 + 620, r11.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r5,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r5.u32);
	// stw r31,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r31.u32);
	// stw r30,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r30.u32);
	// stw r5,4(r28)
	PPC_STORE_U32(r28.u32 + 4, ctx.r5.u32);
	// stw r31,4(r27)
	PPC_STORE_U32(r27.u32 + 4, r31.u32);
	// stw r30,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r30.u32);
	// stw r5,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r5.u32);
	// stw r31,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r31.u32);
	// stw r30,8(r26)
	PPC_STORE_U32(r26.u32 + 8, r30.u32);
	// stw r11,624(r1)
	PPC_STORE_U32(ctx.r1.u32 + 624, r11.u32);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// stw r29,4(r15)
	PPC_STORE_U32(r15.u32 + 4, r29.u32);
	// stw r29,8(r15)
	PPC_STORE_U32(r15.u32 + 8, r29.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,616
	ctx.r8.s64 = ctx.r1.s64 + 616;
	// addi r7,r1,600
	ctx.r7.s64 = ctx.r1.s64 + 600;
	// addi r6,r1,824
	ctx.r6.s64 = ctx.r1.s64 + 824;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,824
	ctx.r7.s64 = ctx.r1.s64 + 824;
	// addi r6,r1,752
	ctx.r6.s64 = ctx.r1.s64 + 752;
	// oris r5,r25,4112
	ctx.r5.u64 = r25.u64 | 269484032;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r8,r1,752
	ctx.r8.s64 = ctx.r1.s64 + 752;
	// addi r7,r1,808
	ctx.r7.s64 = ctx.r1.s64 + 808;
	// oris r5,r25,8256
	ctx.r5.u64 = r25.u64 | 541065216;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FD558:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd594
	if (cr6.eq) goto loc_823FD594;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd594
	if (cr0.eq) goto loc_823FD594;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD588:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd588
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD588;
loc_823FD594:
	// li r11,269
	r11.s64 = 269;
	// li r9,0
	ctx.r9.s64 = 0;
loc_823FD59C:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
loc_823FD5A4:
	// li r8,0
	ctx.r8.s64 = 0;
loc_823FD5A8:
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// b 0x82402760
	goto loc_82402760;
loc_823FD5B0:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd5ec
	if (cr6.eq) goto loc_823FD5EC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd5ec
	if (cr0.eq) goto loc_823FD5EC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD5E0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd5e0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD5E0;
loc_823FD5EC:
	// li r11,135
	r11.s64 = 135;
loc_823FD5F0:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwimi r5,r11,21,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 21) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x823fd5a4
	goto loc_823FD5A4;
loc_823FD600:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r3,8(r14)
	ctx.r3.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfd f1,32136(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 32136);
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd694
	if (cr6.eq) goto loc_823FD694;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd66c
	if (cr0.eq) goto loc_823FD66C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD660:
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd660
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD660;
loc_823FD66C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd694
	if (cr6.eq) goto loc_823FD694;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd694
	if (cr0.eq) goto loc_823FD694;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD688:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd688
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD688;
loc_823FD694:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r11,517
	r11.s64 = 517;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x823fd5a8
	goto loc_823FD5A8;
loc_823FD6A8:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x823fd734
	if (!cr6.eq) goto loc_823FD734;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r11.u32);
loc_823FD6D4:
	// lwz r11,524(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	// lwz r30,12(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd72c
	if (cr0.eq) goto loc_823FD72C;
	// lwz r28,1716(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// addi r29,r1,144
	r29.s64 = ctx.r1.s64 + 144;
loc_823FD6EC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x823fd71c
	if (cr6.eq) goto loc_823FD71C;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r11,28(r28)
	PPC_STORE_U32(r28.u32 + 28, r11.u32);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
loc_823FD71C:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x823fd6ec
	if (!cr0.eq) goto loc_823FD6EC;
loc_823FD72C:
	// li r31,0
	r31.s64 = 0;
	// b 0x82403498
	goto loc_82403498;
loc_823FD734:
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x823fd80c
	if (!cr6.eq) goto loc_823FD80C;
	// li r29,-1
	r29.s64 = -1;
	// addi r10,r1,512
	ctx.r10.s64 = ctx.r1.s64 + 512;
	// mr r11,r29
	r11.u64 = r29.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
	// beq cr6,0x823fd77c
	if (cr6.eq) goto loc_823FD77C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd77c
	if (cr0.eq) goto loc_823FD77C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD770:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd770
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD770;
loc_823FD77C:
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,536
	ctx.r8.s64 = ctx.r1.s64 + 536;
	// addi r7,r1,560
	ctx.r7.s64 = ctx.r1.s64 + 560;
	// addi r6,r1,512
	ctx.r6.s64 = ctx.r1.s64 + 512;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r5,r5,2
	ctx.r5.u64 = ctx.r5.u64 | 2;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r10,560(r1)
	PPC_STORE_U32(ctx.r1.u32 + 560, ctx.r10.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r10,536(r1)
	PPC_STORE_U32(ctx.r1.u32 + 536, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 564, ctx.r10.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,540(r1)
	PPC_STORE_U32(ctx.r1.u32 + 540, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,516
	ctx.r7.s64 = ctx.r1.s64 + 516;
	// addi r6,r1,520
	ctx.r6.s64 = ctx.r1.s64 + 520;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,8256
	ctx.r5.s64 = 541065216;
	// addi r8,r1,520
	ctx.r8.s64 = ctx.r1.s64 + 520;
	// addi r7,r1,512
	ctx.r7.s64 = ctx.r1.s64 + 512;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FD80C:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x823fd9cc
	if (!cr6.eq) goto loc_823FD9CC;
	// li r29,-1
	r29.s64 = -1;
	// addi r7,r1,736
	ctx.r7.s64 = ctx.r1.s64 + 736;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// addi r6,r1,776
	ctx.r6.s64 = ctx.r1.s64 + 776;
	// addi r5,r1,840
	ctx.r5.s64 = ctx.r1.s64 + 840;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// addi r4,r1,792
	ctx.r4.s64 = ctx.r1.s64 + 792;
	// stw r11,4(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4, r11.u32);
	// stw r11,8(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8, r11.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
	// stw r10,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r10.u32);
	// stw r8,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r8.u32);
	// stw r9,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r9.u32);
	// stw r8,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r8.u32);
	// stw r10,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r10.u32);
	// stw r9,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r9.u32);
	// stw r8,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r8.u32);
	// beq cr6,0x823fd88c
	if (cr6.eq) goto loc_823FD88C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd88c
	if (cr0.eq) goto loc_823FD88C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FD880:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd880
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD880;
loc_823FD88C:
	// lwz r30,144(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lis r11,8272
	r11.s64 = 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r29,r11,3
	r29.u64 = r11.u64 | 3;
	// addi r8,r1,480
	ctx.r8.s64 = ctx.r1.s64 + 480;
	// addi r7,r1,272
	ctx.r7.s64 = ctx.r1.s64 + 272;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r6,r1,736
	ctx.r6.s64 = ctx.r1.s64 + 736;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, r11.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,480(r1)
	PPC_STORE_U32(ctx.r1.u32 + 480, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,484(r1)
	PPC_STORE_U32(ctx.r1.u32 + 484, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,488(r1)
	PPC_STORE_U32(ctx.r1.u32 + 488, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,480
	ctx.r8.s64 = ctx.r1.s64 + 480;
	// addi r7,r1,272
	ctx.r7.s64 = ctx.r1.s64 + 272;
	// addi r6,r1,776
	ctx.r6.s64 = ctx.r1.s64 + 776;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, r11.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r11,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,480(r1)
	PPC_STORE_U32(ctx.r1.u32 + 480, r11.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,484(r1)
	PPC_STORE_U32(ctx.r1.u32 + 484, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,488(r1)
	PPC_STORE_U32(ctx.r1.u32 + 488, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,776
	ctx.r7.s64 = ctx.r1.s64 + 776;
	// addi r6,r1,840
	ctx.r6.s64 = ctx.r1.s64 + 840;
	// ori r5,r5,3
	ctx.r5.u64 = ctx.r5.u64 | 3;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,8256
	ctx.r5.s64 = 541065216;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,840
	ctx.r8.s64 = ctx.r1.s64 + 840;
	// addi r7,r1,736
	ctx.r7.s64 = ctx.r1.s64 + 736;
	// addi r6,r1,792
	ctx.r6.s64 = ctx.r1.s64 + 792;
	// ori r5,r5,3
	ctx.r5.u64 = ctx.r5.u64 | 3;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r8,r1,272
	ctx.r8.s64 = ctx.r1.s64 + 272;
	// addi r7,r1,792
	ctx.r7.s64 = ctx.r1.s64 + 792;
	// lis r5,20480
	ctx.r5.s64 = 1342177280;
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, r11.u32);
loc_823FD9C4:
	// ori r5,r5,3
	ctx.r5.u64 = ctx.r5.u64 | 3;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FD9CC:
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x823fd6d4
	if (!cr6.eq) goto loc_823FD6D4;
	// li r29,-1
	r29.s64 = -1;
	// addi r11,r1,992
	r11.s64 = ctx.r1.s64 + 992;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r10,12
	ctx.r10.s64 = 12;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_823FD9E8:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fd9e8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FD9E8;
	// addi r11,r1,944
	r11.s64 = ctx.r1.s64 + 944;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r10,12
	ctx.r10.s64 = 12;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_823FDA04:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fda04
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FDA04;
	// addi r11,r1,1040
	r11.s64 = ctx.r1.s64 + 1040;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r10,12
	ctx.r10.s64 = 12;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_823FDA20:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fda20
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FDA20;
	// addi r11,r1,896
	r11.s64 = ctx.r1.s64 + 896;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r10,12
	ctx.r10.s64 = 12;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_823FDA3C:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fda3c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FDA3C;
	// mr r11,r29
	r11.u64 = r29.u64;
	// addi r10,r1,544
	ctx.r10.s64 = ctx.r1.s64 + 544;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// beq cr6,0x823fda84
	if (cr6.eq) goto loc_823FDA84;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fda84
	if (cr0.eq) goto loc_823FDA84;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FDA78:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fda78
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FDA78;
loc_823FDA84:
	// lwz r30,144(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lis r11,8272
	r11.s64 = 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r29,r11,3
	r29.u64 = r11.u64 | 3;
	// addi r8,r1,432
	ctx.r8.s64 = ctx.r1.s64 + 432;
	// addi r7,r1,224
	ctx.r7.s64 = ctx.r1.s64 + 224;
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// addi r6,r1,992
	ctx.r6.s64 = ctx.r1.s64 + 992;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r11,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, r11.u32);
	// lwz r11,56(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// stw r11,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, r11.u32);
	// lwz r11,56(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// stw r11,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r11,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, r11.u32);
	// lwz r11,56(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// stw r11,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r11,260(r1)
	PPC_STORE_U32(ctx.r1.u32 + 260, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, r11.u32);
	// lwz r11,60(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// stw r11,432(r1)
	PPC_STORE_U32(ctx.r1.u32 + 432, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,436(r1)
	PPC_STORE_U32(ctx.r1.u32 + 436, r11.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,440(r1)
	PPC_STORE_U32(ctx.r1.u32 + 440, r11.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,444(r1)
	PPC_STORE_U32(ctx.r1.u32 + 444, r11.u32);
	// lwz r11,60(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// stw r11,448(r1)
	PPC_STORE_U32(ctx.r1.u32 + 448, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,452(r1)
	PPC_STORE_U32(ctx.r1.u32 + 452, r11.u32);
	// lwz r11,60(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// stw r11,456(r1)
	PPC_STORE_U32(ctx.r1.u32 + 456, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,460(r1)
	PPC_STORE_U32(ctx.r1.u32 + 460, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,464(r1)
	PPC_STORE_U32(ctx.r1.u32 + 464, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,468(r1)
	PPC_STORE_U32(ctx.r1.u32 + 468, r11.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,472(r1)
	PPC_STORE_U32(ctx.r1.u32 + 472, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,476(r1)
	PPC_STORE_U32(ctx.r1.u32 + 476, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,444
	ctx.r8.s64 = ctx.r1.s64 + 444;
	// addi r7,r1,236
	ctx.r7.s64 = ctx.r1.s64 + 236;
	// addi r6,r1,1004
	ctx.r6.s64 = ctx.r1.s64 + 1004;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,456
	ctx.r8.s64 = ctx.r1.s64 + 456;
	// addi r7,r1,248
	ctx.r7.s64 = ctx.r1.s64 + 248;
	// addi r6,r1,1016
	ctx.r6.s64 = ctx.r1.s64 + 1016;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,468
	ctx.r8.s64 = ctx.r1.s64 + 468;
	// addi r7,r1,260
	ctx.r7.s64 = ctx.r1.s64 + 260;
	// addi r6,r1,1028
	ctx.r6.s64 = ctx.r1.s64 + 1028;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r11,56(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,432
	ctx.r8.s64 = ctx.r1.s64 + 432;
	// addi r7,r1,224
	ctx.r7.s64 = ctx.r1.s64 + 224;
	// addi r6,r1,944
	ctx.r6.s64 = ctx.r1.s64 + 944;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r11,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, r11.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r11,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r11,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r11,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, r11.u32);
	// lwz r11,56(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// stw r11,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, r11.u32);
	// lwz r11,56(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// stw r11,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,260(r1)
	PPC_STORE_U32(ctx.r1.u32 + 260, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r11,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, r11.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,432(r1)
	PPC_STORE_U32(ctx.r1.u32 + 432, r11.u32);
	// lwz r11,60(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// stw r11,436(r1)
	PPC_STORE_U32(ctx.r1.u32 + 436, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,440(r1)
	PPC_STORE_U32(ctx.r1.u32 + 440, r11.u32);
	// lwz r11,60(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// stw r11,444(r1)
	PPC_STORE_U32(ctx.r1.u32 + 444, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,448(r1)
	PPC_STORE_U32(ctx.r1.u32 + 448, r11.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,452(r1)
	PPC_STORE_U32(ctx.r1.u32 + 452, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,456(r1)
	PPC_STORE_U32(ctx.r1.u32 + 456, r11.u32);
	// lwz r11,60(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// stw r11,460(r1)
	PPC_STORE_U32(ctx.r1.u32 + 460, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,464(r1)
	PPC_STORE_U32(ctx.r1.u32 + 464, r11.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,468(r1)
	PPC_STORE_U32(ctx.r1.u32 + 468, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,472(r1)
	PPC_STORE_U32(ctx.r1.u32 + 472, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,476(r1)
	PPC_STORE_U32(ctx.r1.u32 + 476, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,444
	ctx.r8.s64 = ctx.r1.s64 + 444;
	// addi r7,r1,236
	ctx.r7.s64 = ctx.r1.s64 + 236;
	// addi r6,r1,956
	ctx.r6.s64 = ctx.r1.s64 + 956;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,456
	ctx.r8.s64 = ctx.r1.s64 + 456;
	// addi r7,r1,248
	ctx.r7.s64 = ctx.r1.s64 + 248;
	// addi r6,r1,968
	ctx.r6.s64 = ctx.r1.s64 + 968;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,468
	ctx.r8.s64 = ctx.r1.s64 + 468;
	// addi r7,r1,260
	ctx.r7.s64 = ctx.r1.s64 + 260;
	// addi r6,r1,980
	ctx.r6.s64 = ctx.r1.s64 + 980;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r11,4112
	r11.s64 = 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r29,r11,3
	r29.u64 = r11.u64 | 3;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,944
	ctx.r7.s64 = ctx.r1.s64 + 944;
	// addi r6,r1,1040
	ctx.r6.s64 = ctx.r1.s64 + 1040;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,956
	ctx.r7.s64 = ctx.r1.s64 + 956;
	// addi r6,r1,1052
	ctx.r6.s64 = ctx.r1.s64 + 1052;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,968
	ctx.r7.s64 = ctx.r1.s64 + 968;
	// addi r6,r1,1064
	ctx.r6.s64 = ctx.r1.s64 + 1064;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,980
	ctx.r7.s64 = ctx.r1.s64 + 980;
	// addi r6,r1,1076
	ctx.r6.s64 = ctx.r1.s64 + 1076;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r11,8256
	r11.s64 = 541065216;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r29,r11,3
	r29.u64 = r11.u64 | 3;
	// addi r8,r1,1040
	ctx.r8.s64 = ctx.r1.s64 + 1040;
	// addi r7,r1,992
	ctx.r7.s64 = ctx.r1.s64 + 992;
	// addi r6,r1,896
	ctx.r6.s64 = ctx.r1.s64 + 896;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,1052
	ctx.r8.s64 = ctx.r1.s64 + 1052;
	// addi r7,r1,1004
	ctx.r7.s64 = ctx.r1.s64 + 1004;
	// addi r6,r1,908
	ctx.r6.s64 = ctx.r1.s64 + 908;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,1064
	ctx.r8.s64 = ctx.r1.s64 + 1064;
	// addi r7,r1,1016
	ctx.r7.s64 = ctx.r1.s64 + 1016;
	// addi r6,r1,920
	ctx.r6.s64 = ctx.r1.s64 + 920;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,1076
	ctx.r8.s64 = ctx.r1.s64 + 1076;
	// addi r7,r1,1028
	ctx.r7.s64 = ctx.r1.s64 + 1028;
	// addi r6,r1,932
	ctx.r6.s64 = ctx.r1.s64 + 932;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r11,20480
	r11.s64 = 1342177280;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r29,r11,3
	r29.u64 = r11.u64 | 3;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r8,r1,224
	ctx.r8.s64 = ctx.r1.s64 + 224;
	// addi r7,r1,896
	ctx.r7.s64 = ctx.r1.s64 + 896;
	// addi r6,r1,544
	ctx.r6.s64 = ctx.r1.s64 + 544;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r11,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, r11.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r11,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, r11.u32);
	// lwz r11,52(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// stw r11,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, r11.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r11,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, r11.u32);
	// lwz r11,52(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// stw r11,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, r11.u32);
	// lwz r11,52(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// stw r11,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,260(r1)
	PPC_STORE_U32(ctx.r1.u32 + 260, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, r11.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r11,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, r11.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,236
	ctx.r8.s64 = ctx.r1.s64 + 236;
	// addi r7,r1,908
	ctx.r7.s64 = ctx.r1.s64 + 908;
	// addi r6,r1,548
	ctx.r6.s64 = ctx.r1.s64 + 548;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,248
	ctx.r8.s64 = ctx.r1.s64 + 248;
	// addi r7,r1,920
	ctx.r7.s64 = ctx.r1.s64 + 920;
	// addi r6,r1,552
	ctx.r6.s64 = ctx.r1.s64 + 552;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,260
	ctx.r8.s64 = ctx.r1.s64 + 260;
	// addi r7,r1,932
	ctx.r7.s64 = ctx.r1.s64 + 932;
	// addi r6,r1,556
	ctx.r6.s64 = ctx.r1.s64 + 556;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r5,20480
	ctx.r5.s64 = 1342177280;
	// addi r8,r1,224
	ctx.r8.s64 = ctx.r1.s64 + 224;
	// addi r7,r1,544
	ctx.r7.s64 = ctx.r1.s64 + 544;
	// ori r5,r5,4
	ctx.r5.u64 = ctx.r5.u64 | 4;
	// stw r11,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, r11.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, r11.u32);
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// stw r11,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, r11.u32);
	// b 0x8240275c
	goto loc_8240275C;
loc_823FDFDC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r31,160(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// rlwinm r4,r31,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// rlwinm r8,r31,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,2
	r11.s64 = 2;
loc_823FE020:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fe020
	if (!cr0.eq) goto loc_823FE020;
	// lwz r27,128(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x823fe068
	if (cr6.eq) goto loc_823FE068;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x823fe068
	if (cr0.eq) goto loc_823FE068;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_823FE05C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe05c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE05C;
loc_823FE068:
	// lwz r28,132(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x823fe094
	if (cr6.eq) goto loc_823FE094;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x823fe094
	if (cr0.eq) goto loc_823FE094;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_823FE088:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe088
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE088;
loc_823FE094:
	// clrlwi r30,r31,12
	r30.u64 = r31.u32 & 0xFFFFF;
	// stw r29,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, r29.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r29,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, r29.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,148(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// addi r6,r1,352
	ctx.r6.s64 = ctx.r1.s64 + 352;
	// oris r5,r30,20480
	ctx.r5.u64 = r30.u64 | 1342177280;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4208
	ctx.r5.s64 = 275775488;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,352
	ctx.r7.s64 = ctx.r1.s64 + 352;
	// addi r6,r1,332
	ctx.r6.s64 = ctx.r1.s64 + 332;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r7,r1,332
	ctx.r7.s64 = ctx.r1.s64 + 332;
loc_823FE14C:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r9,4
	ctx.r9.s64 = 4;
	// lis r5,4144
	ctx.r5.s64 = 271581184;
	// b 0x823fca84
	goto loc_823FCA84;
loc_823FE15C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe1a4
	if (cr6.eq) goto loc_823FE1A4;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe1a4
	if (cr0.eq) goto loc_823FE1A4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE198:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe198
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE198;
loc_823FE1A4:
	// lwz r5,160(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r11,5
	r11.s64 = 5;
	// rlwimi r5,r11,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
loc_823FE1B0:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// b 0x823fd5a8
	goto loc_823FD5A8;
loc_823FE1BC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r11,688(r1)
	PPC_STORE_U32(ctx.r1.u32 + 688, r11.u32);
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,692(r1)
	PPC_STORE_U32(ctx.r1.u32 + 692, ctx.r10.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,696(r1)
	PPC_STORE_U32(ctx.r1.u32 + 696, r11.u32);
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// stw r11,700(r1)
	PPC_STORE_U32(ctx.r1.u32 + 700, r11.u32);
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// stw r11,704(r1)
	PPC_STORE_U32(ctx.r1.u32 + 704, r11.u32);
	// lwz r11,148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,708(r1)
	PPC_STORE_U32(ctx.r1.u32 + 708, ctx.r10.u32);
	// lwz r10,32(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// stw r10,712(r1)
	PPC_STORE_U32(ctx.r1.u32 + 712, ctx.r10.u32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r11,716(r1)
	PPC_STORE_U32(ctx.r1.u32 + 716, r11.u32);
	// beq cr6,0x823fe24c
	if (cr6.eq) goto loc_823FE24C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe24c
	if (cr0.eq) goto loc_823FE24C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE240:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe240
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE240;
loc_823FE24C:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r11,517
	r11.s64 = 517;
	// addi r8,r1,704
	ctx.r8.s64 = ctx.r1.s64 + 704;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// addi r7,r1,688
	ctx.r7.s64 = ctx.r1.s64 + 688;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FE264:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r31,8(r14)
	r31.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lfd f1,264(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 264);
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fdiv f1,f0,f1
	ctx.f1.f64 = f0.f64 / ctx.f1.f64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mulli r4,r30,3
	ctx.r4.s64 = r30.s64 * 3;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,3
	r11.s64 = 3;
loc_823FE2CC:
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x823fe2cc
	if (!cr0.eq) goto loc_823FE2CC;
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe30c
	if (cr6.eq) goto loc_823FE30C;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe30c
	if (cr0.eq) goto loc_823FE30C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE300:
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe300
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE300;
loc_823FE30C:
	// lwz r28,132(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe360
	if (cr6.eq) goto loc_823FE360;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe33c
	if (cr0.eq) goto loc_823FE33C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE330:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe330
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE330;
loc_823FE33C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe360
	if (cr6.eq) goto loc_823FE360;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe360
	if (cr0.eq) goto loc_823FE360;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE354:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe354
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE354;
loc_823FE360:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,8272
	ctx.r5.u64 = r30.u64 | 542113792;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// oris r5,r30,4176
	ctx.r5.u64 = r30.u64 | 273678336;
	// b 0x82402760
	goto loc_82402760;
loc_823FE39C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe3d8
	if (cr6.eq) goto loc_823FE3D8;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe3d8
	if (cr0.eq) goto loc_823FE3D8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE3CC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe3cc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE3CC;
loc_823FE3D8:
	// li r11,261
	r11.s64 = 261;
loc_823FE3DC:
	// li r9,4
	ctx.r9.s64 = 4;
	// b 0x823fd59c
	goto loc_823FD59C;
loc_823FE3E4:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// li r29,-1
	r29.s64 = -1;
	// lwz r8,152(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// clrlwi r25,r30,12
	r25.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,148(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r6,r1,360
	ctx.r6.s64 = ctx.r1.s64 + 360;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r29,360(r1)
	PPC_STORE_U32(ctx.r1.u32 + 360, r29.u32);
	// oris r5,r25,20480
	ctx.r5.u64 = r25.u64 | 1342177280;
	// stw r29,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, r29.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,8240
	ctx.r5.s64 = 540016640;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r8,r14,36
	ctx.r8.s64 = r14.s64 + 36;
	// addi r7,r1,360
	ctx.r7.s64 = ctx.r1.s64 + 360;
	// addi r6,r1,340
	ctx.r6.s64 = ctx.r1.s64 + 340;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r11,4
	r11.s64 = 4;
loc_823FE494:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r31,r10
	ctx.r10.u64 = r31.u64 + ctx.r10.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fe494
	if (!cr0.eq) goto loc_823FE494;
	// lwz r24,172(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe4d4
	if (cr6.eq) goto loc_823FE4D4;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_823FE4C0:
	// lwz r9,340(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x823fe4c0
	if (!cr0.eq) goto loc_823FE4C0;
loc_823FE4D4:
	// lwz r27,160(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe500
	if (cr6.eq) goto loc_823FE500;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe500
	if (cr0.eq) goto loc_823FE500;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE4F4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe4f4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE4F4;
loc_823FE500:
	// lwz r26,164(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe52c
	if (cr6.eq) goto loc_823FE52C;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe52c
	if (cr0.eq) goto loc_823FE52C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE520:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe520
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE520;
loc_823FE52C:
	// lwz r28,168(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe57c
	if (cr6.eq) goto loc_823FE57C;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe558
	if (cr0.eq) goto loc_823FE558;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE54C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe54c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE54C;
loc_823FE558:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe57c
	if (cr6.eq) goto loc_823FE57C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe57c
	if (cr0.eq) goto loc_823FE57C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE570:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe570
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE570;
loc_823FE57C:
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// oris r5,r25,4112
	ctx.r5.u64 = r25.u64 | 269484032;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r30,r25,8256
	r30.u64 = r25.u64 | 541065216;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r25,8272
	ctx.r5.u64 = r25.u64 | 542113792;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FE60C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// rlwinm r4,r30,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// add r27,r11,r28
	r27.u64 = r11.u64 + r28.u64;
	// li r29,-1
	r29.s64 = -1;
	// beq cr6,0x823fe6b4
	if (cr6.eq) goto loc_823FE6B4;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe668
	if (cr0.eq) goto loc_823FE668;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE65C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe65c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE65C;
loc_823FE668:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe6b4
	if (cr6.eq) goto loc_823FE6B4;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe690
	if (cr0.eq) goto loc_823FE690;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE684:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe684
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE684;
loc_823FE690:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe6b4
	if (cr6.eq) goto loc_823FE6B4;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe6b4
	if (cr0.eq) goto loc_823FE6B4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE6A8:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe6a8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE6A8;
loc_823FE6B4:
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// li r9,20
	ctx.r9.s64 = 20;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4160
	ctx.r5.u64 = r30.u64 | 272629760;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,24
	ctx.r9.s64 = 24;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// b 0x823fcfb8
	goto loc_823FCFB8;
loc_823FE6F0:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// rlwinm r4,r30,3,0,28
	ctx.r4.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,8
	r11.s64 = 8;
loc_823FE730:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fe730
	if (!cr0.eq) goto loc_823FE730;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r8,8
	ctx.r8.s64 = 8;
	// li r29,-1
	r29.s64 = -1;
loc_823FE754:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe77c
	if (cr6.eq) goto loc_823FE77C;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe77c
	if (cr0.eq) goto loc_823FE77C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE770:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe770
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE770;
loc_823FE77C:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fe754
	if (!cr0.eq) goto loc_823FE754;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe7ac
	if (cr6.eq) goto loc_823FE7AC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe7ac
	if (cr0.eq) goto loc_823FE7AC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE7A0:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe7a0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE7A0;
loc_823FE7AC:
	// lwz r23,148(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// clrlwi r29,r30,12
	r29.u64 = r30.u32 & 0xFFFFF;
	// lwz r28,160(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r29,4144
	ctx.r5.u64 = r29.u64 | 271581184;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// lwz r28,164(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// oris r24,r29,8272
	r24.u64 = r29.u64 | 542113792;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r27,168(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// oris r25,r29,4112
	r25.u64 = r29.u64 | 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r26,172(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r29,8208
	ctx.r5.u64 = r29.u64 | 537919488;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// lwz r26,176(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r9,20
	ctx.r9.s64 = 20;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r29,4160
	ctx.r5.u64 = r29.u64 | 272629760;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// lwz r28,180(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r29,8240
	ctx.r5.u64 = r29.u64 | 540016640;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r29,184(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// lwz r30,188(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f8108
	sub_823F8108(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FE92C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fe968
	if (cr6.eq) goto loc_823FE968;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fe968
	if (cr0.eq) goto loc_823FE968;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE95C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe95c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE95C;
loc_823FE968:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r11,65
	r11.s64 = 65;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwimi r5,r11,22,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 22) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x823fd5a4
	goto loc_823FD5A4;
loc_823FE97C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r16,r3
	r16.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r16.s32, 0, xer);
	// stw r16,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r16.u32);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// mulli r4,r30,10
	ctx.r4.s64 = r30.s64 * 10;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r11,10
	r11.s64 = 10;
loc_823FE9C0:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fe9c0
	if (!cr0.eq) goto loc_823FE9C0;
	// lwz r18,160(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fea08
	if (cr6.eq) goto loc_823FEA08;
	// mr r11,r18
	r11.u64 = r18.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fea08
	if (cr0.eq) goto loc_823FEA08;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FE9FC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fe9fc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FE9FC;
loc_823FEA08:
	// lwz r23,164(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fea34
	if (cr6.eq) goto loc_823FEA34;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fea34
	if (cr0.eq) goto loc_823FEA34;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEA28:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fea28
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEA28;
loc_823FEA34:
	// lwz r27,168(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fea60
	if (cr6.eq) goto loc_823FEA60;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fea60
	if (cr0.eq) goto loc_823FEA60;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEA54:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fea54
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEA54;
loc_823FEA60:
	// lwz r20,172(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fea8c
	if (cr6.eq) goto loc_823FEA8C;
	// mr r11,r20
	r11.u64 = r20.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fea8c
	if (cr0.eq) goto loc_823FEA8C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEA80:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fea80
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEA80;
loc_823FEA8C:
	// lwz r21,176(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823feab8
	if (cr6.eq) goto loc_823FEAB8;
	// mr r11,r21
	r11.u64 = r21.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823feab8
	if (cr0.eq) goto loc_823FEAB8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEAAC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823feaac
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEAAC;
loc_823FEAB8:
	// lwz r22,180(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823feae4
	if (cr6.eq) goto loc_823FEAE4;
	// mr r11,r22
	r11.u64 = r22.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823feae4
	if (cr0.eq) goto loc_823FEAE4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEAD8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fead8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEAD8;
loc_823FEAE4:
	// lwz r24,184(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823feb10
	if (cr6.eq) goto loc_823FEB10;
	// mr r11,r24
	r11.u64 = r24.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823feb10
	if (cr0.eq) goto loc_823FEB10;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEB04:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823feb04
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEB04;
loc_823FEB10:
	// lwz r25,188(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823feb64
	if (cr6.eq) goto loc_823FEB64;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823feb3c
	if (cr0.eq) goto loc_823FEB3C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEB30:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823feb30
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEB30;
loc_823FEB3C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823feb64
	if (cr6.eq) goto loc_823FEB64;
	// mr r11,r16
	r11.u64 = r16.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823feb64
	if (cr0.eq) goto loc_823FEB64;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEB58:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823feb58
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEB58;
loc_823FEB64:
	// clrlwi r28,r30,12
	r28.u64 = r30.u32 & 0xFFFFF;
	// lwz r17,144(r1)
	r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// oris r26,r28,4112
	r26.u64 = r28.u64 | 269484032;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// oris r5,r28,8208
	ctx.r5.u64 = r28.u64 | 537919488;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// oris r5,r28,8240
	ctx.r5.u64 = r28.u64 | 540016640;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r27,r28,8256
	r27.u64 = r28.u64 | 541065216;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// oris r5,r28,4192
	ctx.r5.u64 = r28.u64 | 274726912;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,20
	ctx.r9.s64 = 20;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// oris r5,r28,4160
	ctx.r5.u64 = r28.u64 | 272629760;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r26,192(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fed10
	if (cr6.eq) goto loc_823FED10;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fed10
	if (cr0.eq) goto loc_823FED10;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FED04:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fed04
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FED04;
loc_823FED10:
	// lwz r27,196(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fed60
	if (cr6.eq) goto loc_823FED60;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fed3c
	if (cr0.eq) goto loc_823FED3C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FED30:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fed30
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FED30;
loc_823FED3C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fed60
	if (cr6.eq) goto loc_823FED60;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fed60
	if (cr0.eq) goto loc_823FED60;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FED54:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fed54
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FED54;
loc_823FED60:
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r16
	ctx.r7.u64 = r16.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r28,4176
	ctx.r5.u64 = r28.u64 | 273678336;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// oris r5,r28,4144
	ctx.r5.u64 = r28.u64 | 271581184;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
loc_823FEDB8:
	// oris r5,r28,8272
	ctx.r5.u64 = r28.u64 | 542113792;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FEDC0:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mulli r4,r30,6
	ctx.r4.s64 = r30.s64 * 6;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,6
	r11.s64 = 6;
loc_823FEDF4:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823fedf4
	if (!cr0.eq) goto loc_823FEDF4;
	// lwz r23,160(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fee3c
	if (cr6.eq) goto loc_823FEE3C;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fee3c
	if (cr0.eq) goto loc_823FEE3C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEE30:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fee30
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEE30;
loc_823FEE3C:
	// lwz r22,164(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fee68
	if (cr6.eq) goto loc_823FEE68;
	// mr r11,r22
	r11.u64 = r22.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fee68
	if (cr0.eq) goto loc_823FEE68;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEE5C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fee5c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEE5C;
loc_823FEE68:
	// lwz r21,168(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fee94
	if (cr6.eq) goto loc_823FEE94;
	// mr r11,r21
	r11.u64 = r21.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fee94
	if (cr0.eq) goto loc_823FEE94;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEE88:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fee88
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEE88;
loc_823FEE94:
	// lwz r25,172(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823feec0
	if (cr6.eq) goto loc_823FEEC0;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823feec0
	if (cr0.eq) goto loc_823FEEC0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEEB4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823feeb4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEEB4;
loc_823FEEC0:
	// lwz r24,176(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823feeec
	if (cr6.eq) goto loc_823FEEEC;
	// mr r11,r24
	r11.u64 = r24.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823feeec
	if (cr0.eq) goto loc_823FEEEC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEEE0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823feee0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEEE0;
loc_823FEEEC:
	// lwz r26,180(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fef3c
	if (cr6.eq) goto loc_823FEF3C;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fef18
	if (cr0.eq) goto loc_823FEF18;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEF0C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fef0c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEF0C;
loc_823FEF18:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fef3c
	if (cr6.eq) goto loc_823FEF3C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fef3c
	if (cr0.eq) goto loc_823FEF3C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FEF30:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fef30
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FEF30;
loc_823FEF3C:
	// lwz r27,144(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4304
	ctx.r5.u64 = r30.u64 | 282066944;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r28,r30,4112
	r28.u64 = r30.u64 | 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r29,r30,8208
	r29.u64 = r30.u64 | 537919488;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// oris r5,r30,4320
	ctx.r5.u64 = r30.u64 | 283115520;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// b 0x823fcfe4
	goto loc_823FCFE4;
loc_823FF04C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823ff2d8
	if (!cr0.eq) goto loc_823FF2D8;
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r11,4
	r11.s64 = 4;
loc_823FF090:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823ff090
	if (!cr0.eq) goto loc_823FF090;
	// lwz r23,160(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff0d8
	if (cr6.eq) goto loc_823FF0D8;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff0d8
	if (cr0.eq) goto loc_823FF0D8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF0CC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff0cc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF0CC;
loc_823FF0D8:
	// lwz r24,164(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff104
	if (cr6.eq) goto loc_823FF104;
	// mr r11,r24
	r11.u64 = r24.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff104
	if (cr0.eq) goto loc_823FF104;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF0F8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff0f8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF0F8;
loc_823FF104:
	// lwz r27,168(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff130
	if (cr6.eq) goto loc_823FF130;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff130
	if (cr0.eq) goto loc_823FF130;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF124:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff124
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF124;
loc_823FF130:
	// lwz r25,172(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff180
	if (cr6.eq) goto loc_823FF180;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff15c
	if (cr0.eq) goto loc_823FF15C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF150:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff150
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF150;
loc_823FF15C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff180
	if (cr6.eq) goto loc_823FF180;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff180
	if (cr0.eq) goto loc_823FF180;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF174:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff174
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF174;
loc_823FF180:
	// clrlwi r29,r30,12
	r29.u64 = r30.u32 & 0xFFFFF;
	// lwz r26,144(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,64
	ctx.r9.s64 = 64;
	// oris r28,r29,4112
	r28.u64 = r29.u64 | 269484032;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,64
	ctx.r9.s64 = 64;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// oris r5,r29,8256
	ctx.r5.u64 = r29.u64 | 541065216;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,64
	ctx.r9.s64 = 64;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// oris r5,r29,8272
	ctx.r5.u64 = r29.u64 | 542113792;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,64
	ctx.r9.s64 = 64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,87
	ctx.r9.s64 = 87;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// oris r5,r29,8240
	ctx.r5.u64 = r29.u64 | 540016640;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r27,r22
	r27.u64 = r22.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r29,r15
	r29.u64 = r15.u64;
	// subf r28,r15,r26
	r28.s64 = r26.s64 - r15.s64;
loc_823FF268:
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// lwzx r4,r28,r29
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + r29.u32);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lfd f0,176(r14)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r14.u32 + 176);
	// lfd f13,160(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// lfd f12,168(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x823ff2a8
	if (!cr6.gt) goto loc_823FF2A8;
	// lfd f11,168(r14)
	ctx.f11.u64 = PPC_LOAD_U64(r14.u32 + 168);
	// fcmpu cr6,f12,f11
	cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// bge cr6,0x823ff2a8
	if (!cr6.lt) goto loc_823FF2A8;
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// b 0x823ff2c0
	goto loc_823FF2C0;
loc_823FF2A8:
	// lfd f11,168(r14)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(r14.u32 + 168);
	// fcmpu cr6,f13,f11
	cr6.compare(ctx.f13.f64, ctx.f11.f64);
	// beq cr6,0x823ff2bc
	if (cr6.eq) goto loc_823FF2BC;
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// bne cr6,0x823ff2c4
	if (!cr6.eq) goto loc_823FF2C4;
loc_823FF2BC:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
loc_823FF2C0:
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_823FF2C4:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r27,r30
	cr6.compare<uint32_t>(r27.u32, r30.u32, xer);
	// blt cr6,0x823ff268
	if (cr6.lt) goto loc_823FF268;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_823FF2D8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r11,r15
	r11.u64 = r15.u64;
loc_823FF2E4:
	// lwz r10,32(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823ff2e4
	if (!cr0.eq) goto loc_823FF2E4;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_823FF2FC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823ff558
	if (!cr0.eq) goto loc_823FF558;
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r11,4
	r11.s64 = 4;
loc_823FF340:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r31,r10
	ctx.r10.u64 = r31.u64 + ctx.r10.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823ff340
	if (!cr0.eq) goto loc_823FF340;
	// lwz r25,160(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff388
	if (cr6.eq) goto loc_823FF388;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff388
	if (cr0.eq) goto loc_823FF388;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF37C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff37c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF37C;
loc_823FF388:
	// lwz r27,164(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff3b4
	if (cr6.eq) goto loc_823FF3B4;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff3b4
	if (cr0.eq) goto loc_823FF3B4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF3A8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff3a8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF3A8;
loc_823FF3B4:
	// lwz r26,168(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff42c
	if (cr6.eq) goto loc_823FF42C;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff3e0
	if (cr0.eq) goto loc_823FF3E0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF3D4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff3d4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF3D4;
loc_823FF3E0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff42c
	if (cr6.eq) goto loc_823FF42C;
	// lwz r11,172(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff408
	if (cr0.eq) goto loc_823FF408;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF3FC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff3fc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF3FC;
loc_823FF408:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff42c
	if (cr6.eq) goto loc_823FF42C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff42c
	if (cr0.eq) goto loc_823FF42C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF420:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff420
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF420;
loc_823FF42C:
	// lwz r28,144(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r29,r30,12
	r29.u64 = r30.u32 & 0xFFFFF;
	// li r9,64
	ctx.r9.s64 = 64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r29,4144
	ctx.r5.u64 = r29.u64 | 271581184;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,64
	ctx.r9.s64 = 64;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// oris r5,r29,8272
	ctx.r5.u64 = r29.u64 | 542113792;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,64
	ctx.r9.s64 = 64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r29,4112
	ctx.r5.u64 = r29.u64 | 269484032;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,87
	ctx.r9.s64 = 87;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// oris r5,r29,8240
	ctx.r5.u64 = r29.u64 | 540016640;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r27,r22
	r27.u64 = r22.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r29,r15
	r29.u64 = r15.u64;
	// subf r28,r15,r28
	r28.s64 = r28.s64 - r15.s64;
loc_823FF4E8:
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// lwzx r4,r29,r28
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + r28.u32);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lfd f0,176(r14)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r14.u32 + 176);
	// lfd f13,160(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// lfd f12,168(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x823ff528
	if (!cr6.gt) goto loc_823FF528;
	// lfd f11,168(r14)
	ctx.f11.u64 = PPC_LOAD_U64(r14.u32 + 168);
	// fcmpu cr6,f12,f11
	cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// bge cr6,0x823ff528
	if (!cr6.lt) goto loc_823FF528;
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// b 0x823ff540
	goto loc_823FF540;
loc_823FF528:
	// lfd f11,168(r14)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(r14.u32 + 168);
	// fcmpu cr6,f13,f11
	cr6.compare(ctx.f13.f64, ctx.f11.f64);
	// beq cr6,0x823ff53c
	if (cr6.eq) goto loc_823FF53C;
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// bne cr6,0x823ff544
	if (!cr6.eq) goto loc_823FF544;
loc_823FF53C:
	// lwz r11,32(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 32);
loc_823FF540:
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_823FF544:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r27,r30
	cr6.compare<uint32_t>(r27.u32, r30.u32, xer);
	// blt cr6,0x823ff4e8
	if (cr6.lt) goto loc_823FF4E8;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_823FF558:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r11,r15
	r11.u64 = r15.u64;
loc_823FF564:
	// lwz r10,36(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823ff564
	if (!cr0.eq) goto loc_823FF564;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_823FF57C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823ff800
	if (!cr0.eq) goto loc_823FF800;
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r11,4
	r11.s64 = 4;
loc_823FF5C0:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r31,r10
	ctx.r10.u64 = r31.u64 + ctx.r10.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823ff5c0
	if (!cr0.eq) goto loc_823FF5C0;
	// lwz r25,160(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff608
	if (cr6.eq) goto loc_823FF608;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff608
	if (cr0.eq) goto loc_823FF608;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF5FC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff5fc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF5FC;
loc_823FF608:
	// lwz r23,164(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff634
	if (cr6.eq) goto loc_823FF634;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff634
	if (cr0.eq) goto loc_823FF634;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF628:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff628
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF628;
loc_823FF634:
	// lwz r27,168(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff660
	if (cr6.eq) goto loc_823FF660;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff660
	if (cr0.eq) goto loc_823FF660;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF654:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff654
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF654;
loc_823FF660:
	// lwz r24,172(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff6b0
	if (cr6.eq) goto loc_823FF6B0;
	// mr r11,r24
	r11.u64 = r24.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff68c
	if (cr0.eq) goto loc_823FF68C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF680:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff680
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF680;
loc_823FF68C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff6b0
	if (cr6.eq) goto loc_823FF6B0;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff6b0
	if (cr0.eq) goto loc_823FF6B0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF6A4:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff6a4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF6A4;
loc_823FF6B0:
	// lwz r26,144(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r29,r30,12
	r29.u64 = r30.u32 & 0xFFFFF;
	// li r9,64
	ctx.r9.s64 = 64;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r29,8272
	ctx.r5.u64 = r29.u64 | 542113792;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r28,r29,4112
	r28.u64 = r29.u64 | 269484032;
	// li r9,64
	ctx.r9.s64 = 64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r29,r29,8240
	r29.u64 = r29.u64 | 540016640;
	// li r9,87
	ctx.r9.s64 = 87;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,90
	ctx.r9.s64 = 90;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,87
	ctx.r9.s64 = 87;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r27,r22
	r27.u64 = r22.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r29,r15
	r29.u64 = r15.u64;
	// subf r28,r15,r26
	r28.s64 = r26.s64 - r15.s64;
loc_823FF79C:
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// lwzx r4,r29,r28
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + r28.u32);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lfd f12,176(r14)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r14.u32 + 176);
	// lfd f11,160(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// fcmpu cr6,f11,f12
	cr6.compare(ctx.f11.f64, ctx.f12.f64);
	// bgt cr6,0x823ff7e4
	if (cr6.gt) goto loc_823FF7E4;
	// lfd f0,168(r14)
	f0.u64 = PPC_LOAD_U64(r14.u32 + 168);
	// lfd f13,168(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x823ff7e4
	if (cr6.lt) goto loc_823FF7E4;
	// fcmpu cr6,f11,f0
	cr6.compare(ctx.f11.f64, f0.f64);
	// beq cr6,0x823ff7e4
	if (cr6.eq) goto loc_823FF7E4;
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bne cr6,0x823ff7ec
	if (!cr6.eq) goto loc_823FF7EC;
loc_823FF7E4:
	// lwz r11,36(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_823FF7EC:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r27,r30
	cr6.compare<uint32_t>(r27.u32, r30.u32, xer);
	// blt cr6,0x823ff79c
	if (cr6.lt) goto loc_823FF79C;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_823FF800:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r11,r15
	r11.u64 = r15.u64;
loc_823FF80C:
	// lwz r10,36(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823ff80c
	if (!cr0.eq) goto loc_823FF80C;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_823FF824:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff89c
	if (cr6.eq) goto loc_823FF89C;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff878
	if (cr0.eq) goto loc_823FF878;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF86C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff86c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF86C;
loc_823FF878:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ff89c
	if (cr6.eq) goto loc_823FF89C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff89c
	if (cr0.eq) goto loc_823FF89C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF890:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff890
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF890;
loc_823FF89C:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,148(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4176
	ctx.r5.u64 = r30.u64 | 273678336;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
loc_823FF8CC:
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// oris r5,r30,8272
	ctx.r5.u64 = r30.u64 | 542113792;
	// b 0x8240275c
	goto loc_8240275C;
loc_823FF8D8:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r5,160(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// bne cr6,0x823ff948
	if (!cr6.eq) goto loc_823FF948;
	// lwz r30,144(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r29,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, r29.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// addi r6,r1,368
	ctx.r6.s64 = ctx.r1.s64 + 368;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// addi r8,r1,368
	ctx.r8.s64 = ctx.r1.s64 + 368;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lis r5,8208
	ctx.r5.s64 = 537919488;
	// b 0x823fca84
	goto loc_823FCA84;
loc_823FF948:
	// stw r29,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, r29.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r29,376(r1)
	PPC_STORE_U32(ctx.r1.u32 + 376, r29.u32);
	// beq cr6,0x823ff974
	if (cr6.eq) goto loc_823FF974;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ff974
	if (cr0.eq) goto loc_823FF974;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FF968:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ff968
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FF968;
loc_823FF974:
	// lwz r8,144(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r11,5
	r11.s64 = 5;
	// li r9,4
	ctx.r9.s64 = 4;
	// rlwimi r5,r11,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// addi r6,r1,348
	ctx.r6.s64 = ctx.r1.s64 + 348;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4208
	ctx.r5.s64 = 275775488;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,348
	ctx.r7.s64 = ctx.r1.s64 + 348;
	// addi r6,r1,376
	ctx.r6.s64 = ctx.r1.s64 + 376;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r7,r1,376
	ctx.r7.s64 = ctx.r1.s64 + 376;
	// b 0x823fe14c
	goto loc_823FE14C;
loc_823FF9D4:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// lwz r8,152(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// lwz r7,148(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// lwz r6,144(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f8108
	sub_823F8108(ctx, base);
	// b 0x82402770
	goto loc_82402770;
loc_823FFA24:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// bne cr6,0x82403490
	if (!cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm. r11,r11,0,7,7
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ffac4
	if (cr0.eq) goto loc_823FFAC4;
	// lwz r10,144(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r11,-1
	r11.s64 = -1;
	// lis r5,20496
	ctx.r5.s64 = 1343225856;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,640
	ctx.r7.s64 = ctx.r1.s64 + 640;
	// ori r5,r5,4
	ctx.r5.u64 = ctx.r5.u64 | 4;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r10,640(r1)
	PPC_STORE_U32(ctx.r1.u32 + 640, ctx.r10.u32);
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r10,644(r1)
	PPC_STORE_U32(ctx.r1.u32 + 644, ctx.r10.u32);
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r8,648(r1)
	PPC_STORE_U32(ctx.r1.u32 + 648, ctx.r8.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r10,652(r1)
	PPC_STORE_U32(ctx.r1.u32 + 652, ctx.r10.u32);
	// stw r11,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r11.u32);
	// stw r11,4(r15)
	PPC_STORE_U32(r15.u32 + 4, r11.u32);
	// stw r11,8(r15)
	PPC_STORE_U32(r15.u32 + 8, r11.u32);
	// stw r11,12(r15)
	PPC_STORE_U32(r15.u32 + 12, r11.u32);
	// b 0x82402764
	goto loc_82402764;
loc_823FFAC4:
	// li r4,6
	ctx.r4.s64 = 6;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// subf r9,r10,r3
	ctx.r9.s64 = ctx.r3.s64 - ctx.r10.s64;
	// li r10,6
	ctx.r10.s64 = 6;
loc_823FFAE4:
	// add r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 + r11.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x823ffae4
	if (!cr0.eq) goto loc_823FFAE4;
	// li r29,-1
	r29.s64 = -1;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r10,6
	ctx.r10.s64 = 6;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_823FFB0C:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ffb0c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFB0C;
	// lwz r30,144(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// lwz r28,160(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r29,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r29.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r29,4(r15)
	PPC_STORE_U32(r15.u32 + 4, r29.u32);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// stw r29,8(r15)
	PPC_STORE_U32(r15.u32 + 8, r29.u32);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// stw r29,12(r15)
	PPC_STORE_U32(r15.u32 + 12, r29.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r27,164(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lis r5,8224
	ctx.r5.s64 = 538968064;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r11,8272
	r11.s64 = 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r28,r11,1
	r28.u64 = r11.u64 | 1;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// addi r6,r15,4
	ctx.r6.s64 = r15.s64 + 4;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r29,148(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// lwz r30,168(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r30,172(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lis r5,8224
	ctx.r5.s64 = 538968064;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// lwz r27,176(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r30,180(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r7,152(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f8630
	sub_823F8630(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// addi r6,r15,8
	ctx.r6.s64 = r15.s64 + 8;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r30,r14,32
	r30.s64 = r14.s64 + 32;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// li r9,23
	ctx.r9.s64 = 23;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// li r9,23
	ctx.r9.s64 = 23;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// addi r6,r15,12
	ctx.r6.s64 = r15.s64 + 12;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// b 0x82402768
	goto loc_82402768;
loc_823FFCEC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r31,8(r14)
	r31.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lfd f1,264(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 264);
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm r4,r30,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,2
	r11.s64 = 2;
loc_823FFD48:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x823ffd48
	if (!cr0.eq) goto loc_823FFD48;
	// lwz r27,128(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ffd88
	if (cr6.eq) goto loc_823FFD88;
	// mr r11,r27
	r11.u64 = r27.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ffd88
	if (cr0.eq) goto loc_823FFD88;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFD7C:
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ffd7c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFD7C;
loc_823FFD88:
	// lwz r28,132(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ffddc
	if (cr6.eq) goto loc_823FFDDC;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ffdb8
	if (cr0.eq) goto loc_823FFDB8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFDAC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ffdac
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFDAC;
loc_823FFDB8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ffddc
	if (cr6.eq) goto loc_823FFDDC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ffddc
	if (cr0.eq) goto loc_823FFDDC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFDD0:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ffdd0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFDD0;
loc_823FFDDC:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4192
	ctx.r5.u64 = r30.u64 | 274726912;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// b 0x823ff8cc
	goto loc_823FF8CC;
loc_823FFE10:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r31,8(r14)
	r31.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lfd f1,264(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 264);
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// lfd f1,32128(r11)
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 32128);
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fdiv f1,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64 / ctx.f1.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm r4,r30,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,2
	r11.s64 = 2;
loc_823FFE80:
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r3,r3,r9
	ctx.r3.u64 = ctx.r3.u64 + ctx.r9.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x823ffe80
	if (!cr0.eq) goto loc_823FFE80;
	// lwz r27,128(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ffec0
	if (cr6.eq) goto loc_823FFEC0;
	// mr r11,r27
	r11.u64 = r27.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ffec0
	if (cr0.eq) goto loc_823FFEC0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFEB4:
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ffeb4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFEB4;
loc_823FFEC0:
	// lwz r28,132(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ffddc
	if (cr6.eq) goto loc_823FFDDC;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ffef0
	if (cr0.eq) goto loc_823FFEF0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFEE4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ffee4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFEE4;
loc_823FFEF0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ffddc
	if (cr6.eq) goto loc_823FFDDC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ffddc
	if (cr0.eq) goto loc_823FFDDC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFF08:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fff08
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFF08;
	// b 0x823ffddc
	goto loc_823FFDDC;
loc_823FFF18:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fff54
	if (cr6.eq) goto loc_823FFF54;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fff54
	if (cr0.eq) goto loc_823FFF54;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFF48:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fff48
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFF48;
loc_823FFF54:
	// li r11,131
	r11.s64 = 131;
	// b 0x823fd5f0
	goto loc_823FD5F0;
loc_823FFF5C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fffa4
	if (cr6.eq) goto loc_823FFFA4;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fffa4
	if (cr0.eq) goto loc_823FFFA4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFF98:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823fff98
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFF98;
loc_823FFFA4:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r11,513
	r11.s64 = 513;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x823fe1b0
	goto loc_823FE1B0;
loc_823FFFB4:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823ffffc
	if (cr6.eq) goto loc_823FFFFC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823ffffc
	if (cr0.eq) goto loc_823FFFFC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_823FFFF0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x823ffff0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFFF0;
loc_823FFFFC:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r11,1
	r11.s64 = 1;
	// rlwimi r5,r11,29,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 29) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x823fe1b0
	goto loc_823FE1B0;
loc_8240000C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r19,r3
	r19.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r19.s32, 0, xer);
	// stw r19,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r19.u32);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// mulli r4,r30,10
	ctx.r4.s64 = r30.s64 * 10;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r11,10
	r11.s64 = 10;
loc_82400050:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82400050
	if (!cr0.eq) goto loc_82400050;
	// lwz r17,160(r1)
	r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400098
	if (cr6.eq) goto loc_82400098;
	// mr r11,r17
	r11.u64 = r17.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400098
	if (cr0.eq) goto loc_82400098;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240008C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240008c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240008C;
loc_82400098:
	// lwz r16,164(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824000c4
	if (cr6.eq) goto loc_824000C4;
	// mr r11,r16
	r11.u64 = r16.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824000c4
	if (cr0.eq) goto loc_824000C4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824000B8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824000b8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824000B8;
loc_824000C4:
	// lwz r27,168(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824000f0
	if (cr6.eq) goto loc_824000F0;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824000f0
	if (cr0.eq) goto loc_824000F0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824000E4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824000e4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824000E4;
loc_824000F0:
	// lwz r15,172(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240011c
	if (cr6.eq) goto loc_8240011C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240011c
	if (cr0.eq) goto loc_8240011C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400110:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400110
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400110;
loc_8240011C:
	// lwz r20,176(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400148
	if (cr6.eq) goto loc_82400148;
	// mr r11,r20
	r11.u64 = r20.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400148
	if (cr0.eq) goto loc_82400148;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240013C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240013c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240013C;
loc_82400148:
	// lwz r18,180(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400174
	if (cr6.eq) goto loc_82400174;
	// mr r11,r18
	r11.u64 = r18.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400174
	if (cr0.eq) goto loc_82400174;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400168:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400168
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400168;
loc_82400174:
	// lwz r21,184(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824001a0
	if (cr6.eq) goto loc_824001A0;
	// mr r11,r21
	r11.u64 = r21.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824001a0
	if (cr0.eq) goto loc_824001A0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400194:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400194
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400194;
loc_824001A0:
	// lwz r22,188(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824001cc
	if (cr6.eq) goto loc_824001CC;
	// mr r11,r22
	r11.u64 = r22.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824001cc
	if (cr0.eq) goto loc_824001CC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824001C0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824001c0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824001C0;
loc_824001CC:
	// lwz r23,192(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400220
	if (cr6.eq) goto loc_82400220;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824001f8
	if (cr0.eq) goto loc_824001F8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824001EC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824001ec
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824001EC;
loc_824001F8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400220
	if (cr6.eq) goto loc_82400220;
	// mr r11,r19
	r11.u64 = r19.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400220
	if (cr0.eq) goto loc_82400220;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400214:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400214
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400214;
loc_82400220:
	// lwz r24,144(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r28,r30,12
	r28.u64 = r30.u32 & 0xFFFFF;
	// lwz r25,1724(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r28,4128
	ctx.r5.u64 = r28.u64 | 270532608;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,20
	ctx.r9.s64 = 20;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// oris r5,r28,4160
	ctx.r5.u64 = r28.u64 | 272629760;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r26,r28,4112
	r26.u64 = r28.u64 | 269484032;
	// li r9,24
	ctx.r9.s64 = 24;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r16
	ctx.r7.u64 = r16.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// lwz r17,1724(r1)
	r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	// oris r25,r28,8256
	r25.u64 = r28.u64 | 541065216;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r27,r28,8224
	r27.u64 = r28.u64 | 538968064;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r16
	ctx.r7.u64 = r16.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// oris r5,r28,8272
	ctx.r5.u64 = r28.u64 | 542113792;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r27,1732(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r28,196(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400428
	if (cr6.eq) goto loc_82400428;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400404
	if (cr0.eq) goto loc_82400404;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824003F8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824003f8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824003F8;
loc_82400404:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400428
	if (cr6.eq) goto loc_82400428;
	// mr r11,r27
	r11.u64 = r27.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400428
	if (cr0.eq) goto loc_82400428;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240041C:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240041c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240041C;
loc_82400428:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,16
	ctx.r9.s64 = 16;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// b 0x8240276c
	goto loc_8240276C;
loc_82400470:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824004f4
	if (cr6.eq) goto loc_824004F4;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_824004B4:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x824004b4
	if (!cr0.eq) goto loc_824004B4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824004f4
	if (cr6.eq) goto loc_824004F4;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824004f4
	if (cr0.eq) goto loc_824004F4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824004E8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824004e8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824004E8;
loc_824004F4:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r11,517
	r11.s64 = 517;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x8240275c
	goto loc_8240275C;
loc_82400508:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd694
	if (cr6.eq) goto loc_823FD694;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8240054C:
	// lwz r9,148(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8240054c
	if (!cr0.eq) goto loc_8240054C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd694
	if (cr6.eq) goto loc_823FD694;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd694
	if (cr0.eq) goto loc_823FD694;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400580:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400580
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400580;
	// b 0x823fd694
	goto loc_823FD694;
loc_82400590:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r29,132(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r28,16(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x82403490
	if (cr0.eq) goto loc_82403490;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82403490
	if (!cr6.eq) goto loc_82403490;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x824005dc
	if (!cr6.eq) goto loc_824005DC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// b 0x82400600
	goto loc_82400600;
loc_824005DC:
	// li r9,1024
	ctx.r9.s64 = 1024;
	// lwz r5,20(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r8,32(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r7,28(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// addi r3,r1,1488
	ctx.r3.s64 = ctx.r1.s64 + 1488;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// addi r4,r1,1488
	ctx.r4.s64 = ctx.r1.s64 + 1488;
loc_82400600:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// lwz r6,160(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r29,16(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r14,32(r28)
	r14.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// lwz r15,28(r28)
	r15.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x82403490
	if (cr0.eq) goto loc_82403490;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82403490
	if (!cr6.eq) goto loc_82403490;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82400674
	if (!cr6.eq) goto loc_82400674;
	// lwz r26,164(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r27,148(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// lwz r3,1716(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r16,32(r29)
	r16.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// lwz r18,28(r29)
	r18.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// b 0x824006c0
	goto loc_824006C0;
loc_82400674:
	// li r9,2048
	ctx.r9.s64 = 2048;
	// lwz r5,20(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r8,32(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r7,28(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// addi r3,r1,1440
	ctx.r3.s64 = ctx.r1.s64 + 1440;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// lwz r26,164(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r27,148(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r4,r1,1440
	ctx.r4.s64 = ctx.r1.s64 + 1440;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// lwz r3,1716(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r16,28(r29)
	r16.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// lwz r18,32(r29)
	r18.u64 = PPC_LOAD_U32(r29.u32 + 32);
loc_824006C0:
	// cmplw cr6,r14,r16
	cr6.compare<uint32_t>(r14.u32, r16.u32, xer);
	// bne cr6,0x82403490
	if (!cr6.eq) goto loc_82403490;
	// mullw r11,r18,r15
	r11.s64 = int64_t(r18.s32) * int64_t(r15.s32);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x82403490
	if (!cr6.eq) goto loc_82403490;
	// lwz r31,1716(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// lwz r5,16(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,144(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// bl 0x823f4728
	sub_823F4728(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne 0x824008c4
	if (!cr0.eq) goto loc_824008C4;
	// mulli r4,r15,5
	ctx.r4.s64 = r15.s64 * 5;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// rlwinm r17,r15,2,0,29
	r17.u64 = __builtin_rotateleft64(r15.u32 | (r15.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,5
	r11.s64 = 5;
loc_82400718:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r17,r10
	ctx.r10.u64 = r17.u64 + ctx.r10.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82400718
	if (!cr0.eq) goto loc_82400718;
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r19,1732(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	// li r29,-1
	r29.s64 = -1;
	// lwz r20,176(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r25,172(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lwz r23,168(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r28,164(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r26,160(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
loc_82400758:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x82400880
	if (cr6.eq) goto loc_82400880;
	// clrlwi r24,r15,12
	r24.u64 = r15.u32 & 0xFFFFF;
	// oris r21,r24,8272
	r21.u64 = r24.u64 | 542113792;
loc_8240076C:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x824007dc
	if (cr6.eq) goto loc_824007DC;
	// mullw r11,r30,r18
	r11.s64 = int64_t(r30.s32) * int64_t(r18.s32);
	// add r9,r11,r22
	ctx.r9.u64 = r11.u64 + r22.u64;
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r9,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r11,r28
	r11.u64 = r28.u64;
	// rlwinm r8,r14,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// subf r7,r28,r26
	ctx.r7.s64 = r26.s64 - r28.s64;
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_8240079C:
	// lwz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// stwx r5,r7,r11
	PPC_STORE_U32(ctx.r7.u32 + r11.u32, ctx.r5.u32);
	// lwzx r5,r6,r27
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + r27.u32);
	// stw r5,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r5.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8240079c
	if (!cr0.eq) goto loc_8240079C;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r15,0
	cr0.compare<uint32_t>(r15.u32, 0, xer);
	// beq 0x824007dc
	if (cr0.eq) goto loc_824007DC;
	// mtctr r15
	ctr.u64 = r15.u64;
loc_824007D0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824007d0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824007D0;
loc_824007DC:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,1724(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// lwz r3,1716(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82400814
	if (!cr6.eq) goto loc_82400814;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// b 0x82400868
	goto loc_82400868;
loc_82400814:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x8240083c
	if (cr6.eq) goto loc_8240083C;
	// mr r11,r20
	r11.u64 = r20.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r15,0
	cr0.compare<uint32_t>(r15.u32, 0, xer);
	// beq 0x8240083c
	if (cr0.eq) goto loc_8240083C;
	// mtctr r15
	ctr.u64 = r15.u64;
loc_82400830:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400830
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400830;
loc_8240083C:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,1724(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// lwz r3,1716(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// oris r5,r24,8256
	ctx.r5.u64 = r24.u64 | 541065216;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
loc_82400868:
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r16
	cr6.compare<uint32_t>(r30.u32, r16.u32, xer);
	// blt cr6,0x8240076c
	if (cr6.lt) goto loc_8240076C;
loc_82400880:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x824008b0
	if (cr6.eq) goto loc_824008B0;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// rlwinm r8,r18,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
	// mr r11,r15
	r11.u64 = r15.u64;
loc_82400898:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// bne 0x82400898
	if (!cr0.eq) goto loc_82400898;
loc_824008B0:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// addi r19,r19,4
	r19.s64 = r19.s64 + 4;
	// cmplw cr6,r22,r18
	cr6.compare<uint32_t>(r22.u32, r18.u32, xer);
	// blt cr6,0x82400758
	if (cr6.lt) goto loc_82400758;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_824008C4:
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// lwz r5,16(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x823f4900
	sub_823F4900(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq 0x82400a04
	if (cr0.eq) goto loc_82400A04;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r20,r3
	r20.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r20.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x8240094c
	if (cr6.eq) goto loc_8240094C;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// rlwinm r4,r18,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
loc_8240090C:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x8240093c
	if (cr6.eq) goto loc_8240093C;
	// rlwinm r6,r16,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(r16.u32 | (r16.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
	// mr r11,r18
	r11.u64 = r18.u64;
loc_82400924:
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r3,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r3.u32);
	// add r9,r6,r9
	ctx.r9.u64 = ctx.r6.u64 + ctx.r9.u64;
	// bne 0x82400924
	if (!cr0.eq) goto loc_82400924;
loc_8240093C:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// add r8,r4,r8
	ctx.r8.u64 = ctx.r4.u64 + ctx.r8.u64;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x8240090c
	if (!cr0.eq) goto loc_8240090C;
loc_8240094C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400974
	if (cr6.eq) goto loc_82400974;
	// lwz r11,1732(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400974
	if (cr0.eq) goto loc_82400974;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400968:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400968
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400968;
loc_82400974:
	// li r21,0
	r21.s64 = 0;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r28,1732(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	// rlwinm r23,r18,2,0,29
	r23.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r27,144(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// rlwinm r22,r14,2,0,29
	r22.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
loc_82400990:
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x824009ec
	if (cr6.eq) goto loc_824009EC;
	// clrlwi r11,r14,12
	r11.u64 = r14.u32 & 0xFFFFF;
	// rlwinm r25,r16,2,0,29
	r25.u64 = __builtin_rotateleft64(r16.u32 | (r16.u64 << 32), 2) & 0xFFFFFFFC;
	// oris r26,r11,20480
	r26.u64 = r11.u64 | 1342177280;
	// mr r30,r28
	r30.u64 = r28.u64;
	// mr r29,r20
	r29.u64 = r20.u64;
loc_824009B0:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,1724(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r3,1716(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// add r29,r29,r25
	r29.u64 = r29.u64 + r25.u64;
	// cmplw cr6,r24,r18
	cr6.compare<uint32_t>(r24.u32, r18.u32, xer);
	// blt cr6,0x824009b0
	if (cr6.lt) goto loc_824009B0;
loc_824009EC:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// add r27,r27,r22
	r27.u64 = r27.u64 + r22.u64;
	// add r28,r23,r28
	r28.u64 = r23.u64 + r28.u64;
	// cmplw cr6,r21,r15
	cr6.compare<uint32_t>(r21.u32, r15.u32, xer);
	// blt cr6,0x82400990
	if (cr6.lt) goto loc_82400990;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_82400A04:
	// mulli r4,r18,5
	ctx.r4.s64 = r18.s64 * 5;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// rlwinm r17,r18,2,0,29
	r17.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,5
	r11.s64 = 5;
loc_82400A20:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r17,r10
	ctx.r10.u64 = r17.u64 + ctx.r10.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82400a20
	if (!cr0.eq) goto loc_82400A20;
	// li r16,0
	r16.s64 = 0;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r19,1732(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	// li r24,0
	r24.s64 = 0;
	// lwz r20,176(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r29,-1
	r29.s64 = -1;
	// lwz r26,172(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lwz r22,168(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r28,164(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r21,160(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
loc_82400A64:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x82400b88
	if (cr6.eq) goto loc_82400B88;
	// clrlwi r25,r18,12
	r25.u64 = r18.u32 & 0xFFFFF;
	// oris r23,r25,8272
	r23.u64 = r25.u64 | 542113792;
loc_82400A78:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82400ae4
	if (cr6.eq) goto loc_82400AE4;
	// mullw r10,r18,r30
	ctx.r10.s64 = int64_t(r18.s32) * int64_t(r30.s32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r24,r30
	r11.u64 = r24.u64 + r30.u64;
	// add r9,r10,r27
	ctx.r9.u64 = ctx.r10.u64 + r27.u64;
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r28
	r11.u64 = r28.u64;
	// subf r8,r28,r21
	ctx.r8.s64 = r21.s64 - r28.s64;
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
loc_82400AA0:
	// lwz r6,144(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r6,r7,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stwx r6,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r6.u32);
	// lwz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82400aa0
	if (!cr0.eq) goto loc_82400AA0;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r18,0
	cr0.compare<uint32_t>(r18.u32, 0, xer);
	// beq 0x82400ae4
	if (cr0.eq) goto loc_82400AE4;
	// mtctr r18
	ctr.u64 = r18.u64;
loc_82400AD8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400ad8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400AD8;
loc_82400AE4:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,1724(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// lwz r3,1716(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82400b1c
	if (!cr6.eq) goto loc_82400B1C;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// b 0x82400b70
	goto loc_82400B70;
loc_82400B1C:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82400b44
	if (cr6.eq) goto loc_82400B44;
	// mr r11,r20
	r11.u64 = r20.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r18,0
	cr0.compare<uint32_t>(r18.u32, 0, xer);
	// beq 0x82400b44
	if (cr0.eq) goto loc_82400B44;
	// mtctr r18
	ctr.u64 = r18.u64;
loc_82400B38:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400b38
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400B38;
loc_82400B44:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,1724(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// lwz r3,1716(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// oris r5,r25,8256
	ctx.r5.u64 = r25.u64 | 541065216;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
loc_82400B70:
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r14
	cr6.compare<uint32_t>(r30.u32, r14.u32, xer);
	// blt cr6,0x82400a78
	if (cr6.lt) goto loc_82400A78;
loc_82400B88:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82400bb4
	if (cr6.eq) goto loc_82400BB4;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
	// mr r11,r18
	r11.u64 = r18.u64;
loc_82400B9C:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82400b9c
	if (!cr0.eq) goto loc_82400B9C;
loc_82400BB4:
	// addi r16,r16,1
	r16.s64 = r16.s64 + 1;
	// add r24,r14,r24
	r24.u64 = r14.u64 + r24.u64;
	// add r19,r19,r17
	r19.u64 = r19.u64 + r17.u64;
	// cmplw cr6,r16,r15
	cr6.compare<uint32_t>(r16.u32, r15.u32, xer);
	// blt cr6,0x82400a64
	if (cr6.lt) goto loc_82400A64;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_82400BCC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// li r10,-1
	ctx.r10.s64 = -1;
	// lwz r5,160(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r11,641
	r11.s64 = 641;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,16
	ctx.r9.s64 = 16;
	// rlwimi r5,r11,21,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 21) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r10,0(r15)
	PPC_STORE_U32(r15.u32 + 0, ctx.r10.u32);
	// b 0x82402760
	goto loc_82402760;
loc_82400C04:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bne cr6,0x82400d50
	if (!cr6.eq) goto loc_82400D50;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// subf r9,r10,r3
	ctx.r9.s64 = ctx.r3.s64 - ctx.r10.s64;
	// li r10,4
	ctx.r10.s64 = 4;
loc_82400C44:
	// add r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 + r11.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82400c44
	if (!cr0.eq) goto loc_82400C44;
	// li r29,-1
	r29.s64 = -1;
	// lwz r30,160(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lwz r27,164(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// lwz r28,168(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// mr r11,r29
	r11.u64 = r29.u64;
	// lwz r26,172(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r29,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r29.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r29,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r29.u32);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// stw r29,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r29.u32);
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// stw r10,0(r15)
	PPC_STORE_U32(r15.u32 + 0, ctx.r10.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,8224
	ctx.r5.s64 = 538968064;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,8224
	ctx.r5.s64 = 538968064;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,26
	ctx.r9.s64 = 26;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,18
	ctx.r9.s64 = 18;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// lis r5,8256
	ctx.r5.s64 = 541065216;
	// b 0x823fca84
	goto loc_823FCA84;
loc_82400D50:
	// li r29,-1
	r29.s64 = -1;
	// lwz r27,144(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r28,r30,12
	r28.u64 = r30.u32 & 0xFFFFF;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// addi r6,r1,396
	ctx.r6.s64 = ctx.r1.s64 + 396;
	// stw r29,396(r1)
	PPC_STORE_U32(ctx.r1.u32 + 396, r29.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r29,400(r1)
	PPC_STORE_U32(ctx.r1.u32 + 400, r29.u32);
	// oris r5,r28,20480
	ctx.r5.u64 = r28.u64 | 1342177280;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4208
	ctx.r5.s64 = 275775488;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,396
	ctx.r7.s64 = ctx.r1.s64 + 396;
	// addi r6,r1,400
	ctx.r6.s64 = ctx.r1.s64 + 400;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400e10
	if (cr6.eq) goto loc_82400E10;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82400DD8:
	// lwz r9,400(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82400dd8
	if (!cr0.eq) goto loc_82400DD8;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82400e10
	if (cr6.eq) goto loc_82400E10;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400e10
	if (cr0.eq) goto loc_82400E10;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400E04:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400e04
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400E04;
loc_82400E10:
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// b 0x823fedb8
	goto loc_823FEDB8;
loc_82400E18:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// lwz r7,148(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// lwz r6,144(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f8630
	sub_823F8630(ctx, base);
	// b 0x82402770
	goto loc_82402770;
loc_82400E58:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r3,8(r14)
	ctx.r3.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfd f1,32120(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 32120);
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd694
	if (cr6.eq) goto loc_823FD694;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82400ec4
	if (cr0.eq) goto loc_82400EC4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400EB8:
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400eb8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400EB8;
loc_82400EC4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x823fd694
	if (cr6.eq) goto loc_823FD694;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x823fd694
	if (cr0.eq) goto loc_823FD694;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82400EE0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82400ee0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400EE0;
	// b 0x823fd694
	goto loc_823FD694;
loc_82400EF0:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// li r29,-1
	r29.s64 = -1;
	// lwz r26,148(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r25,144(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r27,r30,12
	r27.u64 = r30.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// addi r6,r1,296
	ctx.r6.s64 = ctx.r1.s64 + 296;
	// stw r29,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, r29.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r29,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, r29.u32);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r29,416(r1)
	PPC_STORE_U32(ctx.r1.u32 + 416, r29.u32);
	// oris r5,r27,20480
	ctx.r5.u64 = r27.u64 | 1342177280;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,8256
	ctx.r5.s64 = 541065216;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,296
	ctx.r8.s64 = ctx.r1.s64 + 296;
	// addi r7,r1,296
	ctx.r7.s64 = ctx.r1.s64 + 296;
	// addi r6,r1,364
	ctx.r6.s64 = ctx.r1.s64 + 364;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,364
	ctx.r7.s64 = ctx.r1.s64 + 364;
	// addi r6,r1,416
	ctx.r6.s64 = ctx.r1.s64 + 416;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// rlwinm r4,r30,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,2
	r11.s64 = 2;
loc_82400FCC:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82400fcc
	if (!cr0.eq) goto loc_82400FCC;
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240100c
	if (cr6.eq) goto loc_8240100C;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82400FF8:
	// lwz r9,416(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82400ff8
	if (!cr0.eq) goto loc_82400FF8;
loc_8240100C:
	// lwz r28,132(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240105c
	if (cr6.eq) goto loc_8240105C;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401038
	if (cr0.eq) goto loc_82401038;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240102C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240102c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240102C;
loc_82401038:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240105c
	if (cr6.eq) goto loc_8240105C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240105c
	if (cr0.eq) goto loc_8240105C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401050:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401050
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401050;
loc_8240105C:
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r27,8272
	ctx.r5.u64 = r27.u64 | 542113792;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// oris r5,r27,8256
	ctx.r5.u64 = r27.u64 | 541065216;
	// b 0x8240275c
	goto loc_8240275C;
loc_82401090:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// li r29,-1
	r29.s64 = -1;
	// lwz r22,148(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r23,144(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r24,r30,12
	r24.u64 = r30.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// addi r6,r1,216
	ctx.r6.s64 = ctx.r1.s64 + 216;
	// stw r29,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, r29.u32);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r29,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, r29.u32);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r29,388(r1)
	PPC_STORE_U32(ctx.r1.u32 + 388, r29.u32);
	// oris r5,r24,20480
	ctx.r5.u64 = r24.u64 | 1342177280;
	// stw r29,380(r1)
	PPC_STORE_U32(ctx.r1.u32 + 380, r29.u32);
	// stw r29,308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 308, r29.u32);
	// stw r29,408(r1)
	PPC_STORE_U32(ctx.r1.u32 + 408, r29.u32);
	// stw r29,392(r1)
	PPC_STORE_U32(ctx.r1.u32 + 392, r29.u32);
	// stw r29,304(r1)
	PPC_STORE_U32(ctx.r1.u32 + 304, r29.u32);
	// stw r29,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, r29.u32);
	// stw r29,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, r29.u32);
	// stw r29,288(r1)
	PPC_STORE_U32(ctx.r1.u32 + 288, r29.u32);
	// stw r29,336(r1)
	PPC_STORE_U32(ctx.r1.u32 + 336, r29.u32);
	// stw r29,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, r29.u32);
	// stw r29,328(r1)
	PPC_STORE_U32(ctx.r1.u32 + 328, r29.u32);
	// stw r29,344(r1)
	PPC_STORE_U32(ctx.r1.u32 + 344, r29.u32);
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r11,8272
	r11.s64 = 542113792;
	// li r9,4
	ctx.r9.s64 = 4;
	// ori r28,r11,1
	r28.u64 = r11.u64 | 1;
	// addi r8,r1,216
	ctx.r8.s64 = ctx.r1.s64 + 216;
	// addi r7,r1,216
	ctx.r7.s64 = ctx.r1.s64 + 216;
	// addi r6,r1,372
	ctx.r6.s64 = ctx.r1.s64 + 372;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r26,152(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// li r9,4
	ctx.r9.s64 = 4;
	// addi r6,r1,388
	ctx.r6.s64 = ctx.r1.s64 + 388;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,372
	ctx.r7.s64 = ctx.r1.s64 + 372;
	// addi r6,r1,380
	ctx.r6.s64 = ctx.r1.s64 + 380;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r11,8256
	r11.s64 = 541065216;
	// addi r27,r14,32
	r27.s64 = r14.s64 + 32;
	// ori r25,r11,1
	r25.u64 = r11.u64 | 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,380
	ctx.r8.s64 = ctx.r1.s64 + 380;
	// addi r6,r1,308
	ctx.r6.s64 = ctx.r1.s64 + 308;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,308
	ctx.r8.s64 = ctx.r1.s64 + 308;
	// addi r7,r1,388
	ctx.r7.s64 = ctx.r1.s64 + 388;
	// addi r6,r1,408
	ctx.r6.s64 = ctx.r1.s64 + 408;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,408
	ctx.r7.s64 = ctx.r1.s64 + 408;
	// addi r6,r1,392
	ctx.r6.s64 = ctx.r1.s64 + 392;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,392
	ctx.r8.s64 = ctx.r1.s64 + 392;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// addi r6,r1,304
	ctx.r6.s64 = ctx.r1.s64 + 304;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,8240
	ctx.r5.s64 = 540016640;
	// li r9,23
	ctx.r9.s64 = 23;
	// addi r8,r14,36
	ctx.r8.s64 = r14.s64 + 36;
	// addi r7,r1,304
	ctx.r7.s64 = ctx.r1.s64 + 304;
	// addi r6,r1,300
	ctx.r6.s64 = ctx.r1.s64 + 300;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// addi r8,r1,300
	ctx.r8.s64 = ctx.r1.s64 + 300;
	// addi r7,r1,304
	ctx.r7.s64 = ctx.r1.s64 + 304;
	// addi r6,r1,312
	ctx.r6.s64 = ctx.r1.s64 + 312;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,300
	ctx.r8.s64 = ctx.r1.s64 + 300;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// addi r6,r1,288
	ctx.r6.s64 = ctx.r1.s64 + 288;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,216
	ctx.r8.s64 = ctx.r1.s64 + 216;
	// addi r7,r1,288
	ctx.r7.s64 = ctx.r1.s64 + 288;
	// addi r6,r1,336
	ctx.r6.s64 = ctx.r1.s64 + 336;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4208
	ctx.r5.s64 = 275775488;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,312
	ctx.r7.s64 = ctx.r1.s64 + 312;
	// addi r6,r1,320
	ctx.r6.s64 = ctx.r1.s64 + 320;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lis r5,4144
	ctx.r5.s64 = 271581184;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,320
	ctx.r7.s64 = ctx.r1.s64 + 320;
	// addi r6,r1,328
	ctx.r6.s64 = ctx.r1.s64 + 328;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,328
	ctx.r8.s64 = ctx.r1.s64 + 328;
	// addi r7,r1,336
	ctx.r7.s64 = ctx.r1.s64 + 336;
	// addi r6,r1,344
	ctx.r6.s64 = ctx.r1.s64 + 344;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mulli r4,r30,5
	ctx.r4.s64 = r30.s64 * 5;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,5
	r11.s64 = 5;
loc_824013AC:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x824013ac
	if (!cr0.eq) goto loc_824013AC;
	// lwz r25,176(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwz r7,172(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// beq cr6,0x824013fc
	if (cr6.eq) goto loc_824013FC;
	// mr r11,r25
	r11.u64 = r25.u64;
	// subf r9,r25,r7
	ctx.r9.s64 = ctx.r7.s64 - r25.s64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_824013E0:
	// lwz r8,288(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stwx r8,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r8.u32);
	// lwz r8,344(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x824013e0
	if (!cr0.eq) goto loc_824013E0;
loc_824013FC:
	// lwz r26,160(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401428
	if (cr6.eq) goto loc_82401428;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401428
	if (cr0.eq) goto loc_82401428;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240141C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240141c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240141C;
loc_82401428:
	// lwz r27,164(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401454
	if (cr6.eq) goto loc_82401454;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401454
	if (cr0.eq) goto loc_82401454;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401448:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401448
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401448;
loc_82401454:
	// lwz r28,168(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824014a4
	if (cr6.eq) goto loc_824014A4;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401480
	if (cr0.eq) goto loc_82401480;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401474:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401474
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401474;
loc_82401480:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824014a4
	if (cr6.eq) goto loc_824014A4;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824014a4
	if (cr0.eq) goto loc_824014A4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401498:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401498
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401498;
loc_824014A4:
	// oris r30,r24,8272
	r30.u64 = r24.u64 | 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r24,4112
	ctx.r5.u64 = r24.u64 | 269484032;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// oris r5,r24,8256
	ctx.r5.u64 = r24.u64 | 541065216;
	// b 0x8240275c
	goto loc_8240275C;
loc_8240152C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r3,8(r14)
	ctx.r3.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfd f1,-28592(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -28592);
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// li r11,4
	r11.s64 = 4;
loc_82401580:
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r3,r31,r3
	ctx.r3.u64 = r31.u64 + ctx.r3.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82401580
	if (!cr0.eq) goto loc_82401580;
	// lwz r8,172(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824015c0
	if (cr6.eq) goto loc_824015C0;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824015c0
	if (cr0.eq) goto loc_824015C0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824015B4:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824015b4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824015B4;
loc_824015C0:
	// lwz r27,160(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824015f0
	if (cr6.eq) goto loc_824015F0;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824015f0
	if (cr0.eq) goto loc_824015F0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824015E4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824015e4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824015E4;
loc_824015F0:
	// lwz r26,164(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240161c
	if (cr6.eq) goto loc_8240161C;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240161c
	if (cr0.eq) goto loc_8240161C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401610:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401610
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401610;
loc_8240161C:
	// lwz r28,168(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240166c
	if (cr6.eq) goto loc_8240166C;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401648
	if (cr0.eq) goto loc_82401648;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240163C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240163c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240163C;
loc_82401648:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240166c
	if (cr6.eq) goto loc_8240166C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240166c
	if (cr0.eq) goto loc_8240166C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401660:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401660
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401660;
loc_8240166C:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// oris r29,r30,8256
	r29.u64 = r30.u64 | 541065216;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,20
	ctx.r9.s64 = 20;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r30,4160
	ctx.r5.u64 = r30.u64 | 272629760;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,24
	ctx.r9.s64 = 24;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// b 0x82402760
	goto loc_82402760;
loc_824016FC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401738
	if (cr6.eq) goto loc_82401738;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401738
	if (cr0.eq) goto loc_82401738;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240172C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240172c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240172C;
loc_82401738:
	// li r11,263
	r11.s64 = 263;
	// b 0x823fe3dc
	goto loc_823FE3DC;
loc_82401740:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mulli r4,r30,3
	ctx.r4.s64 = r30.s64 * 3;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,3
	r11.s64 = 3;
loc_82401774:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82401774
	if (!cr0.eq) goto loc_82401774;
	// lwz r27,132(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// beq cr6,0x824017c4
	if (cr6.eq) goto loc_824017C4;
	// mr r11,r27
	r11.u64 = r27.u64;
	// subf r9,r27,r8
	ctx.r9.s64 = ctx.r8.s64 - r27.s64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_824017A8:
	// lwz r7,36(r14)
	ctx.r7.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stwx r7,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r7.u32);
	// lwz r7,32(r14)
	ctx.r7.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x824017a8
	if (!cr0.eq) goto loc_824017A8;
loc_824017C4:
	// lwz r28,136(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401818
	if (cr6.eq) goto loc_82401818;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824017f4
	if (cr0.eq) goto loc_824017F4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824017E8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824017e8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824017E8;
loc_824017F4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401818
	if (cr6.eq) goto loc_82401818;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401818
	if (cr0.eq) goto loc_82401818;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240180C:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240180c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240180C;
loc_82401818:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,8208
	ctx.r5.u64 = r30.u64 | 537919488;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,20
	ctx.r9.s64 = 20;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// oris r5,r30,8192
	ctx.r5.u64 = r30.u64 | 536870912;
	// b 0x82402760
	goto loc_82402760;
loc_82401854:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// rlwinm r31,r30,2,0,29
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r11,4
	r11.s64 = 4;
loc_82401888:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82401888
	if (!cr0.eq) goto loc_82401888;
	// lwz r26,160(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824018d0
	if (cr6.eq) goto loc_824018D0;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824018d0
	if (cr0.eq) goto loc_824018D0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824018C4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824018c4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824018C4;
loc_824018D0:
	// lwz r23,164(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824018fc
	if (cr6.eq) goto loc_824018FC;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824018fc
	if (cr0.eq) goto loc_824018FC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824018F0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824018f0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824018F0;
loc_824018FC:
	// lwz r24,168(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401928
	if (cr6.eq) goto loc_82401928;
	// mr r11,r24
	r11.u64 = r24.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401928
	if (cr0.eq) goto loc_82401928;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240191C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240191c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240191C;
loc_82401928:
	// lwz r25,172(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401978
	if (cr6.eq) goto loc_82401978;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401954
	if (cr0.eq) goto loc_82401954;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401948:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401948
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401948;
loc_82401954:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401978
	if (cr6.eq) goto loc_82401978;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401978
	if (cr0.eq) goto loc_82401978;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240196C:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240196c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240196C;
loc_82401978:
	// clrlwi r28,r30,12
	r28.u64 = r30.u32 & 0xFFFFF;
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// oris r27,r28,4112
	r27.u64 = r28.u64 | 269484032;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r30,r28,8224
	r30.u64 = r28.u64 | 538968064;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,26
	ctx.r9.s64 = 26;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,18
	ctx.r9.s64 = 18;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// oris r5,r28,8256
	ctx.r5.u64 = r28.u64 | 541065216;
	// b 0x82402760
	goto loc_82402760;
loc_82401A3C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401a78
	if (cr6.eq) goto loc_82401A78;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401a78
	if (cr0.eq) goto loc_82401A78;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401A6C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401a6c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401A6C;
loc_82401A78:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// b 0x823fd120
	goto loc_823FD120;
loc_82401A84:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r31,160(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r30,r31,2,0,29
	r30.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// stw r28,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r28.u32);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stw r7,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r7.u32);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82401b18
	if (cr6.eq) goto loc_82401B18;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x82401af4
	if (cr0.eq) goto loc_82401AF4;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_82401AE8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401ae8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401AE8;
loc_82401AF4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82401b18
	if (cr6.eq) goto loc_82401B18;
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x82401b18
	if (cr0.eq) goto loc_82401B18;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_82401B0C:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401b0c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401B0C;
loc_82401B18:
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// b 0x823fd124
	goto loc_823FD124;
loc_82401B24:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r31,8(r14)
	r31.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lfd f1,264(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 264);
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fdiv f1,f0,f1
	ctx.f1.f64 = f0.f64 / ctx.f1.f64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lfd f1,-28592(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + -28592);
	// lwz r4,120(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// rlwinm r4,r30,3,0,28
	ctx.r4.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,8
	r11.s64 = 8;
loc_82401BB0:
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r3,r3,r9
	ctx.r3.u64 = ctx.r3.u64 + ctx.r9.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82401bb0
	if (!cr0.eq) goto loc_82401BB0;
	// lwz r20,188(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwz r8,184(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// beq cr6,0x82401bf8
	if (cr6.eq) goto loc_82401BF8;
	// mr r11,r20
	r11.u64 = r20.u64;
	// subf r9,r20,r8
	ctx.r9.s64 = ctx.r8.s64 - r20.s64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_82401BE4:
	// stwx r31,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, r31.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82401be4
	if (!cr0.eq) goto loc_82401BE4;
loc_82401BF8:
	// lwz r24,160(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401c28
	if (cr6.eq) goto loc_82401C28;
	// mr r11,r24
	r11.u64 = r24.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401c28
	if (cr0.eq) goto loc_82401C28;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401C1C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401c1c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401C1C;
loc_82401C28:
	// lwz r21,164(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401c54
	if (cr6.eq) goto loc_82401C54;
	// mr r11,r21
	r11.u64 = r21.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401c54
	if (cr0.eq) goto loc_82401C54;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401C48:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401c48
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401C48;
loc_82401C54:
	// lwz r22,168(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401c80
	if (cr6.eq) goto loc_82401C80;
	// mr r11,r22
	r11.u64 = r22.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401c80
	if (cr0.eq) goto loc_82401C80;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401C74:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401c74
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401C74;
loc_82401C80:
	// lwz r23,172(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401cac
	if (cr6.eq) goto loc_82401CAC;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401cac
	if (cr0.eq) goto loc_82401CAC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401CA0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401ca0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401CA0;
loc_82401CAC:
	// lwz r25,176(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401cd8
	if (cr6.eq) goto loc_82401CD8;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401cd8
	if (cr0.eq) goto loc_82401CD8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401CCC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401ccc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401CCC;
loc_82401CD8:
	// lwz r26,180(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401d28
	if (cr6.eq) goto loc_82401D28;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401d04
	if (cr0.eq) goto loc_82401D04;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401CF8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401cf8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401CF8;
loc_82401D04:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401d28
	if (cr6.eq) goto loc_82401D28;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401d28
	if (cr0.eq) goto loc_82401D28;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401D1C:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401d1c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401D1C;
loc_82401D28:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// oris r27,r30,8272
	r27.u64 = r30.u64 | 542113792;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r28,r30,4176
	r28.u64 = r30.u64 | 273678336;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r29,r30,4112
	r29.u64 = r30.u64 | 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// b 0x82402758
	goto loc_82402758;
loc_82401E30:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r3,8(r14)
	ctx.r3.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfd f1,31752(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 31752);
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r4,120(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 120);
	// lfd f1,32112(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32112);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mulli r4,r30,14
	ctx.r4.s64 = r30.s64 * 14;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,14
	r11.s64 = 14;
loc_82401EC0:
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82401ec0
	if (!cr0.eq) goto loc_82401EC0;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r8,10
	ctx.r8.s64 = 10;
	// li r29,-1
	r29.s64 = -1;
loc_82401EE4:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401f0c
	if (cr6.eq) goto loc_82401F0C;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401f0c
	if (cr0.eq) goto loc_82401F0C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401F00:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401f00
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401F00;
loc_82401F0C:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82401ee4
	if (!cr0.eq) goto loc_82401EE4;
	// lwz r22,212(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwz r23,208(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	// lwz r25,204(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// lwz r24,200(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	// beq cr6,0x82401f8c
	if (cr6.eq) goto loc_82401F8C;
	// mr r11,r25
	r11.u64 = r25.u64;
	// subf r9,r25,r24
	ctx.r9.s64 = r24.s64 - r25.s64;
	// subf r8,r25,r23
	ctx.r8.s64 = r23.s64 - r25.s64;
	// subf r7,r25,r22
	ctx.r7.s64 = r22.s64 - r25.s64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_82401F44:
	// lwz r6,36(r14)
	ctx.r6.u64 = PPC_LOAD_U32(r14.u32 + 36);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stwx r6,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r6.u32);
	// lwz r6,32(r14)
	ctx.r6.u64 = PPC_LOAD_U32(r14.u32 + 32);
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// stwx r31,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, r31.u32);
	// stwx r28,r7,r11
	PPC_STORE_U32(ctx.r7.u32 + r11.u32, r28.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82401f44
	if (!cr0.eq) goto loc_82401F44;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401f8c
	if (cr6.eq) goto loc_82401F8C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82401f8c
	if (cr0.eq) goto loc_82401F8C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82401F80:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82401f80
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82401F80;
loc_82401F8C:
	// lwz r29,160(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r28,164(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// oris r26,r30,8256
	r26.u64 = r30.u64 | 541065216;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r7,148(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r27,168(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r7,152(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r29,172(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r30,4144
	ctx.r5.u64 = r30.u64 | 271581184;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r29,176(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// oris r28,r30,8272
	r28.u64 = r30.u64 | 542113792;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r29,180(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r30,8208
	ctx.r5.u64 = r30.u64 | 537919488;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r29,184(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r9,20
	ctx.r9.s64 = 20;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r30,8192
	ctx.r5.u64 = r30.u64 | 536870912;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r30,188(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// li r9,8
	ctx.r9.s64 = 8;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r27,192(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// lwz r30,196(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// li r9,20
	ctx.r9.s64 = 20;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// b 0x8240275c
	goto loc_8240275C;
loc_82402160:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824021d8
	if (cr6.eq) goto loc_824021D8;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824021b4
	if (cr0.eq) goto loc_824021B4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824021A8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824021a8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824021A8;
loc_824021B4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824021d8
	if (cr6.eq) goto loc_824021D8;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824021d8
	if (cr0.eq) goto loc_824021D8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824021CC:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824021cc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824021CC;
loc_824021D8:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4208
	ctx.r5.u64 = r30.u64 | 275775488;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// oris r5,r30,4144
	ctx.r5.u64 = r30.u64 | 271581184;
	// b 0x82402760
	goto loc_82402760;
loc_82402218:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402260
	if (cr6.eq) goto loc_82402260;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402260
	if (cr0.eq) goto loc_82402260;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402254:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402254
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402254;
loc_82402260:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r8,144(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r11,515
	r11.s64 = 515;
	// lwz r7,148(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,23
	ctx.r9.s64 = 23;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x82402760
	goto loc_82402760;
loc_8240227C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// mulli r4,r30,3
	ctx.r4.s64 = r30.s64 * 3;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402420
	if (cr0.eq) goto loc_82402420;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,3
	r11.s64 = 3;
loc_824022A8:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x824022a8
	if (!cr0.eq) goto loc_824022A8;
	// lwz r26,128(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824022f0
	if (cr6.eq) goto loc_824022F0;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824022f0
	if (cr0.eq) goto loc_824022F0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824022E4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824022e4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824022E4;
loc_824022F0:
	// lwz r27,132(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240231c
	if (cr6.eq) goto loc_8240231C;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240231c
	if (cr0.eq) goto loc_8240231C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402310:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402310
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402310;
loc_8240231C:
	// lwz r28,136(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240236c
	if (cr6.eq) goto loc_8240236C;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402348
	if (cr0.eq) goto loc_82402348;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240233C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240233c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240233C;
loc_82402348:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240236c
	if (cr6.eq) goto loc_8240236C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240236c
	if (cr0.eq) goto loc_8240236C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402360:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402360
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402360;
loc_8240236C:
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f6740
	sub_823F6740(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// oris r5,r30,4144
	ctx.r5.u64 = r30.u64 | 271581184;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// b 0x823ff8cc
	goto loc_823FF8CC;
loc_824023C4:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r31,8(r14)
	r31.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lfd f1,264(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 264);
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fdiv f1,f0,f1
	ctx.f1.f64 = f0.f64 / ctx.f1.f64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mulli r4,r30,9
	ctx.r4.s64 = r30.s64 * 9;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x8240242c
	if (!cr0.eq) goto loc_8240242C;
loc_82402420:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x82403498
	goto loc_82403498;
loc_8240242C:
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,9
	r11.s64 = 9;
loc_82402438:
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r3,r3,r9
	ctx.r3.u64 = ctx.r3.u64 + ctx.r9.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402438
	if (!cr0.eq) goto loc_82402438;
	// lwz r8,192(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402478
	if (cr6.eq) goto loc_82402478;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402478
	if (cr0.eq) goto loc_82402478;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240246C:
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240246c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240246C;
loc_82402478:
	// lwz r23,160(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r29,-1
	r29.s64 = -1;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824024a8
	if (cr6.eq) goto loc_824024A8;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824024a8
	if (cr0.eq) goto loc_824024A8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240249C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240249c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240249C;
loc_824024A8:
	// lwz r18,164(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824024d4
	if (cr6.eq) goto loc_824024D4;
	// mr r11,r18
	r11.u64 = r18.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824024d4
	if (cr0.eq) goto loc_824024D4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824024C8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824024c8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824024C8;
loc_824024D4:
	// lwz r20,168(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402500
	if (cr6.eq) goto loc_82402500;
	// mr r11,r20
	r11.u64 = r20.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402500
	if (cr0.eq) goto loc_82402500;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824024F4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824024f4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824024F4;
loc_82402500:
	// lwz r22,172(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240252c
	if (cr6.eq) goto loc_8240252C;
	// mr r11,r22
	r11.u64 = r22.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240252c
	if (cr0.eq) goto loc_8240252C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402520:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402520
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402520;
loc_8240252C:
	// lwz r24,176(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402558
	if (cr6.eq) goto loc_82402558;
	// mr r11,r24
	r11.u64 = r24.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402558
	if (cr0.eq) goto loc_82402558;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240254C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240254c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240254C;
loc_82402558:
	// lwz r21,180(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402584
	if (cr6.eq) goto loc_82402584;
	// mr r11,r21
	r11.u64 = r21.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402584
	if (cr0.eq) goto loc_82402584;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402578:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402578
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402578;
loc_82402584:
	// lwz r25,184(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824025b0
	if (cr6.eq) goto loc_824025B0;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824025b0
	if (cr0.eq) goto loc_824025B0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824025A4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824025a4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824025A4;
loc_824025B0:
	// lwz r26,188(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402600
	if (cr6.eq) goto loc_82402600;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824025dc
	if (cr0.eq) goto loc_824025DC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824025D0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824025d0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824025D0;
loc_824025DC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402600
	if (cr6.eq) goto loc_82402600;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402600
	if (cr0.eq) goto loc_82402600;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824025F4:
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824025f4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824025F4;
loc_82402600:
	// clrlwi r30,r30,12
	r30.u64 = r30.u32 & 0xFFFFF;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r9,0
	ctx.r9.s64 = 0;
	// oris r27,r30,8272
	r27.u64 = r30.u64 | 542113792;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r28,r30,4176
	r28.u64 = r30.u64 | 273678336;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r29,r30,4112
	r29.u64 = r30.u64 | 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// oris r29,r30,8256
	r29.u64 = r30.u64 | 541065216;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r30,4144
	ctx.r5.u64 = r30.u64 | 271581184;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82403498
	if (cr0.lt) goto loc_82403498;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
loc_82402758:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
loc_8240275C:
	// li r9,0
	ctx.r9.s64 = 0;
loc_82402760:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
loc_82402764:
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
loc_82402768:
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
loc_8240276C:
	// bl 0x823f5698
	sub_823F5698(ctx, base);
loc_82402770:
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bge 0x823fd6d4
	if (!cr0.lt) goto loc_823FD6D4;
	// b 0x82403498
	goto loc_82403498;
loc_8240277C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r9,148(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r11,r1,680
	r11.s64 = ctx.r1.s64 + 680;
	// li r10,2
	ctx.r10.s64 = 2;
loc_824027A8:
	// lwz r8,144(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r8,-8(r11)
	PPC_STORE_U32(r11.u32 + -8, ctx.r8.u32);
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x824027a8
	if (!cr0.eq) goto loc_824027A8;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,504
	ctx.r5.s64 = ctx.r1.s64 + 504;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// stw r11,504(r1)
	PPC_STORE_U32(ctx.r1.u32 + 504, r11.u32);
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// lwz r11,680(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r6,4(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,27,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824028ac
	if (cr0.eq) goto loc_824028AC;
	// lwz r9,16(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x824028ac
	if (!cr6.eq) goto loc_824028AC;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x82402884
	if (cr0.eq) goto loc_82402884;
loc_82402830:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x8240286c
	if (!cr6.eq) goto loc_8240286C;
	// lwz r5,8(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x8240286c
	if (!cr6.eq) goto loc_8240286C;
	// lwz r5,12(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x8240286c
	if (!cr6.eq) goto loc_8240286C;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x82402880
	if (cr6.eq) goto loc_82402880;
loc_8240286C:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// blt cr6,0x82402830
	if (cr6.lt) goto loc_82402830;
	// b 0x82402884
	goto loc_82402884;
loc_82402880:
	// stw r9,684(r1)
	PPC_STORE_U32(ctx.r1.u32 + 684, ctx.r9.u32);
loc_82402884:
	// lwz r11,8(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x824028ac
	if (!cr6.eq) goto loc_824028AC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3509
	ctx.r5.s64 = 3509;
	// addi r6,r11,32024
	ctx.r6.s64 = r11.s64 + 32024;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_824028AC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824028d4
	if (cr6.eq) goto loc_824028D4;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824028d4
	if (cr0.eq) goto loc_824028D4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824028C8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824028c8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824028C8;
loc_824028D4:
	// addi r8,r1,680
	ctx.r8.s64 = ctx.r1.s64 + 680;
	// addi r7,r1,672
	ctx.r7.s64 = ctx.r1.s64 + 672;
	// lis r5,24576
	ctx.r5.s64 = 1610612736;
loc_824028E0:
	// ori r5,r5,2
	ctx.r5.u64 = ctx.r5.u64 | 2;
	// b 0x8240275c
	goto loc_8240275C;
loc_824028E8:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r11,r1,1416
	r11.s64 = ctx.r1.s64 + 1416;
	// li r10,2
	ctx.r10.s64 = 2;
loc_82402928:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,-8(r11)
	PPC_STORE_U32(r11.u32 + -8, ctx.r9.u32);
	// lwz r9,148(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,152(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// lwz r9,156(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82402928
	if (!cr0.eq) goto loc_82402928;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240298c
	if (cr6.eq) goto loc_8240298C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240298c
	if (cr0.eq) goto loc_8240298C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402980:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402980
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402980;
loc_8240298C:
	// addi r8,r1,1416
	ctx.r8.s64 = ctx.r1.s64 + 1416;
	// addi r7,r1,1408
	ctx.r7.s64 = ctx.r1.s64 + 1408;
	// lis r5,24592
	ctx.r5.s64 = 1611661312;
	// b 0x824028e0
	goto loc_824028E0;
loc_8240299C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1184
	ctx.r10.s64 = ctx.r1.s64 + 1184;
	// li r11,4
	r11.s64 = 4;
loc_824029C4:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x824029c4
	if (!cr0.eq) goto loc_824029C4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402a04
	if (cr6.eq) goto loc_82402A04;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402a04
	if (cr0.eq) goto loc_82402A04;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824029F8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824029f8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824029F8;
loc_82402A04:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1184
	ctx.r7.s64 = ctx.r1.s64 + 1184;
	// lis r5,24608
	ctx.r5.s64 = 1612709888;
	// b 0x8240346c
	goto loc_8240346C;
loc_82402A18:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1200
	ctx.r10.s64 = ctx.r1.s64 + 1200;
	// li r11,4
	r11.s64 = 4;
loc_82402A40:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402a40
	if (!cr0.eq) goto loc_82402A40;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402a80
	if (cr6.eq) goto loc_82402A80;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402a80
	if (cr0.eq) goto loc_82402A80;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402A74:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402a74
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402A74;
loc_82402A80:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1200
	ctx.r7.s64 = ctx.r1.s64 + 1200;
	// lis r5,24624
	ctx.r5.s64 = 1613758464;
	// b 0x8240346c
	goto loc_8240346C;
loc_82402A94:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1344
	ctx.r10.s64 = ctx.r1.s64 + 1344;
	// li r11,4
	r11.s64 = 4;
loc_82402ABC:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402abc
	if (!cr0.eq) goto loc_82402ABC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402afc
	if (cr6.eq) goto loc_82402AFC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402afc
	if (cr0.eq) goto loc_82402AFC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402AF0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402af0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402AF0;
loc_82402AFC:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1344
	ctx.r7.s64 = ctx.r1.s64 + 1344;
	// lis r5,24640
	ctx.r5.s64 = 1614807040;
	// b 0x8240346c
	goto loc_8240346C;
loc_82402B10:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,768
	ctx.r10.s64 = ctx.r1.s64 + 768;
	// li r11,2
	r11.s64 = 2;
loc_82402B38:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402b38
	if (!cr0.eq) goto loc_82402B38;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402b78
	if (cr6.eq) goto loc_82402B78;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402b78
	if (cr0.eq) goto loc_82402B78;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402B6C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402b6c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402B6C;
loc_82402B78:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r7,r1,768
	ctx.r7.s64 = ctx.r1.s64 + 768;
	// lis r5,24656
	ctx.r5.s64 = 1615855616;
	// b 0x824028e0
	goto loc_824028E0;
loc_82402B88:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r10,r1,864
	ctx.r10.s64 = ctx.r1.s64 + 864;
	// addi r8,r1,872
	ctx.r8.s64 = ctx.r1.s64 + 872;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r6,r1,880
	ctx.r6.s64 = ctx.r1.s64 + 880;
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - r11.s64;
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r4,r1,888
	ctx.r4.s64 = ctx.r1.s64 + 888;
	// subf r5,r11,r10
	ctx.r5.s64 = ctx.r10.s64 - r11.s64;
	// subf r8,r11,r8
	ctx.r8.s64 = ctx.r8.s64 - r11.s64;
	// subf r6,r11,r6
	ctx.r6.s64 = ctx.r6.s64 - r11.s64;
	// subf r4,r11,r4
	ctx.r4.s64 = ctx.r4.s64 - r11.s64;
	// li r10,2
	ctx.r10.s64 = 2;
loc_82402BF8:
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stwx r3,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r3.u32);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stwx r3,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r3.u32);
	// lwzx r3,r7,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// stwx r3,r6,r11
	PPC_STORE_U32(ctx.r6.u32 + r11.u32, ctx.r3.u32);
	// lwzx r3,r5,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// stwx r3,r4,r11
	PPC_STORE_U32(ctx.r4.u32 + r11.u32, ctx.r3.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82402bf8
	if (!cr0.eq) goto loc_82402BF8;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402c50
	if (cr6.eq) goto loc_82402C50;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402c50
	if (cr0.eq) goto loc_82402C50;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402C44:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402c44
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402C44;
loc_82402C50:
	// addi r8,r1,872
	ctx.r8.s64 = ctx.r1.s64 + 872;
	// addi r7,r1,864
	ctx.r7.s64 = ctx.r1.s64 + 864;
	// lis r5,24672
	ctx.r5.s64 = 1616904192;
	// b 0x824028e0
	goto loc_824028E0;
loc_82402C60:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1152
	ctx.r10.s64 = ctx.r1.s64 + 1152;
	// li r11,4
	r11.s64 = 4;
loc_82402C88:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402c88
	if (!cr0.eq) goto loc_82402C88;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402cc8
	if (cr6.eq) goto loc_82402CC8;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402cc8
	if (cr0.eq) goto loc_82402CC8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402CBC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402cbc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402CBC;
loc_82402CC8:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1152
	ctx.r7.s64 = ctx.r1.s64 + 1152;
	// lis r5,24688
	ctx.r5.s64 = 1617952768;
	// b 0x8240346c
	goto loc_8240346C;
loc_82402CDC:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1120
	ctx.r10.s64 = ctx.r1.s64 + 1120;
	// li r11,4
	r11.s64 = 4;
loc_82402D04:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402d04
	if (!cr0.eq) goto loc_82402D04;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402d44
	if (cr6.eq) goto loc_82402D44;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402d44
	if (cr0.eq) goto loc_82402D44;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402D38:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402d38
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402D38;
loc_82402D44:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1120
	ctx.r7.s64 = ctx.r1.s64 + 1120;
	// lis r5,24704
	ctx.r5.s64 = 1619001344;
	// b 0x8240346c
	goto loc_8240346C;
loc_82402D58:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1216
	ctx.r10.s64 = ctx.r1.s64 + 1216;
	// li r11,4
	r11.s64 = 4;
loc_82402D80:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402d80
	if (!cr0.eq) goto loc_82402D80;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402dc0
	if (cr6.eq) goto loc_82402DC0;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402dc0
	if (cr0.eq) goto loc_82402DC0;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402DB4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402db4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402DB4;
loc_82402DC0:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1216
	ctx.r7.s64 = ctx.r1.s64 + 1216;
	// lis r5,24720
	ctx.r5.s64 = 1620049920;
	// b 0x8240346c
	goto loc_8240346C;
loc_82402DD4:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1104
	ctx.r10.s64 = ctx.r1.s64 + 1104;
	// li r11,3
	r11.s64 = 3;
loc_82402DFC:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402dfc
	if (!cr0.eq) goto loc_82402DFC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402e3c
	if (cr6.eq) goto loc_82402E3C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402e3c
	if (cr0.eq) goto loc_82402E3C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402E30:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402e30
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402E30;
loc_82402E3C:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r7,r1,1104
	ctx.r7.s64 = ctx.r1.s64 + 1104;
	// lis r5,24736
	ctx.r5.s64 = 1621098496;
	// b 0x823fd9c4
	goto loc_823FD9C4;
loc_82402E4C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r10,r1,1280
	ctx.r10.s64 = ctx.r1.s64 + 1280;
	// addi r8,r1,1292
	ctx.r8.s64 = ctx.r1.s64 + 1292;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r6,r1,1304
	ctx.r6.s64 = ctx.r1.s64 + 1304;
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - r11.s64;
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r4,r1,1316
	ctx.r4.s64 = ctx.r1.s64 + 1316;
	// subf r5,r11,r10
	ctx.r5.s64 = ctx.r10.s64 - r11.s64;
	// subf r8,r11,r8
	ctx.r8.s64 = ctx.r8.s64 - r11.s64;
	// subf r6,r11,r6
	ctx.r6.s64 = ctx.r6.s64 - r11.s64;
	// subf r4,r11,r4
	ctx.r4.s64 = ctx.r4.s64 - r11.s64;
	// li r10,3
	ctx.r10.s64 = 3;
loc_82402EBC:
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stwx r3,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r3.u32);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stwx r3,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r3.u32);
	// lwzx r3,r7,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// stwx r3,r6,r11
	PPC_STORE_U32(ctx.r6.u32 + r11.u32, ctx.r3.u32);
	// lwzx r3,r5,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// stwx r3,r4,r11
	PPC_STORE_U32(ctx.r4.u32 + r11.u32, ctx.r3.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82402ebc
	if (!cr0.eq) goto loc_82402EBC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402f14
	if (cr6.eq) goto loc_82402F14;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402f14
	if (cr0.eq) goto loc_82402F14;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402F08:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402f08
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402F08;
loc_82402F14:
	// addi r8,r1,1292
	ctx.r8.s64 = ctx.r1.s64 + 1292;
	// addi r7,r1,1280
	ctx.r7.s64 = ctx.r1.s64 + 1280;
	// lis r5,24752
	ctx.r5.s64 = 1622147072;
	// b 0x823fd9c4
	goto loc_823FD9C4;
loc_82402F24:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1328
	ctx.r10.s64 = ctx.r1.s64 + 1328;
	// li r11,4
	r11.s64 = 4;
loc_82402F4C:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402f4c
	if (!cr0.eq) goto loc_82402F4C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82402f8c
	if (cr6.eq) goto loc_82402F8C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82402f8c
	if (cr0.eq) goto loc_82402F8C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402F80:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402f80
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402F80;
loc_82402F8C:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1328
	ctx.r7.s64 = ctx.r1.s64 + 1328;
	// lis r5,24768
	ctx.r5.s64 = 1623195648;
	// b 0x8240346c
	goto loc_8240346C;
loc_82402FA0:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1360
	ctx.r10.s64 = ctx.r1.s64 + 1360;
	// li r11,4
	r11.s64 = 4;
loc_82402FC8:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82402fc8
	if (!cr0.eq) goto loc_82402FC8;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82403008
	if (cr6.eq) goto loc_82403008;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82403008
	if (cr0.eq) goto loc_82403008;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82402FFC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82402ffc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82402FFC;
loc_82403008:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1360
	ctx.r7.s64 = ctx.r1.s64 + 1360;
	// lis r5,24784
	ctx.r5.s64 = 1624244224;
	// b 0x8240346c
	goto loc_8240346C;
loc_8240301C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1392
	ctx.r10.s64 = ctx.r1.s64 + 1392;
	// li r11,4
	r11.s64 = 4;
loc_82403044:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82403044
	if (!cr0.eq) goto loc_82403044;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82403084
	if (cr6.eq) goto loc_82403084;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82403084
	if (cr0.eq) goto loc_82403084;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82403078:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82403078
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82403078;
loc_82403084:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1392
	ctx.r7.s64 = ctx.r1.s64 + 1392;
	// lis r5,24800
	ctx.r5.s64 = 1625292800;
	// b 0x8240346c
	goto loc_8240346C;
loc_82403098:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1088
	ctx.r10.s64 = ctx.r1.s64 + 1088;
	// li r11,3
	r11.s64 = 3;
loc_824030C0:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x824030c0
	if (!cr0.eq) goto loc_824030C0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82403100
	if (cr6.eq) goto loc_82403100;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82403100
	if (cr0.eq) goto loc_82403100;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824030F4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824030f4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824030F4;
loc_82403100:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r7,r1,1088
	ctx.r7.s64 = ctx.r1.s64 + 1088;
	// lis r5,24816
	ctx.r5.s64 = 1626341376;
	// b 0x823fd9c4
	goto loc_823FD9C4;
loc_82403110:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r10,r1,1232
	ctx.r10.s64 = ctx.r1.s64 + 1232;
	// addi r8,r1,1244
	ctx.r8.s64 = ctx.r1.s64 + 1244;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r6,r1,1256
	ctx.r6.s64 = ctx.r1.s64 + 1256;
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - r11.s64;
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r4,r1,1268
	ctx.r4.s64 = ctx.r1.s64 + 1268;
	// subf r5,r11,r10
	ctx.r5.s64 = ctx.r10.s64 - r11.s64;
	// subf r8,r11,r8
	ctx.r8.s64 = ctx.r8.s64 - r11.s64;
	// subf r6,r11,r6
	ctx.r6.s64 = ctx.r6.s64 - r11.s64;
	// subf r4,r11,r4
	ctx.r4.s64 = ctx.r4.s64 - r11.s64;
	// li r10,3
	ctx.r10.s64 = 3;
loc_82403180:
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stwx r3,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r3.u32);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stwx r3,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r3.u32);
	// lwzx r3,r7,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// stwx r3,r6,r11
	PPC_STORE_U32(ctx.r6.u32 + r11.u32, ctx.r3.u32);
	// lwzx r3,r5,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// stwx r3,r4,r11
	PPC_STORE_U32(ctx.r4.u32 + r11.u32, ctx.r3.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82403180
	if (!cr0.eq) goto loc_82403180;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824031d8
	if (cr6.eq) goto loc_824031D8;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824031d8
	if (cr0.eq) goto loc_824031D8;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824031CC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824031cc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824031CC;
loc_824031D8:
	// addi r8,r1,1244
	ctx.r8.s64 = ctx.r1.s64 + 1244;
	// addi r7,r1,1232
	ctx.r7.s64 = ctx.r1.s64 + 1232;
	// lis r5,24832
	ctx.r5.s64 = 1627389952;
	// b 0x823fd9c4
	goto loc_823FD9C4;
loc_824031E8:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1136
	ctx.r10.s64 = ctx.r1.s64 + 1136;
	// li r11,4
	r11.s64 = 4;
loc_82403210:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82403210
	if (!cr0.eq) goto loc_82403210;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82403250
	if (cr6.eq) goto loc_82403250;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82403250
	if (cr0.eq) goto loc_82403250;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82403244:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82403244
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82403244;
loc_82403250:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1136
	ctx.r7.s64 = ctx.r1.s64 + 1136;
	// lis r5,24848
	ctx.r5.s64 = 1628438528;
	// b 0x8240346c
	goto loc_8240346C;
loc_82403264:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1168
	ctx.r10.s64 = ctx.r1.s64 + 1168;
	// li r11,4
	r11.s64 = 4;
loc_8240328C:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8240328c
	if (!cr0.eq) goto loc_8240328C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824032cc
	if (cr6.eq) goto loc_824032CC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824032cc
	if (cr0.eq) goto loc_824032CC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824032C0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824032c0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824032C0;
loc_824032CC:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1168
	ctx.r7.s64 = ctx.r1.s64 + 1168;
	// lis r5,24864
	ctx.r5.s64 = 1629487104;
	// b 0x8240346c
	goto loc_8240346C;
loc_824032E0:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// addi r10,r1,1376
	ctx.r10.s64 = ctx.r1.s64 + 1376;
	// li r11,4
	r11.s64 = 4;
loc_82403308:
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82403308
	if (!cr0.eq) goto loc_82403308;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82403348
	if (cr6.eq) goto loc_82403348;
	// mr r11,r15
	r11.u64 = r15.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82403348
	if (cr0.eq) goto loc_82403348;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_8240333C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240333c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240333C;
loc_82403348:
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,1376
	ctx.r7.s64 = ctx.r1.s64 + 1376;
	// lis r5,24880
	ctx.r5.s64 = 1630535680;
	// b 0x8240346c
	goto loc_8240346C;
loc_8240335C:
	// lwz r9,128(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r11,24(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x823fd6d4
	if (!cr6.gt) goto loc_823FD6D4;
	// lwz r8,20(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
loc_82403384:
	// mr r11,r22
	r11.u64 = r22.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x824033cc
	if (cr6.eq) goto loc_824033CC;
loc_82403390:
	// lwz r8,24(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// lwz r7,24(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// mullw r8,r11,r8
	ctx.r8.s64 = int64_t(r11.s32) * int64_t(ctx.r8.s32);
	// add r6,r8,r10
	ctx.r6.u64 = ctx.r8.u64 + ctx.r10.u64;
	// mullw r8,r10,r7
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,144(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// add r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 + r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stwx r7,r8,r15
	PPC_STORE_U32(ctx.r8.u32 + r15.u32, ctx.r7.u32);
	// lwz r8,20(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82403390
	if (cr6.lt) goto loc_82403390;
loc_824033CC:
	// lwz r11,24(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82403384
	if (cr6.lt) goto loc_82403384;
	// b 0x823fd6d4
	goto loc_823FD6D4;
loc_824033E0:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403490
	if (cr6.eq) goto loc_82403490;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823fd6d4
	if (cr6.eq) goto loc_823FD6D4;
	// lwz r3,8(r14)
	ctx.r3.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfd f1,32016(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 32016);
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r8,144(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r11,-1
	r11.s64 = -1;
	// addi r7,r1,656
	ctx.r7.s64 = ctx.r1.s64 + 656;
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// stw r9,656(r1)
	PPC_STORE_U32(ctx.r1.u32 + 656, ctx.r9.u32);
	// lwz r9,4(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// stw r9,660(r1)
	PPC_STORE_U32(ctx.r1.u32 + 660, ctx.r9.u32);
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r9,664(r1)
	PPC_STORE_U32(ctx.r1.u32 + 664, ctx.r9.u32);
	// li r9,6
	ctx.r9.s64 = 6;
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// stw r10,720(r1)
	PPC_STORE_U32(ctx.r1.u32 + 720, ctx.r10.u32);
	// stw r10,724(r1)
	PPC_STORE_U32(ctx.r1.u32 + 724, ctx.r10.u32);
	// stw r10,728(r1)
	PPC_STORE_U32(ctx.r1.u32 + 728, ctx.r10.u32);
	// stw r10,732(r1)
	PPC_STORE_U32(ctx.r1.u32 + 732, ctx.r10.u32);
	// stw r8,668(r1)
	PPC_STORE_U32(ctx.r1.u32 + 668, ctx.r8.u32);
	// addi r8,r1,720
	ctx.r8.s64 = ctx.r1.s64 + 720;
	// stw r11,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r11.u32);
	// stw r11,4(r15)
	PPC_STORE_U32(r15.u32 + 4, r11.u32);
	// stw r11,8(r15)
	PPC_STORE_U32(r15.u32 + 8, r11.u32);
	// stw r11,12(r15)
	PPC_STORE_U32(r15.u32 + 12, r11.u32);
loc_8240346C:
	// ori r5,r5,4
	ctx.r5.u64 = ctx.r5.u64 | 4;
	// b 0x82402760
	goto loc_82402760;
loc_82403474:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,56(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 56);
	// li r5,3042
	ctx.r5.s64 = 3042;
	// addi r6,r11,31968
	ctx.r6.s64 = r11.s64 + 31968;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
loc_82403490:
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
loc_82403498:
	// lwz r10,532(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// addi r29,r1,144
	r29.s64 = ctx.r1.s64 + 144;
	// lwz r11,1716(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	// li r30,4
	r30.s64 = 4;
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// lwz r10,528(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	// stw r10,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r10.u32);
loc_824034B4:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// bne 0x824034b4
	if (!cr0.eq) goto loc_824034B4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x824034dc
	goto loc_824034DC;
loc_824034D4:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_824034DC:
	// addi r1,r1,1696
	ctx.r1.s64 = ctx.r1.s64 + 1696;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_824034E8"))) PPC_WEAK_FUNC(sub_824034E8);
PPC_FUNC_IMPL(__imp__sub_824034E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc8
	// stfd f29,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f29.u64);
	// stfd f30,-152(r1)
	PPC_STORE_U64(ctx.r1.u32 + -152, f30.u64);
	// stfd f31,-144(r1)
	PPC_STORE_U64(ctx.r1.u32 + -144, f31.u64);
	// stwu r1,-480(r1)
	ea = -480 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r8
	r29.u64 = ctx.r8.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r21,r4
	r21.u64 = ctx.r4.u64;
	// mr r16,r5
	r16.u64 = ctx.r5.u64;
	// mr r20,r6
	r20.u64 = ctx.r6.u64;
	// mr r19,r7
	r19.u64 = ctx.r7.u64;
	// mr r30,r9
	r30.u64 = ctx.r9.u64;
	// mr r24,r10
	r24.u64 = ctx.r10.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82403728
	if (cr6.eq) goto loc_82403728;
	// li r18,0
	r18.s64 = 0;
	// li r26,1
	r26.s64 = 1;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// stw r18,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r18.u32);
	// beq cr6,0x82403548
	if (cr6.eq) goto loc_82403548;
	// divwu r25,r29,r20
	r25.u32 = r29.u32 / r20.u32;
	// twllei r20,0
	// b 0x8240354c
	goto loc_8240354C;
loc_82403548:
	// mr r25,r26
	r25.u64 = r26.u64;
loc_8240354C:
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// lwz r4,0(r24)
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lfd f29,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// blt 0x82403648
	if (cr0.lt) goto loc_82403648;
	// lfd f0,192(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// bge cr6,0x82403584
	if (!cr6.lt) goto loc_82403584;
	// lfd f13,184(r31)
	ctx.f13.u64 = PPC_LOAD_U64(r31.u32 + 184);
	// fsub f30,f0,f13
	f30.f64 = f0.f64 - ctx.f13.f64;
	// b 0x8240359c
	goto loc_8240359C;
loc_82403584:
	// fcmpu cr6,f0,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f29.f64);
	// ble cr6,0x82403598
	if (!cr6.gt) goto loc_82403598;
	// lfd f13,184(r31)
	ctx.f13.u64 = PPC_LOAD_U64(r31.u32 + 184);
	// fadd f30,f13,f0
	f30.f64 = ctx.f13.f64 + f0.f64;
	// b 0x8240359c
	goto loc_8240359C;
loc_82403598:
	// fmr f30,f29
	ctx.fpscr.disableFlushMode();
	f30.f64 = f29.f64;
loc_8240359C:
	// lfd f0,200(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// bge cr6,0x824035b4
	if (!cr6.lt) goto loc_824035B4;
	// lfd f13,184(r31)
	ctx.f13.u64 = PPC_LOAD_U64(r31.u32 + 184);
	// fsub f31,f0,f13
	f31.f64 = f0.f64 - ctx.f13.f64;
	// b 0x824035cc
	goto loc_824035CC;
loc_824035B4:
	// fcmpu cr6,f0,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f29.f64);
	// ble cr6,0x824035c8
	if (!cr6.gt) goto loc_824035C8;
	// lfd f13,184(r31)
	ctx.f13.u64 = PPC_LOAD_U64(r31.u32 + 184);
	// fadd f31,f13,f0
	f31.f64 = ctx.f13.f64 + f0.f64;
	// b 0x824035cc
	goto loc_824035CC;
loc_824035C8:
	// fmr f31,f29
	ctx.fpscr.disableFlushMode();
	f31.f64 = f29.f64;
loc_824035CC:
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x823ae098
	sub_823AE098(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824035f8
	if (cr0.eq) goto loc_824035F8;
	// fcmpu cr6,f30,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f29.f64);
	// blt cr6,0x824035f8
	if (cr6.lt) goto loc_824035F8;
	// addi r11,r1,164
	r11.s64 = ctx.r1.s64 + 164;
	// fctidz f0,f30
	f0.s64 = (f30.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&f30.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r18,164(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// b 0x824035fc
	goto loc_824035FC;
loc_824035F8:
	// li r18,0
	r18.s64 = 0;
loc_824035FC:
	// fcmpu cr6,f31,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f29.f64);
	// blt cr6,0x8240370c
	if (cr6.lt) goto loc_8240370C;
	// mullw r11,r18,r20
	r11.s64 = int64_t(r18.s32) * int64_t(r20.s32);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bge cr6,0x8240370c
	if (!cr6.lt) goto loc_8240370C;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x823ae098
	sub_823AE098(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82403634
	if (cr0.eq) goto loc_82403634;
	// addi r11,r1,164
	r11.s64 = ctx.r1.s64 + 164;
	// fctidz f0,f31
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f31.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&f31.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// b 0x82403638
	goto loc_82403638;
loc_82403634:
	// addi r11,r25,-1
	r11.s64 = r25.s64 + -1;
loc_82403638:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// ble cr6,0x82403648
	if (!cr6.gt) goto loc_82403648;
	// mr r25,r11
	r25.u64 = r11.u64;
loc_82403648:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x82404a34
	if (cr6.eq) goto loc_82404A34;
	// lwz r27,564(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82403678
	if (!cr6.eq) goto loc_82403678;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f9608
	sub_823F9608(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
loc_82403678:
	// li r17,-1
	r17.s64 = -1;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x824036d0
	if (cr6.eq) goto loc_824036D0;
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r10,r19
	ctx.r10.u64 = r19.u64;
	// mr r11,r29
	r11.u64 = r29.u64;
	// lwz r6,20(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// lwz r5,16(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
loc_824036A0:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// and r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 & ctx.r9.u64;
	// bne 0x824036a0
	if (!cr0.eq) goto loc_824036A0;
loc_824036D0:
	// not r10,r8
	ctx.r10.u64 = ~ctx.r8.u64;
	// rlwinm. r11,r8,0,11,11
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r30,r9,0,30,30
	r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	// rlwinm r28,r10,25,31,31
	r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x1;
	// rlwinm r3,r9,0,25,25
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	// rlwinm r4,r9,0,21,21
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x400;
	// beq 0x82403738
	if (cr0.eq) goto loc_82403738;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// cmplw cr6,r18,r11
	cr6.compare<uint32_t>(r18.u32, r11.u32, xer);
	// blt cr6,0x82403704
	if (cr6.lt) goto loc_82403704;
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// ble cr6,0x82403754
	if (!cr6.gt) goto loc_82403754;
loc_82403704:
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x82403750
	goto loc_82403750;
loc_8240370C:
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82403728
	if (cr6.eq) goto loc_82403728;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// stw r26,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r26.u32);
	// beq cr6,0x82404a34
	if (cr6.eq) goto loc_82404A34;
	// b 0x82403840
	goto loc_82403840;
loc_82403728:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3030
	ctx.r5.s64 = 3030;
	// addi r6,r11,32272
	ctx.r6.s64 = r11.s64 + 32272;
	// b 0x82403938
	goto loc_82403938;
loc_82403738:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bne cr6,0x82403754
	if (!cr6.eq) goto loc_82403754;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rlwinm. r11,r11,0,10,10
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82403754
	if (!cr0.eq) goto loc_82403754;
loc_82403750:
	// stw r26,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r26.u32);
loc_82403754:
	// addi r11,r18,1
	r11.s64 = r18.s64 + 1;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x82403770
	if (!cr6.eq) goto loc_82403770;
	// mullw r11,r18,r20
	r11.s64 = int64_t(r18.s32) * int64_t(r20.s32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r19
	ctx.r4.u64 = r11.u64 + r19.u64;
	// b 0x82403844
	goto loc_82403844;
loc_82403770:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// cmplw cr6,r20,r29
	cr6.compare<uint32_t>(r20.u32, r29.u32, xer);
	// bge cr6,0x82403824
	if (!cr6.lt) goto loc_82403824;
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
	// add r8,r11,r19
	ctx.r8.u64 = r11.u64 + r19.u64;
loc_82403790:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bne cr6,0x824037a0
	if (!cr6.eq) goto loc_824037A0;
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x8240382c
	if (cr6.eq) goto loc_8240382C;
loc_824037A0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r23,0(r8)
	r23.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r23,2,0,29
	r23.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r23,r11
	r11.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// lwz r23,4(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r22,4(r11)
	r22.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r23,r22
	cr6.compare<uint32_t>(r23.u32, r22.u32, xer);
	// bne cr6,0x82403808
	if (!cr6.eq) goto loc_82403808;
	// lwz r23,8(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r22,8(r11)
	r22.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r23,r22
	cr6.compare<uint32_t>(r23.u32, r22.u32, xer);
	// bne cr6,0x82403808
	if (!cr6.eq) goto loc_82403808;
	// lwz r23,12(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r22,12(r11)
	r22.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r23,r22
	cr6.compare<uint32_t>(r23.u32, r22.u32, xer);
	// beq cr6,0x824037f4
	if (cr6.eq) goto loc_824037F4;
	// li r5,0
	ctx.r5.s64 = 0;
loc_824037F4:
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82403810
	if (cr6.eq) goto loc_82403810;
	// b 0x8240380c
	goto loc_8240380C;
loc_82403808:
	// li r5,0
	ctx.r5.s64 = 0;
loc_8240380C:
	// li r6,0
	ctx.r6.s64 = 0;
loc_82403810:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r29
	cr6.compare<uint32_t>(ctx.r7.u32, r29.u32, xer);
	// blt cr6,0x82403790
	if (cr6.lt) goto loc_82403790;
loc_82403824:
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne cr6,0x82403830
	if (!cr6.eq) goto loc_82403830;
loc_8240382C:
	// li r4,0
	ctx.r4.s64 = 0;
loc_82403830:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x82403854
	if (cr6.eq) goto loc_82403854;
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x82403854
	if (cr6.eq) goto loc_82403854;
loc_82403840:
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
loc_82403844:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// rlwinm r5,r20,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// b 0x82404a34
	goto loc_82404A34;
loc_82403854:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq cr6,0x82403900
	if (cr6.eq) goto loc_82403900;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bne cr6,0x824038f8
	if (!cr6.eq) goto loc_824038F8;
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,0(r19)
	ctx.r8.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// cmplwi cr6,r20,1
	cr6.compare<uint32_t>(r20.u32, 1, xer);
	// add r9,r11,r19
	ctx.r9.u64 = r11.u64 + r19.u64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r7,12(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// subf r6,r7,r11
	ctx.r6.s64 = r11.s64 - ctx.r7.s64;
	// ble cr6,0x824038f8
	if (!cr6.gt) goto loc_824038F8;
	// lwz r7,20(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// addi r11,r9,4
	r11.s64 = ctx.r9.s64 + 4;
	// addi r10,r19,4
	ctx.r10.s64 = r19.s64 + 4;
loc_824038B0:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r23,0(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r23,2,0,29
	r23.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwzx r23,r23,r7
	r23.u64 = PPC_LOAD_U32(r23.u32 + ctx.r7.u32);
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r23,12(r23)
	r23.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// subf r9,r23,r9
	ctx.r9.s64 = ctx.r9.s64 - r23.s64;
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// bne cr6,0x824038f4
	if (!cr6.eq) goto loc_824038F4;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r20
	cr6.compare<uint32_t>(ctx.r8.u32, r20.u32, xer);
	// blt cr6,0x824038b0
	if (cr6.lt) goto loc_824038B0;
	// b 0x824038f8
	goto loc_824038F8;
loc_824038F4:
	// li r4,0
	ctx.r4.s64 = 0;
loc_824038F8:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bne cr6,0x82403904
	if (!cr6.eq) goto loc_82403904;
loc_82403900:
	// li r30,0
	r30.s64 = 0;
loc_82403904:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82403948
	if (cr6.eq) goto loc_82403948;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x82403948
	if (!cr6.eq) goto loc_82403948;
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8240392c
	if (cr6.eq) goto loc_8240392C;
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82403e30
	if (!cr6.eq) goto loc_82403E30;
loc_8240392C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3042
	ctx.r5.s64 = 3042;
	// addi r6,r11,32200
	ctx.r6.s64 = r11.s64 + 32200;
loc_82403938:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82403e30
	goto loc_82403E30;
loc_82403948:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq cr6,0x82403e08
	if (cr6.eq) goto loc_82403E08;
	// mr r11,r26
	r11.u64 = r26.u64;
	// cmplw cr6,r29,r20
	cr6.compare<uint32_t>(r29.u32, r20.u32, xer);
	// ble cr6,0x8240398c
	if (!cr6.gt) goto loc_8240398C;
	// rlwinm r10,r20,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,0(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r19
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r19.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
loc_8240398C:
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
	// lis r10,8256
	ctx.r10.s64 = 541065216;
	// ori r28,r10,1
	r28.u64 = ctx.r10.u64 | 1;
	// bne cr6,0x824039b4
	if (!cr6.eq) goto loc_824039B4;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82403b08
	if (!cr0.eq) goto loc_82403B08;
loc_824039B4:
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// std r11,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, r11.u64);
	// lfd f0,192(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// fcfid f1,f0
	ctx.f1.f64 = double(f0.s64);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// stw r3,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// mr r11,r17
	r11.u64 = r17.u64;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
	// lwz r8,160(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// stw r11,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, r11.u32);
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82403ad4
	if (!cr0.eq) goto loc_82403AD4;
	// lis r5,4128
	ctx.r5.s64 = 270532608;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,208
	ctx.r6.s64 = ctx.r1.s64 + 208;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lis r5,4160
	ctx.r5.s64 = 272629760;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,208
	ctx.r7.s64 = ctx.r1.s64 + 208;
	// addi r6,r1,212
	ctx.r6.s64 = ctx.r1.s64 + 212;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,212
	ctx.r7.s64 = ctx.r1.s64 + 212;
	// addi r6,r1,216
	ctx.r6.s64 = ctx.r1.s64 + 216;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// li r9,6
	ctx.r9.s64 = 6;
	// addi r8,r1,208
	ctx.r8.s64 = ctx.r1.s64 + 208;
	// addi r7,r1,216
	ctx.r7.s64 = ctx.r1.s64 + 216;
	// addi r6,r1,220
	ctx.r6.s64 = ctx.r1.s64 + 220;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r11,220(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
loc_82403AD4:
	// lis r5,8272
	ctx.r5.s64 = 542113792;
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,224
	ctx.r6.s64 = ctx.r1.s64 + 224;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r11,224(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
loc_82403B08:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// stw r8,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r8.u32);
	// beq cr6,0x82403c60
	if (cr6.eq) goto loc_82403C60;
	// lwz r7,20(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,136(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 136);
	// mr r11,r17
	r11.u64 = r17.u64;
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r9,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r9.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// lwz r9,164(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// stw r11,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, r11.u32);
	// lwz r11,20(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82403c30
	if (!cr0.eq) goto loc_82403C30;
	// lis r5,4128
	ctx.r5.s64 = 270532608;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,164
	ctx.r7.s64 = ctx.r1.s64 + 164;
	// addi r6,r1,240
	ctx.r6.s64 = ctx.r1.s64 + 240;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lis r5,4160
	ctx.r5.s64 = 272629760;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,240
	ctx.r7.s64 = ctx.r1.s64 + 240;
	// addi r6,r1,244
	ctx.r6.s64 = ctx.r1.s64 + 244;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,244
	ctx.r7.s64 = ctx.r1.s64 + 244;
	// addi r6,r1,248
	ctx.r6.s64 = ctx.r1.s64 + 248;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// li r9,6
	ctx.r9.s64 = 6;
	// addi r8,r1,240
	ctx.r8.s64 = ctx.r1.s64 + 240;
	// addi r7,r1,248
	ctx.r7.s64 = ctx.r1.s64 + 248;
	// addi r6,r1,252
	ctx.r6.s64 = ctx.r1.s64 + 252;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r11,252(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r11.u32);
loc_82403C30:
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// addi r7,r1,164
	ctx.r7.s64 = ctx.r1.s64 + 164;
	// addi r6,r1,256
	ctx.r6.s64 = ctx.r1.s64 + 256;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r11,256(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
loc_82403C60:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82403cc0
	if (cr6.eq) goto loc_82403CC0;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// stw r17,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, r17.u32);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,168
	ctx.r6.s64 = ctx.r1.s64 + 168;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r10,168(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,140(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 140);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
loc_82403CC0:
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82404a34
	if (cr6.eq) goto loc_82404A34;
	// mr r29,r19
	r29.u64 = r19.u64;
	// subf r27,r19,r16
	r27.s64 = r16.s64 - r19.s64;
loc_82403CD4:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// lwz r4,136(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stwx r3,r27,r29
	PPC_STORE_U32(r27.u32 + r29.u32, ctx.r3.u32);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r4,r9,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243dd20
	sub_8243DD20(ctx, base);
	// stw r17,52(r30)
	PPC_STORE_U32(r30.u32 + 52, r17.u32);
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r11,31
	r11.s64 = 31;
	// cmplw cr6,r18,r25
	cr6.compare<uint32_t>(r18.u32, r25.u32, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// stw r10,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r10.u32);
	// lfd f0,168(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 168);
	// stfd f0,32(r30)
	PPC_STORE_U64(r30.u32 + 32, f0.u64);
	// lfd f0,176(r31)
	f0.u64 = PPC_LOAD_U64(r31.u32 + 176);
	// stfd f0,40(r30)
	PPC_STORE_U64(r30.u32 + 40, f0.u64);
	// bge cr6,0x82403dc4
	if (!cr6.lt) goto loc_82403DC4;
	// mullw r11,r18,r20
	r11.s64 = int64_t(r18.s32) * int64_t(r20.s32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// rlwinm r8,r20,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r18,r25
	ctx.r9.s64 = r25.s64 - r18.s64;
	// add r10,r11,r19
	ctx.r10.u64 = r11.u64 + r19.u64;
loc_82403D60:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r6,0(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// and r7,r6,r7
	ctx.r7.u64 = ctx.r6.u64 & ctx.r7.u64;
	// stw r7,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r7.u32);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r7,r7,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82403db8
	if (cr0.eq) goto loc_82403DB8;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// lfd f13,32(r30)
	ctx.f13.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x82403da4
	if (!cr6.gt) goto loc_82403DA4;
	// stfd f0,32(r30)
	PPC_STORE_U64(r30.u32 + 32, f0.u64);
loc_82403DA4:
	// lfd f0,40(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// lfd f13,40(r30)
	ctx.f13.u64 = PPC_LOAD_U64(r30.u32 + 40);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x82403db8
	if (!cr6.lt) goto loc_82403DB8;
	// stfd f0,40(r30)
	PPC_STORE_U64(r30.u32 + 40, f0.u64);
loc_82403DB8:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// bne 0x82403d60
	if (!cr0.eq) goto loc_82403D60;
loc_82403DC4:
	// lfd f0,32(r30)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// lfd f13,40(r30)
	ctx.f13.u64 = PPC_LOAD_U64(r30.u32 + 40);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x82403de0
	if (cr6.gt) goto loc_82403DE0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_82403DE0:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x82403df4
	if (!cr6.eq) goto loc_82403DF4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// ori r11,r11,128
	r11.u64 = r11.u64 | 128;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_82403DF4:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r20
	cr6.compare<uint32_t>(r28.u32, r20.u32, xer);
	// blt cr6,0x82403cd4
	if (cr6.lt) goto loc_82403CD4;
	// b 0x82404a34
	goto loc_82404A34;
loc_82403E08:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x82403e3c
	if (!cr6.eq) goto loc_82403E3C;
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82403e2c
	if (!cr6.eq) goto loc_82403E2C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3512
	ctx.r5.s64 = 3512;
	// addi r6,r11,32144
	ctx.r6.s64 = r11.s64 + 32144;
	// b 0x82403938
	goto loc_82403938;
loc_82403E2C:
	// stw r26,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r26.u32);
loc_82403E30:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82404a38
	goto loc_82404A38;
loc_82403E3C:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82403ee8
	if (cr0.eq) goto loc_82403EE8;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x824049c0
	if (cr0.eq) goto loc_824049C0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82403ebc
	if (cr6.eq) goto loc_82403EBC;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r11,r20
	r11.u64 = r20.u64;
loc_82403E80:
	// lwz r9,0(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82403e80
	if (!cr0.eq) goto loc_82403E80;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82403ebc
	if (cr6.eq) goto loc_82403EBC;
	// mr r11,r16
	r11.u64 = r16.u64;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// cmplwi r20,0
	cr0.compare<uint32_t>(r20.u32, 0, xer);
	// beq 0x82403ebc
	if (cr0.eq) goto loc_82403EBC;
	// mtctr r20
	ctr.u64 = r20.u64;
loc_82403EB0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82403eb0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82403EB0;
loc_82403EBC:
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
	// add r7,r11,r19
	ctx.r7.u64 = r11.u64 + r19.u64;
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f8108
	sub_823F8108(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// b 0x82404a34
	goto loc_82404A34;
loc_82403EE8:
	// subf r22,r18,r25
	r22.s64 = r25.s64 - r18.s64;
	// cmplwi cr6,r22,4
	cr6.compare<uint32_t>(r22.u32, 4, xer);
	// bgt cr6,0x82404458
	if (cr6.gt) goto loc_82404458;
	// cmplwi cr6,r20,1
	cr6.compare<uint32_t>(r20.u32, 1, xer);
	// bne cr6,0x82403f04
	if (!cr6.eq) goto loc_82403F04;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82403f14
	if (cr6.eq) goto loc_82403F14;
loc_82403F04:
	// cmplwi cr6,r20,4
	cr6.compare<uint32_t>(r20.u32, 4, xer);
	// bgt cr6,0x82404458
	if (cr6.gt) goto loc_82404458;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x82404458
	if (cr6.eq) goto loc_82404458;
loc_82403F14:
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82403f38
	if (cr6.eq) goto loc_82403F38;
	// cmplwi cr6,r20,1
	cr6.compare<uint32_t>(r20.u32, 1, xer);
	// bgt cr6,0x82403f34
	if (cr6.gt) goto loc_82403F34;
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rlwinm. r11,r11,0,10,10
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82403f38
	if (!cr0.eq) goto loc_82403F38;
loc_82403F34:
	// stw r26,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r26.u32);
loc_82403F38:
	// mulli r11,r22,7
	r11.s64 = r22.s64 * 7;
	// addi r30,r11,4
	r30.s64 = r11.s64 + 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r11,r3
	r11.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824049c0
	if (cr0.eq) goto loc_824049C0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82403f7c
	if (cr6.eq) goto loc_82403F7C;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x82403f7c
	if (cr0.eq) goto loc_82403F7C;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_82403F70:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82403f70
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82403F70;
loc_82403F7C:
	// addi r9,r1,272
	ctx.r9.s64 = ctx.r1.s64 + 272;
	// li r10,4
	ctx.r10.s64 = 4;
loc_82403F84:
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82403f84
	if (!cr0.eq) goto loc_82403F84;
	// rlwinm r8,r22,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,288
	ctx.r9.s64 = ctx.r1.s64 + 288;
	// li r10,7
	ctx.r10.s64 = 7;
loc_82403FA8:
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82403fa8
	if (!cr0.eq) goto loc_82403FA8;
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
	// lwz r8,20(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lis r8,8256
	ctx.r8.s64 = 541065216;
	// ori r28,r8,1
	r28.u64 = ctx.r8.u64 | 1;
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x824040c8
	if (!cr0.eq) goto loc_824040C8;
	// lwz r9,112(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rlwinm. r9,r9,0,10,10
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82404004
	if (cr0.eq) goto loc_82404004;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824040c8
	if (!cr0.eq) goto loc_824040C8;
loc_82404004:
	// lwz r29,272(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// lis r5,4128
	ctx.r5.s64 = 270532608;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r30,276(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// lis r5,4160
	ctx.r5.s64 = 272629760;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r30,280(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r30,284(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// li r9,6
	ctx.r9.s64 = 6;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
loc_824040C8:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r25,308(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// lwz r11,112(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// rlwinm. r11,r11,0,10,10
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824042a8
	if (cr0.eq) goto loc_824042A8;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82404148
	if (cr6.eq) goto loc_82404148;
	// clrldi r11,r18,32
	r11.u64 = r18.u64 & 0xFFFFFFFF;
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// std r11,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, r11.u64);
	// lfd f0,192(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// stw r3,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// li r9,4
	ctx.r9.s64 = 4;
	// stw r17,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r17.u32);
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r11,172(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
loc_82404148:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824041a8
	if (cr6.eq) goto loc_824041A8;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// stw r17,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r17.u32);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,176
	ctx.r6.s64 = ctx.r1.s64 + 176;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,140(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 140);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
loc_824041A8:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f31,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// bne cr6,0x82404234
	if (!cr6.eq) goto loc_82404234;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,14412
	ctx.r4.s64 = r11.s64 + 14412;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1873
	ctx.r5.s64 = 1873;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,72(r31)
	PPC_STORE_U32(r31.u32 + 72, ctx.r3.u32);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// li r29,0
	r29.s64 = 0;
loc_824041E8:
	// li r30,0
	r30.s64 = 0;
loc_824041EC:
	// cmplw cr6,r29,r30
	cr6.compare<uint32_t>(r29.u32, r30.u32, xer);
	// bne cr6,0x824041fc
	if (!cr6.eq) goto loc_824041FC;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// b 0x82404200
	goto loc_82404200;
loc_824041FC:
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
loc_82404200:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r4,72(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// blt cr6,0x824041ec
	if (cr6.lt) goto loc_824041EC;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// blt cr6,0x824041e8
	if (cr6.lt) goto loc_824041E8;
loc_82404234:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x8240439c
	if (cr6.eq) goto loc_8240439C;
	// mr r30,r25
	r30.u64 = r25.u64;
loc_82404244:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r4,72(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rotlwi r10,r3,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// lwz r9,160(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r22
	cr6.compare<uint32_t>(r29.u32, r22.u32, xer);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// li r10,279
	ctx.r10.s64 = 279;
	// stfd f29,32(r11)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + 32, f29.u64);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// stfd f31,40(r11)
	PPC_STORE_U64(r11.u32 + 40, f31.u64);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// blt cr6,0x82404244
	if (cr6.lt) goto loc_82404244;
	// b 0x8240439c
	goto loc_8240439C;
loc_824042A8:
	// lwz r27,292(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// li r29,0
	r29.s64 = 0;
	// lwz r26,288(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82404318
	if (cr6.eq) goto loc_82404318;
	// mr r30,r27
	r30.u64 = r27.u64;
	// subf r28,r27,r26
	r28.s64 = r26.s64 - r27.s64;
	// b 0x824042cc
	goto loc_824042CC;
loc_824042C8:
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
loc_824042CC:
	// add r11,r29,r18
	r11.u64 = r29.u64 + r18.u64;
	// stwx r10,r28,r30
	PPC_STORE_U32(r28.u32 + r30.u32, ctx.r10.u32);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// std r11,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, r11.u64);
	// lfd f0,192(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r22
	cr6.compare<uint32_t>(r29.u32, r22.u32, xer);
	// blt cr6,0x824042c8
	if (cr6.lt) goto loc_824042C8;
loc_82404318:
	// lwz r29,296(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// clrlwi r30,r22,12
	r30.u64 = r22.u32 & 0xFFFFF;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r28,300(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// lwz r29,304(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// oris r5,r30,8240
	ctx.r5.u64 = r30.u64 | 540016640;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
loc_8240439C:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x824043c4
	if (cr6.eq) goto loc_824043C4;
	// mr r11,r16
	r11.u64 = r16.u64;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// cmplwi r20,0
	cr0.compare<uint32_t>(r20.u32, 0, xer);
	// beq 0x824043c4
	if (cr0.eq) goto loc_824043C4;
	// mtctr r20
	ctr.u64 = r20.u64;
loc_824043B8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824043b8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824043B8;
loc_824043C4:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82404a34
	if (cr6.eq) goto loc_82404A34;
	// clrlwi r11,r22,12
	r11.u64 = r22.u32 & 0xFFFFF;
	// lwz r30,312(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// mr r28,r16
	r28.u64 = r16.u64;
	// oris r27,r11,20480
	r27.u64 = r11.u64 | 1342177280;
loc_824043E0:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x8240441c
	if (cr6.eq) goto loc_8240441C;
	// mullw r11,r18,r20
	r11.s64 = int64_t(r18.s32) * int64_t(r20.s32);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// rlwinm r8,r20,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r22
	r11.u64 = r22.u64;
	// add r10,r10,r19
	ctx.r10.u64 = ctx.r10.u64 + r19.u64;
loc_82404404:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82404404
	if (!cr0.eq) goto loc_82404404;
loc_8240441C:
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r20
	cr6.compare<uint32_t>(r29.u32, r20.u32, xer);
	// blt cr6,0x824043e0
	if (cr6.lt) goto loc_824043E0;
	// b 0x82404a34
	goto loc_82404A34;
loc_82404458:
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82404468
	if (cr6.eq) goto loc_82404468;
	// stw r26,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r26.u32);
loc_82404468:
	// mulli r11,r22,3
	r11.s64 = r22.s64 * 3;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwinm r30,r11,1,0,30
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r11,r3
	r11.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824049c0
	if (cr0.eq) goto loc_824049C0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824044b4
	if (cr6.eq) goto loc_824044B4;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824044b4
	if (cr0.eq) goto loc_824044B4;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824044A8:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x824044a8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824044A8;
loc_824044B4:
	// addi r9,r1,272
	ctx.r9.s64 = ctx.r1.s64 + 272;
	// li r10,4
	ctx.r10.s64 = 4;
loc_824044BC:
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x824044bc
	if (!cr0.eq) goto loc_824044BC;
	// rlwinm r8,r22,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,288
	ctx.r9.s64 = ctx.r1.s64 + 288;
	// li r10,6
	ctx.r10.s64 = 6;
loc_824044E0:
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x824044e0
	if (!cr0.eq) goto loc_824044E0;
	// rlwinm r23,r20,2,0,29
	r23.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,312
	ctx.r9.s64 = ctx.r1.s64 + 312;
	// li r10,2
	ctx.r10.s64 = 2;
loc_82404504:
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// add r11,r23,r11
	r11.u64 = r23.u64 + r11.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82404504
	if (!cr0.eq) goto loc_82404504;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lis r9,8256
	ctx.r9.s64 = 541065216;
	// ori r28,r9,1
	r28.u64 = ctx.r9.u64 | 1;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240460c
	if (!cr0.eq) goto loc_8240460C;
	// lwz r29,272(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// lis r5,4128
	ctx.r5.s64 = 270532608;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r30,276(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// lis r5,4160
	ctx.r5.s64 = 272629760;
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r30,280(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// lis r5,4112
	ctx.r5.s64 = 269484032;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r30,284(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// li r9,6
	ctx.r9.s64 = 6;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
loc_8240460C:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r24,308(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// lwz r10,112(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// rlwinm. r10,r10,0,10,10
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824047f4
	if (cr0.eq) goto loc_824047F4;
	// cmplwi cr6,r22,4
	cr6.compare<uint32_t>(r22.u32, 4, xer);
	// bgt cr6,0x824047f4
	if (cr6.gt) goto loc_824047F4;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82404694
	if (cr6.eq) goto loc_82404694;
	// clrldi r11,r18,32
	r11.u64 = r18.u64 & 0xFFFFFFFF;
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// std r11,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, r11.u64);
	// lfd f0,192(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// stw r3,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// li r9,4
	ctx.r9.s64 = 4;
	// stw r17,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r17.u32);
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,180
	ctx.r6.s64 = ctx.r1.s64 + 180;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
loc_82404694:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824046f4
	if (cr6.eq) goto loc_824046F4;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// stw r17,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r17.u32);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,184
	ctx.r6.s64 = ctx.r1.s64 + 184;
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// lwz r10,184(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,140(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 140);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
loc_824046F4:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f31,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// bne cr6,0x82404780
	if (!cr6.eq) goto loc_82404780;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,14412
	ctx.r4.s64 = r11.s64 + 14412;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,1873
	ctx.r5.s64 = 1873;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,72(r31)
	PPC_STORE_U32(r31.u32 + 72, ctx.r3.u32);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// li r29,0
	r29.s64 = 0;
loc_82404734:
	// li r30,0
	r30.s64 = 0;
loc_82404738:
	// cmplw cr6,r29,r30
	cr6.compare<uint32_t>(r29.u32, r30.u32, xer);
	// bne cr6,0x82404748
	if (!cr6.eq) goto loc_82404748;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// b 0x8240474c
	goto loc_8240474C;
loc_82404748:
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
loc_8240474C:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r4,72(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// blt cr6,0x82404738
	if (cr6.lt) goto loc_82404738;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplwi cr6,r29,4
	cr6.compare<uint32_t>(r29.u32, 4, xer);
	// blt cr6,0x82404734
	if (cr6.lt) goto loc_82404734;
loc_82404780:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x824048e8
	if (cr6.eq) goto loc_824048E8;
	// mr r30,r24
	r30.u64 = r24.u64;
loc_82404790:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r4,72(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rotlwi r10,r3,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// lwz r9,160(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r22
	cr6.compare<uint32_t>(r29.u32, r22.u32, xer);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// li r10,279
	ctx.r10.s64 = 279;
	// stfd f29,32(r11)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + 32, f29.u64);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// stfd f31,40(r11)
	PPC_STORE_U64(r11.u32 + 40, f31.u64);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// blt cr6,0x82404790
	if (cr6.lt) goto loc_82404790;
	// b 0x824048e8
	goto loc_824048E8;
loc_824047F4:
	// lwz r27,292(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// li r29,0
	r29.s64 = 0;
	// lwz r26,288(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82404864
	if (cr6.eq) goto loc_82404864;
	// mr r30,r27
	r30.u64 = r27.u64;
	// subf r28,r27,r26
	r28.s64 = r26.s64 - r27.s64;
	// b 0x82404818
	goto loc_82404818;
loc_82404814:
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
loc_82404818:
	// add r10,r29,r18
	ctx.r10.u64 = r29.u64 + r18.u64;
	// stwx r11,r28,r30
	PPC_STORE_U32(r28.u32 + r30.u32, r11.u32);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// std r10,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r10.u64);
	// lfd f0,192(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x824049c0
	if (cr6.eq) goto loc_824049C0;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r22
	cr6.compare<uint32_t>(r29.u32, r22.u32, xer);
	// blt cr6,0x82404814
	if (cr6.lt) goto loc_82404814;
loc_82404864:
	// lwz r29,296(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// clrlwi r30,r22,12
	r30.u64 = r22.u32 & 0xFFFFF;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r28,300(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// lwz r29,304(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// oris r5,r30,8240
	ctx.r5.u64 = r30.u64 | 540016640;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
loc_824048E8:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x8240490c
	if (cr6.eq) goto loc_8240490C;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// mr r11,r20
	r11.u64 = r20.u64;
loc_824048F8:
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x824048f8
	if (!cr0.eq) goto loc_824048F8;
loc_8240490C:
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82404a34
	if (cr6.eq) goto loc_82404A34;
	// mullw r11,r18,r20
	r11.s64 = int64_t(r18.s32) * int64_t(r20.s32);
	// lwz r27,316(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r28,312(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// mr r26,r24
	r26.u64 = r24.u64;
	// add r29,r11,r19
	r29.u64 = r11.u64 + r19.u64;
loc_82404930:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82404984
	if (cr6.eq) goto loc_82404984;
	// mr r11,r16
	r11.u64 = r16.u64;
	// subf r9,r16,r28
	ctx.r9.s64 = r28.s64 - r16.s64;
	// subf r8,r16,r27
	ctx.r8.s64 = r27.s64 - r16.s64;
	// mr r10,r20
	ctx.r10.u64 = r20.u64;
loc_82404948:
	// lwz r7,0(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stwx r7,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r7.u32);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stwx r7,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82404948
	if (!cr0.eq) goto loc_82404948;
	// mr r11,r16
	r11.u64 = r16.u64;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// cmplwi r20,0
	cr0.compare<uint32_t>(r20.u32, 0, xer);
	// beq 0x82404984
	if (cr0.eq) goto loc_82404984;
	// mtctr r20
	ctr.u64 = r20.u64;
loc_82404978:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82404978
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82404978;
loc_82404984:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm. r10,r11,0,8,8
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824049cc
	if (cr0.eq) goto loc_824049CC;
	// rlwinm. r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824049cc
	if (!cr0.eq) goto loc_824049CC;
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f8108
	sub_823F8108(ctx, base);
	// b 0x82404a18
	goto loc_82404A18;
loc_824049C0:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82404a38
	goto loc_82404A38;
loc_824049CC:
	// clrlwi r30,r20,12
	r30.u64 = r20.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// oris r5,r30,8272
	ctx.r5.u64 = r30.u64 | 542113792;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r16
	ctx.r7.u64 = r16.u64;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
loc_82404A18:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404a38
	if (cr0.lt) goto loc_82404A38;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// add r29,r29,r23
	r29.u64 = r29.u64 + r23.u64;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r25,r22
	cr6.compare<uint32_t>(r25.u32, r22.u32, xer);
	// blt cr6,0x82404930
	if (cr6.lt) goto loc_82404930;
loc_82404A34:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82404A38:
	// addi r1,r1,480
	ctx.r1.s64 = ctx.r1.s64 + 480;
	// lfd f29,-160(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// lfd f30,-152(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -152);
	// lfd f31,-144(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// b 0x8239bd18
	return;
}

__attribute__((alias("__imp__sub_82404A4C"))) PPC_WEAK_FUNC(sub_82404A4C);
PPC_FUNC_IMPL(__imp__sub_82404A4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82404A50"))) PPC_WEAK_FUNC(sub_82404A50);
PPC_FUNC_IMPL(__imp__sub_82404A50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd4
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// mr r23,r7
	r23.u64 = ctx.r7.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x82404ac8
	if (cr6.eq) goto loc_82404AC8;
	// cmplw cr6,r23,r24
	cr6.compare<uint32_t>(r23.u32, r24.u32, xer);
	// bne cr6,0x82404a94
	if (!cr6.eq) goto loc_82404A94;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,112(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rlwinm. r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82404ac8
	if (!cr0.eq) goto loc_82404AC8;
loc_82404A94:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82404bcc
	if (cr0.lt) goto loc_82404BCC;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82404b00
	if (!cr6.eq) goto loc_82404B00;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82404b00
	if (!cr6.eq) goto loc_82404B00;
	// mr r24,r28
	r24.u64 = r28.u64;
loc_82404AC8:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r30,r10,2,0,29
	r30.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r20,8(r11)
	r20.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r19,12(r11)
	r19.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x82404b08
	if (!cr0.eq) goto loc_82404B08;
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x82404bbc
	goto loc_82404BBC;
loc_82404B00:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82404bcc
	goto loc_82404BCC;
loc_82404B08:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,92(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82404b94
	if (cr6.eq) goto loc_82404B94;
	// li r11,1
	r11.s64 = 1;
	// lwz r27,88(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r26,92(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// lwz r25,96(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// stw r28,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r28.u32);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// stw r28,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r28.u32);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// stw r11,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fad38
	sub_823FAD38(ctx, base);
	// stw r28,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r28.u32);
	// stw r28,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r28.u32);
	// stw r28,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r28.u32);
	// stw r27,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r27.u32);
	// stw r26,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r26.u32);
	// stw r25,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r25.u32);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bge 0x82404bbc
	if (!cr0.lt) goto loc_82404BBC;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5458
	sub_823F5458(ctx, base);
loc_82404B94:
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fbf10
	sub_823FBF10(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x82404bbc
	if (cr0.lt) goto loc_82404BBC;
	// mr r30,r28
	r30.u64 = r28.u64;
loc_82404BBC:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_82404BCC:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8239bd24
	return;
}

__attribute__((alias("__imp__sub_82404BD4"))) PPC_WEAK_FUNC(sub_82404BD4);
PPC_FUNC_IMPL(__imp__sub_82404BD4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82404BD8"))) PPC_WEAK_FUNC(sub_82404BD8);
PPC_FUNC_IMPL(__imp__sub_82404BD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stfd f31,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, f31.u64);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r20,r5
	r20.u64 = ctx.r5.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8240510c
	if (cr6.eq) goto loc_8240510C;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8240510c
	if (!cr6.eq) goto loc_8240510C;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8240510c
	if (!cr6.eq) goto loc_8240510C;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// lwz r30,12(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r21,r30
	r21.u64 = r30.u64;
	// bne cr6,0x82404e18
	if (!cr6.eq) goto loc_82404E18;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82404c9c
	if (!cr6.eq) goto loc_82404C9C;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// lwz r26,16(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r25,20(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82404c60
	if (!cr0.eq) goto loc_82404C60;
	// lwz r9,44(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// li r22,1
	r22.s64 = 1;
	// rlwinm. r9,r9,0,25,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x82404c64
	if (!cr0.eq) goto loc_82404C64;
loc_82404C60:
	// li r22,0
	r22.s64 = 0;
loc_82404C64:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82404c7c
	if (cr6.eq) goto loc_82404C7C;
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// li r23,1
	r23.s64 = 1;
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82404c80
	if (!cr0.eq) goto loc_82404C80;
loc_82404C7C:
	// li r23,0
	r23.s64 = 0;
loc_82404C80:
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// lwz r27,48(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// rlwinm r9,r10,0,22,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFF3FF;
	// lwz r24,64(r11)
	r24.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// rlwinm r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// stw r9,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r9.u32);
	// b 0x82404cd0
	goto loc_82404CD0;
loc_82404C9C:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8240510c
	if (!cr6.eq) goto loc_8240510C;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// li r22,0
	r22.s64 = 0;
	// li r23,0
	r23.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r26,16(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r9,r9,0,22,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFF3FF;
	// lwz r25,20(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r27,40(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// lwz r24,60(r11)
	r24.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// stw r9,32(r11)
	PPC_STORE_U32(r11.u32 + 32, ctx.r9.u32);
loc_82404CD0:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82404cfc
	if (cr6.eq) goto loc_82404CFC;
	// lwz r9,24(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
	// lwz r4,56(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	// bl 0x82406038
	sub_82406038(ctx, base);
	// b 0x82405044
	goto loc_82405044;
loc_82404CFC:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82404da8
	if (cr6.eq) goto loc_82404DA8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// rlwinm r28,r26,2,0,29
	r28.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82404D14:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x82404d2c
	if (cr6.eq) goto loc_82404D2C;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r28,r11
	r11.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82404d98
	if (!cr6.eq) goto loc_82404D98;
loc_82404D2C:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x82404d40
	if (cr6.eq) goto loc_82404D40;
	// lwz r4,124(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 124);
	// b 0x82404d44
	goto loc_82404D44;
loc_82404D40:
	// lwz r4,116(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 116);
loc_82404D44:
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// bge cr6,0x82404d74
	if (!cr6.lt) goto loc_82404D74;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x82404d78
	goto loc_82404D78;
loc_82404D74:
	// li r11,0
	r11.s64 = 0;
loc_82404D78:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82404d90
	if (cr6.eq) goto loc_82404D90;
	// add r10,r30,r26
	ctx.r10.u64 = r30.u64 + r26.u64;
	// stw r29,96(r11)
	PPC_STORE_U32(r11.u32 + 96, r29.u32);
	// stw r30,100(r11)
	PPC_STORE_U32(r11.u32 + 100, r30.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
loc_82404D90:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stwx r3,r28,r11
	PPC_STORE_U32(r28.u32 + r11.u32, ctx.r3.u32);
loc_82404D98:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// blt cr6,0x82404d14
	if (cr6.lt) goto loc_82404D14;
loc_82404DA8:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x82405044
	if (cr6.eq) goto loc_82405044;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r30,r26,2,0,29
	r30.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r5,r11,r30
	ctx.r5.u64 = r11.u64 + r30.u64;
	// bl 0x823f9100
	sub_823F9100(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405110
	if (cr0.lt) goto loc_82405110;
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// add r5,r11,r30
	ctx.r5.u64 = r11.u64 + r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r6,124(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 124);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f94b8
	sub_823F94B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405110
	if (cr0.lt) goto loc_82405110;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,24(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x823f33a0
	sub_823F33A0(ctx, base);
	// b 0x82404efc
	goto loc_82404EFC;
loc_82404E18:
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// bne cr6,0x82405000
	if (!cr6.eq) goto loc_82405000;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// blt cr6,0x82404f08
	if (cr6.lt) goto loc_82404F08;
	// beq cr6,0x82404ebc
	if (cr6.eq) goto loc_82404EBC;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x82404e88
	if (cr6.lt) goto loc_82404E88;
	// beq cr6,0x82404e7c
	if (cr6.eq) goto loc_82404E7C;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// blt cr6,0x82404e70
	if (cr6.lt) goto loc_82404E70;
	// bne cr6,0x82405044
	if (!cr6.eq) goto loc_82405044;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r4,24(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// addi r5,r31,40
	ctx.r5.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f8be8
	sub_823F8BE8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405110
	if (cr0.lt) goto loc_82405110;
	// li r11,1
	r11.s64 = 1;
	// stw r11,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r11.u32);
	// b 0x82405044
	goto loc_82405044;
loc_82404E70:
	// lwz r7,28(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// b 0x82404ea8
	goto loc_82404EA8;
loc_82404E7C:
	// lwz r7,28(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x82404ea8
	goto loc_82404EA8;
loc_82404E88:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r5,40(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r4,28(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// lwz r5,20(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
loc_82404EA8:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r6,24(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404a50
	sub_82404A50(ctx, base);
	// b 0x82404efc
	goto loc_82404EFC;
loc_82404EBC:
	// li r11,-1
	r11.s64 = -1;
	// lwz r4,24(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// bl 0x82406038
	sub_82406038(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405110
	if (cr0.lt) goto loc_82405110;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,32(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r6,28(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// lwz r4,24(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x823f9cc0
	sub_823F9CC0(ctx, base);
loc_82404EFC:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82405044
	if (!cr0.lt) goto loc_82405044;
	// b 0x82405110
	goto loc_82405110;
loc_82404F08:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,20(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405110
	if (cr0.lt) goto loc_82405110;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r30,r5
	cr6.compare<uint32_t>(r30.u32, ctx.r5.u32, xer);
	// bge cr6,0x82404fa0
	if (!cr6.lt) goto loc_82404FA0;
	// rotlwi r8,r11,0
	ctx.r8.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,56(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// add r9,r11,r10
	ctx.r9.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// subf r8,r30,r11
	ctx.r8.s64 = r11.s64 - r30.s64;
loc_82404F58:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x82404f94
	if (!cr6.eq) goto loc_82404F94;
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82404f94
	if (cr0.eq) goto loc_82404F94;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x82404f94
	if (!cr6.eq) goto loc_82404F94;
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// blt cr6,0x82404f94
	if (cr6.lt) goto loc_82404F94;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
loc_82404F94:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82404f58
	if (!cr0.eq) goto loc_82404F58;
loc_82404FA0:
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// cmplw cr6,r30,r5
	cr6.compare<uint32_t>(r30.u32, ctx.r5.u32, xer);
	// bge cr6,0x82404fe8
	if (!cr6.lt) goto loc_82404FE8;
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
loc_82404FB0:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,56(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r7,56(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// bne cr6,0x82404fd0
	if (!cr6.eq) goto loc_82404FD0;
	// stw r4,60(r10)
	PPC_STORE_U32(ctx.r10.u32 + 60, ctx.r4.u32);
loc_82404FD0:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x82404fb0
	if (cr6.lt) goto loc_82404FB0;
loc_82404FE8:
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// b 0x82405044
	goto loc_82405044;
loc_82405000:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8240511c
	if (!cr6.eq) goto loc_8240511C;
loc_82405008:
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82405044
	if (!cr6.eq) goto loc_82405044;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82405044
	if (!cr6.eq) goto loc_82405044;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,8(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405110
	if (cr0.lt) goto loc_82405110;
	// lwz r29,12(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// bne 0x82405008
	if (!cr0.eq) goto loc_82405008;
loc_82405044:
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8240510c
	if (cr6.eq) goto loc_8240510C;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x8240510c
	if (cr6.eq) goto loc_8240510C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r27,0
	r27.s64 = 0;
	// mr r28,r21
	r28.u64 = r21.u64;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// bge cr6,0x824050d0
	if (!cr6.lt) goto loc_824050D0;
	// rlwinm r30,r21,2,0,29
	r30.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
loc_82405074:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r29,r11,r30
	r29.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82405098
	if (!cr6.eq) goto loc_82405098;
	// lwz r27,60(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + 60);
loc_82405098:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stwx r10,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, ctx.r10.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82405074
	if (cr6.lt) goto loc_82405074;
loc_824050D0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// stw r21,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r21.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r31,40
	ctx.r5.s64 = r31.s64 + 40;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f8be8
	sub_823F8BE8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405110
	if (cr0.lt) goto loc_82405110;
loc_8240510C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82405110:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f31,-112(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x8239bd28
	return;
loc_8240511C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32300
	ctx.r6.s64 = r11.s64 + 32300;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82405110
	goto loc_82405110;
}

__attribute__((alias("__imp__sub_82405140"))) PPC_WEAK_FUNC(sub_82405140);
PPC_FUNC_IMPL(__imp__sub_82405140) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r16,0
	r16.s64 = 0;
	// stw r4,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, ctx.r4.u32);
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// stw r9,388(r1)
	PPC_STORE_U32(ctx.r1.u32 + 388, ctx.r9.u32);
	// mr r19,r16
	r19.u64 = r16.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// stw r16,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r16.u32);
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// stw r28,380(r1)
	PPC_STORE_U32(ctx.r1.u32 + 380, r28.u32);
	// stw r19,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r19.u32);
	// mr r14,r16
	r14.u64 = r16.u64;
	// stw r16,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r16.u32);
	// mr r15,r16
	r15.u64 = r16.u64;
	// mr r22,r16
	r22.u64 = r16.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82405eb0
	if (cr6.eq) goto loc_82405EB0;
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// bne cr6,0x82405eb0
	if (!cr6.eq) goto loc_82405EB0;
	// lwz r11,72(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x824051d4
	if (cr6.eq) goto loc_824051D4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r7,r4
	ctx.r7.u64 = ctx.r4.u64;
	// addi r6,r11,32584
	ctx.r6.s64 = r11.s64 + 32584;
	// li r5,3042
	ctx.r5.s64 = 3042;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82405eb8
	goto loc_82405EB8;
loc_824051D4:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x824051ec
	if (cr6.eq) goto loc_824051EC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x82442d18
	sub_82442D18(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
loc_824051EC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824051fc
	if (cr6.eq) goto loc_824051FC;
	// lwz r29,8(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// b 0x82405200
	goto loc_82405200;
loc_824051FC:
	// mr r29,r16
	r29.u64 = r16.u64;
loc_82405200:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82405210
	if (cr6.eq) goto loc_82405210;
	// lwz r20,12(r30)
	r20.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// b 0x82405214
	goto loc_82405214;
loc_82405210:
	// mr r20,r16
	r20.u64 = r16.u64;
loc_82405214:
	// lwz r11,44(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 44);
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82405264
	if (cr0.eq) goto loc_82405264;
loc_82405224:
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82405250
	if (cr0.eq) goto loc_82405250;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82405250
	if (cr0.eq) goto loc_82405250;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,12
	cr6.compare<int32_t>(ctx.r9.s32, 12, xer);
	// bne cr6,0x82405250
	if (!cr6.eq) goto loc_82405250;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_82405250:
	// lwz r9,24(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// bne cr6,0x82405224
	if (!cr6.eq) goto loc_82405224;
loc_82405264:
	// rlwinm r30,r10,2,0,29
	r30.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r27,r3
	r27.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// stw r27,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r27.u32);
	// beq 0x82405ea4
	if (cr0.eq) goto loc_82405EA4;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x8240529c
	if (cr6.eq) goto loc_8240529C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r15,r3
	r15.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r15.s32, 0, xer);
	// beq 0x82405ea4
	if (cr0.eq) goto loc_82405EA4;
loc_8240529C:
	// lwz r25,44(r23)
	r25.u64 = PPC_LOAD_U32(r23.u32 + 44);
	// mr r21,r29
	r21.u64 = r29.u64;
	// mr r24,r27
	r24.u64 = r27.u64;
	// li r17,1
	r17.s64 = 1;
	// cmplwi r25,0
	cr0.compare<uint32_t>(r25.u32, 0, xer);
	// beq 0x824055ec
	if (cr0.eq) goto loc_824055EC;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r19,r11,32536
	r19.s64 = r11.s64 + 32536;
	// lfd f31,-31368(r10)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
loc_824052C4:
	// lwz r26,8(r25)
	r26.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r28,r16
	r28.u64 = r16.u64;
	// lwz r25,12(r25)
	r25.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplwi r25,0
	cr0.compare<uint32_t>(r25.u32, 0, xer);
	// beq 0x824052f8
	if (cr0.eq) goto loc_824052F8;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824052f8
	if (cr0.eq) goto loc_824052F8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,12
	cr6.compare<int32_t>(ctx.r10.s32, 12, xer);
	// bne cr6,0x824052f8
	if (!cr6.eq) goto loc_824052F8;
	// lwz r25,12(r25)
	r25.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r28,r11
	r28.u64 = r11.u64;
loc_824052F8:
	// lwz r11,380(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// lwz r30,24(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82405524
	if (cr6.eq) goto loc_82405524;
	// lwz r11,388(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82405320
	if (cr6.eq) goto loc_82405320;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82405524
	if (!cr0.eq) goto loc_82405524;
loc_82405320:
	// lwz r10,44(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r28,116(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// rlwinm. r9,r10,0,25,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8240533c
	if (cr0.eq) goto loc_8240533C;
	// lwz r28,124(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// b 0x82405348
	goto loc_82405348;
loc_8240533C:
	// rlwinm. r10,r10,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82405348
	if (cr0.eq) goto loc_82405348;
	// lwz r28,128(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 128);
loc_82405348:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r29,r16
	r29.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824053cc
	if (!cr6.gt) goto loc_824053CC;
loc_82405358:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// add r27,r29,r11
	r27.u64 = r29.u64 + r11.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// bge cr6,0x82405398
	if (!cr6.lt) goto loc_82405398;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x8240539c
	goto loc_8240539C;
loc_82405398:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_8240539C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824053b0
	if (cr6.eq) goto loc_824053B0;
	// stw r27,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r27.u32);
	// stw r26,96(r11)
	PPC_STORE_U32(r11.u32 + 96, r26.u32);
	// stw r29,100(r11)
	PPC_STORE_U32(r11.u32 + 100, r29.u32);
loc_824053B0:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r27,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// stwx r3,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82405358
	if (cr6.lt) goto loc_82405358;
loc_824053CC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// beq cr6,0x82405404
	if (cr6.eq) goto loc_82405404;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,20(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r4,48(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x823f9100
	sub_823F9100(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
loc_82405404:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,124(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// cmplw cr6,r10,r28
	cr6.compare<uint32_t>(ctx.r10.u32, r28.u32, xer);
	// bne cr6,0x8240545c
	if (!cr6.eq) goto loc_8240545C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,64(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 64);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r4,48(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// add r5,r11,r5
	ctx.r5.u64 = r11.u64 + ctx.r5.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f94b8
	sub_823F94B8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f33a0
	sub_823F33A0(ctx, base);
	// b 0x824055c8
	goto loc_824055C8;
loc_8240545C:
	// lwz r11,128(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x824055d0
	if (!cr6.eq) goto loc_824055D0;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,64(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 64);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// lwz r9,60(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// add r5,r11,r5
	ctx.r5.u64 = r11.u64 + ctx.r5.u64;
	// bl 0x823f94b8
	sub_823F94B8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,20(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x823f46c0
	sub_823F46C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82405500
	if (cr0.eq) goto loc_82405500;
	// mr r11,r16
	r11.u64 = r16.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x824055d0
	if (cr6.eq) goto loc_824055D0;
	// rlwinm r10,r22,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r15
	ctx.r10.u64 = ctx.r10.u64 + r15.u64;
loc_824054D8:
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x824054d8
	if (cr6.lt) goto loc_824054D8;
	// b 0x824055d0
	goto loc_824055D0;
loc_82405500:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// li r5,3502
	ctx.r5.s64 = 3502;
	// lwz r7,348(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x824055d0
	goto loc_824055D0;
loc_82405524:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824055b8
	if (cr6.eq) goto loc_824055B8;
	// lwz r28,8(r21)
	r28.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x8240556c
	if (cr0.eq) goto loc_8240556C;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
loc_8240556C:
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824055b0
	if (cr0.eq) goto loc_824055B0;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r5,20(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwimi r5,r17,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r17.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// add r6,r11,r10
	ctx.r6.u64 = r11.u64 + ctx.r10.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
loc_824055B0:
	// lwz r21,12(r21)
	r21.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// b 0x824055d0
	goto loc_824055D0;
loc_824055B8:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
loc_824055C8:
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
loc_824055D0:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r24,r11,r24
	r24.u64 = r11.u64 + r24.u64;
	// bne cr6,0x824052c4
	if (!cr6.eq) goto loc_824052C4;
	// lwz r27,148(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r19,144(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
loc_824055EC:
	// lwz r25,380(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x82405810
	if (cr6.eq) goto loc_82405810;
	// mr r29,r16
	r29.u64 = r16.u64;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82405654
	if (cr6.eq) goto loc_82405654;
	// mr r30,r15
	r30.u64 = r15.u64;
loc_82405608:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824058cc
	if (cr0.lt) goto loc_824058CC;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r22
	cr6.compare<uint32_t>(r29.u32, r22.u32, xer);
	// blt cr6,0x82405608
	if (cr6.lt) goto loc_82405608;
loc_82405654:
	// lis r11,-32193
	r11.s64 = -2109800448;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// addi r3,r11,20376
	ctx.r3.s64 = r11.s64 + 20376;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82405810
	if (cr6.eq) goto loc_82405810;
	// lwz r11,0(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 0);
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r7,20(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r7
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// ble cr6,0x82405810
	if (!cr6.gt) goto loc_82405810;
	// addi r29,r15,4
	r29.s64 = r15.s64 + 4;
	// addi r28,r22,-1
	r28.s64 = r22.s64 + -1;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
loc_824056B0:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r4,108(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 108);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r3,108(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// cmplw cr6,r4,r3
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r3.u32, xer);
	// bne cr6,0x824056fc
	if (!cr6.eq) goto loc_824056FC;
	// lwz r4,16(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r3,16(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r4,r3
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r3.u32, xer);
	// bne cr6,0x824056fc
	if (!cr6.eq) goto loc_824056FC;
	// lwz r4,0(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r4,r3
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r3.u32, xer);
	// bne cr6,0x824056fc
	if (!cr6.eq) goto loc_824056FC;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// b 0x82405700
	goto loc_82405700;
loc_824056FC:
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
loc_82405700:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x824056b0
	if (!cr0.eq) goto loc_824056B0;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82405810
	if (cr6.eq) goto loc_82405810;
	// rlwinm r30,r5,2,0,29
	r30.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// stw r26,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r26.u32);
	// beq 0x82405ea4
	if (cr0.eq) goto loc_82405EA4;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r14,r3
	r14.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r14.s32, 0, xer);
	// beq 0x82405ea4
	if (cr0.eq) goto loc_82405EA4;
	// lwz r11,0(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 0);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// subf r3,r14,r26
	ctx.r3.s64 = r26.s64 - r14.s64;
	// lwzx r9,r7,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r8,20(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
loc_82405774:
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r6,0(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r30,108(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 108);
	// lwz r29,20(r7)
	r29.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// rlwinm r8,r7,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r29,r8
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + ctx.r8.u32);
	// lwz r29,108(r8)
	r29.u64 = PPC_LOAD_U32(ctx.r8.u32 + 108);
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// bne cr6,0x824057d4
	if (!cr6.eq) goto loc_824057D4;
	// lwz r30,16(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r29,16(r8)
	r29.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// bne cr6,0x824057d4
	if (!cr6.eq) goto loc_824057D4;
	// stwx r7,r3,r10
	PPC_STORE_U32(ctx.r3.u32 + ctx.r10.u32, ctx.r7.u32);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x824057dc
	goto loc_824057DC;
loc_824057D4:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_824057DC:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x82405774
	if (!cr0.eq) goto loc_82405774;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwimi r5,r17,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r17.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
loc_82405810:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// beq cr6,0x8240584c
	if (cr6.eq) goto loc_8240584C;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r19,r3
	r19.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r19.s32, 0, xer);
	// stw r19,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r19.u32);
	// beq 0x82405ea4
	if (cr0.eq) goto loc_82405EA4;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_8240584C:
	// lwz r30,80(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r16,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r16.u32);
	// lwz r4,48(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 48);
	// stw r17,72(r23)
	PPC_STORE_U32(r23.u32 + 72, r17.u32);
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82405888
	if (!cr6.eq) goto loc_82405888;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r16
	r11.u64 = r16.u64;
	// beq cr6,0x8240588c
	if (cr6.eq) goto loc_8240588C;
loc_82405888:
	// mr r11,r17
	r11.u64 = r17.u64;
loc_8240588C:
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// stw r16,72(r23)
	PPC_STORE_U32(r23.u32 + 72, r16.u32);
	// blt cr6,0x82405e3c
	if (cr6.lt) goto loc_82405E3C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x824058d8
	if (!cr6.eq) goto loc_824058D8;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824058d8
	if (!cr6.gt) goto loc_824058D8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,348(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// li r5,3507
	ctx.r5.s64 = 3507;
	// addi r6,r11,32500
	ctx.r6.s64 = r11.s64 + 32500;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
loc_824058CC:
	// lis r29,-32768
	r29.s64 = -2147483648;
	// ori r29,r29,16389
	r29.u64 = r29.u64 | 16389;
	// b 0x82405e3c
	goto loc_82405E3C;
loc_824058D8:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x82405a74
	if (cr6.eq) goto loc_82405A74;
	// lwz r10,20(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82405adc
	if (cr0.eq) goto loc_82405ADC;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8240592c
	if (cr6.eq) goto loc_8240592C;
	// mr r11,r16
	r11.u64 = r16.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8240592c
	if (cr6.eq) goto loc_8240592C;
loc_82405904:
	// lwz r10,16(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lwz r8,36(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r8.u32);
	// lwz r10,20(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x82405904
	if (cr6.lt) goto loc_82405904;
loc_8240592C:
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,20(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// add r7,r11,r10
	ctx.r7.u64 = r11.u64 + ctx.r10.u64;
	// rlwimi r5,r17,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r17.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,20(r23)
	ctx.r6.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// lwz r4,40(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x823f9100
	sub_823F9100(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r8,1
	ctx.r8.s64 = 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,56(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 56);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r4,40(r23)
	ctx.r4.u64 = PPC_LOAD_U32(r23.u32 + 40);
	// add r5,r11,r6
	ctx.r5.u64 = r11.u64 + ctx.r6.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,132(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// bl 0x823f94b8
	sub_823F94B8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,20(r23)
	ctx.r5.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x823f46c0
	sub_823F46C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82405a54
	if (cr0.eq) goto loc_82405A54;
	// mr r30,r16
	r30.u64 = r16.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82405adc
	if (cr6.eq) goto loc_82405ADC;
loc_824059F8:
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405a4c
	if (cr0.lt) goto loc_82405A4C;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x824059f8
	if (cr6.lt) goto loc_824059F8;
	// b 0x82405adc
	goto loc_82405ADC;
loc_82405A4C:
	// stw r17,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r17.u32);
	// b 0x82405adc
	goto loc_82405ADC;
loc_82405A54:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,348(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// li r5,3503
	ctx.r5.s64 = 3503;
	// addi r6,r11,32452
	ctx.r6.s64 = r11.s64 + 32452;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82405adc
	goto loc_82405ADC;
loc_82405A74:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82405adc
	if (cr6.eq) goto loc_82405ADC;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82405abc
	if (cr6.eq) goto loc_82405ABC;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82405adc
	if (!cr6.gt) goto loc_82405ADC;
	// mr r11,r18
	r11.u64 = r18.u64;
loc_82405A9C:
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r9,20(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82405a9c
	if (cr6.lt) goto loc_82405A9C;
	// b 0x82405adc
	goto loc_82405ADC;
loc_82405ABC:
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// lwz r9,20(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_82405ADC:
	// lwz r24,44(r23)
	r24.u64 = PPC_LOAD_U32(r23.u32 + 44);
	// mr r23,r27
	r23.u64 = r27.u64;
	// cmplwi r24,0
	cr0.compare<uint32_t>(r24.u32, 0, xer);
	// beq 0x82405e38
	if (cr0.eq) goto loc_82405E38;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r22,r11,32448
	r22.s64 = r11.s64 + 32448;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r21,r11,32400
	r21.s64 = r11.s64 + 32400;
loc_82405AFC:
	// lwz r25,8(r24)
	r25.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r24,12(r24)
	r24.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// cmplwi r24,0
	cr0.compare<uint32_t>(r24.u32, 0, xer);
	// beq 0x82405b28
	if (cr0.eq) goto loc_82405B28;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82405b28
	if (cr0.eq) goto loc_82405B28;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// bne cr6,0x82405b28
	if (!cr6.eq) goto loc_82405B28;
	// lwz r24,12(r24)
	r24.u64 = PPC_LOAD_U32(r24.u32 + 12);
loc_82405B28:
	// lwz r30,24(r25)
	r30.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405d74
	if (cr0.eq) goto loc_82405D74;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// lwz r28,20(r25)
	r28.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82405b84
	if (cr6.eq) goto loc_82405B84;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r11,r16
	r11.u64 = r16.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82405bf4
	if (!cr6.gt) goto loc_82405BF4;
loc_82405B58:
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwz r8,36(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r8.u32);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x82405b58
	if (cr6.lt) goto loc_82405B58;
	// b 0x82405bf4
	goto loc_82405BF4;
loc_82405B84:
	// lwz r7,20(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x82405bf4
	if (cr0.eq) goto loc_82405BF4;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
loc_82405BA8:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r6,8(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bge cr6,0x82405bc8
	if (!cr6.lt) goto loc_82405BC8;
	// lwz r6,20(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// b 0x82405bcc
	goto loc_82405BCC;
loc_82405BC8:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_82405BCC:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82405be4
	if (cr6.eq) goto loc_82405BE4;
	// lwz r6,116(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 116);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// beq cr6,0x82405e80
	if (cr6.eq) goto loc_82405E80;
loc_82405BE4:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// blt cr6,0x82405ba8
	if (cr6.lt) goto loc_82405BA8;
loc_82405BF4:
	// lwz r11,380(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82405d48
	if (cr6.eq) goto loc_82405D48;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,20(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// add r7,r11,r10
	ctx.r7.u64 = r11.u64 + ctx.r10.u64;
	// rlwimi r5,r17,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r17.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,20(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r4,48(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// add r5,r11,r10
	ctx.r5.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x823f9100
	sub_823F9100(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r8,1
	ctx.r8.s64 = 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,60(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r4,48(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// add r5,r11,r6
	ctx.r5.u64 = r11.u64 + ctx.r6.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,132(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// bl 0x823f94b8
	sub_823F94B8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,20(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x823f46c0
	sub_823F46C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82405d28
	if (cr0.eq) goto loc_82405D28;
	// mr r28,r16
	r28.u64 = r16.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82405d74
	if (cr6.eq) goto loc_82405D74;
loc_82405CCC:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82405d20
	if (cr0.lt) goto loc_82405D20;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82405ccc
	if (cr6.lt) goto loc_82405CCC;
	// b 0x82405d74
	goto loc_82405D74;
loc_82405D20:
	// stw r17,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r17.u32);
	// b 0x82405d74
	goto loc_82405D74;
loc_82405D28:
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// lwz r8,24(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// li r5,3503
	ctx.r5.s64 = 3503;
	// lwz r7,348(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82405d74
	goto loc_82405D74;
loc_82405D48:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82405e24
	if (cr6.eq) goto loc_82405E24;
	// lwz r4,8(r20)
	ctx.r4.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x82405e18
	if (cr0.eq) goto loc_82405E18;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82405e3c
	if (cr0.lt) goto loc_82405E3C;
loc_82405D74:
	// lwz r11,380(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82405e18
	if (cr6.eq) goto loc_82405E18;
	// lwz r11,388(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82405d98
	if (cr6.eq) goto loc_82405D98;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82405e18
	if (!cr0.eq) goto loc_82405E18;
loc_82405D98:
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405e24
	if (cr0.eq) goto loc_82405E24;
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r26,24(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lbz r11,0(r26)
	r11.u64 = PPC_LOAD_U8(r26.u32 + 0);
	// cmplwi cr6,r11,36
	cr6.compare<uint32_t>(r11.u32, 36, xer);
	// beq cr6,0x82405e24
	if (cr6.eq) goto loc_82405E24;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_82405DC0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82405dc0
	if (!cr6.eq) goto loc_82405DC0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r27,r11,2
	r27.s64 = r11.s64 + 2;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82405ea4
	if (cr0.eq) goto loc_82405EA4;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823df1b0
	sub_823DF1B0(ctx, base);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// stw r28,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r28.u32);
	// b 0x82405e24
	goto loc_82405E24;
loc_82405E18:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82405e24
	if (cr6.eq) goto loc_82405E24;
	// lwz r20,12(r20)
	r20.u64 = PPC_LOAD_U32(r20.u32 + 12);
loc_82405E24:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r23,r11,r23
	r23.u64 = r11.u64 + r23.u64;
	// bne cr6,0x82405afc
	if (!cr6.eq) goto loc_82405AFC;
loc_82405E38:
	// mr r29,r16
	r29.u64 = r16.u64;
loc_82405E3C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,148(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,152(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x82405eb8
	goto loc_82405EB8;
loc_82405E80:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r8,24(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// li r5,3508
	ctx.r5.s64 = 3508;
	// lwz r7,348(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// addi r6,r10,32348
	ctx.r6.s64 = ctx.r10.s64 + 32348;
	// lwz r4,96(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82405e3c
	goto loc_82405E3C;
loc_82405EA4:
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x82405e3c
	goto loc_82405E3C;
loc_82405EB0:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82405EB8:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_82405EC4"))) PPC_WEAK_FUNC(sub_82405EC4);
PPC_FUNC_IMPL(__imp__sub_82405EC4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82405EC8"))) PPC_WEAK_FUNC(sub_82405EC8);
PPC_FUNC_IMPL(__imp__sub_82405EC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r30,4(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240601c
	if (cr0.eq) goto loc_8240601C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x8240601c
	if (!cr6.eq) goto loc_8240601C;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x82405f10
	if (!cr0.eq) goto loc_82405F10;
loc_82405F04:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82406020
	goto loc_82406020;
loc_82405F10:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r5,r11,24
	ctx.r5.s64 = r11.s64 + 24;
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x82447870
	sub_82447870(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82406020
	if (cr0.lt) goto loc_82406020;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// bne 0x82405f64
	if (!cr0.eq) goto loc_82405F64;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82406020
	goto loc_82406020;
loc_82405F64:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// li r4,255
	ctx.r4.s64 = 255;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// lfd f1,-31360(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lfd f1,-31368(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// lwz r4,120(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r4,120(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 120);
	// lfd f1,-30984(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + -30984);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r9,-1
	ctx.r9.s64 = -1;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// stw r10,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r10.u32);
	// stw r9,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r9.u32);
	// stw r8,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r8.u32);
	// lwz r4,40(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// bl 0x82404bd8
	sub_82404BD8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82406020
	if (cr0.lt) goto loc_82406020;
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82405f04
	if (!cr6.eq) goto loc_82405F04;
loc_8240601C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82406020:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82406038"))) PPC_WEAK_FUNC(sub_82406038);
PPC_FUNC_IMPL(__imp__sub_82406038) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r16,r4
	r16.u64 = ctx.r4.u64;
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// mr r15,r5
	r15.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x82406070
	if (!cr6.eq) goto loc_82406070;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// bne cr6,0x82407d7c
	if (!cr6.eq) goto loc_82407D7C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82407d84
	goto loc_82407D84;
loc_82406070:
	// lwz r11,4(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82407d7c
	if (!cr6.eq) goto loc_82407D7C;
	// li r22,0
	r22.s64 = 0;
	// lwz r11,32(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 32);
	// lwz r10,24(r16)
	ctx.r10.u64 = PPC_LOAD_U32(r16.u32 + 24);
	// li r27,0
	r27.s64 = 0;
	// lwz r9,20(r16)
	ctx.r9.u64 = PPC_LOAD_U32(r16.u32 + 20);
	// li r31,0
	r31.s64 = 0;
	// li r14,0
	r14.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// stw r22,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r22.u32);
	// li r28,0
	r28.s64 = 0;
	// mullw r21,r9,r10
	r21.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824060cc
	if (cr0.eq) goto loc_824060CC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x824060cc
	if (!cr6.eq) goto loc_824060CC;
	// mr r30,r11
	r30.u64 = r11.u64;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mullw r27,r11,r10
	r27.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
loc_824060CC:
	// lwz r11,36(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 36);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824060f4
	if (cr0.eq) goto loc_824060F4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x824060f4
	if (!cr6.eq) goto loc_824060F4;
	// mr r28,r11
	r28.u64 = r11.u64;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mullw r31,r11,r10
	r31.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
loc_824060F4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82406110
	if (cr6.eq) goto loc_82406110;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f52f0
	sub_823F52F0(ctx, base);
	// mr. r14,r3
	r14.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r14.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
loc_82406110:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82406134
	if (cr6.eq) goto loc_82406134;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f52f0
	sub_823F52F0(ctx, base);
	// stw r3,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// rotlwi r22,r3,0
	r22.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
loc_82406134:
	// lwz r11,28(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 28);
	// li r29,0
	r29.s64 = 0;
	// li r20,1
	r20.s64 = 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// blt 0x8240616c
	if (cr0.lt) goto loc_8240616C;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// ble cr6,0x82406168
	if (!cr6.gt) goto loc_82406168;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// ble cr6,0x8240616c
	if (!cr6.gt) goto loc_8240616C;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// ble cr6,0x824061b4
	if (!cr6.gt) goto loc_824061B4;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bgt cr6,0x8240616c
	if (cr6.gt) goto loc_8240616C;
loc_82406168:
	// mr r29,r26
	r29.u64 = r26.u64;
loc_8240616C:
	// lwz r11,40(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 40);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x824061bc
	if (cr6.eq) goto loc_824061BC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240619c
	if (cr6.eq) goto loc_8240619C;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
loc_8240619C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82406204
	if (cr6.eq) goto loc_82406204;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// b 0x824061f4
	goto loc_824061F4;
loc_824061B4:
	// mr r29,r20
	r29.u64 = r20.u64;
	// b 0x8240616c
	goto loc_8240616C;
loc_824061BC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x824061e0
	if (cr6.eq) goto loc_824061E0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
loc_824061E0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82406204
	if (cr6.eq) goto loc_82406204;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_824061F4:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
loc_82406204:
	// lwz r10,28(r16)
	ctx.r10.u64 = PPC_LOAD_U32(r16.u32 + 28);
	// cmplwi cr6,r10,32
	cr6.compare<uint32_t>(ctx.r10.u32, 32, xer);
	// bgt cr6,0x82407cdc
	if (cr6.gt) goto loc_82407CDC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r23,-1
	r23.s64 = -1;
	// li r19,257
	r19.s64 = 257;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,31600
	r12.s64 = r12.s64 + 31600;
	// rlwinm r0,r10,1,0,30
	r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32192
	r12.s64 = -2109734912;
	// addi r12,r12,25160
	r12.s64 = r12.s64 + 25160;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82406248;
	case 1:
		goto loc_82406248;
	case 2:
		goto loc_82406484;
	case 3:
		goto loc_824064D8;
	case 4:
		goto loc_8240651C;
	case 5:
		goto loc_82406620;
	case 6:
		goto loc_8240666C;
	case 7:
		goto loc_82407CDC;
	case 8:
		goto loc_82406F24;
	case 9:
		goto loc_82406F70;
	case 10:
		goto loc_82407024;
	case 11:
		goto loc_824066B0;
	case 12:
		goto loc_82406704;
	case 13:
		goto loc_82407CDC;
	case 14:
		goto loc_82407CDC;
	case 15:
		goto loc_824067B8;
	case 16:
		goto loc_82406804;
	case 17:
		goto loc_8240685C;
	case 18:
		goto loc_824068AC;
	case 19:
		goto loc_82406900;
	case 20:
		goto loc_82406A3C;
	case 21:
		goto loc_82407CDC;
	case 22:
		goto loc_82407CDC;
	case 23:
		goto loc_82407CDC;
	case 24:
		goto loc_82406B78;
	case 25:
		goto loc_82406D50;
	case 26:
		goto loc_82406344;
	case 27:
		goto loc_82406430;
	case 28:
		goto loc_82407268;
	case 29:
		goto loc_8240729C;
	case 30:
		goto loc_8240732C;
	case 31:
		goto loc_82407548;
	case 32:
		goto loc_824075B4;
	default:
		__builtin_unreachable();
	}
loc_82406248:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240632c
	if (cr6.eq) goto loc_8240632C;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r27,1
	cr6.compare<uint32_t>(r27.u32, 1, xer);
	// bne cr6,0x824062ac
	if (!cr6.eq) goto loc_824062AC;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406284
	if (cr6.eq) goto loc_82406284;
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82406270:
	// lwz r9,0(r14)
	ctx.r9.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82406270
	if (!cr0.eq) goto loc_82406270;
loc_82406284:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// lwz r11,160(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 160);
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// ble cr6,0x824075fc
	if (!cr6.gt) goto loc_824075FC;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// rlwinm r31,r11,1,0,30
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// bne cr6,0x824075cc
	if (!cr6.eq) goto loc_824075CC;
	// li r31,16
	r31.s64 = 16;
	// b 0x824075cc
	goto loc_824075CC;
loc_824062AC:
	// cmplw cr6,r21,r27
	cr6.compare<uint32_t>(r21.u32, r27.u32, xer);
	// beq cr6,0x8240640c
	if (cr6.eq) goto loc_8240640C;
	// lwz r11,20(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 20);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x824062c8
	if (!cr6.eq) goto loc_824062C8;
	// cmplw cr6,r21,r27
	cr6.compare<uint32_t>(r21.u32, r27.u32, xer);
	// blt cr6,0x8240640c
	if (cr6.lt) goto loc_8240640C;
loc_824062C8:
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x82407cf4
	if (cr6.gt) goto loc_82407CF4;
	// lwz r10,24(r16)
	ctx.r10.u64 = PPC_LOAD_U32(r16.u32 + 24);
	// lwz r9,24(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bgt cr6,0x82407cf4
	if (cr6.gt) goto loc_82407CF4;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82406284
	if (cr6.eq) goto loc_82406284;
loc_824062F0:
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r11,24(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 24);
	// mullw r10,r10,r31
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(r31.s32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r10,r14
	ctx.r4.u64 = ctx.r10.u64 + r14.u64;
	// mullw r10,r11,r31
	ctx.r10.s64 = int64_t(r11.s32) * int64_t(r31.s32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r10,r15
	ctx.r3.u64 = ctx.r10.u64 + r15.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,20(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 20);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x824062f0
	if (cr6.lt) goto loc_824062F0;
	// b 0x82406284
	goto loc_82406284;
loc_8240632C:
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// lwz r4,32(r16)
	ctx.r4.u64 = PPC_LOAD_U32(r16.u32 + 32);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82407d90
	sub_82407D90(ctx, base);
	// b 0x8240753c
	goto loc_8240753C;
loc_82406344:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406284
	if (cr6.eq) goto loc_82406284;
	// lwz r11,8(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// lwz r10,0(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x82406380
	if (!cr6.lt) goto loc_82406380;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// b 0x82406384
	goto loc_82406384;
loc_82406380:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82406384:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82406404
	if (cr6.eq) goto loc_82406404;
	// lwz r9,116(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x82406404
	if (!cr6.eq) goto loc_82406404;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824063d8
	if (cr6.eq) goto loc_824063D8;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mr r11,r14
	r11.u64 = r14.u64;
loc_824063B0:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,48(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82406420
	if (cr6.eq) goto loc_82406420;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// blt cr6,0x824063b0
	if (cr6.lt) goto loc_824063B0;
loc_824063D8:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwimi r5,r20,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r20.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
loc_824063E8:
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
loc_82406404:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
loc_8240640C:
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
loc_82406410:
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// rlwinm r5,r21,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// b 0x82406284
	goto loc_82406284;
loc_82406420:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// addi r6,r11,32712
	ctx.r6.s64 = r11.s64 + 32712;
	// b 0x82407ce8
	goto loc_82407CE8;
loc_82406430:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406284
	if (cr6.eq) goto loc_82406284;
	// lwz r9,8(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r11,r14
	r11.u64 = r14.u64;
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
loc_82406458:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,48(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82406420
	if (cr6.eq) goto loc_82406420;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// blt cr6,0x82406458
	if (cr6.lt) goto loc_82406458;
	// b 0x824063d8
	goto loc_824063D8;
loc_82406484:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824064c4
	if (cr6.eq) goto loc_824064C4;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r11,r21
	r11.u64 = r21.u64;
loc_824064B0:
	// lwz r9,32(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 32);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x824064b0
	if (!cr0.eq) goto loc_824064B0;
loc_824064C4:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r11,129
	r11.s64 = 129;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// rlwimi r5,r11,22,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 22) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x824063e8
	goto loc_824063E8;
loc_824064D8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824064c4
	if (cr6.eq) goto loc_824064C4;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82406504:
	// lwz r9,40(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 40);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82406504
	if (!cr0.eq) goto loc_82406504;
	// b 0x824064c4
	goto loc_824064C4;
loc_8240651C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// rlwinm r4,r21,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// rlwinm r8,r21,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,2
	r11.s64 = 2;
loc_8240654C:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8240654c
	if (!cr0.eq) goto loc_8240654C;
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406590
	if (cr6.eq) goto loc_82406590;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406590
	if (cr0.eq) goto loc_82406590;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406584:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406584
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406584;
loc_82406590:
	// lwz r30,148(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824065e4
	if (cr6.eq) goto loc_824065E4;
	// mr r11,r30
	r11.u64 = r30.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824065bc
	if (cr0.eq) goto loc_824065BC;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_824065B0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824065b0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824065B0;
loc_824065BC:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824065e4
	if (cr6.eq) goto loc_824065E4;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824065e4
	if (cr0.eq) goto loc_824065E4;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_824065D8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824065d8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824065D8;
loc_824065E4:
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r11,515
	r11.s64 = 515;
	// li r9,23
	ctx.r9.s64 = 23;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// b 0x82407250
	goto loc_82407250;
loc_82406620:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406658
	if (cr6.eq) goto loc_82406658;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406658
	if (cr0.eq) goto loc_82406658;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_8240664C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240664c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240664C;
loc_82406658:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// rlwimi r5,r19,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r19.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
loc_82406660:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// b 0x82406c28
	goto loc_82406C28;
loc_8240666C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824066a4
	if (cr6.eq) goto loc_824066A4;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824066a4
	if (cr0.eq) goto loc_824066A4;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406698:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406698
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406698;
loc_824066A4:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// rlwimi r5,r20,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r20.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x82406660
	goto loc_82406660;
loc_824066B0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824066f0
	if (cr6.eq) goto loc_824066F0;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824066f0
	if (cr0.eq) goto loc_824066F0;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_824066E4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824066e4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824066E4;
loc_824066F0:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r11,129
	r11.s64 = 129;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwimi r5,r11,22,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 22) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x82406c24
	goto loc_82406C24;
loc_82406704:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406780
	if (cr6.eq) goto loc_82406780;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406758
	if (cr0.eq) goto loc_82406758;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_8240674C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240674c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240674C;
loc_82406758:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406780
	if (cr6.eq) goto loc_82406780;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406780
	if (cr0.eq) goto loc_82406780;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406774:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406774
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406774;
loc_82406780:
	// clrlwi r30,r21,12
	r30.u64 = r21.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// b 0x8240724c
	goto loc_8240724C;
loc_824067B8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824067f8
	if (cr6.eq) goto loc_824067F8;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824067f8
	if (cr0.eq) goto loc_824067F8;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_824067EC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824067ec
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824067EC;
loc_824067F8:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// rlwimi r5,r19,21,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r19.u32, 21) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x82406c20
	goto loc_82406C20;
loc_82406804:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406844
	if (cr6.eq) goto loc_82406844;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406844
	if (cr0.eq) goto loc_82406844;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406838:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406838
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406838;
loc_82406844:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// rlwimi r5,r19,21,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r19.u32, 21) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
loc_8240684C:
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r14
	ctx.r8.u64 = r14.u64;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// b 0x82407254
	goto loc_82407254;
loc_8240685C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8240689c
	if (cr6.eq) goto loc_8240689C;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x8240689c
	if (cr0.eq) goto loc_8240689C;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406890:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406890
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406890;
loc_8240689C:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r11,515
	r11.s64 = 515;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x8240684c
	goto loc_8240684C;
loc_824068AC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824068ec
	if (cr6.eq) goto loc_824068EC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824068ec
	if (cr0.eq) goto loc_824068EC;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_824068E0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824068e0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824068E0;
loc_824068EC:
	// li r11,515
	r11.s64 = 515;
	// li r9,23
	ctx.r9.s64 = 23;
loc_824068F4:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x82406c24
	goto loc_82406C24;
loc_82406900:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// rlwinm r31,r21,2,0,29
	r31.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r11,4
	r11.s64 = 4;
loc_8240693C:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r31,r10
	ctx.r10.u64 = r31.u64 + ctx.r10.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8240693c
	if (!cr0.eq) goto loc_8240693C;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82406978
	if (cr6.eq) goto loc_82406978;
	// mr r11,r23
	r11.u64 = r23.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x82406978
	if (cr0.eq) goto loc_82406978;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_8240696C:
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// bdnz 0x8240696c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240696C;
loc_82406978:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824069a0
	if (cr6.eq) goto loc_824069A0;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824069a0
	if (cr0.eq) goto loc_824069A0;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406994:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406994
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406994;
loc_824069A0:
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r30,r21,12
	r30.u64 = r21.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r29,148(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r28,152(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r29,156(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// oris r5,r30,8240
	ctx.r5.u64 = r30.u64 | 540016640;
	// b 0x82407254
	goto loc_82407254;
loc_82406A3C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// rlwinm r31,r21,2,0,29
	r31.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r11,4
	r11.s64 = 4;
loc_82406A78:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r31,r10
	ctx.r10.u64 = r31.u64 + ctx.r10.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82406a78
	if (!cr0.eq) goto loc_82406A78;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82406ab4
	if (cr6.eq) goto loc_82406AB4;
	// mr r11,r23
	r11.u64 = r23.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x82406ab4
	if (cr0.eq) goto loc_82406AB4;
	// mtctr r31
	ctr.u64 = r31.u64;
loc_82406AA8:
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// bdnz 0x82406aa8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406AA8;
loc_82406AB4:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406adc
	if (cr6.eq) goto loc_82406ADC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406adc
	if (cr0.eq) goto loc_82406ADC;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406AD0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406ad0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406AD0;
loc_82406ADC:
	// lwz r29,144(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// clrlwi r30,r21,12
	r30.u64 = r21.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r29,148(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r28,152(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r29,156(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
loc_82406B68:
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// oris r5,r30,8224
	ctx.r5.u64 = r30.u64 | 538968064;
	// b 0x82407254
	goto loc_82407254;
loc_82406B78:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406c14
	if (cr6.eq) goto loc_82406C14;
	// lwz r10,8(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// mr r11,r22
	r11.u64 = r22.u64;
	// subf r9,r22,r14
	ctx.r9.s64 = r14.s64 - r22.s64;
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
loc_82406BAC:
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// clrlwi. r7,r7,31
	ctx.r7.u64 = ctx.r7.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82406c30
	if (cr0.eq) goto loc_82406C30;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// clrlwi. r7,r7,31
	ctx.r7.u64 = ctx.r7.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82406c30
	if (cr0.eq) goto loc_82406C30;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r21
	cr6.compare<uint32_t>(ctx.r8.u32, r21.u32, xer);
	// blt cr6,0x82406bac
	if (cr6.lt) goto loc_82406BAC;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406c14
	if (cr6.eq) goto loc_82406C14;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406c14
	if (cr0.eq) goto loc_82406C14;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406C08:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406c08
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406C08;
loc_82406C14:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r11,517
	r11.s64 = 517;
	// rlwimi r5,r11,20,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
loc_82406C20:
	// li r9,23
	ctx.r9.s64 = 23;
loc_82406C24:
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
loc_82406C28:
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// b 0x82407254
	goto loc_82407254;
loc_82406C30:
	// mulli r4,r21,3
	ctx.r4.s64 = r21.s64 * 3;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// rlwinm r8,r21,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,3
	r11.s64 = 3;
loc_82406C50:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82406c50
	if (!cr0.eq) goto loc_82406C50;
	// rlwinm r11,r21,2,0,29
	r11.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r28,144(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// rlwinm. r10,r11,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82406c90
	if (cr0.eq) goto loc_82406C90;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82406C84:
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x82406c84
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406C84;
loc_82406C90:
	// lwz r27,148(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// rlwinm. r10,r11,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// beq 0x82406cb4
	if (cr0.eq) goto loc_82406CB4;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82406CA8:
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x82406ca8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406CA8;
loc_82406CB4:
	// lwz r29,152(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// rlwinm. r10,r11,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// beq 0x82406cd8
	if (cr0.eq) goto loc_82406CD8;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82406CCC:
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x82406ccc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406CCC;
loc_82406CD8:
	// rlwinm. r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// beq 0x82406cf8
	if (cr0.eq) goto loc_82406CF8;
	// mtctr r11
	ctr.u64 = r11.u64;
loc_82406CEC:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82406cec
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406CEC;
loc_82406CF8:
	// clrlwi r30,r21,12
	r30.u64 = r21.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// oris r5,r30,8272
	ctx.r5.u64 = r30.u64 | 542113792;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// b 0x82406b68
	goto loc_82406B68;
loc_82406D50:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// rlwinm r31,r21,2,0,29
	r31.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// li r11,4
	r11.s64 = 4;
loc_82406D88:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82406d88
	if (!cr0.eq) goto loc_82406D88;
	// lwz r26,144(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406dcc
	if (cr6.eq) goto loc_82406DCC;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406dcc
	if (cr0.eq) goto loc_82406DCC;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406DC0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406dc0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406DC0;
loc_82406DCC:
	// lwz r27,148(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406df8
	if (cr6.eq) goto loc_82406DF8;
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406df8
	if (cr0.eq) goto loc_82406DF8;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406DEC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406dec
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406DEC;
loc_82406DF8:
	// lwz r29,152(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406e24
	if (cr6.eq) goto loc_82406E24;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406e24
	if (cr0.eq) goto loc_82406E24;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406E18:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406e18
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406E18;
loc_82406E24:
	// lwz r28,156(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406e78
	if (cr6.eq) goto loc_82406E78;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406e50
	if (cr0.eq) goto loc_82406E50;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406E44:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406e44
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406E44;
loc_82406E50:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406e78
	if (cr6.eq) goto loc_82406E78;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406e78
	if (cr0.eq) goto loc_82406E78;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406E6C:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406e6c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406E6C;
loc_82406E78:
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// clrlwi r30,r21,12
	r30.u64 = r21.u32 & 0xFFFFF;
	// li r9,4
	ctx.r9.s64 = 4;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// oris r5,r30,8256
	ctx.r5.u64 = r30.u64 | 541065216;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r30,4112
	ctx.r5.u64 = r30.u64 | 269484032;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// oris r5,r30,8224
	ctx.r5.u64 = r30.u64 | 538968064;
	// b 0x82407250
	goto loc_82407250;
loc_82406F24:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406f64
	if (cr6.eq) goto loc_82406F64;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406f64
	if (cr0.eq) goto loc_82406F64;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406F58:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406f58
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406F58;
loc_82406F64:
	// li r11,517
	r11.s64 = 517;
	// li r9,0
	ctx.r9.s64 = 0;
	// b 0x824068f4
	goto loc_824068F4;
loc_82406F70:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406fec
	if (cr6.eq) goto loc_82406FEC;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406fc4
	if (cr0.eq) goto loc_82406FC4;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406FB8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406fb8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406FB8;
loc_82406FC4:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406fec
	if (cr6.eq) goto loc_82406FEC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82406fec
	if (cr0.eq) goto loc_82406FEC;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82406FE0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82406fe0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82406FE0;
loc_82406FEC:
	// clrlwi r30,r21,12
	r30.u64 = r21.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// oris r5,r30,4144
	ctx.r5.u64 = r30.u64 | 271581184;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// oris r5,r30,8272
	ctx.r5.u64 = r30.u64 | 542113792;
	// b 0x8240724c
	goto loc_8240724C;
loc_82407024:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// rlwinm r4,r21,3,0,28
	ctx.r4.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// rlwinm r8,r21,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,8
	r11.s64 = 8;
loc_8240705C:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8240705c
	if (!cr0.eq) goto loc_8240705C;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// li r8,8
	ctx.r8.s64 = 8;
loc_8240707C:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824070a4
	if (cr6.eq) goto loc_824070A4;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824070a4
	if (cr0.eq) goto loc_824070A4;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82407098:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82407098
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82407098;
loc_824070A4:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8240707c
	if (!cr0.eq) goto loc_8240707C;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824070d8
	if (cr6.eq) goto loc_824070D8;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824070d8
	if (cr0.eq) goto loc_824070D8;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_824070CC:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824070cc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824070CC;
loc_824070D8:
	// clrlwi r30,r21,12
	r30.u64 = r21.u32 & 0xFFFFF;
	// lwz r29,160(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// li r9,0
	ctx.r9.s64 = 0;
	// oris r26,r30,8272
	r26.u64 = r30.u64 | 542113792;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// lwz r28,164(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// oris r27,r30,4112
	r27.u64 = r30.u64 | 269484032;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// lwz r28,168(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// oris r5,r30,8240
	ctx.r5.u64 = r30.u64 | 540016640;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// lwz r29,172(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// lwz r28,176(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8108
	sub_823F8108(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// lwz r29,180(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r9,64
	ctx.r9.s64 = 64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r30,4144
	ctx.r5.u64 = r30.u64 | 271581184;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// lwz r29,184(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r29,188(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// li r9,4
	ctx.r9.s64 = 4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r30,4160
	ctx.r5.u64 = r30.u64 | 272629760;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
loc_8240724C:
	// li r9,0
	ctx.r9.s64 = 0;
loc_82407250:
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
loc_82407254:
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// b 0x8240753c
	goto loc_8240753C;
loc_82407268:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x824034e8
	sub_824034E8(ctx, base);
	// b 0x8240753c
	goto loc_8240753C;
loc_8240729C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// lwz r11,36(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 36);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407cf4
	if (cr0.eq) goto loc_82407CF4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// bne cr6,0x824072e0
	if (!cr6.eq) goto loc_824072E0;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x82407cf4
	if (!cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r14
	ctx.r4.u64 = r11.u64 + r14.u64;
	// b 0x82406410
	goto loc_82406410;
loc_824072E0:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82407cf4
	if (!cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82406284
	if (cr6.eq) goto loc_82406284;
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82407304:
	// lwz r8,8(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,24(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r14
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r14.u32);
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// bne 0x82407304
	if (!cr0.eq) goto loc_82407304;
	// b 0x82406284
	goto loc_82406284;
loc_8240732C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82407cf4
	if (cr6.eq) goto loc_82407CF4;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// mulli r4,r21,3
	ctx.r4.s64 = r21.s64 * 3;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// rlwinm r24,r21,2,0,29
	r24.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,3
	r11.s64 = 3;
loc_82407364:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r24,r10
	ctx.r10.u64 = r24.u64 + ctx.r10.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82407364
	if (!cr0.eq) goto loc_82407364;
	// lwz r25,144(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82407404
	if (cr6.eq) goto loc_82407404;
	// mr r31,r25
	r31.u64 = r25.u64;
	// add r29,r24,r22
	r29.u64 = r24.u64 + r22.u64;
	// subf r28,r22,r14
	r28.s64 = r14.s64 - r22.s64;
	// subf r27,r25,r22
	r27.s64 = r22.s64 - r25.s64;
loc_8240739C:
	// add r30,r27,r31
	r30.u64 = r27.u64 + r31.u64;
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// lwzx r4,r28,r30
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + r30.u32);
	// bl 0x823f3990
	sub_823F3990(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82407404
	if (cr0.lt) goto loc_82407404;
	// lfd f13,160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bgt cr6,0x824073e8
	if (cr6.gt) goto loc_824073E8;
	// lfd f0,168(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// blt cr6,0x824073e8
	if (cr6.lt) goto loc_824073E8;
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bne cr6,0x82407404
	if (!cr6.eq) goto loc_82407404;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x82407404
	if (!cr6.eq) goto loc_82407404;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// b 0x824073ec
	goto loc_824073EC;
loc_824073E8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
loc_824073EC:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r26,r21
	cr6.compare<uint32_t>(r26.u32, r21.u32, xer);
	// blt cr6,0x8240739c
	if (cr6.lt) goto loc_8240739C;
loc_82407404:
	// cmplw cr6,r26,r21
	cr6.compare<uint32_t>(r26.u32, r21.u32, xer);
	// bne cr6,0x8240744c
	if (!cr6.eq) goto loc_8240744C;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82407434
	if (cr6.eq) goto loc_82407434;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82407434
	if (cr0.eq) goto loc_82407434;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82407428:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82407428
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82407428;
loc_82407434:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwimi r5,r20,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r20.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// b 0x82407254
	goto loc_82407254;
loc_8240744C:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82407474
	if (cr6.eq) goto loc_82407474;
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x82407474
	if (cr0.eq) goto loc_82407474;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82407468:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82407468
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82407468;
loc_82407474:
	// lwz r29,148(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824074a0
	if (cr6.eq) goto loc_824074A0;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824074a0
	if (cr0.eq) goto loc_824074A0;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_82407494:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82407494
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82407494;
loc_824074A0:
	// lwz r30,152(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824074cc
	if (cr6.eq) goto loc_824074CC;
	// mr r11,r30
	r11.u64 = r30.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r21,0
	cr0.compare<uint32_t>(r21.u32, 0, xer);
	// beq 0x824074cc
	if (cr0.eq) goto loc_824074CC;
	// mtctr r21
	ctr.u64 = r21.u64;
loc_824074C0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824074c0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824074C0;
loc_824074CC:
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// li r9,23
	ctx.r9.s64 = 23;
	// rlwimi r5,r19,21,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r19.u32, 21) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// add r6,r24,r22
	ctx.r6.u64 = r24.u64 + r22.u64;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8108
	sub_823F8108(ctx, base);
loc_8240753C:
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bge 0x82406284
	if (!cr0.lt) goto loc_82406284;
	// b 0x82407d04
	goto loc_82407D04;
loc_82407548:
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// lwz r4,32(r16)
	ctx.r4.u64 = PPC_LOAD_U32(r16.u32 + 32);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f4c28
	sub_823F4C28(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bne 0x82407580
	if (!cr0.eq) goto loc_82407580;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r7,56(r16)
	ctx.r7.u64 = PPC_LOAD_U32(r16.u32 + 56);
	// li r5,3510
	ctx.r5.s64 = 3510;
	// addi r6,r11,32672
	ctx.r6.s64 = r11.s64 + 32672;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82407cf4
	goto loc_82407CF4;
loc_82407580:
	// lwz r11,56(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 56);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,144(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// stw r11,56(r18)
	PPC_STORE_U32(r18.u32 + 56, r11.u32);
	// lwz r6,36(r16)
	ctx.r6.u64 = PPC_LOAD_U32(r16.u32 + 36);
	// bl 0x82405140
	sub_82405140(ctx, base);
	// lwz r11,56(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 56);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,56(r18)
	PPC_STORE_U32(r18.u32 + 56, r11.u32);
	// b 0x8240753c
	goto loc_8240753C;
loc_824075B4:
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823fc758
	sub_823FC758(ctx, base);
	// b 0x8240753c
	goto loc_8240753C;
loc_824075C8:
	// rlwinm r31,r31,1,0,30
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
loc_824075CC:
	// cmplw cr6,r31,r21
	cr6.compare<uint32_t>(r31.u32, r21.u32, xer);
	// blt cr6,0x824075c8
	if (cr6.lt) goto loc_824075C8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r31,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,156(r18)
	ctx.r3.u64 = PPC_LOAD_U32(r18.u32 + 156);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// stw r30,156(r18)
	PPC_STORE_U32(r18.u32 + 156, r30.u32);
	// stw r31,160(r18)
	PPC_STORE_U32(r18.u32 + 160, r31.u32);
loc_824075FC:
	// lwz r25,156(r18)
	r25.u64 = PPC_LOAD_U32(r18.u32 + 156);
	// rlwinm r11,r21,2,0,29
	r11.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// lwz r4,16(r16)
	ctx.r4.u64 = PPC_LOAD_U32(r16.u32 + 16);
	// add r17,r11,r25
	r17.u64 = r11.u64 + r25.u64;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// bl 0x823f6248
	sub_823F6248(ctx, base);
	// li r27,0
	r27.s64 = 0;
	// li r24,0
	r24.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// subf r6,r17,r15
	ctx.r6.s64 = r15.s64 - r17.s64;
	// subf r5,r25,r17
	ctx.r5.s64 = r17.s64 - r25.s64;
loc_82407638:
	// lwz r11,8(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// add r7,r5,r9
	ctx.r7.u64 = ctx.r5.u64 + ctx.r9.u64;
	// lwzx r10,r7,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bge cr6,0x82407660
	if (!cr6.lt) goto loc_82407660;
	// lwz r8,20(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// b 0x82407664
	goto loc_82407664;
loc_82407660:
	// li r8,0
	ctx.r8.s64 = 0;
loc_82407664:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x824077c0
	if (cr6.eq) goto loc_824077C0;
	// lwz r11,116(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824076cc
	if (cr6.eq) goto loc_824076CC;
	// lwz r3,0(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// clrlwi. r3,r3,31
	ctx.r3.u64 = ctx.r3.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824076a0
	if (cr0.eq) goto loc_824076A0;
	// lwz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// clrlwi. r3,r3,31
	ctx.r3.u64 = ctx.r3.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824076a0
	if (!cr0.eq) goto loc_824076A0;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// stw r20,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r20.u32);
	// b 0x824076d4
	goto loc_824076D4;
loc_824076A0:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824076cc
	if (cr6.eq) goto loc_824076CC;
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824076cc
	if (cr0.eq) goto loc_824076CC;
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824076cc
	if (!cr0.eq) goto loc_824076CC;
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// li r11,2
	r11.s64 = 2;
	// b 0x824076d0
	goto loc_824076D0;
loc_824076CC:
	// li r11,0
	r11.s64 = 0;
loc_824076D0:
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
loc_824076D4:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r4,r21
	cr6.compare<uint32_t>(ctx.r4.u32, r21.u32, xer);
	// blt cr6,0x82407638
	if (cr6.lt) goto loc_82407638;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8240785c
	if (cr6.eq) goto loc_8240785C;
	// rlwinm r31,r27,2,0,29
	r31.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407878
	if (cr0.eq) goto loc_82407878;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// li r11,4
	r11.s64 = 4;
loc_8240770C:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8240770c
	if (!cr0.eq) goto loc_8240770C;
	// lwz r28,148(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82407750
	if (cr6.eq) goto loc_82407750;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r27,0
	cr0.compare<uint32_t>(r27.u32, 0, xer);
	// beq 0x82407750
	if (cr0.eq) goto loc_82407750;
	// mtctr r27
	ctr.u64 = r27.u64;
loc_82407744:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82407744
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82407744;
loc_82407750:
	// lwz r29,152(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8240777c
	if (cr6.eq) goto loc_8240777C;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r27,0
	cr0.compare<uint32_t>(r27.u32, 0, xer);
	// beq 0x8240777c
	if (cr0.eq) goto loc_8240777C;
	// mtctr r27
	ctr.u64 = r27.u64;
loc_82407770:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82407770
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82407770;
loc_8240777C:
	// lwz r30,156(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// mr r11,r15
	r11.u64 = r15.u64;
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// subf r26,r15,r25
	r26.s64 = r25.s64 - r15.s64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// subf r6,r30,r7
	ctx.r6.s64 = ctx.r7.s64 - r30.s64;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
loc_82407798:
	// lwzx r9,r26,r11
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + r11.u32);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x824077d8
	if (!cr6.eq) goto loc_824077D8;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stwx r9,r6,r10
	PPC_STORE_U32(ctx.r6.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r9,28(r16)
	ctx.r9.u64 = PPC_LOAD_U32(r16.u32 + 28);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x824077cc
	if (cr6.eq) goto loc_824077CC;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x824077d0
	goto loc_824077D0;
loc_824077C0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,31224
	ctx.r6.s64 = r11.s64 + 31224;
	// b 0x82407ce4
	goto loc_82407CE4;
loc_824077CC:
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
loc_824077D0:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_824077D8:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82407798
	if (!cr0.eq) goto loc_82407798;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f8db8
	sub_823F8DB8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r9,23
	ctx.r9.s64 = 23;
	// rlwimi r5,r19,21,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r19.u32, 21) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d04
	if (cr0.lt) goto loc_82407D04;
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_82407838:
	// lwzx r9,r11,r26
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x82407850
	if (!cr6.eq) goto loc_82407850;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
loc_82407850:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82407838
	if (!cr0.eq) goto loc_82407838;
loc_8240785C:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x82407c44
	if (cr6.eq) goto loc_82407C44;
	// mulli r4,r24,11
	ctx.r4.s64 = r24.s64 * 11;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5278
	sub_823F5278(ctx, base);
	// mr. r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240789c
	if (!cr0.eq) goto loc_8240789C;
loc_82407878:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,12944
	ctx.r6.s64 = r11.s64 + 12944;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x82407d04
	goto loc_82407D04;
loc_8240789C:
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// rlwinm r8,r24,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,11
	r11.s64 = 11;
loc_824078A8:
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x824078a8
	if (!cr0.eq) goto loc_824078A8;
	// subf r19,r15,r25
	r19.s64 = r25.s64 - r15.s64;
	// lwz r22,200(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	// lwz r25,160(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// mr r11,r15
	r11.u64 = r15.u64;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// subf r20,r22,r25
	r20.s64 = r25.s64 - r22.s64;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
loc_824078DC:
	// lwzx r9,r11,r19
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r19.u32);
	// cmplwi cr6,r9,2
	cr6.compare<uint32_t>(ctx.r9.u32, 2, xer);
	// bne cr6,0x82407910
	if (!cr6.eq) goto loc_82407910;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stwx r9,r20,r10
	PPC_STORE_U32(r20.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r9,28(r16)
	ctx.r9.u64 = PPC_LOAD_U32(r16.u32 + 28);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82407904
	if (cr6.eq) goto loc_82407904;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x82407908
	goto loc_82407908;
loc_82407904:
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
loc_82407908:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_82407910:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x824078dc
	if (!cr0.eq) goto loc_824078DC;
	// addi r9,r1,164
	ctx.r9.s64 = ctx.r1.s64 + 164;
	// li r8,9
	ctx.r8.s64 = 9;
loc_82407924:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8240794c
	if (cr6.eq) goto loc_8240794C;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi r24,0
	cr0.compare<uint32_t>(r24.u32, 0, xer);
	// beq 0x8240794c
	if (cr0.eq) goto loc_8240794C;
	// mtctr r24
	ctr.u64 = r24.u64;
loc_82407940:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82407940
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82407940;
loc_8240794C:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82407924
	if (!cr0.eq) goto loc_82407924;
	// lwz r28,164(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// clrlwi r30,r24,12
	r30.u64 = r24.u32 & 0xFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// oris r5,r30,4128
	ctx.r5.u64 = r30.u64 | 270532608;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// lwz r26,168(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// li r9,20
	ctx.r9.s64 = 20;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// oris r5,r30,4160
	ctx.r5.u64 = r30.u64 | 272629760;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// lwz r29,172(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// oris r27,r30,4112
	r27.u64 = r30.u64 | 269484032;
	// li r9,24
	ctx.r9.s64 = 24;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// lwz r23,176(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// oris r24,r30,8256
	r24.u64 = r30.u64 | 541065216;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// lwz r28,180(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// lwz r25,184(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// oris r29,r30,8224
	r29.u64 = r30.u64 | 538968064;
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// lwz r28,188(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// lwz r28,192(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// lwz r29,196(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// li r9,23
	ctx.r9.s64 = 23;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// oris r5,r30,8272
	ctx.r5.u64 = r30.u64 | 542113792;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82407d00
	if (cr0.lt) goto loc_82407D00;
	// mr r28,r15
	r28.u64 = r15.u64;
	// mr r29,r22
	r29.u64 = r22.u64;
	// mr r27,r21
	r27.u64 = r21.u64;
loc_82407B28:
	// lwzx r11,r19,r28
	r11.u64 = PPC_LOAD_U32(r19.u32 + r28.u32);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x82407c34
	if (!cr6.eq) goto loc_82407C34;
	// lwz r11,8(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// lwzx r10,r20,r29
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + r29.u32);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r30,r9,r11
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407b70
	if (cr0.eq) goto loc_82407B70;
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 32);
	// stfd f0,40(r31)
	PPC_STORE_U64(r31.u32 + 40, f0.u64);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82407B70:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407c28
	if (cr0.eq) goto loc_82407C28;
	// lfd f1,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 32);
	// bl 0x823ae098
	sub_823AE098(ctx, base);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82407bb8
	if (cr0.eq) goto loc_82407BB8;
	// lfd f13,184(r18)
	ctx.f13.u64 = PPC_LOAD_U64(r18.u32 + 184);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// blt cr6,0x82407bac
	if (cr6.lt) goto loc_82407BAC;
	// fadd f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 + f0.f64;
	// bl 0x8239da30
	sub_8239DA30(ctx, base);
	// stfd f1,32(r30)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r30.u32 + 32, ctx.f1.u64);
	// b 0x82407bbc
	goto loc_82407BBC;
loc_82407BAC:
	// fsub f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f13.f64 - f0.f64;
	// bl 0x8239da30
	sub_8239DA30(ctx, base);
	// fneg f0,f1
	ctx.fpscr.disableFlushMode();
	f0.u64 = ctx.f1.u64 ^ 0x8000000000000000;
loc_82407BB8:
	// stfd f0,32(r30)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r30.u32 + 32, f0.u64);
loc_82407BBC:
	// lfd f1,40(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 40);
	// bl 0x823ae098
	sub_823AE098(ctx, base);
	// lfd f0,40(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 40);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82407bf8
	if (cr0.eq) goto loc_82407BF8;
	// lfd f13,184(r18)
	ctx.f13.u64 = PPC_LOAD_U64(r18.u32 + 184);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// blt cr6,0x82407bec
	if (cr6.lt) goto loc_82407BEC;
	// fadd f1,f13,f0
	ctx.f1.f64 = ctx.f13.f64 + f0.f64;
	// bl 0x8239da30
	sub_8239DA30(ctx, base);
	// stfd f1,40(r30)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r30.u32 + 40, ctx.f1.u64);
	// b 0x82407bfc
	goto loc_82407BFC;
loc_82407BEC:
	// fsub f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f13.f64 - f0.f64;
	// bl 0x8239da30
	sub_8239DA30(ctx, base);
	// fneg f0,f1
	ctx.fpscr.disableFlushMode();
	f0.u64 = ctx.f1.u64 ^ 0x8000000000000000;
loc_82407BF8:
	// stfd f0,40(r30)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r30.u32 + 40, f0.u64);
loc_82407BFC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lfd f0,32(r30)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// lfd f13,40(r30)
	ctx.f13.u64 = PPC_LOAD_U64(r30.u32 + 40);
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bne cr6,0x82407c20
	if (!cr6.eq) goto loc_82407C20;
	// ori r11,r11,128
	r11.u64 = r11.u64 | 128;
	// b 0x82407c24
	goto loc_82407C24;
loc_82407C20:
	// rlwinm r11,r11,0,25,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
loc_82407C24:
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_82407C28:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_82407C34:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// bne 0x82407b28
	if (!cr0.eq) goto loc_82407B28;
	// lwz r22,128(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_82407C44:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82407cd4
	if (cr6.eq) goto loc_82407CD4;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// subf r6,r17,r15
	ctx.r6.s64 = r15.s64 - r17.s64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
loc_82407C58:
	// lwz r11,8(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// lwzx r10,r6,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r8,0,7,3
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// or r10,r5,r11
	ctx.r10.u64 = ctx.r5.u64 | r11.u64;
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// rlwinm. r11,r10,0,4,6
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,0,4,6
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	// bne 0x82407c94
	if (!cr0.eq) goto loc_82407C94;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82407C94:
	// lwz r5,92(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 92);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82407cac
	if (!cr6.eq) goto loc_82407CAC;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x82407cb8
	if (cr6.lt) goto loc_82407CB8;
	// b 0x82407cb4
	goto loc_82407CB4;
loc_82407CAC:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x82407cb8
	if (cr6.gt) goto loc_82407CB8;
loc_82407CB4:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82407CB8:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// rlwinm r10,r10,0,7,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// bne 0x82407c58
	if (!cr0.eq) goto loc_82407C58;
loc_82407CD4:
	// li r31,0
	r31.s64 = 0;
	// b 0x82407d04
	goto loc_82407D04;
loc_82407CDC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,32632
	ctx.r6.s64 = r11.s64 + 32632;
loc_82407CE4:
	// li r4,0
	ctx.r4.s64 = 0;
loc_82407CE8:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
loc_82407CF4:
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
	// b 0x82407d04
	goto loc_82407D04;
loc_82407D00:
	// lwz r22,128(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_82407D04:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82407d3c
	if (cr6.eq) goto loc_82407D3C;
	// addi r3,r22,-8
	ctx.r3.s64 = r22.s64 + -8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,140(r18)
	PPC_STORE_U32(r18.u32 + 140, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82407d2c
	if (!cr0.gt) goto loc_82407D2C;
	// stw r11,144(r18)
	PPC_STORE_U32(r18.u32 + 144, r11.u32);
	// b 0x82407d3c
	goto loc_82407D3C;
loc_82407D2C:
	// neg r11,r11
	r11.s64 = -r11.s64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// stw r11,144(r18)
	PPC_STORE_U32(r18.u32 + 144, r11.u32);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
loc_82407D3C:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x82407d74
	if (cr6.eq) goto loc_82407D74;
	// addi r3,r14,-8
	ctx.r3.s64 = r14.s64 + -8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,140(r18)
	PPC_STORE_U32(r18.u32 + 140, r11.u32);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82407d64
	if (!cr0.gt) goto loc_82407D64;
	// stw r11,144(r18)
	PPC_STORE_U32(r18.u32 + 144, r11.u32);
	// b 0x82407d74
	goto loc_82407D74;
loc_82407D64:
	// neg r11,r11
	r11.s64 = -r11.s64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// stw r11,144(r18)
	PPC_STORE_U32(r18.u32 + 144, r11.u32);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
loc_82407D74:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82407d84
	goto loc_82407D84;
loc_82407D7C:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82407D84:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_82407D90"))) PPC_WEAK_FUNC(sub_82407D90);
PPC_FUNC_IMPL(__imp__sub_82407D90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82407e34
	if (!cr6.eq) goto loc_82407E34;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407e2c
	if (cr6.eq) goto loc_82407E2C;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x82407e2c
	if (cr6.eq) goto loc_82407E2C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// li r29,-1
	r29.s64 = -1;
	// lfd f31,-31368(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82407DD4:
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r4,136(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// bge cr6,0x82407e10
	if (!cr6.lt) goto loc_82407E10;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x82407e14
	goto loc_82407E14;
loc_82407E10:
	// li r11,0
	r11.s64 = 0;
loc_82407E14:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82407e20
	if (cr6.eq) goto loc_82407E20;
	// stw r29,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r29.u32);
loc_82407E20:
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x82407dd4
	if (!cr0.eq) goto loc_82407DD4;
loc_82407E2C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82408070
	goto loc_82408070;
loc_82407E34:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x82407f90
	if (!cr6.eq) goto loc_82407F90;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82407e2c
	if (cr6.eq) goto loc_82407E2C;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x82407ec8
	if (!cr6.eq) goto loc_82407EC8;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82407e8c
	if (!cr6.eq) goto loc_82407E8C;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x82407e2c
	if (cr6.eq) goto loc_82407E2C;
	// li r11,0
	r11.s64 = 0;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
loc_82407E70:
	// lwz r9,28(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r9,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82407e70
	if (!cr0.eq) goto loc_82407E70;
	// b 0x82407e2c
	goto loc_82407E2C;
loc_82407E8C:
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x82407e2c
	if (cr6.eq) goto loc_82407E2C;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_82407E9C:
	// lwz r9,24(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r8,24(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x82407e9c
	if (cr6.lt) goto loc_82407E9C;
	// b 0x82407e2c
	goto loc_82407E2C;
loc_82407EC8:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// lfd f1,-31368(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// blt cr6,0x82407f1c
	if (cr6.lt) goto loc_82407F1C;
	// beq cr6,0x82407f04
	if (cr6.eq) goto loc_82407F04;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x82407ef4
	if (cr6.lt) goto loc_82407EF4;
	// bne cr6,0x82407f34
	if (!cr6.eq) goto loc_82407F34;
	// lfd f1,24(r29)
	ctx.f1.u64 = PPC_LOAD_U64(r29.u32 + 24);
	// b 0x82407f34
	goto loc_82407F34;
loc_82407EF4:
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// b 0x82407f10
	goto loc_82407F10;
loc_82407F04:
	// lwa r11,24(r29)
	r11.s64 = int32_t(PPC_LOAD_U32(r29.u32 + 24));
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
loc_82407F10:
	// li r31,2
	r31.s64 = 2;
	// fcfid f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(f0.s64);
	// b 0x82407f34
	goto loc_82407F34;
loc_82407F1C:
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82407f30
	if (cr6.eq) goto loc_82407F30;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f1,-31360(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_82407F30:
	// li r31,23
	r31.s64 = 23;
loc_82407F34:
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,120(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// bge cr6,0x82407f6c
	if (!cr6.lt) goto loc_82407F6C;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x82407f70
	goto loc_82407F70;
loc_82407F6C:
	// li r11,0
	r11.s64 = 0;
loc_82407F70:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82407e2c
	if (cr6.eq) goto loc_82407E2C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// li r9,-1
	ctx.r9.s64 = -1;
	// or r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 | r31.u64;
	// stw r9,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r9.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x82407e2c
	goto loc_82407E2C;
loc_82407F90:
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82407fb0
	if (!cr6.eq) goto loc_82407FB0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// b 0x82408070
	goto loc_82408070;
loc_82407FB0:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82408050
	if (!cr6.eq) goto loc_82408050;
loc_82407FB8:
	// lwz r4,8(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x82407ff8
	if (cr0.eq) goto loc_82407FF8;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x82407ff8
	if (!cr6.eq) goto loc_82407FF8;
	// lwz r11,16(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// li r31,1
	r31.s64 = 1;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x82407fe4
	if (!cr6.eq) goto loc_82407FE4;
	// lwz r31,28(r4)
	r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
loc_82407FE4:
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82407d90
	sub_82407D90(ctx, base);
	// b 0x82408028
	goto loc_82408028;
loc_82407FF8:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82408050
	if (cr6.eq) goto loc_82408050;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82408050
	if (!cr6.eq) goto loc_82408050;
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r10,20(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mullw r31,r11,r10
	r31.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// bl 0x82406038
	sub_82406038(ctx, base);
loc_82408028:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82408070
	if (cr0.lt) goto loc_82408070;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82408040
	if (cr6.eq) goto loc_82408040;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
loc_82408040:
	// lwz r29,12(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// bne 0x82407fb8
	if (!cr0.eq) goto loc_82407FB8;
	// b 0x82407e2c
	goto loc_82407E2C;
loc_82408050:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32748
	ctx.r6.s64 = r11.s64 + 32748;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82408070:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8240807C"))) PPC_WEAK_FUNC(sub_8240807C);
PPC_FUNC_IMPL(__imp__sub_8240807C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82408080"))) PPC_WEAK_FUNC(sub_82408080);
PPC_FUNC_IMPL(__imp__sub_82408080) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x824080a8
	if (cr6.eq) goto loc_824080A8;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x824081e8
	goto loc_824081E8;
loc_824080A8:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mullw r30,r11,r10
	r30.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x824080d4
	if (!cr0.eq) goto loc_824080D4;
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x824081c4
	goto loc_824081C4;
loc_824080D4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824080fc
	if (cr6.eq) goto loc_824080FC;
	// mr r11,r29
	r11.u64 = r29.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824080fc
	if (cr0.eq) goto loc_824080FC;
	// mtctr r30
	ctr.u64 = r30.u64;
loc_824080F0:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x824080f0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824080F0;
loc_824080FC:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82406038
	sub_82406038(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x824081c4
	if (cr0.lt) goto loc_824081C4;
	// li r11,1
	r11.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwimi r5,r11,28,0,11
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r5.u64 & 0xFFFFFFFF000FFFFF);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823f5698
	sub_823F5698(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x824081c4
	if (cr0.lt) goto loc_824081C4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82408198
	if (cr6.eq) goto loc_82408198;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_82408154:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bge cr6,0x82408178
	if (!cr6.lt) goto loc_82408178;
	// lwz r8,20(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// b 0x8240817c
	goto loc_8240817C;
loc_82408178:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8240817C:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8240818c
	if (cr6.eq) goto loc_8240818C;
	// lwz r11,132(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
loc_8240818C:
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82408154
	if (!cr0.eq) goto loc_82408154;
loc_82408198:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,16(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r6,132(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 132);
	// bl 0x823f94b8
	sub_823F94B8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_824081C4:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lwz r11,76(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 76);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x824081e4
	if (cr6.eq) goto loc_824081E4;
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
loc_824081E4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_824081E8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_824081F0"))) PPC_WEAK_FUNC(sub_824081F0);
PPC_FUNC_IMPL(__imp__sub_824081F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r19,19276(r14)
	r19.u64 = PPC_LOAD_U32(r14.u32 + 19276);
	// lwz r16,-14032(r14)
	r16.u64 = PPC_LOAD_U32(r14.u32 + -14032);
	// mflr r12
	// bl 0x8239bcc0
	// addi r31,r1,-624
	r31.s64 = ctx.r1.s64 + -624;
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,644(r31)
	PPC_STORE_U32(r31.u32 + 644, r30.u32);
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r18,r6
	r18.u64 = ctx.r6.u64;
	// stw r18,668(r31)
	PPC_STORE_U32(r31.u32 + 668, r18.u32);
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// mr r16,r8
	r16.u64 = ctx.r8.u64;
	// mr r15,r9
	r15.u64 = ctx.r9.u64;
	// mr r24,r10
	r24.u64 = ctx.r10.u64;
	// lis r5,1
	ctx.r5.s64 = 65536;
	// lis r4,16
	ctx.r4.s64 = 1048576;
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x824091d0
	sub_824091D0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// stw r26,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r26.u32);
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
	// mr r14,r26
	r14.u64 = r26.u64;
	// stw r14,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r14.u32);
	// stw r26,212(r31)
	PPC_STORE_U32(r31.u32 + 212, r26.u32);
	// mr r22,r26
	r22.u64 = r26.u64;
	// mr r21,r26
	r21.u64 = r26.u64;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// stw r3,216(r31)
	PPC_STORE_U32(r31.u32 + 216, ctx.r3.u32);
	// lis r4,8
	ctx.r4.s64 = 524288;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// li r29,-1
	r29.s64 = -1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// lis r4,3
	ctx.r4.s64 = 196608;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// lwz r19,740(r31)
	r19.u64 = PPC_LOAD_U32(r31.u32 + 740);
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// bne cr6,0x824082c4
	if (!cr6.eq) goto loc_824082C4;
	// addi r11,r31,288
	r11.s64 = r31.s64 + 288;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_824082AC:
	// std r9,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r9.u64);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// bdnz 0x824082ac
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824082AC;
	// addi r19,r31,288
	r19.s64 = r31.s64 + 288;
	// stw r19,740(r31)
	PPC_STORE_U32(r31.u32 + 740, r19.u32);
	// b 0x824082c8
	goto loc_824082C8;
loc_824082C4:
	// stw r26,28(r19)
	PPC_STORE_U32(r19.u32 + 28, r26.u32);
loc_824082C8:
	// lwz r27,716(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 716);
	// lis r12,-863
	r12.s64 = -56557568;
	// ori r12,r12,57344
	r12.u64 = r12.u64 | 57344;
	// and. r11,r27,r12
	r11.u64 = r27.u64 & r12.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824082e8
	if (cr0.eq) goto loc_824082E8;
loc_824082DC:
	// lis r29,-30602
	r29.s64 = -2005532672;
	// ori r29,r29,2156
	r29.u64 = r29.u64 | 2156;
	// b 0x82408bd4
	goto loc_82408BD4;
loc_824082E8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x824082f8
	if (cr6.eq) goto loc_824082F8;
	// rlwinm. r11,r27,0,27,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824082dc
	if (!cr0.eq) goto loc_824082DC;
loc_824082F8:
	// lwz r11,724(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 724);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824082dc
	if (cr6.eq) goto loc_824082DC;
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408324
	if (cr0.eq) goto loc_82408324;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82408324:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// addi r23,r30,4
	r23.s64 = r30.s64 + 4;
	// stw r26,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r26.u32);
	// stw r26,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r26.u32);
	// stw r26,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r26.u32);
	// stw r28,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r28.u32);
	// stw r26,80(r30)
	PPC_STORE_U32(r30.u32 + 80, r26.u32);
	// lwz r3,708(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 708);
	// stw r26,84(r30)
	PPC_STORE_U32(r30.u32 + 84, r26.u32);
	// stw r26,88(r30)
	PPC_STORE_U32(r30.u32 + 88, r26.u32);
	// stw r26,92(r30)
	PPC_STORE_U32(r30.u32 + 92, r26.u32);
	// stw r26,96(r30)
	PPC_STORE_U32(r30.u32 + 96, r26.u32);
	// stw r26,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r26.u32);
	// stw r26,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r26.u32);
	// stw r26,60(r30)
	PPC_STORE_U32(r30.u32 + 60, r26.u32);
	// stw r26,64(r30)
	PPC_STORE_U32(r30.u32 + 64, r26.u32);
	// stw r26,68(r30)
	PPC_STORE_U32(r30.u32 + 68, r26.u32);
	// stw r26,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r26.u32);
	// stw r26,112(r30)
	PPC_STORE_U32(r30.u32 + 112, r26.u32);
	// stw r29,72(r30)
	PPC_STORE_U32(r30.u32 + 72, r29.u32);
	// stw r26,116(r30)
	PPC_STORE_U32(r30.u32 + 116, r26.u32);
	// stw r26,120(r30)
	PPC_STORE_U32(r30.u32 + 120, r26.u32);
	// mr r17,r26
	r17.u64 = r26.u64;
	// stw r26,124(r30)
	PPC_STORE_U32(r30.u32 + 124, r26.u32);
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// stw r26,128(r30)
	PPC_STORE_U32(r30.u32 + 128, r26.u32);
	// stw r26,132(r30)
	PPC_STORE_U32(r30.u32 + 132, r26.u32);
	// stw r24,136(r30)
	PPC_STORE_U32(r30.u32 + 136, r24.u32);
	// stw r26,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r26.u32);
	// stw r26,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r26.u32);
	// stw r3,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r3.u32);
	// stw r27,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r27.u32);
	// beq cr6,0x824083f0
	if (cr6.eq) goto loc_824083F0;
	// lis r11,18008
	r11.s64 = 1180172288;
	// ori r11,r11,512
	r11.u64 = r11.u64 | 512;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,508
	ctx.r3.s64 = 508;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824083d8
	if (cr0.eq) goto loc_824083D8;
	// bl 0x82483878
	sub_82483878(ctx, base);
	// b 0x824083dc
	goto loc_824083DC;
loc_824083D8:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_824083DC:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r17,1
	r17.s64 = 1;
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// b 0x82408748
	goto loc_82408748;
loc_824083F0:
	// rlwinm. r11,r27,0,24,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xC0;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824084ac
	if (cr0.eq) goto loc_824084AC;
	// addi r5,r31,232
	ctx.r5.s64 = r31.s64 + 232;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8240842c
	if (!cr0.lt) goto loc_8240842C;
loc_8240840C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32148
	ctx.r6.s64 = r11.s64 + -32148;
	// li r5,3506
	ctx.r5.s64 = 3506;
	// lwz r7,12(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x824082dc
	goto loc_824082DC;
loc_8240842C:
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 236);
	// rlwinm r11,r10,0,0,15
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	// lis r9,-2
	ctx.r9.s64 = -131072;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8240847c
	if (cr6.eq) goto loc_8240847C;
	// lis r9,-1
	ctx.r9.s64 = -65536;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x824084ac
	if (!cr6.eq) goto loc_824084AC;
	// rlwinm. r11,r27,0,24,24
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824084ac
	if (cr0.eq) goto loc_824084AC;
	// rlwinm r11,r10,0,16,23
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFF00;
	// ori r27,r27,5
	r27.u64 = r27.u64 | 5;
	// cmplwi cr6,r11,768
	cr6.compare<uint32_t>(r11.u32, 768, xer);
	// bne cr6,0x82408470
	if (!cr6.eq) goto loc_82408470;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,5784
	r11.s64 = r11.s64 + 5784;
	// b 0x824084a8
	goto loc_824084A8;
loc_82408470:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,5800
	r11.s64 = r11.s64 + 5800;
	// b 0x824084a8
	goto loc_824084A8;
loc_8240847C:
	// rlwinm. r11,r27,0,25,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824084ac
	if (cr0.eq) goto loc_824084AC;
	// rlwinm r11,r10,0,16,23
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFF00;
	// ori r27,r27,5
	r27.u64 = r27.u64 | 5;
	// cmplwi cr6,r11,768
	cr6.compare<uint32_t>(r11.u32, 768, xer);
	// bne cr6,0x824084a0
	if (!cr6.eq) goto loc_824084A0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,5624
	r11.s64 = r11.s64 + 5624;
	// b 0x824084a8
	goto loc_824084A8;
loc_824084A0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,5640
	r11.s64 = r11.s64 + 5640;
loc_824084A8:
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_824084AC:
	// addi r5,r31,232
	ctx.r5.s64 = r31.s64 + 232;
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240840c
	if (cr0.lt) goto loc_8240840C;
	// lwz r9,236(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 236);
	// lis r11,-2
	r11.s64 = -131072;
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// stw r27,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r27.u32);
	// stw r9,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r9.u32);
	// bne cr6,0x824084f0
	if (!cr6.eq) goto loc_824084F0;
	// lis r11,-2
	r11.s64 = -131072;
	// ori r11,r11,257
	r11.u64 = r11.u64 | 257;
	// li r22,1
	r22.s64 = 1;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
loc_824084F0:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82408514
	if (!cr6.eq) goto loc_82408514;
	// lis r11,-1
	r11.s64 = -65536;
	// ori r11,r11,257
	r11.u64 = r11.u64 | 257;
	// li r21,1
	r21.s64 = 1;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
loc_82408514:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,612
	ctx.r10.u64 = ctx.r10.u64 | 612;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x824086fc
	if (cr6.gt) goto loc_824086FC;
	// beq cr6,0x824086dc
	if (cr6.eq) goto loc_824086DC;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,768
	ctx.r10.u64 = ctx.r10.u64 | 768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x824085bc
	if (cr6.gt) goto loc_824085BC;
	// beq cr6,0x82408724
	if (cr6.eq) goto loc_82408724;
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408598
	if (cr6.eq) goto loc_82408598;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,257
	ctx.r10.u64 = ctx.r10.u64 | 257;
	// subf. r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82408578
	if (cr0.eq) goto loc_82408578;
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// beq cr6,0x82408578
	if (cr6.eq) goto loc_82408578;
	// cmplwi cr6,r11,257
	cr6.compare<uint32_t>(r11.u32, 257, xer);
	// beq cr6,0x82408578
	if (cr6.eq) goto loc_82408578;
	// cmplwi cr6,r11,510
	cr6.compare<uint32_t>(r11.u32, 510, xer);
	// bne cr6,0x8240871c
	if (!cr6.eq) goto loc_8240871C;
loc_82408578:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,504
	ctx.r3.s64 = 504;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8247fee0
	sub_8247FEE0(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_82408598:
	// ori r11,r27,256
	r11.u64 = r27.u64 | 256;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,508
	ctx.r3.s64 = 508;
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// bl 0x82483878
	sub_82483878(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_824085BC:
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,260
	ctx.r10.u64 = ctx.r10.u64 | 260;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// bgt cr6,0x824086b0
	if (cr6.gt) goto loc_824086B0;
	// ori r10,r10,257
	ctx.r10.u64 = ctx.r10.u64 | 257;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8240868c
	if (!cr6.lt) goto loc_8240868C;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,1021
	ctx.r10.u64 = ctx.r10.u64 | 1021;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x8240871c
	if (cr6.lt) goto loc_8240871C;
	// lis r8,-2
	ctx.r8.s64 = -131072;
	// ori r8,r8,1022
	ctx.r8.u64 = ctx.r8.u64 | 1022;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// ble cr6,0x8240860c
	if (!cr6.gt) goto loc_8240860C;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,1023
	ctx.r10.u64 = ctx.r10.u64 | 1023;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// b 0x82408718
	goto loc_82408718;
loc_8240860C:
	// rlwinm r11,r9,0,0,15
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFF0000;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm. r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82408624
	if (cr0.eq) goto loc_82408624;
	// twi 31,r0,22
loc_82408624:
	// lwz r29,24(r19)
	r29.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x8240863c
	if (cr0.eq) goto loc_8240863C;
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408640
	if (!cr6.eq) goto loc_82408640;
loc_8240863C:
	// mr r29,r18
	r29.u64 = r18.u64;
loc_82408640:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,1820
	ctx.r3.s64 = 1820;
	// bne 0x82408670
	if (!cr0.eq) goto loc_82408670;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x823f30c0
	sub_823F30C0(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_82408670:
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x823f3110
	sub_823F3110(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_8240868C:
	// rlwinm r11,r27,0,30,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,1156
	ctx.r3.s64 = 1156;
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// bl 0x824706e8
	sub_824706E8(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_824086B0:
	// ori r10,r10,512
	ctx.r10.u64 = ctx.r10.u64 | 512;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824086dc
	if (cr6.eq) goto loc_824086DC;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,513
	ctx.r10.u64 = ctx.r10.u64 | 513;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8240871c
	if (!cr6.gt) goto loc_8240871C;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,515
	ctx.r10.u64 = ctx.r10.u64 | 515;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8240871c
	if (cr6.gt) goto loc_8240871C;
loc_824086DC:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,556
	ctx.r3.s64 = 556;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8246c6f0
	sub_8246C6F0(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_824086FC:
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,767
	ctx.r10.u64 = ctx.r10.u64 | 767;
	// subf. r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824086dc
	if (cr0.eq) goto loc_824086DC;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x82408724
	if (cr6.eq) goto loc_82408724;
	// cmplwi cr6,r11,256
	cr6.compare<uint32_t>(r11.u32, 256, xer);
loc_82408718:
	// beq cr6,0x82408724
	if (cr6.eq) goto loc_82408724;
loc_8240871C:
	// stw r26,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r26.u32);
	// b 0x8240874c
	goto loc_8240874C;
loc_82408724:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,504
	ctx.r3.s64 = 504;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x82439cf0
	sub_82439CF0(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_82408744:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82408748:
	// stw r3,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r3.u32);
loc_8240874C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408764
	if (!cr6.eq) goto loc_82408764;
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x82408bd4
	goto loc_82408BD4;
loc_82408764:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x824087b4
	if (!cr6.eq) goto loc_824087B4;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r3,r31,352
	ctx.r3.s64 = r31.s64 + 352;
	// lwz r29,0(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// oris r28,r11,32768
	r28.u64 = r11.u64 | 2147483648;
	// bl 0x824590f0
	sub_824590F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// bl 0x8246c570
	sub_8246C570(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cntlzw r11,r29
	r11.u64 = r29.u32 == 0 ? 32 : __builtin_clz(r29.u32);
	// addi r3,r31,352
	ctx.r3.s64 = r31.s64 + 352;
	// cntlzw r28,r11
	r28.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// rlwinm. r11,r28,27,31,31
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408bd4
	if (!cr0.eq) goto loc_82408BD4;
	// b 0x824087b8
	goto loc_824087B8;
loc_824087B4:
	// stw r25,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r25.u32);
loc_824087B8:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x824087d8
	if (cr6.eq) goto loc_824087D8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,29712
	ctx.r6.s64 = r11.s64 + 29712;
	// li r5,3505
	ctx.r5.s64 = 3505;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_824087D8:
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x824087f8
	if (cr6.eq) goto loc_824087F8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,29668
	ctx.r6.s64 = r11.s64 + 29668;
	// li r5,3505
	ctx.r5.s64 = 3505;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_824087F8:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x8240885c
	if (!cr6.eq) goto loc_8240885C;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82408820
	if (cr6.eq) goto loc_82408820;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x823f4ad8
	sub_823F4AD8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r25,r26
	r25.u64 = r26.u64;
	// b 0x82408864
	goto loc_82408864;
loc_82408820:
	// addi r5,r31,668
	ctx.r5.s64 = r31.s64 + 668;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// bl 0x823f4c28
	sub_823F4C28(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x82408850
	if (!cr0.eq) goto loc_82408850;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32180
	ctx.r6.s64 = r11.s64 + -32180;
	// li r5,3501
	ctx.r5.s64 = 3501;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82408d6c
	goto loc_82408D6C;
loc_82408850:
	// li r25,1
	r25.s64 = 1;
	// lwz r18,668(r31)
	r18.u64 = PPC_LOAD_U32(r31.u32 + 668);
	// b 0x82408864
	goto loc_82408864;
loc_8240885C:
	// lwz r28,216(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 216);
	// lwz r25,216(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + 216);
loc_82408864:
	// lwz r4,20(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm. r10,r4,0,6,6
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240887c
	if (!cr0.eq) goto loc_8240887C;
	// rlwinm. r11,r4,0,9,9
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x400000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// beq 0x82408880
	if (cr0.eq) goto loc_82408880;
loc_8240887C:
	// li r11,1
	r11.s64 = 1;
loc_82408880:
	// clrlwi r29,r11,24
	r29.u64 = r11.u32 & 0xFF;
	// lwz r11,16(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240889c
	if (cr0.eq) goto loc_8240889C;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// beq cr6,0x8240889c
	if (cr6.eq) goto loc_8240889C;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_8240889C:
	// lwz r11,36(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824088b4
	if (!cr6.eq) goto loc_824088B4;
	// lwz r11,44(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824088b8
	if (cr6.eq) goto loc_824088B8;
loc_824088B4:
	// mr r29,r26
	r29.u64 = r26.u64;
loc_824088B8:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// andi. r11,r11,18
	r11.u64 = r11.u64 & 18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824088cc
	if (cr0.eq) goto loc_824088CC;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_824088CC:
	// rlwinm. r11,r4,0,11,11
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408a0c
	if (!cr0.eq) goto loc_82408A0C;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x82408a0c
	if (!cr6.eq) goto loc_82408A0C;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x82408a3c
	if (!cr6.eq) goto loc_82408A3C;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x824088f8
	if (cr6.eq) goto loc_824088F8;
	// li r14,1
	r14.s64 = 1;
	// stw r14,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r14.u32);
	// b 0x82408a0c
	goto loc_82408A0C;
loc_824088F8:
	// lis r11,-32193
	r11.s64 = -2109800448;
	// lwz r6,0(r23)
	ctx.r6.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// addi r5,r31,208
	ctx.r5.s64 = r31.s64 + 208;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r11,r11,21880
	r11.s64 = r11.s64 + 21880;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r19.u32);
	// addi r10,r31,196
	ctx.r10.s64 = r31.s64 + 196;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r9,r15
	ctx.r9.u64 = r15.u64;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// bl 0x82497ab0
	sub_82497AB0(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// stw r14,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r14.u32);
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408978
	if (cr6.eq) goto loc_82408978;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408978
	if (cr0.eq) goto loc_82408978;
	// lwz r11,28(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82408978
	if (!cr6.eq) goto loc_82408978;
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// bl 0x823f5150
	sub_823F5150(ctx, base);
	// stw r3,28(r19)
	PPC_STORE_U32(r19.u32 + 28, ctx.r3.u32);
loc_82408978:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bge cr6,0x82408a0c
	if (!cr6.lt) goto loc_82408A0C;
	// lwz r11,28(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82408a0c
	if (!cr6.eq) goto loc_82408A0C;
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82408a0c
	if (cr0.eq) goto loc_82408A0C;
	// lis r11,-32768
	r11.s64 = -2147483648;
	// ori r11,r11,16388
	r11.u64 = r11.u64 | 16388;
	// cmpw cr6,r14,r11
	cr6.compare<int32_t>(r14.s32, r11.s32, xer);
	// bne cr6,0x824089ac
	if (!cr6.eq) goto loc_824089AC;
	// mr r29,r26
	r29.u64 = r26.u64;
	// b 0x82408a0c
	goto loc_82408A0C;
loc_824089AC:
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824089cc
	if (cr6.eq) goto loc_824089CC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r26.u32);
loc_824089CC:
	// lwz r3,208(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824089ec
	if (cr6.eq) goto loc_824089EC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
loc_824089EC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r4,r31,212
	ctx.r4.s64 = r31.s64 + 212;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// stw r26,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r26.u32);
	// bl 0x823eaf78
	sub_823EAF78(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823eb9d8
	sub_823EB9D8(ctx, base);
loc_82408A0C:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x82408a3c
	if (!cr6.eq) goto loc_82408A3C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82408a3c
	if (!cr6.eq) goto loc_82408A3C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32208
	ctx.r6.s64 = r11.s64 + -32208;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// li r5,3501
	ctx.r5.s64 = 3501;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82408d6c
	goto loc_82408D6C;
loc_82408A3C:
	// lwz r9,28(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 28);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82408a4c
	if (cr0.eq) goto loc_82408A4C;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_82408A4C:
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408a64
	if (!cr6.eq) goto loc_82408A64;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm. r11,r10,0,6,6
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408a74
	if (!cr0.eq) goto loc_82408A74;
loc_82408A64:
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm. r11,r10,0,9,9
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// beq 0x82408a78
	if (cr0.eq) goto loc_82408A78;
loc_82408A74:
	// li r11,1
	r11.s64 = 1;
loc_82408A78:
	// clrlwi. r27,r11,24
	r27.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// stb r27,200(r31)
	PPC_STORE_U8(r31.u32 + 200, r27.u8);
	// beq 0x82408b38
	if (cr0.eq) goto loc_82408B38;
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408b38
	if (!cr0.eq) goto loc_82408B38;
	// rlwinm. r11,r10,0,7,7
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r27,r26
	r27.u64 = r26.u64;
	// stb r27,200(r31)
	PPC_STORE_U8(r31.u32 + 200, r27.u8);
	// beq 0x82408aa8
	if (cr0.eq) goto loc_82408AA8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32256
	ctx.r6.s64 = r11.s64 + -32256;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408AA8:
	// lwz r11,16(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82408ac8
	if (cr0.eq) goto loc_82408AC8;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// beq cr6,0x82408ac8
	if (cr6.eq) goto loc_82408AC8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32308
	ctx.r6.s64 = r11.s64 + -32308;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408AC8:
	// lwz r11,36(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408b20
	if (!cr6.eq) goto loc_82408B20;
	// lwz r11,44(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408b20
	if (!cr6.eq) goto loc_82408B20;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82408af4
	if (cr6.eq) goto loc_82408AF4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32364
	ctx.r6.s64 = r11.s64 + -32364;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408AF4:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82408b0c
	if (cr0.eq) goto loc_82408B0C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32408
	ctx.r6.s64 = r11.s64 + -32408;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408B0C:
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82408b38
	if (cr0.eq) goto loc_82408B38;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32452
	ctx.r6.s64 = r11.s64 + -32452;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408B20:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32504
	ctx.r6.s64 = r11.s64 + -32504;
loc_82408B28:
	// li r5,3042
	ctx.r5.s64 = 3042;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_82408B38:
	// clrlwi. r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408ca4
	if (!cr0.eq) goto loc_82408CA4;
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408b54
	if (!cr6.eq) goto loc_82408B54;
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bge cr6,0x82408ca4
	if (!cr6.lt) goto loc_82408CA4;
loc_82408B54:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// blt cr6,0x82408f18
	if (cr6.lt) {
		// ERROR 82408F18
		return;
	}
	// lwz r28,732(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 732);
	// lwz r27,724(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 724);
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82408bd0
	if (cr6.eq) goto loc_82408BD0;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408b90
	if (cr0.eq) goto loc_82408B90;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r26.u32);
loc_82408B90:
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// stw r26,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r26.u32);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// beq cr6,0x82408bd0
	if (cr6.eq) goto loc_82408BD0;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408bc4
	if (cr0.eq) goto loc_82408BC4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r26.u32);
loc_82408BC4:
	// lwz r11,208(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_82408BD0:
	// mr r29,r26
	r29.u64 = r26.u64;
loc_82408BD4:
	// bl 0x823b4cf0
	sub_823B4CF0(ctx, base);
	// lis r4,11
	ctx.r4.s64 = 720896;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// lwz r3,216(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 216);
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// stw r26,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r26.u32);
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408c0c
	if (cr0.eq) goto loc_82408C0C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82408C0C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// stw r26,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r26.u32);
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r26,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r26.u32);
	// bl 0x8243de68
	sub_8243DE68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8243d698
	sub_8243D698(ctx, base);
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408c50
	if (cr6.eq) goto loc_82408C50;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r26.u32);
loc_82408C50:
	// lwz r3,208(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408c70
	if (cr6.eq) goto loc_82408C70;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
loc_82408C70:
	// lwz r3,212(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 212);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408c90
	if (cr6.eq) goto loc_82408C90;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,212(r31)
	PPC_STORE_U32(r31.u32 + 212, r26.u32);
loc_82408C90:
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x82409218
	sub_82409218(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_82408C9C:
	// addi r1,r31,624
	ctx.r1.s64 = r31.s64 + 624;
	// b 0x8239bd10
	return;
loc_82408CA4:
	// clrlwi. r11,r17,24
	r11.u64 = r17.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408cc4
	if (!cr0.eq) goto loc_82408CC4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32576
	ctx.r6.s64 = r11.s64 + -32576;
	// li r5,3505
	ctx.r5.s64 = 3505;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_82408CC4:
	// lwz r11,140(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408d04
	if (!cr6.eq) goto loc_82408D04;
	// li r11,4096
	r11.s64 = 4096;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,16384
	ctx.r3.s64 = 16384;
	// stw r11,144(r30)
	PPC_STORE_U32(r30.u32 + 144, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,140(r30)
	PPC_STORE_U32(r30.u32 + 140, ctx.r3.u32);
	// bne 0x82408d04
	if (!cr0.eq) goto loc_82408D04;
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x82409218
	sub_82409218(ctx, base);
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82408c9c
	goto loc_82408C9C;
loc_82408D04:
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x8243de68
	sub_8243DE68(ctx, base);
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x8243d698
	sub_8243D698(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82405ec8
	sub_82405EC8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82408bd4
	if (cr0.lt) goto loc_82408BD4;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82408d3c
	if (cr6.eq) goto loc_82408D3C;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// bl 0x82408080
	sub_82408080(ctx, base);
	// b 0x82408d58
	goto loc_82408D58;
loc_82408D3C:
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x82405140
	sub_82405140(ctx, base);
loc_82408D58:
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82408bd4
	if (cr0.lt) goto loc_82408BD4;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82408d78
	if (cr6.eq) goto loc_82408D78;
loc_82408D6C:
	// lis r29,-32768
	r29.s64 = -2147483648;
	// ori r29,r29,16389
	r29.u64 = r29.u64 | 16389;
	// b 0x82408bd4
	goto loc_82408BD4;
loc_82408D78:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f4d80
	sub_823F4D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82408bd4
	if (cr0.lt) goto loc_82408BD4;
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
	// stw r26,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r26.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r4,r31,192
	ctx.r4.s64 = r31.s64 + 192;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// stw r29,224(r31)
	PPC_STORE_U32(r31.u32 + 224, r29.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// b 0x82408e04
	// ERROR 82408E04
	return;
}

__attribute__((alias("__imp__sub_824081F8"))) PPC_WEAK_FUNC(sub_824081F8);
PPC_FUNC_IMPL(__imp__sub_824081F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// addi r31,r1,-624
	r31.s64 = ctx.r1.s64 + -624;
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,644(r31)
	PPC_STORE_U32(r31.u32 + 644, r30.u32);
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r18,r6
	r18.u64 = ctx.r6.u64;
	// stw r18,668(r31)
	PPC_STORE_U32(r31.u32 + 668, r18.u32);
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// mr r16,r8
	r16.u64 = ctx.r8.u64;
	// mr r15,r9
	r15.u64 = ctx.r9.u64;
	// mr r24,r10
	r24.u64 = ctx.r10.u64;
	// lis r5,1
	ctx.r5.s64 = 65536;
	// lis r4,16
	ctx.r4.s64 = 1048576;
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x824091d0
	sub_824091D0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// stw r26,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r26.u32);
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
	// mr r14,r26
	r14.u64 = r26.u64;
	// stw r14,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r14.u32);
	// stw r26,212(r31)
	PPC_STORE_U32(r31.u32 + 212, r26.u32);
	// mr r22,r26
	r22.u64 = r26.u64;
	// mr r21,r26
	r21.u64 = r26.u64;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// stw r3,216(r31)
	PPC_STORE_U32(r31.u32 + 216, ctx.r3.u32);
	// lis r4,8
	ctx.r4.s64 = 524288;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// li r29,-1
	r29.s64 = -1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// lis r4,3
	ctx.r4.s64 = 196608;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// lwz r19,740(r31)
	r19.u64 = PPC_LOAD_U32(r31.u32 + 740);
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// bne cr6,0x824082c4
	if (!cr6.eq) goto loc_824082C4;
	// addi r11,r31,288
	r11.s64 = r31.s64 + 288;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_824082AC:
	// std r9,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r9.u64);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// bdnz 0x824082ac
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824082AC;
	// addi r19,r31,288
	r19.s64 = r31.s64 + 288;
	// stw r19,740(r31)
	PPC_STORE_U32(r31.u32 + 740, r19.u32);
	// b 0x824082c8
	goto loc_824082C8;
loc_824082C4:
	// stw r26,28(r19)
	PPC_STORE_U32(r19.u32 + 28, r26.u32);
loc_824082C8:
	// lwz r27,716(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 716);
	// lis r12,-863
	r12.s64 = -56557568;
	// ori r12,r12,57344
	r12.u64 = r12.u64 | 57344;
	// and. r11,r27,r12
	r11.u64 = r27.u64 & r12.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824082e8
	if (cr0.eq) goto loc_824082E8;
loc_824082DC:
	// lis r29,-30602
	r29.s64 = -2005532672;
	// ori r29,r29,2156
	r29.u64 = r29.u64 | 2156;
	// b 0x82408bd4
	goto loc_82408BD4;
loc_824082E8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x824082f8
	if (cr6.eq) goto loc_824082F8;
	// rlwinm. r11,r27,0,27,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824082dc
	if (!cr0.eq) goto loc_824082DC;
loc_824082F8:
	// lwz r11,724(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 724);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824082dc
	if (cr6.eq) goto loc_824082DC;
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408324
	if (cr0.eq) goto loc_82408324;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82408324:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// addi r23,r30,4
	r23.s64 = r30.s64 + 4;
	// stw r26,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r26.u32);
	// stw r26,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r26.u32);
	// stw r26,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r26.u32);
	// stw r28,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r28.u32);
	// stw r26,80(r30)
	PPC_STORE_U32(r30.u32 + 80, r26.u32);
	// lwz r3,708(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 708);
	// stw r26,84(r30)
	PPC_STORE_U32(r30.u32 + 84, r26.u32);
	// stw r26,88(r30)
	PPC_STORE_U32(r30.u32 + 88, r26.u32);
	// stw r26,92(r30)
	PPC_STORE_U32(r30.u32 + 92, r26.u32);
	// stw r26,96(r30)
	PPC_STORE_U32(r30.u32 + 96, r26.u32);
	// stw r26,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r26.u32);
	// stw r26,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r26.u32);
	// stw r26,60(r30)
	PPC_STORE_U32(r30.u32 + 60, r26.u32);
	// stw r26,64(r30)
	PPC_STORE_U32(r30.u32 + 64, r26.u32);
	// stw r26,68(r30)
	PPC_STORE_U32(r30.u32 + 68, r26.u32);
	// stw r26,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r26.u32);
	// stw r26,112(r30)
	PPC_STORE_U32(r30.u32 + 112, r26.u32);
	// stw r29,72(r30)
	PPC_STORE_U32(r30.u32 + 72, r29.u32);
	// stw r26,116(r30)
	PPC_STORE_U32(r30.u32 + 116, r26.u32);
	// stw r26,120(r30)
	PPC_STORE_U32(r30.u32 + 120, r26.u32);
	// mr r17,r26
	r17.u64 = r26.u64;
	// stw r26,124(r30)
	PPC_STORE_U32(r30.u32 + 124, r26.u32);
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// stw r26,128(r30)
	PPC_STORE_U32(r30.u32 + 128, r26.u32);
	// stw r26,132(r30)
	PPC_STORE_U32(r30.u32 + 132, r26.u32);
	// stw r24,136(r30)
	PPC_STORE_U32(r30.u32 + 136, r24.u32);
	// stw r26,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r26.u32);
	// stw r26,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r26.u32);
	// stw r3,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r3.u32);
	// stw r27,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r27.u32);
	// beq cr6,0x824083f0
	if (cr6.eq) goto loc_824083F0;
	// lis r11,18008
	r11.s64 = 1180172288;
	// ori r11,r11,512
	r11.u64 = r11.u64 | 512;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,508
	ctx.r3.s64 = 508;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824083d8
	if (cr0.eq) goto loc_824083D8;
	// bl 0x82483878
	sub_82483878(ctx, base);
	// b 0x824083dc
	goto loc_824083DC;
loc_824083D8:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_824083DC:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r17,1
	r17.s64 = 1;
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// b 0x82408748
	goto loc_82408748;
loc_824083F0:
	// rlwinm. r11,r27,0,24,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xC0;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824084ac
	if (cr0.eq) goto loc_824084AC;
	// addi r5,r31,232
	ctx.r5.s64 = r31.s64 + 232;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8240842c
	if (!cr0.lt) goto loc_8240842C;
loc_8240840C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32148
	ctx.r6.s64 = r11.s64 + -32148;
	// li r5,3506
	ctx.r5.s64 = 3506;
	// lwz r7,12(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x824082dc
	goto loc_824082DC;
loc_8240842C:
	// lwz r10,236(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 236);
	// rlwinm r11,r10,0,0,15
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	// lis r9,-2
	ctx.r9.s64 = -131072;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8240847c
	if (cr6.eq) goto loc_8240847C;
	// lis r9,-1
	ctx.r9.s64 = -65536;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x824084ac
	if (!cr6.eq) goto loc_824084AC;
	// rlwinm. r11,r27,0,24,24
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824084ac
	if (cr0.eq) goto loc_824084AC;
	// rlwinm r11,r10,0,16,23
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFF00;
	// ori r27,r27,5
	r27.u64 = r27.u64 | 5;
	// cmplwi cr6,r11,768
	cr6.compare<uint32_t>(r11.u32, 768, xer);
	// bne cr6,0x82408470
	if (!cr6.eq) goto loc_82408470;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,5784
	r11.s64 = r11.s64 + 5784;
	// b 0x824084a8
	goto loc_824084A8;
loc_82408470:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,5800
	r11.s64 = r11.s64 + 5800;
	// b 0x824084a8
	goto loc_824084A8;
loc_8240847C:
	// rlwinm. r11,r27,0,25,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824084ac
	if (cr0.eq) goto loc_824084AC;
	// rlwinm r11,r10,0,16,23
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFF00;
	// ori r27,r27,5
	r27.u64 = r27.u64 | 5;
	// cmplwi cr6,r11,768
	cr6.compare<uint32_t>(r11.u32, 768, xer);
	// bne cr6,0x824084a0
	if (!cr6.eq) goto loc_824084A0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,5624
	r11.s64 = r11.s64 + 5624;
	// b 0x824084a8
	goto loc_824084A8;
loc_824084A0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,5640
	r11.s64 = r11.s64 + 5640;
loc_824084A8:
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_824084AC:
	// addi r5,r31,232
	ctx.r5.s64 = r31.s64 + 232;
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240840c
	if (cr0.lt) goto loc_8240840C;
	// lwz r9,236(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 236);
	// lis r11,-2
	r11.s64 = -131072;
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// stw r27,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r27.u32);
	// stw r9,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r9.u32);
	// bne cr6,0x824084f0
	if (!cr6.eq) goto loc_824084F0;
	// lis r11,-2
	r11.s64 = -131072;
	// ori r11,r11,257
	r11.u64 = r11.u64 | 257;
	// li r22,1
	r22.s64 = 1;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
loc_824084F0:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82408514
	if (!cr6.eq) goto loc_82408514;
	// lis r11,-1
	r11.s64 = -65536;
	// ori r11,r11,257
	r11.u64 = r11.u64 | 257;
	// li r21,1
	r21.s64 = 1;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
loc_82408514:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,612
	ctx.r10.u64 = ctx.r10.u64 | 612;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x824086fc
	if (cr6.gt) goto loc_824086FC;
	// beq cr6,0x824086dc
	if (cr6.eq) goto loc_824086DC;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,768
	ctx.r10.u64 = ctx.r10.u64 | 768;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x824085bc
	if (cr6.gt) goto loc_824085BC;
	// beq cr6,0x82408724
	if (cr6.eq) goto loc_82408724;
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408598
	if (cr6.eq) goto loc_82408598;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,257
	ctx.r10.u64 = ctx.r10.u64 | 257;
	// subf. r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82408578
	if (cr0.eq) goto loc_82408578;
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// beq cr6,0x82408578
	if (cr6.eq) goto loc_82408578;
	// cmplwi cr6,r11,257
	cr6.compare<uint32_t>(r11.u32, 257, xer);
	// beq cr6,0x82408578
	if (cr6.eq) goto loc_82408578;
	// cmplwi cr6,r11,510
	cr6.compare<uint32_t>(r11.u32, 510, xer);
	// bne cr6,0x8240871c
	if (!cr6.eq) goto loc_8240871C;
loc_82408578:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,504
	ctx.r3.s64 = 504;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8247fee0
	sub_8247FEE0(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_82408598:
	// ori r11,r27,256
	r11.u64 = r27.u64 | 256;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,508
	ctx.r3.s64 = 508;
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// bl 0x82483878
	sub_82483878(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_824085BC:
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,260
	ctx.r10.u64 = ctx.r10.u64 | 260;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// bgt cr6,0x824086b0
	if (cr6.gt) goto loc_824086B0;
	// ori r10,r10,257
	ctx.r10.u64 = ctx.r10.u64 | 257;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8240868c
	if (!cr6.lt) goto loc_8240868C;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,1021
	ctx.r10.u64 = ctx.r10.u64 | 1021;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x8240871c
	if (cr6.lt) goto loc_8240871C;
	// lis r8,-2
	ctx.r8.s64 = -131072;
	// ori r8,r8,1022
	ctx.r8.u64 = ctx.r8.u64 | 1022;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// ble cr6,0x8240860c
	if (!cr6.gt) goto loc_8240860C;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,1023
	ctx.r10.u64 = ctx.r10.u64 | 1023;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// b 0x82408718
	goto loc_82408718;
loc_8240860C:
	// rlwinm r11,r9,0,0,15
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFF0000;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm. r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82408624
	if (cr0.eq) goto loc_82408624;
	// twi 31,r0,22
loc_82408624:
	// lwz r29,24(r19)
	r29.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x8240863c
	if (cr0.eq) goto loc_8240863C;
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408640
	if (!cr6.eq) goto loc_82408640;
loc_8240863C:
	// mr r29,r18
	r29.u64 = r18.u64;
loc_82408640:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,1820
	ctx.r3.s64 = 1820;
	// bne 0x82408670
	if (!cr0.eq) goto loc_82408670;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x823f30c0
	sub_823F30C0(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_82408670:
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x823f3110
	sub_823F3110(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_8240868C:
	// rlwinm r11,r27,0,30,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,1156
	ctx.r3.s64 = 1156;
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// bl 0x824706e8
	sub_824706E8(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_824086B0:
	// ori r10,r10,512
	ctx.r10.u64 = ctx.r10.u64 | 512;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824086dc
	if (cr6.eq) goto loc_824086DC;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,513
	ctx.r10.u64 = ctx.r10.u64 | 513;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8240871c
	if (!cr6.gt) goto loc_8240871C;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,515
	ctx.r10.u64 = ctx.r10.u64 | 515;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8240871c
	if (cr6.gt) goto loc_8240871C;
loc_824086DC:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,556
	ctx.r3.s64 = 556;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8246c6f0
	sub_8246C6F0(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_824086FC:
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// ori r10,r10,767
	ctx.r10.u64 = ctx.r10.u64 | 767;
	// subf. r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824086dc
	if (cr0.eq) goto loc_824086DC;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x82408724
	if (cr6.eq) goto loc_82408724;
	// cmplwi cr6,r11,256
	cr6.compare<uint32_t>(r11.u32, 256, xer);
loc_82408718:
	// beq cr6,0x82408724
	if (cr6.eq) goto loc_82408724;
loc_8240871C:
	// stw r26,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r26.u32);
	// b 0x8240874c
	goto loc_8240874C;
loc_82408724:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,504
	ctx.r3.s64 = 504;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408744
	if (cr0.eq) goto loc_82408744;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x82439cf0
	sub_82439CF0(ctx, base);
	// b 0x82408748
	goto loc_82408748;
loc_82408744:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82408748:
	// stw r3,8(r30)
	PPC_STORE_U32(r30.u32 + 8, ctx.r3.u32);
loc_8240874C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408764
	if (!cr6.eq) goto loc_82408764;
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x82408bd4
	goto loc_82408BD4;
loc_82408764:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x824087b4
	if (!cr6.eq) goto loc_824087B4;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r3,r31,352
	ctx.r3.s64 = r31.s64 + 352;
	// lwz r29,0(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// oris r28,r11,32768
	r28.u64 = r11.u64 | 2147483648;
	// bl 0x824590f0
	sub_824590F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// bl 0x8246c570
	sub_8246C570(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cntlzw r11,r29
	r11.u64 = r29.u32 == 0 ? 32 : __builtin_clz(r29.u32);
	// addi r3,r31,352
	ctx.r3.s64 = r31.s64 + 352;
	// cntlzw r28,r11
	r28.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// rlwinm. r11,r28,27,31,31
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408bd4
	if (!cr0.eq) goto loc_82408BD4;
	// b 0x824087b8
	goto loc_824087B8;
loc_824087B4:
	// stw r25,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r25.u32);
loc_824087B8:
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x824087d8
	if (cr6.eq) goto loc_824087D8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,29712
	ctx.r6.s64 = r11.s64 + 29712;
	// li r5,3505
	ctx.r5.s64 = 3505;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_824087D8:
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x824087f8
	if (cr6.eq) goto loc_824087F8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,29668
	ctx.r6.s64 = r11.s64 + 29668;
	// li r5,3505
	ctx.r5.s64 = 3505;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_824087F8:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x8240885c
	if (!cr6.eq) goto loc_8240885C;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82408820
	if (cr6.eq) goto loc_82408820;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x823f4ad8
	sub_823F4AD8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r25,r26
	r25.u64 = r26.u64;
	// b 0x82408864
	goto loc_82408864;
loc_82408820:
	// addi r5,r31,668
	ctx.r5.s64 = r31.s64 + 668;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// bl 0x823f4c28
	sub_823F4C28(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x82408850
	if (!cr0.eq) goto loc_82408850;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32180
	ctx.r6.s64 = r11.s64 + -32180;
	// li r5,3501
	ctx.r5.s64 = 3501;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82408d6c
	goto loc_82408D6C;
loc_82408850:
	// li r25,1
	r25.s64 = 1;
	// lwz r18,668(r31)
	r18.u64 = PPC_LOAD_U32(r31.u32 + 668);
	// b 0x82408864
	goto loc_82408864;
loc_8240885C:
	// lwz r28,216(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 216);
	// lwz r25,216(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + 216);
loc_82408864:
	// lwz r4,20(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm. r10,r4,0,6,6
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240887c
	if (!cr0.eq) goto loc_8240887C;
	// rlwinm. r11,r4,0,9,9
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x400000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// beq 0x82408880
	if (cr0.eq) goto loc_82408880;
loc_8240887C:
	// li r11,1
	r11.s64 = 1;
loc_82408880:
	// clrlwi r29,r11,24
	r29.u64 = r11.u32 & 0xFF;
	// lwz r11,16(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240889c
	if (cr0.eq) goto loc_8240889C;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// beq cr6,0x8240889c
	if (cr6.eq) goto loc_8240889C;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_8240889C:
	// lwz r11,36(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824088b4
	if (!cr6.eq) goto loc_824088B4;
	// lwz r11,44(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824088b8
	if (cr6.eq) goto loc_824088B8;
loc_824088B4:
	// mr r29,r26
	r29.u64 = r26.u64;
loc_824088B8:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// andi. r11,r11,18
	r11.u64 = r11.u64 & 18;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824088cc
	if (cr0.eq) goto loc_824088CC;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_824088CC:
	// rlwinm. r11,r4,0,11,11
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408a0c
	if (!cr0.eq) goto loc_82408A0C;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x82408a0c
	if (!cr6.eq) goto loc_82408A0C;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x82408a3c
	if (!cr6.eq) goto loc_82408A3C;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x824088f8
	if (cr6.eq) goto loc_824088F8;
	// li r14,1
	r14.s64 = 1;
	// stw r14,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r14.u32);
	// b 0x82408a0c
	goto loc_82408A0C;
loc_824088F8:
	// lis r11,-32193
	r11.s64 = -2109800448;
	// lwz r6,0(r23)
	ctx.r6.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// addi r5,r31,208
	ctx.r5.s64 = r31.s64 + 208;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r11,r11,21880
	r11.s64 = r11.s64 + 21880;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r19.u32);
	// addi r10,r31,196
	ctx.r10.s64 = r31.s64 + 196;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r9,r15
	ctx.r9.u64 = r15.u64;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// bl 0x82497ab0
	sub_82497AB0(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// stw r14,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r14.u32);
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408978
	if (cr6.eq) goto loc_82408978;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408978
	if (cr0.eq) goto loc_82408978;
	// lwz r11,28(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82408978
	if (!cr6.eq) goto loc_82408978;
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// bl 0x823f5150
	sub_823F5150(ctx, base);
	// stw r3,28(r19)
	PPC_STORE_U32(r19.u32 + 28, ctx.r3.u32);
loc_82408978:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bge cr6,0x82408a0c
	if (!cr6.lt) goto loc_82408A0C;
	// lwz r11,28(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82408a0c
	if (!cr6.eq) goto loc_82408A0C;
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82408a0c
	if (cr0.eq) goto loc_82408A0C;
	// lis r11,-32768
	r11.s64 = -2147483648;
	// ori r11,r11,16388
	r11.u64 = r11.u64 | 16388;
	// cmpw cr6,r14,r11
	cr6.compare<int32_t>(r14.s32, r11.s32, xer);
	// bne cr6,0x824089ac
	if (!cr6.eq) goto loc_824089AC;
	// mr r29,r26
	r29.u64 = r26.u64;
	// b 0x82408a0c
	goto loc_82408A0C;
loc_824089AC:
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824089cc
	if (cr6.eq) goto loc_824089CC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r26.u32);
loc_824089CC:
	// lwz r3,208(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824089ec
	if (cr6.eq) goto loc_824089EC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
loc_824089EC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r4,r31,212
	ctx.r4.s64 = r31.s64 + 212;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// stw r26,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r26.u32);
	// bl 0x823eaf78
	sub_823EAF78(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823eb9d8
	sub_823EB9D8(ctx, base);
loc_82408A0C:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x82408a3c
	if (!cr6.eq) goto loc_82408A3C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82408a3c
	if (!cr6.eq) goto loc_82408A3C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32208
	ctx.r6.s64 = r11.s64 + -32208;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// li r5,3501
	ctx.r5.s64 = 3501;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5580
	sub_823F5580(ctx, base);
	// b 0x82408d6c
	goto loc_82408D6C;
loc_82408A3C:
	// lwz r9,28(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 28);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82408a4c
	if (cr0.eq) goto loc_82408A4C;
	// mr r29,r26
	r29.u64 = r26.u64;
loc_82408A4C:
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408a64
	if (!cr6.eq) goto loc_82408A64;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm. r11,r10,0,6,6
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408a74
	if (!cr0.eq) goto loc_82408A74;
loc_82408A64:
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm. r11,r10,0,9,9
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// beq 0x82408a78
	if (cr0.eq) goto loc_82408A78;
loc_82408A74:
	// li r11,1
	r11.s64 = 1;
loc_82408A78:
	// clrlwi. r27,r11,24
	r27.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// stb r27,200(r31)
	PPC_STORE_U8(r31.u32 + 200, r27.u8);
	// beq 0x82408b38
	if (cr0.eq) goto loc_82408B38;
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408b38
	if (!cr0.eq) goto loc_82408B38;
	// rlwinm. r11,r10,0,7,7
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r27,r26
	r27.u64 = r26.u64;
	// stb r27,200(r31)
	PPC_STORE_U8(r31.u32 + 200, r27.u8);
	// beq 0x82408aa8
	if (cr0.eq) goto loc_82408AA8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32256
	ctx.r6.s64 = r11.s64 + -32256;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408AA8:
	// lwz r11,16(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82408ac8
	if (cr0.eq) goto loc_82408AC8;
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// beq cr6,0x82408ac8
	if (cr6.eq) goto loc_82408AC8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32308
	ctx.r6.s64 = r11.s64 + -32308;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408AC8:
	// lwz r11,36(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408b20
	if (!cr6.eq) goto loc_82408B20;
	// lwz r11,44(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408b20
	if (!cr6.eq) goto loc_82408B20;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82408af4
	if (cr6.eq) goto loc_82408AF4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32364
	ctx.r6.s64 = r11.s64 + -32364;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408AF4:
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82408b0c
	if (cr0.eq) goto loc_82408B0C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32408
	ctx.r6.s64 = r11.s64 + -32408;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408B0C:
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82408b38
	if (cr0.eq) goto loc_82408B38;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32452
	ctx.r6.s64 = r11.s64 + -32452;
	// b 0x82408b28
	goto loc_82408B28;
loc_82408B20:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32504
	ctx.r6.s64 = r11.s64 + -32504;
loc_82408B28:
	// li r5,3042
	ctx.r5.s64 = 3042;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_82408B38:
	// clrlwi. r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408ca4
	if (!cr0.eq) goto loc_82408CA4;
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408b54
	if (!cr6.eq) goto loc_82408B54;
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bge cr6,0x82408ca4
	if (!cr6.lt) goto loc_82408CA4;
loc_82408B54:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// blt cr6,0x82408f18
	if (cr6.lt) goto loc_82408F18;
	// lwz r28,732(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 732);
	// lwz r27,724(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 724);
loc_82408B64:
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82408bd0
	if (cr6.eq) goto loc_82408BD0;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408b90
	if (cr0.eq) goto loc_82408B90;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r26.u32);
loc_82408B90:
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// stw r26,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r26.u32);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// beq cr6,0x82408bd0
	if (cr6.eq) goto loc_82408BD0;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408bc4
	if (cr0.eq) goto loc_82408BC4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r26.u32);
loc_82408BC4:
	// lwz r11,208(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_82408BD0:
	// mr r29,r26
	r29.u64 = r26.u64;
loc_82408BD4:
	// bl 0x823b4cf0
	sub_823B4CF0(ctx, base);
	// lis r4,11
	ctx.r4.s64 = 720896;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// lwz r3,216(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 216);
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// stw r26,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r26.u32);
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408c0c
	if (cr0.eq) goto loc_82408C0C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82408C0C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// stw r26,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r26.u32);
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r26,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r26.u32);
	// bl 0x8243de68
	sub_8243DE68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8243d698
	sub_8243D698(ctx, base);
	// lwz r3,196(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408c50
	if (cr6.eq) goto loc_82408C50;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r26.u32);
loc_82408C50:
	// lwz r3,208(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408c70
	if (cr6.eq) goto loc_82408C70;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
loc_82408C70:
	// lwz r3,212(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 212);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408c90
	if (cr6.eq) goto loc_82408C90;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,212(r31)
	PPC_STORE_U32(r31.u32 + 212, r26.u32);
loc_82408C90:
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x82409218
	sub_82409218(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_82408C9C:
	// addi r1,r31,624
	ctx.r1.s64 = r31.s64 + 624;
	// b 0x8239bd10
	return;
loc_82408CA4:
	// clrlwi. r11,r17,24
	r11.u64 = r17.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408cc4
	if (!cr0.eq) goto loc_82408CC4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32576
	ctx.r6.s64 = r11.s64 + -32576;
	// li r5,3505
	ctx.r5.s64 = 3505;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
loc_82408CC4:
	// lwz r11,140(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82408d04
	if (!cr6.eq) goto loc_82408D04;
	// li r11,4096
	r11.s64 = 4096;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,16384
	ctx.r3.s64 = 16384;
	// stw r11,144(r30)
	PPC_STORE_U32(r30.u32 + 144, r11.u32);
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,140(r30)
	PPC_STORE_U32(r30.u32 + 140, ctx.r3.u32);
	// bne 0x82408d04
	if (!cr0.eq) goto loc_82408D04;
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x82409218
	sub_82409218(ctx, base);
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82408c9c
	goto loc_82408C9C;
loc_82408D04:
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x8243de68
	sub_8243DE68(ctx, base);
	// addi r3,r31,256
	ctx.r3.s64 = r31.s64 + 256;
	// bl 0x8243d698
	sub_8243D698(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82405ec8
	sub_82405EC8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82408bd4
	if (cr0.lt) goto loc_82408BD4;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82408d3c
	if (cr6.eq) goto loc_82408D3C;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// bl 0x82408080
	sub_82408080(ctx, base);
	// b 0x82408d58
	goto loc_82408D58;
loc_82408D3C:
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// bl 0x82405140
	sub_82405140(ctx, base);
loc_82408D58:
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82408bd4
	if (cr0.lt) goto loc_82408BD4;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82408d78
	if (cr6.eq) goto loc_82408D78;
loc_82408D6C:
	// lis r29,-32768
	r29.s64 = -2147483648;
	// ori r29,r29,16389
	r29.u64 = r29.u64 | 16389;
	// b 0x82408bd4
	goto loc_82408BD4;
loc_82408D78:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f4d80
	sub_823F4D80(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82408bd4
	if (cr0.lt) goto loc_82408BD4;
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
	// stw r26,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r26.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r4,r31,192
	ctx.r4.s64 = r31.s64 + 192;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// stw r29,224(r31)
	PPC_STORE_U32(r31.u32 + 224, r29.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// b 0x82408e04
	goto loc_82408E04;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32672
	ctx.r6.s64 = r11.s64 + -32672;
	// li r5,3042
	ctx.r5.s64 = 3042;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r30,644(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 644);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
	// lis r29,-32768
	r29.s64 = -2147483648;
	// ori r29,r29,16385
	r29.u64 = r29.u64 | 16385;
	// stw r29,224(r31)
	PPC_STORE_U32(r31.u32 + 224, r29.u32);
	// li r26,0
	r26.s64 = 0;
	// lwz r19,740(r31)
	r19.u64 = PPC_LOAD_U32(r31.u32 + 740);
	// lwz r14,220(r31)
	r14.u64 = PPC_LOAD_U32(r31.u32 + 220);
	// lbz r27,200(r31)
	r27.u64 = PPC_LOAD_U8(r31.u32 + 200);
loc_82408E04:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// blt cr6,0x82408bd4
	if (cr6.lt) goto loc_82408BD4;
	// lwz r28,732(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 732);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82408e64
	if (cr6.eq) goto loc_82408E64;
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r29,r31,204
	r29.s64 = r31.s64 + 204;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x823df1a8
	sub_823DF1A8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bge 0x82408e64
	if (!cr0.lt) goto loc_82408E64;
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408bd4
	if (cr6.eq) goto loc_82408BD4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
	// b 0x82408bd4
	goto loc_82408BD4;
loc_82408E64:
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm. r9,r11,0,11,11
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r10,0,0,15
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	// bne 0x82408fe4
	if (!cr0.eq) goto loc_82408FE4;
	// lis r10,18008
	ctx.r10.s64 = 1180172288;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408fe4
	if (cr6.eq) goto loc_82408FE4;
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408fe4
	if (cr6.eq) goto loc_82408FE4;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,1022
	ctx.r10.u64 = ctx.r10.u64 | 1022;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408fe4
	if (cr6.eq) goto loc_82408FE4;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,1021
	ctx.r10.u64 = ctx.r10.u64 | 1021;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408fe4
	if (cr6.eq) goto loc_82408FE4;
	// clrlwi. r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408f20
	if (!cr0.eq) goto loc_82408F20;
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408ef0
	if (cr6.eq) goto loc_82408EF0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
loc_82408EF0:
	// lwz r3,204(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408f10
	if (cr6.eq) goto loc_82408F10;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r26.u32);
loc_82408F10:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bge cr6,0x82408d6c
	if (!cr6.lt) goto loc_82408D6C;
loc_82408F18:
	// mr r29,r14
	r29.u64 = r14.u64;
	// b 0x82408bd4
	goto loc_82408BD4;
loc_82408F20:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x821efd88
	sub_821EFD88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408f58
	if (cr0.eq) goto loc_82408F58;
loc_82408F34:
	// lwz r3,204(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408bd4
	if (cr6.eq) goto loc_82408BD4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r26.u32);
	// b 0x82408bd4
	goto loc_82408BD4;
loc_82408F58:
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r11,-32193
	r11.s64 = -2109800448;
	// addi r29,r11,21864
	r29.s64 = r11.s64 + 21864;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,192(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// rlwinm r3,r11,0,7,5
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFDFFFFFF;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r27,724(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 724);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
	// bl 0x823eddb8
	sub_823EDDB8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// bge 0x82409010
	if (!cr0.lt) goto loc_82409010;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408f34
	if (cr6.eq) goto loc_82408F34;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
	// b 0x82408f34
	goto loc_82408F34;
loc_82408FE4:
	// lwz r27,724(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 724);
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409008
	if (cr0.eq) goto loc_82409008;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r26.u32);
loc_82409008:
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
loc_82409010:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82409020
	if (cr6.eq) goto loc_82409020;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_82409020:
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824090fc
	if (cr6.eq) goto loc_824090FC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x821efd88
	sub_821EFD88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x82408bd4
	if (!cr0.eq) goto loc_82408BD4;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,196(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// beq cr6,0x82409074
	if (cr6.eq) goto loc_82409074;
	// bl 0x8234e1e0
	sub_8234E1E0(ctx, base);
	// b 0x82409078
	goto loc_82409078;
loc_82409074:
	// bl 0x8234e1e0
	sub_8234E1E0(ctx, base);
loc_82409078:
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824090a0
	if (cr6.eq) goto loc_824090A0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// stw r3,192(r31)
	PPC_STORE_U32(r31.u32 + 192, ctx.r3.u32);
loc_824090A0:
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824090c8
	if (cr6.eq) goto loc_824090C8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r26.u32);
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
loc_824090C8:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x824090d4
	if (cr6.eq) goto loc_824090D4;
	// stw r26,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r26.u32);
loc_824090D4:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x824090f8
	if (!cr6.eq) goto loc_824090F8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32752
	ctx.r6.s64 = r11.s64 + -32752;
	// li r5,3042
	ctx.r5.s64 = 3042;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
	// b 0x82408d6c
	goto loc_82408D6C;
loc_824090F8:
	// lwz r27,724(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 724);
loc_824090FC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408b64
	if (cr6.eq) goto loc_82408B64;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x82408b64
	if (cr6.eq) goto loc_82408B64;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
	// b 0x82408b64
	goto loc_82408B64;
}

__attribute__((alias("__imp__sub_82408DC8"))) PPC_WEAK_FUNC(sub_82408DC8);
PPC_FUNC_IMPL(__imp__sub_82408DC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r19{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32672
	ctx.r6.s64 = r11.s64 + -32672;
	// li r5,3042
	ctx.r5.s64 = 3042;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r30,644(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 644);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
	// lis r29,-32768
	r29.s64 = -2147483648;
	// ori r29,r29,16385
	r29.u64 = r29.u64 | 16385;
	// stw r29,224(r31)
	PPC_STORE_U32(r31.u32 + 224, r29.u32);
	// li r26,0
	r26.s64 = 0;
	// lwz r19,740(r31)
	r19.u64 = PPC_LOAD_U32(r31.u32 + 740);
	// lwz r14,220(r31)
	r14.u64 = PPC_LOAD_U32(r31.u32 + 220);
	// lbz r27,200(r31)
	r27.u64 = PPC_LOAD_U8(r31.u32 + 200);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// blt cr6,0x82408bd4
	if (cr6.lt) {
		// ERROR 82408BD4
		return;
	}
	// lwz r28,732(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 732);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82408e64
	if (cr6.eq) goto loc_82408E64;
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r29,r31,204
	r29.s64 = r31.s64 + 204;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x823df1a8
	sub_823DF1A8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bge 0x82408e64
	if (!cr0.lt) goto loc_82408E64;
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408bd4
	if (cr6.eq) {
		// ERROR 82408BD4
		return;
	}
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
	// b 0x82408bd4
	// ERROR 82408BD4
	return;
loc_82408E64:
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm. r9,r11,0,11,11
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r10,0,0,15
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	// bne 0x82408fe4
	if (!cr0.eq) goto loc_82408FE4;
	// lis r10,18008
	ctx.r10.s64 = 1180172288;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408fe4
	if (cr6.eq) goto loc_82408FE4;
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408fe4
	if (cr6.eq) goto loc_82408FE4;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,1022
	ctx.r10.u64 = ctx.r10.u64 | 1022;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408fe4
	if (cr6.eq) goto loc_82408FE4;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// ori r10,r10,1021
	ctx.r10.u64 = ctx.r10.u64 | 1021;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82408fe4
	if (cr6.eq) goto loc_82408FE4;
	// clrlwi. r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82408f20
	if (!cr0.eq) goto loc_82408F20;
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408ef0
	if (cr6.eq) goto loc_82408EF0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
loc_82408EF0:
	// lwz r3,204(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408f10
	if (cr6.eq) goto loc_82408F10;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r26.u32);
loc_82408F10:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bge cr6,0x82408d6c
	if (!cr6.lt) {
		// ERROR 82408D6C
		return;
	}
	// mr r29,r14
	r29.u64 = r14.u64;
	// b 0x82408bd4
	// ERROR 82408BD4
	return;
loc_82408F20:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x821efd88
	sub_821EFD88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82408f58
	if (cr0.eq) goto loc_82408F58;
loc_82408F34:
	// lwz r3,204(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408bd4
	if (cr6.eq) {
		// ERROR 82408BD4
		return;
	}
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r26.u32);
	// b 0x82408bd4
	// ERROR 82408BD4
	return;
loc_82408F58:
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r11,-32193
	r11.s64 = -2109800448;
	// addi r29,r11,21864
	r29.s64 = r11.s64 + 21864;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,192(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// rlwinm r3,r11,0,7,5
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFDFFFFFF;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwz r27,724(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 724);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
	// bl 0x823eddb8
	sub_823EDDB8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// bge 0x82409010
	if (!cr0.lt) goto loc_82409010;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408f34
	if (cr6.eq) goto loc_82408F34;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
	// b 0x82408f34
	goto loc_82408F34;
loc_82408FE4:
	// lwz r27,724(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 724);
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409008
	if (cr0.eq) goto loc_82409008;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r26.u32);
loc_82409008:
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
loc_82409010:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82409020
	if (cr6.eq) goto loc_82409020;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_82409020:
	// lwz r11,196(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824090fc
	if (cr6.eq) goto loc_824090FC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x821efd88
	sub_821EFD88(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x82408bd4
	if (!cr0.eq) {
		// ERROR 82408BD4
		return;
	}
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,196(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 196);
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// beq cr6,0x82409074
	if (cr6.eq) goto loc_82409074;
	// bl 0x8234e1e0
	sub_8234E1E0(ctx, base);
	// b 0x82409078
	goto loc_82409078;
loc_82409074:
	// bl 0x8234e1e0
	sub_8234E1E0(ctx, base);
loc_82409078:
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824090a0
	if (cr6.eq) goto loc_824090A0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// stw r3,192(r31)
	PPC_STORE_U32(r31.u32 + 192, ctx.r3.u32);
loc_824090A0:
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824090c8
	if (cr6.eq) goto loc_824090C8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r26.u32);
	// lwz r3,192(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 192);
loc_824090C8:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x824090d4
	if (cr6.eq) goto loc_824090D4;
	// stw r26,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r26.u32);
loc_824090D4:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x824090f8
	if (!cr6.eq) goto loc_824090F8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r6,r11,-32752
	ctx.r6.s64 = r11.s64 + -32752;
	// li r5,3042
	ctx.r5.s64 = 3042;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5610
	sub_823F5610(ctx, base);
	// b 0x82408d6c
	// ERROR 82408D6C
	return;
loc_824090F8:
	// lwz r27,724(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 724);
loc_824090FC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82408b64
	if (cr6.eq) {
		// ERROR 82408B64
		return;
	}
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x82408b64
	if (cr6.eq) {
		// ERROR 82408B64
		return;
	}
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r26,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r26.u32);
	// b 0x82408b64
	// ERROR 82408B64
	return;
}

__attribute__((alias("__imp__sub_82409128"))) PPC_WEAK_FUNC(sub_82409128);
PPC_FUNC_IMPL(__imp__sub_82409128) {
	PPC_FUNC_PROLOGUE();
	// li r3,1
	ctx.r3.s64 = 1;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409134"))) PPC_WEAK_FUNC(sub_82409134);
PPC_FUNC_IMPL(__imp__sub_82409134) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409138"))) PPC_WEAK_FUNC(sub_82409138);
PPC_FUNC_IMPL(__imp__sub_82409138) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// mr r30,r9
	r30.u64 = ctx.r9.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82409168
	if (cr6.eq) goto loc_82409168;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_82409168:
	// lwz r8,228(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82409178
	if (cr6.eq) goto loc_82409178;
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
loc_82409178:
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x8240918c
	if (!cr6.eq) goto loc_8240918C;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x824091b8
	goto loc_824091B8;
loc_8240918C:
	// lwz r9,236(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// stw r9,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r9.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// bl 0x824081f8
	sub_824081F8(ctx, base);
loc_824091B8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824091D0"))) PPC_WEAK_FUNC(sub_824091D0);
PPC_FUNC_IMPL(__imp__sub_824091D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// addi r10,r5,4095
	ctx.r10.s64 = ctx.r5.s64 + 4095;
	// li r11,0
	r11.s64 = 0;
	// rlwinm r10,r10,0,0,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// bne cr6,0x824091fc
	if (!cr6.eq) goto loc_824091FC;
	// lis r4,16
	ctx.r4.s64 = 1048576;
loc_824091FC:
	// add r11,r10,r4
	r11.u64 = ctx.r10.u64 + ctx.r4.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// andc r11,r11,r10
	r11.u64 = r11.u64 & ~ctx.r10.u64;
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409214"))) PPC_WEAK_FUNC(sub_82409214);
PPC_FUNC_IMPL(__imp__sub_82409214) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409218"))) PPC_WEAK_FUNC(sub_82409218);
PPC_FUNC_IMPL(__imp__sub_82409218) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82409244
	goto loc_82409244;
loc_82409230:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
loc_82409244:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82409230
	if (!cr6.eq) goto loc_82409230;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409264"))) PPC_WEAK_FUNC(sub_82409264);
PPC_FUNC_IMPL(__imp__sub_82409264) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409268"))) PPC_WEAK_FUNC(sub_82409268);
PPC_FUNC_IMPL(__imp__sub_82409268) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r5,-1
	r11.s64 = ctx.r5.s64 + -1;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// add r10,r5,r10
	ctx.r10.u64 = ctx.r5.u64 + ctx.r10.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// and r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 & r11.u64;
	// add r30,r10,r28
	r30.u64 = ctx.r10.u64 + r28.u64;
	// cmplw cr6,r30,r9
	cr6.compare<uint32_t>(r30.u32, ctx.r9.u32, xer);
	// ble cr6,0x824092f0
	if (!cr6.gt) goto loc_824092F0;
	// addi r10,r5,3
	ctx.r10.s64 = ctx.r5.s64 + 3;
	// lwz r29,20(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// and r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	// add r30,r11,r28
	r30.u64 = r11.u64 + r28.u64;
	// b 0x824092bc
	goto loc_824092BC;
loc_824092B8:
	// rlwinm r29,r29,1,0,30
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
loc_824092BC:
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// bgt cr6,0x824092b8
	if (cr6.gt) goto loc_824092B8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409324
	if (cr0.eq) goto loc_82409324;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r29,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r29.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// b 0x82409300
	goto loc_82409300;
loc_824092F0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// ble cr6,0x82409314
	if (!cr6.gt) goto loc_82409314;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
loc_82409300:
	// add r10,r11,r30
	ctx.r10.u64 = r11.u64 + r30.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r11,r10,r11
	r11.u64 = ctx.r10.u64 & ~r11.u64;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_82409314:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// subf r11,r28,r11
	r11.s64 = r11.s64 - r28.s64;
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
loc_82409324:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8240932C"))) PPC_WEAK_FUNC(sub_8240932C);
PPC_FUNC_IMPL(__imp__sub_8240932C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409330"))) PPC_WEAK_FUNC(sub_82409330);
PPC_FUNC_IMPL(__imp__sub_82409330) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409368"))) PPC_WEAK_FUNC(sub_82409368);
PPC_FUNC_IMPL(__imp__sub_82409368) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824093B0"))) PPC_WEAK_FUNC(sub_824093B0);
PPC_FUNC_IMPL(__imp__sub_824093B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824093EC"))) PPC_WEAK_FUNC(sub_824093EC);
PPC_FUNC_IMPL(__imp__sub_824093EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824093F0"))) PPC_WEAK_FUNC(sub_824093F0);
PPC_FUNC_IMPL(__imp__sub_824093F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-19872
	ctx.r10.s64 = r11.s64 + -19872;
	// li r11,0
	r11.s64 = 0;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409410"))) PPC_WEAK_FUNC(sub_82409410);
PPC_FUNC_IMPL(__imp__sub_82409410) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,-19872
	r11.s64 = r11.s64 + -19872;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409430"))) PPC_WEAK_FUNC(sub_82409430);
PPC_FUNC_IMPL(__imp__sub_82409430) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x82409440
	if (!cr6.eq) goto loc_82409440;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82409440:
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409458"))) PPC_WEAK_FUNC(sub_82409458);
PPC_FUNC_IMPL(__imp__sub_82409458) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824094ac
	if (cr0.eq) goto loc_824094AC;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r10,r10,-19872
	ctx.r10.s64 = ctx.r10.s64 + -19872;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// b 0x824094b0
	goto loc_824094B0;
loc_824094AC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824094B0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824094C4"))) PPC_WEAK_FUNC(sub_824094C4);
PPC_FUNC_IMPL(__imp__sub_824094C4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824094C8"))) PPC_WEAK_FUNC(sub_824094C8);
PPC_FUNC_IMPL(__imp__sub_824094C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824094e0
	if (cr6.eq) goto loc_824094E0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	return;
loc_824094E0:
	// addi r11,r4,0
	r11.s64 = ctx.r4.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824094F0"))) PPC_WEAK_FUNC(sub_824094F0);
PPC_FUNC_IMPL(__imp__sub_824094F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x824094fc
	if (!cr6.eq) goto loc_824094FC;
	// blr 
	return;
loc_824094FC:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_8240950C"))) PPC_WEAK_FUNC(sub_8240950C);
PPC_FUNC_IMPL(__imp__sub_8240950C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409510"))) PPC_WEAK_FUNC(sub_82409510);
PPC_FUNC_IMPL(__imp__sub_82409510) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, r11.u32);
	// bne cr6,0x82409528
	if (!cr6.eq) goto loc_82409528;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// blr 
	return;
loc_82409528:
	// addi r11,r1,20
	r11.s64 = ctx.r1.s64 + 20;
loc_8240952C:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8240952c
	if (!cr6.eq) goto loc_8240952C;
	// stw r4,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r4.u32);
	// lwz r3,20(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240954C"))) PPC_WEAK_FUNC(sub_8240954C);
PPC_FUNC_IMPL(__imp__sub_8240954C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409550"))) PPC_WEAK_FUNC(sub_82409550);
PPC_FUNC_IMPL(__imp__sub_82409550) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r10,r11,-19860
	ctx.r10.s64 = r11.s64 + -19860;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409578"))) PPC_WEAK_FUNC(sub_82409578);
PPC_FUNC_IMPL(__imp__sub_82409578) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r4.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r5,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r5.u32);
	// addi r11,r11,-19860
	r11.s64 = r11.s64 + -19860;
	// stw r6,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r6.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240959C"))) PPC_WEAK_FUNC(sub_8240959C);
PPC_FUNC_IMPL(__imp__sub_8240959C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824095A0"))) PPC_WEAK_FUNC(sub_824095A0);
PPC_FUNC_IMPL(__imp__sub_824095A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x824095cc
	if (cr6.eq) goto loc_824095CC;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x824095d4
	if (cr6.eq) goto loc_824095D4;
loc_824095CC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82409670
	goto loc_82409670;
loc_824095D4:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
loc_824095DC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82409648
	if (!cr6.eq) goto loc_82409648;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824095cc
	if (cr6.eq) goto loc_824095CC;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x824095cc
	if (!cr6.eq) goto loc_824095CC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409620
	if (cr0.eq) goto loc_82409620;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240962c
	goto loc_8240962C;
loc_82409620:
	// addi r11,r4,0
	r11.s64 = ctx.r4.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240962C:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x824095cc
	if (cr6.eq) goto loc_824095CC;
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x824095dc
	if (!cr0.eq) goto loc_824095DC;
	// b 0x8240966c
	goto loc_8240966C;
loc_82409648:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x82409670
	if (cr0.eq) goto loc_82409670;
loc_8240966C:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82409670:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409688"))) PPC_WEAK_FUNC(sub_82409688);
PPC_FUNC_IMPL(__imp__sub_82409688) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r29,0
	r29.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r1,80
	r30.s64 = ctx.r1.s64 + 80;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// beq cr6,0x82409784
	if (cr6.eq) goto loc_82409784;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r28,r11,-19860
	r28.s64 = r11.s64 + -19860;
loc_824096B4:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8240976c
	if (!cr6.eq) goto loc_8240976C;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// li r4,20
	ctx.r4.s64 = 20;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824096fc
	if (cr0.eq) goto loc_824096FC;
	// li r11,1
	r11.s64 = 1;
	// stw r29,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r29.u32);
	// stw r29,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r29.u32);
	// stw r28,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r28.u32);
	// stw r29,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r29.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x82409700
	goto loc_82409700;
loc_824096FC:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_82409700:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// beq cr6,0x82409784
	if (cr6.eq) goto loc_82409784;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240974c
	if (cr6.eq) goto loc_8240974C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82409764
	if (cr6.eq) goto loc_82409764;
loc_8240974C:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// addi r30,r11,12
	r30.s64 = r11.s64 + 12;
	// bne 0x824096b4
	if (!cr0.eq) goto loc_824096B4;
	// b 0x82409784
	goto loc_82409784;
loc_82409764:
	// stw r29,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r29.u32);
	// b 0x82409784
	goto loc_82409784;
loc_8240976C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
loc_82409784:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_82409790"))) PPC_WEAK_FUNC(sub_82409790);
PPC_FUNC_IMPL(__imp__sub_82409790) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r5,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r5.u32);
	// addi r11,r11,-19848
	r11.s64 = r11.s64 + -19848;
	// stw r6,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r6.u32);
	// stw r7,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r7.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824097B8"))) PPC_WEAK_FUNC(sub_824097B8);
PPC_FUNC_IMPL(__imp__sub_824097B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x824097e4
	if (cr6.eq) goto loc_824097E4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x824097ec
	if (cr6.eq) goto loc_824097EC;
loc_824097E4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82409884
	goto loc_82409884;
loc_824097EC:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824097e4
	if (!cr6.eq) goto loc_824097E4;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824097e4
	if (!cr6.eq) goto loc_824097E4;
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409834
	if (cr0.eq) goto loc_82409834;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82409840
	goto loc_82409840;
loc_82409834:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82409840:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x824097e4
	if (cr6.eq) goto loc_824097E4;
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240986c
	if (cr0.eq) goto loc_8240986C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82409878
	goto loc_82409878;
loc_8240986C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82409878:
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
loc_82409884:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240988C"))) PPC_WEAK_FUNC(sub_8240988C);
PPC_FUNC_IMPL(__imp__sub_8240988C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409890"))) PPC_WEAK_FUNC(sub_82409890);
PPC_FUNC_IMPL(__imp__sub_82409890) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x824098a8
	if (cr6.eq) goto loc_824098A8;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_824098A8:
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bgt cr6,0x8240999c
	if (cr6.gt) {
		// ERROR 8240999C
		return;
	}
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,-19832
	r12.s64 = r12.s64 + -19832;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// lis r12,-32191
	r12.s64 = -2109669376;
	// addi r12,r12,-26408
	r12.s64 = r12.s64 + -26408;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		// ERROR: 0x824098D8
		return;
	case 1:
		// ERROR: 0x824098EC
		return;
	case 2:
		// ERROR: 0x824098D8
		return;
	case 3:
		// ERROR: 0x824098D8
		return;
	case 4:
		// ERROR: 0x824098D8
		return;
	case 5:
		// ERROR: 0x82409924
		return;
	case 6:
		// ERROR: 0x82409924
		return;
	case 7:
		// ERROR: 0x82409924
		return;
	case 8:
		// ERROR: 0x82409924
		return;
	case 9:
		// ERROR: 0x82409934
		return;
	case 10:
		// ERROR: 0x82409964
		return;
	default:
		__builtin_unreachable();
	}
}

__attribute__((alias("__imp__sub_824098D8"))) PPC_WEAK_FUNC(sub_824098D8);
PPC_FUNC_IMPL(__imp__sub_824098D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8240999c
	if (cr6.eq) {
		// ERROR 8240999C
		return;
	}
	// b 0x824098a0
	// ERROR 824098A0
	return;
}

__attribute__((alias("__imp__sub_824098EC"))) PPC_WEAK_FUNC(sub_824098EC);
PPC_FUNC_IMPL(__imp__sub_824098EC) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// addi r10,r4,8
	ctx.r10.s64 = ctx.r4.s64 + 8;
	// addi r11,r3,8
	r11.s64 = ctx.r3.s64 + 8;
loc_824098F4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82409918
	if (cr0.eq) goto loc_82409918;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824098f4
	if (cr6.eq) goto loc_824098F4;
loc_82409918:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8240999c
	if (cr0.eq) {
		// ERROR 8240999C
		return;
	}
	// b 0x824098a0
	// ERROR 824098A0
	return;
}

__attribute__((alias("__imp__sub_82409924"))) PPC_WEAK_FUNC(sub_82409924);
PPC_FUNC_IMPL(__imp__sub_82409924) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister f0{};
	// lfd f0,8(r3)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// lfd f13,8(r4)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r4.u32 + 8);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// b 0x824098e4
	// ERROR 824098E4
	return;
}

__attribute__((alias("__imp__sub_82409934"))) PPC_WEAK_FUNC(sub_82409934);
PPC_FUNC_IMPL(__imp__sub_82409934) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
loc_8240993C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82409918
	if (cr0.eq) {
		// ERROR 82409918
		return;
	}
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240993c
	if (cr6.eq) goto loc_8240993C;
	// b 0x82409918
	// ERROR 82409918
	return;
}

__attribute__((alias("__imp__sub_82409964"))) PPC_WEAK_FUNC(sub_82409964);
PPC_FUNC_IMPL(__imp__sub_82409964) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
loc_8240996C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82409990
	if (cr0.eq) goto loc_82409990;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240996c
	if (cr6.eq) goto loc_8240996C;
loc_82409990:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bnelr 
	if (!cr0.eq) return;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824099A4"))) PPC_WEAK_FUNC(sub_824099A4);
PPC_FUNC_IMPL(__imp__sub_824099A4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824099A8"))) PPC_WEAK_FUNC(sub_824099A8);
PPC_FUNC_IMPL(__imp__sub_824099A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,-19820
	r11.s64 = r11.s64 + -19820;
	// li r9,3
	ctx.r9.s64 = 3;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824099CC"))) PPC_WEAK_FUNC(sub_824099CC);
PPC_FUNC_IMPL(__imp__sub_824099CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824099D0"))) PPC_WEAK_FUNC(sub_824099D0);
PPC_FUNC_IMPL(__imp__sub_824099D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r9,r3,16
	ctx.r9.s64 = ctx.r3.s64 + 16;
	// addi r10,r11,-19820
	ctx.r10.s64 = r11.s64 + -19820;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,3
	ctx.r8.s64 = 3;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r8,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r8.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// ld r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 0);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// ld r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 8);
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// ld r10,16(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 16);
	// std r10,16(r11)
	PPC_STORE_U64(r11.u32 + 16, ctx.r10.u64);
	// ld r10,24(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 24);
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409A1C"))) PPC_WEAK_FUNC(sub_82409A1C);
PPC_FUNC_IMPL(__imp__sub_82409A1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409A20"))) PPC_WEAK_FUNC(sub_82409A20);
PPC_FUNC_IMPL(__imp__sub_82409A20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82409a44
	if (cr6.eq) goto loc_82409A44;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x82409a4c
	if (cr6.eq) goto loc_82409A4C;
loc_82409A44:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82409a64
	goto loc_82409A64;
loc_82409A4C:
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// addi r3,r3,16
	ctx.r3.s64 = ctx.r3.s64 + 16;
	// bl 0x82409890
	sub_82409890(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
loc_82409A64:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409A74"))) PPC_WEAK_FUNC(sub_82409A74);
PPC_FUNC_IMPL(__imp__sub_82409A74) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409A78"))) PPC_WEAK_FUNC(sub_82409A78);
PPC_FUNC_IMPL(__imp__sub_82409A78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,48
	ctx.r4.s64 = 48;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409acc
	if (cr0.eq) goto loc_82409ACC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,-19820
	r11.s64 = r11.s64 + -19820;
	// li r9,3
	ctx.r9.s64 = 3;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// b 0x82409ad0
	goto loc_82409AD0;
loc_82409ACC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82409AD0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82409b00
	if (cr6.eq) goto loc_82409B00;
	// addi r11,r31,16
	r11.s64 = r31.s64 + 16;
	// addi r10,r3,16
	ctx.r10.s64 = ctx.r3.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// std r9,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 16);
	// std r9,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	r11.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// std r11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, r11.u64);
loc_82409B00:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409B14"))) PPC_WEAK_FUNC(sub_82409B14);
PPC_FUNC_IMPL(__imp__sub_82409B14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82409B18"))) PPC_WEAK_FUNC(sub_82409B18);
PPC_FUNC_IMPL(__imp__sub_82409B18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,4
	ctx.r9.s64 = 4;
	// addi r10,r11,-19808
	ctx.r10.s64 = r11.s64 + -19808;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409B58"))) PPC_WEAK_FUNC(sub_82409B58);
PPC_FUNC_IMPL(__imp__sub_82409B58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r30{};
	PPCRegister r31{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r31,0
	r31.s64 = 0;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r11,r11,-19808
	r11.s64 = r11.s64 + -19808;
	// stw r6,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r6.u32);
	// li r30,4
	r30.s64 = 4;
	// stw r7,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r7.u32);
	// stw r8,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r8.u32);
	// stw r9,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r9.u32);
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r31.u32);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r31.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409BA8"))) PPC_WEAK_FUNC(sub_82409BA8);
PPC_FUNC_IMPL(__imp__sub_82409BA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82409c6c
	if (cr6.eq) goto loc_82409C6C;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82409c6c
	if (!cr6.eq) goto loc_82409C6C;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,16(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82409c6c
	if (!cr6.eq) goto loc_82409C6C;
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r10,20(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82409c6c
	if (!cr6.eq) goto loc_82409C6C;
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r10,24(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82409c6c
	if (!cr6.eq) goto loc_82409C6C;
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82409c6c
	if (!cr6.eq) goto loc_82409C6C;
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r10,36(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82409c6c
	if (!cr6.eq) goto loc_82409C6C;
	// lwz r11,32(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// lwz r10,32(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82409c6c
	if (!cr6.eq) goto loc_82409C6C;
	// lwz r3,40(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwz r4,40(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 40);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409c50
	if (cr0.eq) goto loc_82409C50;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82409c5c
	goto loc_82409C5C;
loc_82409C50:
	// addi r11,r4,0
	r11.s64 = ctx.r4.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82409C5C:
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// b 0x82409c70
	goto loc_82409C70;
loc_82409C6C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82409C70:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409C80"))) PPC_WEAK_FUNC(sub_82409C80);
PPC_FUNC_IMPL(__imp__sub_82409C80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,44
	ctx.r4.s64 = 44;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409cf8
	if (cr0.eq) goto loc_82409CF8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,4
	ctx.r9.s64 = 4;
	// addi r10,r11,-19808
	ctx.r10.s64 = r11.s64 + -19808;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// b 0x82409cfc
	goto loc_82409CFC;
loc_82409CF8:
	// li r31,0
	r31.s64 = 0;
loc_82409CFC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82409d0c
	if (!cr6.eq) goto loc_82409D0C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82409d70
	goto loc_82409D70;
loc_82409D0C:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82409d6c
	if (cr6.eq) goto loc_82409D6C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x82409d70
	if (cr0.eq) goto loc_82409D70;
loc_82409D6C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82409D70:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409D88"))) PPC_WEAK_FUNC(sub_82409D88);
PPC_FUNC_IMPL(__imp__sub_82409D88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r11,r11,-19796
	r11.s64 = r11.s64 + -19796;
	// stw r6,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r6.u32);
	// li r9,5
	ctx.r9.s64 = 5;
	// stw r7,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r7.u32);
	// stw r8,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r8.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409DC0"))) PPC_WEAK_FUNC(sub_82409DC0);
PPC_FUNC_IMPL(__imp__sub_82409DC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82409ebc
	if (cr6.eq) goto loc_82409EBC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82409ebc
	if (!cr6.eq) goto loc_82409EBC;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82409ebc
	if (!cr6.eq) goto loc_82409EBC;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82409ebc
	if (!cr6.eq) goto loc_82409EBC;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409e34
	if (cr0.eq) goto loc_82409E34;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82409e40
	goto loc_82409E40;
loc_82409E34:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82409E40:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82409ebc
	if (cr6.eq) goto loc_82409EBC;
	// lwz r3,28(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409e6c
	if (cr0.eq) goto loc_82409E6C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82409e78
	goto loc_82409E78;
loc_82409E6C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82409E78:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82409ebc
	if (cr6.eq) goto loc_82409EBC;
	// lwz r3,32(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409ea4
	if (cr0.eq) goto loc_82409EA4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82409eb0
	goto loc_82409EB0;
loc_82409EA4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82409EB0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x82409ec0
	if (!cr6.eq) goto loc_82409EC0;
loc_82409EBC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82409EC0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_82409EC8"))) PPC_WEAK_FUNC(sub_82409EC8);
PPC_FUNC_IMPL(__imp__sub_82409EC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,36
	ctx.r4.s64 = 36;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82409f38
	if (cr0.eq) goto loc_82409F38;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,5
	ctx.r9.s64 = 5;
	// addi r10,r11,-19796
	ctx.r10.s64 = r11.s64 + -19796;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// b 0x82409f3c
	goto loc_82409F3C;
loc_82409F38:
	// li r31,0
	r31.s64 = 0;
loc_82409F3C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82409f4c
	if (!cr6.eq) goto loc_82409F4C;
loc_82409F44:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82409fe4
	goto loc_82409FE4;
loc_82409F4C:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82409f88
	if (cr6.eq) goto loc_82409F88;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x82409f44
	if (cr0.eq) goto loc_82409F44;
loc_82409F88:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82409fb4
	if (cr6.eq) goto loc_82409FB4;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// beq 0x82409f44
	if (cr0.eq) goto loc_82409F44;
loc_82409FB4:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82409fe0
	if (cr6.eq) goto loc_82409FE0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq 0x82409f44
	if (cr0.eq) goto loc_82409F44;
loc_82409FE0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82409FE4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409FFC"))) PPC_WEAK_FUNC(sub_82409FFC);
PPC_FUNC_IMPL(__imp__sub_82409FFC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240A000"))) PPC_WEAK_FUNC(sub_8240A000);
PPC_FUNC_IMPL(__imp__sub_8240A000) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,6
	ctx.r9.s64 = 6;
	// addi r10,r11,-19784
	ctx.r10.s64 = r11.s64 + -19784;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A04C"))) PPC_WEAK_FUNC(sub_8240A04C);
PPC_FUNC_IMPL(__imp__sub_8240A04C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240A050"))) PPC_WEAK_FUNC(sub_8240A050);
PPC_FUNC_IMPL(__imp__sub_8240A050) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r9,6
	ctx.r9.s64 = 6;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r10,r11,-19784
	ctx.r10.s64 = r11.s64 + -19784;
	// stw r6,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r6.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r7,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r7.u32);
	// stw r8,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r8.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A09C"))) PPC_WEAK_FUNC(sub_8240A09C);
PPC_FUNC_IMPL(__imp__sub_8240A09C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240A0A0"))) PPC_WEAK_FUNC(sub_8240A0A0);
PPC_FUNC_IMPL(__imp__sub_8240A0A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240a204
	if (cr6.eq) goto loc_8240A204;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240a204
	if (!cr6.eq) goto loc_8240A204;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240a204
	if (!cr6.eq) goto loc_8240A204;
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240a204
	if (!cr6.eq) goto loc_8240A204;
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240a204
	if (!cr6.eq) goto loc_8240A204;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240a204
	if (!cr6.eq) goto loc_8240A204;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240a204
	if (!cr6.eq) goto loc_8240A204;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a144
	if (cr0.eq) goto loc_8240A144;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a150
	goto loc_8240A150;
loc_8240A144:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A150:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240a204
	if (cr6.eq) goto loc_8240A204;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a17c
	if (cr0.eq) goto loc_8240A17C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a188
	goto loc_8240A188;
loc_8240A17C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A188:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240a204
	if (cr6.eq) goto loc_8240A204;
	// lwz r3,28(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a1b4
	if (cr0.eq) goto loc_8240A1B4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a1c0
	goto loc_8240A1C0;
loc_8240A1B4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A1C0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240a204
	if (cr6.eq) goto loc_8240A204;
	// lwz r3,32(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a1ec
	if (cr0.eq) goto loc_8240A1EC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a1f8
	goto loc_8240A1F8;
loc_8240A1EC:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A1F8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240a208
	if (!cr6.eq) goto loc_8240A208;
loc_8240A204:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240A208:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240A210"))) PPC_WEAK_FUNC(sub_8240A210);
PPC_FUNC_IMPL(__imp__sub_8240A210) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,52
	ctx.r4.s64 = 52;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a294
	if (cr0.eq) goto loc_8240A294;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,6
	ctx.r9.s64 = 6;
	// addi r10,r11,-19784
	ctx.r10.s64 = r11.s64 + -19784;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// b 0x8240a298
	goto loc_8240A298;
loc_8240A294:
	// li r31,0
	r31.s64 = 0;
loc_8240A298:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240a2a8
	if (!cr6.eq) goto loc_8240A2A8;
loc_8240A2A0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240a384
	goto loc_8240A384;
loc_8240A2A8:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a2fc
	if (cr6.eq) goto loc_8240A2FC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8240a2a0
	if (cr0.eq) goto loc_8240A2A0;
loc_8240A2FC:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a328
	if (cr6.eq) goto loc_8240A328;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8240a2a0
	if (cr0.eq) goto loc_8240A2A0;
loc_8240A328:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a354
	if (cr6.eq) goto loc_8240A354;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// beq 0x8240a2a0
	if (cr0.eq) goto loc_8240A2A0;
loc_8240A354:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a380
	if (cr6.eq) goto loc_8240A380;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq 0x8240a2a0
	if (cr0.eq) goto loc_8240A2A0;
loc_8240A380:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240A384:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A39C"))) PPC_WEAK_FUNC(sub_8240A39C);
PPC_FUNC_IMPL(__imp__sub_8240A39C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240A3A0"))) PPC_WEAK_FUNC(sub_8240A3A0);
PPC_FUNC_IMPL(__imp__sub_8240A3A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r4.u32);
	// li r9,21
	ctx.r9.s64 = 21;
	// stw r5,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r5.u32);
	// addi r10,r11,-19772
	ctx.r10.s64 = r11.s64 + -19772;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A3DC"))) PPC_WEAK_FUNC(sub_8240A3DC);
PPC_FUNC_IMPL(__imp__sub_8240A3DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240A3E0"))) PPC_WEAK_FUNC(sub_8240A3E0);
PPC_FUNC_IMPL(__imp__sub_8240A3E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240a4ec
	if (cr6.eq) goto loc_8240A4EC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240a4ec
	if (!cr6.eq) goto loc_8240A4EC;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240a4ec
	if (!cr6.eq) goto loc_8240A4EC;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240a4ec
	if (!cr6.eq) goto loc_8240A4EC;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240a4ec
	if (!cr6.eq) goto loc_8240A4EC;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a464
	if (cr0.eq) goto loc_8240A464;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a470
	goto loc_8240A470;
loc_8240A464:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A470:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240a4ec
	if (cr6.eq) goto loc_8240A4EC;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a49c
	if (cr0.eq) goto loc_8240A49C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a4a8
	goto loc_8240A4A8;
loc_8240A49C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A4A8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240a4ec
	if (cr6.eq) goto loc_8240A4EC;
	// lwz r3,36(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// lwz r4,36(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a4d4
	if (cr0.eq) goto loc_8240A4D4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a4e0
	goto loc_8240A4E0;
loc_8240A4D4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A4E0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240a4f0
	if (!cr6.eq) goto loc_8240A4F0;
loc_8240A4EC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240A4F0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240A4F8"))) PPC_WEAK_FUNC(sub_8240A4F8);
PPC_FUNC_IMPL(__imp__sub_8240A4F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,40
	ctx.r4.s64 = 40;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a56c
	if (cr0.eq) goto loc_8240A56C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,21
	ctx.r9.s64 = 21;
	// addi r10,r11,-19772
	ctx.r10.s64 = r11.s64 + -19772;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// b 0x8240a570
	goto loc_8240A570;
loc_8240A56C:
	// li r31,0
	r31.s64 = 0;
loc_8240A570:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240a580
	if (!cr6.eq) goto loc_8240A580;
loc_8240A578:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240a620
	goto loc_8240A620;
loc_8240A580:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a5c4
	if (cr6.eq) goto loc_8240A5C4;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq 0x8240a578
	if (cr0.eq) goto loc_8240A578;
loc_8240A5C4:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a5f0
	if (cr6.eq) goto loc_8240A5F0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8240a578
	if (cr0.eq) goto loc_8240A578;
loc_8240A5F0:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a61c
	if (cr6.eq) goto loc_8240A61C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// beq 0x8240a578
	if (cr0.eq) goto loc_8240A578;
loc_8240A61C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240A620:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A638"))) PPC_WEAK_FUNC(sub_8240A638);
PPC_FUNC_IMPL(__imp__sub_8240A638) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r11,r11,-19760
	r11.s64 = r11.s64 + -19760;
	// li r9,19
	ctx.r9.s64 = 19;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A664"))) PPC_WEAK_FUNC(sub_8240A664);
PPC_FUNC_IMPL(__imp__sub_8240A664) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240A668"))) PPC_WEAK_FUNC(sub_8240A668);
PPC_FUNC_IMPL(__imp__sub_8240A668) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240a70c
	if (cr6.eq) goto loc_8240A70C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240a70c
	if (!cr6.eq) goto loc_8240A70C;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a6bc
	if (cr0.eq) goto loc_8240A6BC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a6c8
	goto loc_8240A6C8;
loc_8240A6BC:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A6C8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240a70c
	if (cr6.eq) goto loc_8240A70C;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a6f4
	if (cr0.eq) goto loc_8240A6F4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a700
	goto loc_8240A700;
loc_8240A6F4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A700:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240a710
	if (!cr6.eq) goto loc_8240A710;
loc_8240A70C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240A710:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240A718"))) PPC_WEAK_FUNC(sub_8240A718);
PPC_FUNC_IMPL(__imp__sub_8240A718) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,24
	ctx.r4.s64 = 24;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a77c
	if (cr0.eq) goto loc_8240A77C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,19
	ctx.r9.s64 = 19;
	// addi r10,r11,-19760
	ctx.r10.s64 = r11.s64 + -19760;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// b 0x8240a780
	goto loc_8240A780;
loc_8240A77C:
	// li r31,0
	r31.s64 = 0;
loc_8240A780:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240a790
	if (!cr6.eq) goto loc_8240A790;
loc_8240A788:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240a7ec
	goto loc_8240A7EC;
loc_8240A790:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a7bc
	if (cr6.eq) goto loc_8240A7BC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq 0x8240a788
	if (cr0.eq) goto loc_8240A788;
loc_8240A7BC:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a7e8
	if (cr6.eq) goto loc_8240A7E8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8240a788
	if (cr0.eq) goto loc_8240A788;
loc_8240A7E8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240A7EC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A804"))) PPC_WEAK_FUNC(sub_8240A804);
PPC_FUNC_IMPL(__imp__sub_8240A804) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240A808"))) PPC_WEAK_FUNC(sub_8240A808);
PPC_FUNC_IMPL(__imp__sub_8240A808) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,-19748
	r11.s64 = r11.s64 + -19748;
	// li r9,20
	ctx.r9.s64 = 20;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A830"))) PPC_WEAK_FUNC(sub_8240A830);
PPC_FUNC_IMPL(__imp__sub_8240A830) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8240a854
	if (cr6.eq) goto loc_8240A854;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x8240a85c
	if (cr6.eq) goto loc_8240A85C;
loc_8240A854:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240a898
	goto loc_8240A898;
loc_8240A85C:
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r4,16(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a880
	if (cr0.eq) goto loc_8240A880;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240a88c
	goto loc_8240A88C;
loc_8240A880:
	// addi r11,r4,0
	r11.s64 = ctx.r4.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240A88C:
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
loc_8240A898:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A8A8"))) PPC_WEAK_FUNC(sub_8240A8A8);
PPC_FUNC_IMPL(__imp__sub_8240A8A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,20
	ctx.r4.s64 = 20;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240a908
	if (cr0.eq) goto loc_8240A908;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,20
	ctx.r9.s64 = 20;
	// addi r10,r11,-19748
	ctx.r10.s64 = r11.s64 + -19748;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// b 0x8240a90c
	goto loc_8240A90C;
loc_8240A908:
	// li r31,0
	r31.s64 = 0;
loc_8240A90C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240a91c
	if (!cr6.eq) goto loc_8240A91C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240a950
	goto loc_8240A950;
loc_8240A91C:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a94c
	if (cr6.eq) goto loc_8240A94C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x8240a950
	if (cr0.eq) goto loc_8240A950;
loc_8240A94C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240A950:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A968"))) PPC_WEAK_FUNC(sub_8240A968);
PPC_FUNC_IMPL(__imp__sub_8240A968) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r9,7
	ctx.r9.s64 = 7;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r10,r11,-19736
	ctx.r10.s64 = r11.s64 + -19736;
	// stw r6,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r6.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A99C"))) PPC_WEAK_FUNC(sub_8240A99C);
PPC_FUNC_IMPL(__imp__sub_8240A99C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240A9A0"))) PPC_WEAK_FUNC(sub_8240A9A0);
PPC_FUNC_IMPL(__imp__sub_8240A9A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240aa8c
	if (cr6.eq) goto loc_8240AA8C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240aa8c
	if (!cr6.eq) goto loc_8240AA8C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240aa8c
	if (!cr6.eq) goto loc_8240AA8C;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240aa04
	if (cr0.eq) goto loc_8240AA04;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240aa10
	goto loc_8240AA10;
loc_8240AA04:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240AA10:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240aa8c
	if (cr6.eq) goto loc_8240AA8C;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240aa3c
	if (cr0.eq) goto loc_8240AA3C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240aa48
	goto loc_8240AA48;
loc_8240AA3C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240AA48:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240aa8c
	if (cr6.eq) goto loc_8240AA8C;
	// lwz r3,28(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240aa74
	if (cr0.eq) goto loc_8240AA74;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240aa80
	goto loc_8240AA80;
loc_8240AA74:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240AA80:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240aa90
	if (!cr6.eq) goto loc_8240AA90;
loc_8240AA8C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240AA90:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240AA98"))) PPC_WEAK_FUNC(sub_8240AA98);
PPC_FUNC_IMPL(__imp__sub_8240AA98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,32
	ctx.r4.s64 = 32;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240ab04
	if (cr0.eq) goto loc_8240AB04;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,7
	ctx.r9.s64 = 7;
	// addi r10,r11,-19736
	ctx.r10.s64 = r11.s64 + -19736;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// b 0x8240ab08
	goto loc_8240AB08;
loc_8240AB04:
	// li r31,0
	r31.s64 = 0;
loc_8240AB08:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240ab18
	if (!cr6.eq) goto loc_8240AB18;
loc_8240AB10:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240aba8
	goto loc_8240ABA8;
loc_8240AB18:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240ab4c
	if (cr6.eq) goto loc_8240AB4C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8240ab10
	if (cr0.eq) goto loc_8240AB10;
loc_8240AB4C:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240ab78
	if (cr6.eq) goto loc_8240AB78;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8240ab10
	if (cr0.eq) goto loc_8240AB10;
loc_8240AB78:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240aba4
	if (cr6.eq) goto loc_8240ABA4;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// beq 0x8240ab10
	if (cr0.eq) goto loc_8240AB10;
loc_8240ABA4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240ABA8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240ABC0"))) PPC_WEAK_FUNC(sub_8240ABC0);
PPC_FUNC_IMPL(__imp__sub_8240ABC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,8
	ctx.r9.s64 = 8;
	// addi r10,r11,-19724
	ctx.r10.s64 = r11.s64 + -19724;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240ABEC"))) PPC_WEAK_FUNC(sub_8240ABEC);
PPC_FUNC_IMPL(__imp__sub_8240ABEC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240ABF0"))) PPC_WEAK_FUNC(sub_8240ABF0);
PPC_FUNC_IMPL(__imp__sub_8240ABF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r11,r11,-19724
	r11.s64 = r11.s64 + -19724;
	// li r9,8
	ctx.r9.s64 = 8;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240AC1C"))) PPC_WEAK_FUNC(sub_8240AC1C);
PPC_FUNC_IMPL(__imp__sub_8240AC1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240AC20"))) PPC_WEAK_FUNC(sub_8240AC20);
PPC_FUNC_IMPL(__imp__sub_8240AC20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8240ac44
	if (cr6.eq) goto loc_8240AC44;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x8240ac4c
	if (cr6.eq) goto loc_8240AC4C;
loc_8240AC44:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240ac98
	goto loc_8240AC98;
loc_8240AC4C:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r10,20(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240ac44
	if (!cr6.eq) goto loc_8240AC44;
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r4,16(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240ac80
	if (cr0.eq) goto loc_8240AC80;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240ac8c
	goto loc_8240AC8C;
loc_8240AC80:
	// addi r11,r4,0
	r11.s64 = ctx.r4.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240AC8C:
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
loc_8240AC98:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240ACA8"))) PPC_WEAK_FUNC(sub_8240ACA8);
PPC_FUNC_IMPL(__imp__sub_8240ACA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,24
	ctx.r4.s64 = 24;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240ad0c
	if (cr0.eq) goto loc_8240AD0C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,8
	ctx.r9.s64 = 8;
	// addi r10,r11,-19724
	ctx.r10.s64 = r11.s64 + -19724;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// b 0x8240ad10
	goto loc_8240AD10;
loc_8240AD0C:
	// li r31,0
	r31.s64 = 0;
loc_8240AD10:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240ad20
	if (!cr6.eq) goto loc_8240AD20;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240ad5c
	goto loc_8240AD5C;
loc_8240AD20:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240ad58
	if (cr6.eq) goto loc_8240AD58;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x8240ad5c
	if (cr0.eq) goto loc_8240AD5C;
loc_8240AD58:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240AD5C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240AD74"))) PPC_WEAK_FUNC(sub_8240AD74);
PPC_FUNC_IMPL(__imp__sub_8240AD74) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240AD78"))) PPC_WEAK_FUNC(sub_8240AD78);
PPC_FUNC_IMPL(__imp__sub_8240AD78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,9
	ctx.r9.s64 = 9;
	// addi r10,r11,-19712
	ctx.r10.s64 = r11.s64 + -19712;
	// li r11,0
	r11.s64 = 0;
	// li r8,10
	ctx.r8.s64 = 10;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r8,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r8.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240ADB8"))) PPC_WEAK_FUNC(sub_8240ADB8);
PPC_FUNC_IMPL(__imp__sub_8240ADB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r31{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r11,r11,-19712
	r11.s64 = r11.s64 + -19712;
	// stw r6,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r6.u32);
	// li r31,9
	r31.s64 = 9;
	// stw r7,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r7.u32);
	// stw r8,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r8.u32);
	// stw r9,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r9.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240ADFC"))) PPC_WEAK_FUNC(sub_8240ADFC);
PPC_FUNC_IMPL(__imp__sub_8240ADFC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240AE00"))) PPC_WEAK_FUNC(sub_8240AE00);
PPC_FUNC_IMPL(__imp__sub_8240AE00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8240aeb4
	if (cr6.eq) goto loc_8240AEB4;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240aeb4
	if (!cr6.eq) goto loc_8240AEB4;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,16(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240aeb4
	if (!cr6.eq) goto loc_8240AEB4;
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r10,20(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240aeb4
	if (!cr6.eq) goto loc_8240AEB4;
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240aeb4
	if (!cr6.eq) goto loc_8240AEB4;
	// lwz r11,32(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// lwz r10,32(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240aeb4
	if (!cr6.eq) goto loc_8240AEB4;
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r10,36(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240aeb4
	if (!cr6.eq) goto loc_8240AEB4;
	// lwz r3,24(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r4,24(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240ae98
	if (cr0.eq) goto loc_8240AE98;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240aea4
	goto loc_8240AEA4;
loc_8240AE98:
	// addi r11,r4,0
	r11.s64 = ctx.r4.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240AEA4:
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// b 0x8240aeb8
	goto loc_8240AEB8;
loc_8240AEB4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240AEB8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240AEC8"))) PPC_WEAK_FUNC(sub_8240AEC8);
PPC_FUNC_IMPL(__imp__sub_8240AEC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,40
	ctx.r4.s64 = 40;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240af40
	if (cr0.eq) goto loc_8240AF40;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,9
	ctx.r9.s64 = 9;
	// addi r10,r11,-19712
	ctx.r10.s64 = r11.s64 + -19712;
	// li r11,0
	r11.s64 = 0;
	// li r8,10
	ctx.r8.s64 = 10;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r8,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r8.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// b 0x8240af44
	goto loc_8240AF44;
loc_8240AF40:
	// li r31,0
	r31.s64 = 0;
loc_8240AF44:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240af54
	if (!cr6.eq) goto loc_8240AF54;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240afb0
	goto loc_8240AFB0;
loc_8240AF54:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240afac
	if (cr6.eq) goto loc_8240AFAC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x8240afb0
	if (cr0.eq) goto loc_8240AFB0;
loc_8240AFAC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240AFB0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240AFC8"))) PPC_WEAK_FUNC(sub_8240AFC8);
PPC_FUNC_IMPL(__imp__sub_8240AFC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,10
	ctx.r9.s64 = 10;
	// addi r10,r11,-19700
	ctx.r10.s64 = r11.s64 + -19700;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, r11.u32);
	// stw r11,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, r11.u32);
	// stw r11,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, r11.u32);
	// stw r11,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, r11.u32);
	// stw r11,68(r3)
	PPC_STORE_U32(ctx.r3.u32 + 68, r11.u32);
	// stw r11,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, r11.u32);
	// stw r11,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240B02C"))) PPC_WEAK_FUNC(sub_8240B02C);
PPC_FUNC_IMPL(__imp__sub_8240B02C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240B030"))) PPC_WEAK_FUNC(sub_8240B030);
PPC_FUNC_IMPL(__imp__sub_8240B030) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240b2cc
	if (!cr6.eq) goto loc_8240B2CC;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b2cc
	if (!cr6.eq) goto loc_8240B2CC;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b2cc
	if (!cr6.eq) goto loc_8240B2CC;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b2cc
	if (!cr6.eq) goto loc_8240B2CC;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b2cc
	if (!cr6.eq) goto loc_8240B2CC;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b2cc
	if (!cr6.eq) goto loc_8240B2CC;
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240b2cc
	if (!cr6.eq) goto loc_8240B2CC;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// lwz r10,76(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240b2cc
	if (!cr6.eq) goto loc_8240B2CC;
	// lwz r3,36(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,36(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b0f4
	if (cr0.eq) goto loc_8240B0F4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b100
	goto loc_8240B100;
loc_8240B0F4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B100:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r3,40(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b12c
	if (cr0.eq) goto loc_8240B12C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b138
	goto loc_8240B138;
loc_8240B12C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B138:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r3,44(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b164
	if (cr0.eq) goto loc_8240B164;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b170
	goto loc_8240B170;
loc_8240B164:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B170:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lwz r4,48(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b19c
	if (cr0.eq) goto loc_8240B19C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b1a8
	goto loc_8240B1A8;
loc_8240B19C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B1A8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r3,52(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// lwz r4,52(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b1d4
	if (cr0.eq) goto loc_8240B1D4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b1e0
	goto loc_8240B1E0;
loc_8240B1D4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B1E0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r3,56(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// lwz r4,56(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b20c
	if (cr0.eq) goto loc_8240B20C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b218
	goto loc_8240B218;
loc_8240B20C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B218:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r3,60(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// lwz r4,60(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b244
	if (cr0.eq) goto loc_8240B244;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b250
	goto loc_8240B250;
loc_8240B244:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B250:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r3,68(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 68);
	// lwz r4,68(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b27c
	if (cr0.eq) goto loc_8240B27C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b288
	goto loc_8240B288;
loc_8240B27C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B288:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b2cc
	if (cr6.eq) goto loc_8240B2CC;
	// lwz r3,64(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 64);
	// lwz r4,64(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b2b4
	if (cr0.eq) goto loc_8240B2B4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b2c0
	goto loc_8240B2C0;
loc_8240B2B4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B2C0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240b2d0
	if (!cr6.eq) goto loc_8240B2D0;
loc_8240B2CC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240B2D0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240B2D8"))) PPC_WEAK_FUNC(sub_8240B2D8);
PPC_FUNC_IMPL(__imp__sub_8240B2D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,80
	ctx.r4.s64 = 80;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b374
	if (cr0.eq) goto loc_8240B374;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,10
	ctx.r9.s64 = 10;
	// addi r10,r11,-19700
	ctx.r10.s64 = r11.s64 + -19700;
	// li r11,0
	r11.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, r11.u32);
	// stw r11,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, r11.u32);
	// stw r11,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, r11.u32);
	// stw r11,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, r11.u32);
	// stw r11,68(r3)
	PPC_STORE_U32(ctx.r3.u32 + 68, r11.u32);
	// stw r11,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, r11.u32);
	// stw r11,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, r11.u32);
	// b 0x8240b378
	goto loc_8240B378;
loc_8240B374:
	// li r30,0
	r30.s64 = 0;
loc_8240B378:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8240b388
	if (!cr6.eq) goto loc_8240B388;
loc_8240B380:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240b550
	goto loc_8240B550;
loc_8240B388:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r11,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r11.u32);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r11,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r11.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// stw r11,72(r30)
	PPC_STORE_U32(r30.u32 + 72, r11.u32);
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// stw r11,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r11.u32);
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b3ec
	if (cr6.eq) goto loc_8240B3EC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B3EC:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b418
	if (cr6.eq) goto loc_8240B418;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,40(r30)
	PPC_STORE_U32(r30.u32 + 40, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B418:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b444
	if (cr6.eq) goto loc_8240B444;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B444:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b470
	if (cr6.eq) goto loc_8240B470;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B470:
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b49c
	if (cr6.eq) goto loc_8240B49C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,52(r30)
	PPC_STORE_U32(r30.u32 + 52, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B49C:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b4c8
	if (cr6.eq) goto loc_8240B4C8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,56(r30)
	PPC_STORE_U32(r30.u32 + 56, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B4C8:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b4f4
	if (cr6.eq) goto loc_8240B4F4;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,60(r30)
	PPC_STORE_U32(r30.u32 + 60, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B4F4:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b520
	if (cr6.eq) goto loc_8240B520;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,68(r30)
	PPC_STORE_U32(r30.u32 + 68, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B520:
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b54c
	if (cr6.eq) goto loc_8240B54C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,64(r30)
	PPC_STORE_U32(r30.u32 + 64, ctx.r3.u32);
	// beq 0x8240b380
	if (cr0.eq) goto loc_8240B380;
loc_8240B54C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8240B550:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240B568"))) PPC_WEAK_FUNC(sub_8240B568);
PPC_FUNC_IMPL(__imp__sub_8240B568) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,11
	ctx.r9.s64 = 11;
	// addi r10,r11,-19688
	ctx.r10.s64 = r11.s64 + -19688;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, r11.u32);
	// stw r11,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, r11.u32);
	// stw r11,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, r11.u32);
	// stw r11,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, r11.u32);
	// stw r11,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, r11.u32);
	// stw r11,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, r11.u32);
	// stw r11,80(r3)
	PPC_STORE_U32(ctx.r3.u32 + 80, r11.u32);
	// stw r11,84(r3)
	PPC_STORE_U32(ctx.r3.u32 + 84, r11.u32);
	// stw r11,68(r3)
	PPC_STORE_U32(ctx.r3.u32 + 68, r11.u32);
	// stw r10,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r10.u32);
	// stw r10,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r10.u32);
	// stw r10,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r10.u32);
	// stw r10,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240B5D8"))) PPC_WEAK_FUNC(sub_8240B5D8);
PPC_FUNC_IMPL(__imp__sub_8240B5D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240b874
	if (cr6.eq) goto loc_8240B874;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lwz r10,44(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,76(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 76);
	// lwz r10,76(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lwz r10,36(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240b874
	if (!cr6.eq) goto loc_8240B874;
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,48(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b6bc
	if (cr0.eq) goto loc_8240B6BC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b6c8
	goto loc_8240B6C8;
loc_8240B6BC:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B6C8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b874
	if (cr6.eq) goto loc_8240B874;
	// lwz r3,52(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// lwz r4,52(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 52);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b6f4
	if (cr0.eq) goto loc_8240B6F4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b700
	goto loc_8240B700;
loc_8240B6F4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B700:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b874
	if (cr6.eq) goto loc_8240B874;
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwz r4,56(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 56);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b72c
	if (cr0.eq) goto loc_8240B72C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b738
	goto loc_8240B738;
loc_8240B72C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B738:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b874
	if (cr6.eq) goto loc_8240B874;
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwz r4,60(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b764
	if (cr0.eq) goto loc_8240B764;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b770
	goto loc_8240B770;
loc_8240B764:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B770:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b874
	if (cr6.eq) goto loc_8240B874;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// lwz r4,64(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 64);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b79c
	if (cr0.eq) goto loc_8240B79C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b7a8
	goto loc_8240B7A8;
loc_8240B79C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B7A8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b874
	if (cr6.eq) goto loc_8240B874;
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lwz r4,72(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b7d4
	if (cr0.eq) goto loc_8240B7D4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b7e0
	goto loc_8240B7E0;
loc_8240B7D4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B7E0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b874
	if (cr6.eq) goto loc_8240B874;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// lwz r4,68(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 68);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b80c
	if (cr0.eq) goto loc_8240B80C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240b818
	goto loc_8240B818;
loc_8240B80C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240B818:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240b874
	if (cr6.eq) goto loc_8240B874;
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240b86c
	if (cr0.eq) goto loc_8240B86C;
	// rlwinm. r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r9,80(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// beq 0x8240b864
	if (cr0.eq) goto loc_8240B864;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
loc_8240B844:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240b864
	if (!cr0.eq) goto loc_8240B864;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240b844
	if (!cr6.eq) goto loc_8240B844;
loc_8240B864:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240b874
	if (!cr0.eq) goto loc_8240B874;
loc_8240B86C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8240b878
	goto loc_8240B878;
loc_8240B874:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240B878:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240B880"))) PPC_WEAK_FUNC(sub_8240B880);
PPC_FUNC_IMPL(__imp__sub_8240B880) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,88
	ctx.r4.s64 = 88;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240b928
	if (cr0.eq) goto loc_8240B928;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,11
	ctx.r9.s64 = 11;
	// addi r10,r11,-19688
	ctx.r10.s64 = r11.s64 + -19688;
	// li r11,0
	r11.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, r11.u32);
	// stw r11,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, r11.u32);
	// stw r11,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, r11.u32);
	// stw r11,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, r11.u32);
	// stw r11,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, r11.u32);
	// stw r11,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, r11.u32);
	// stw r11,80(r3)
	PPC_STORE_U32(ctx.r3.u32 + 80, r11.u32);
	// stw r11,84(r3)
	PPC_STORE_U32(ctx.r3.u32 + 84, r11.u32);
	// stw r11,68(r3)
	PPC_STORE_U32(ctx.r3.u32 + 68, r11.u32);
	// stw r10,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r10.u32);
	// stw r10,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r10.u32);
	// stw r10,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r10.u32);
	// stw r10,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r10.u32);
	// b 0x8240b92c
	goto loc_8240B92C;
loc_8240B928:
	// li r30,0
	r30.s64 = 0;
loc_8240B92C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8240b93c
	if (!cr6.eq) goto loc_8240B93C;
loc_8240B934:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240bb24
	goto loc_8240BB24;
loc_8240B93C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// stw r11,40(r30)
	PPC_STORE_U32(r30.u32 + 40, r11.u32);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r11,44(r30)
	PPC_STORE_U32(r30.u32 + 44, r11.u32);
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// stw r11,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r11.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r11,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r11.u32);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r11,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r11.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// stw r11,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r11.u32);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b9b0
	if (cr6.eq) goto loc_8240B9B0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
loc_8240B9B0:
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240b9dc
	if (cr6.eq) goto loc_8240B9DC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,52(r30)
	PPC_STORE_U32(r30.u32 + 52, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
loc_8240B9DC:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240ba08
	if (cr6.eq) goto loc_8240BA08;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,56(r30)
	PPC_STORE_U32(r30.u32 + 56, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
loc_8240BA08:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240ba34
	if (cr6.eq) goto loc_8240BA34;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,60(r30)
	PPC_STORE_U32(r30.u32 + 60, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
loc_8240BA34:
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240ba60
	if (cr6.eq) goto loc_8240BA60;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,64(r30)
	PPC_STORE_U32(r30.u32 + 64, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
loc_8240BA60:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240ba8c
	if (cr6.eq) goto loc_8240BA8C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,72(r30)
	PPC_STORE_U32(r30.u32 + 72, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
loc_8240BA8C:
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240bab8
	if (cr6.eq) goto loc_8240BAB8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,68(r30)
	PPC_STORE_U32(r30.u32 + 68, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
loc_8240BAB8:
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240bb20
	if (cr0.eq) goto loc_8240BB20;
	// li r4,16
	ctx.r4.s64 = 16;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82409368
	sub_82409368(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,80(r30)
	PPC_STORE_U32(r30.u32 + 80, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r4,16
	ctx.r4.s64 = 16;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82409368
	sub_82409368(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,84(r30)
	PPC_STORE_U32(r30.u32 + 84, ctx.r3.u32);
	// beq 0x8240b934
	if (cr0.eq) goto loc_8240B934;
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// lwz r4,80(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,80(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r4,84(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,84(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_8240BB20:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8240BB24:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BB3C"))) PPC_WEAK_FUNC(sub_8240BB3C);
PPC_FUNC_IMPL(__imp__sub_8240BB3C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240BB40"))) PPC_WEAK_FUNC(sub_8240BB40);
PPC_FUNC_IMPL(__imp__sub_8240BB40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,12
	ctx.r9.s64 = 12;
	// addi r10,r11,-19676
	ctx.r10.s64 = r11.s64 + -19676;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BB88"))) PPC_WEAK_FUNC(sub_8240BB88);
PPC_FUNC_IMPL(__imp__sub_8240BB88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240bd64
	if (cr6.eq) goto loc_8240BD64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240bd64
	if (!cr6.eq) goto loc_8240BD64;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240bd64
	if (!cr6.eq) goto loc_8240BD64;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240bd64
	if (!cr6.eq) goto loc_8240BD64;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bbfc
	if (cr0.eq) goto loc_8240BBFC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240bc08
	goto loc_8240BC08;
loc_8240BBFC:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240BC08:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240bd64
	if (cr6.eq) goto loc_8240BD64;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bc34
	if (cr0.eq) goto loc_8240BC34;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240bc40
	goto loc_8240BC40;
loc_8240BC34:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240BC40:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240bd64
	if (cr6.eq) goto loc_8240BD64;
	// lwz r3,28(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bc6c
	if (cr0.eq) goto loc_8240BC6C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240bc78
	goto loc_8240BC78;
loc_8240BC6C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240BC78:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240bd64
	if (cr6.eq) goto loc_8240BD64;
	// lwz r3,32(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bca4
	if (cr0.eq) goto loc_8240BCA4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240bcb0
	goto loc_8240BCB0;
loc_8240BCA4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240BCB0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240bd64
	if (cr6.eq) goto loc_8240BD64;
	// lwz r3,36(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// lwz r4,36(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bcdc
	if (cr0.eq) goto loc_8240BCDC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240bce8
	goto loc_8240BCE8;
loc_8240BCDC:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240BCE8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240bd64
	if (cr6.eq) goto loc_8240BD64;
	// lwz r3,40(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bd14
	if (cr0.eq) goto loc_8240BD14;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240bd20
	goto loc_8240BD20;
loc_8240BD14:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240BD20:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240bd64
	if (cr6.eq) goto loc_8240BD64;
	// lwz r3,44(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bd4c
	if (cr0.eq) goto loc_8240BD4C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240bd58
	goto loc_8240BD58;
loc_8240BD4C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240BD58:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240bd68
	if (!cr6.eq) goto loc_8240BD68;
loc_8240BD64:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240BD68:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240BD70"))) PPC_WEAK_FUNC(sub_8240BD70);
PPC_FUNC_IMPL(__imp__sub_8240BD70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,52
	ctx.r4.s64 = 52;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bdf0
	if (cr0.eq) goto loc_8240BDF0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,12
	ctx.r9.s64 = 12;
	// addi r10,r11,-19676
	ctx.r10.s64 = r11.s64 + -19676;
	// li r11,0
	r11.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// b 0x8240bdf4
	goto loc_8240BDF4;
loc_8240BDF0:
	// li r30,0
	r30.s64 = 0;
loc_8240BDF4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8240be04
	if (!cr6.eq) goto loc_8240BE04;
loc_8240BDFC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240bf4c
	goto loc_8240BF4C;
loc_8240BE04:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240be40
	if (cr6.eq) goto loc_8240BE40;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r30)
	PPC_STORE_U32(r30.u32 + 20, ctx.r3.u32);
	// beq 0x8240bdfc
	if (cr0.eq) goto loc_8240BDFC;
loc_8240BE40:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240be6c
	if (cr6.eq) goto loc_8240BE6C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
	// beq 0x8240bdfc
	if (cr0.eq) goto loc_8240BDFC;
loc_8240BE6C:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240be98
	if (cr6.eq) goto loc_8240BE98;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r30)
	PPC_STORE_U32(r30.u32 + 28, ctx.r3.u32);
	// beq 0x8240bdfc
	if (cr0.eq) goto loc_8240BDFC;
loc_8240BE98:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240bec4
	if (cr6.eq) goto loc_8240BEC4;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq 0x8240bdfc
	if (cr0.eq) goto loc_8240BDFC;
loc_8240BEC4:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240bef0
	if (cr6.eq) goto loc_8240BEF0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// beq 0x8240bdfc
	if (cr0.eq) goto loc_8240BDFC;
loc_8240BEF0:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240bf1c
	if (cr6.eq) goto loc_8240BF1C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,40(r30)
	PPC_STORE_U32(r30.u32 + 40, ctx.r3.u32);
	// beq 0x8240bdfc
	if (cr0.eq) goto loc_8240BDFC;
loc_8240BF1C:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240bf48
	if (cr6.eq) goto loc_8240BF48;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// beq 0x8240bdfc
	if (cr0.eq) goto loc_8240BDFC;
loc_8240BF48:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8240BF4C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BF64"))) PPC_WEAK_FUNC(sub_8240BF64);
PPC_FUNC_IMPL(__imp__sub_8240BF64) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240BF68"))) PPC_WEAK_FUNC(sub_8240BF68);
PPC_FUNC_IMPL(__imp__sub_8240BF68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,13
	ctx.r9.s64 = 13;
	// addi r10,r11,-19664
	ctx.r10.s64 = r11.s64 + -19664;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BF94"))) PPC_WEAK_FUNC(sub_8240BF94);
PPC_FUNC_IMPL(__imp__sub_8240BF94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240BF98"))) PPC_WEAK_FUNC(sub_8240BF98);
PPC_FUNC_IMPL(__imp__sub_8240BF98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8240bfbc
	if (cr6.eq) goto loc_8240BFBC;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x8240bfc4
	if (cr6.eq) goto loc_8240BFC4;
loc_8240BFBC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240c010
	goto loc_8240C010;
loc_8240BFC4:
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,16(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240bfbc
	if (!cr6.eq) goto loc_8240BFBC;
	// lwz r3,20(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r4,20(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240bff8
	if (cr0.eq) goto loc_8240BFF8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240c004
	goto loc_8240C004;
loc_8240BFF8:
	// addi r11,r4,0
	r11.s64 = ctx.r4.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240C004:
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
loc_8240C010:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C020"))) PPC_WEAK_FUNC(sub_8240C020);
PPC_FUNC_IMPL(__imp__sub_8240C020) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,14
	ctx.r9.s64 = 14;
	// addi r10,r11,-19652
	ctx.r10.s64 = r11.s64 + -19652;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// std r11,48(r3)
	PPC_STORE_U64(ctx.r3.u32 + 48, r11.u64);
	// std r11,56(r3)
	PPC_STORE_U64(ctx.r3.u32 + 56, r11.u64);
	// std r11,64(r3)
	PPC_STORE_U64(ctx.r3.u32 + 64, r11.u64);
	// std r11,72(r3)
	PPC_STORE_U64(ctx.r3.u32 + 72, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C078"))) PPC_WEAK_FUNC(sub_8240C078);
PPC_FUNC_IMPL(__imp__sub_8240C078) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r30{};
	PPCRegister r31{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// addi r10,r3,48
	ctx.r10.s64 = ctx.r3.s64 + 48;
	// stw r5,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r5.u32);
	// addi r31,r11,-19652
	r31.s64 = r11.s64 + -19652;
	// stw r6,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r6.u32);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// stw r7,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r7.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r8,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r8.u32);
	// li r30,14
	r30.s64 = 14;
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r10,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r10.u32);
	// stw r10,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r10.u32);
	// ld r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// ld r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// ld r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 16);
	// std r10,16(r11)
	PPC_STORE_U64(r11.u32 + 16, ctx.r10.u64);
	// ld r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 24);
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C0F0"))) PPC_WEAK_FUNC(sub_8240C0F0);
PPC_FUNC_IMPL(__imp__sub_8240C0F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240c230
	if (cr6.eq) goto loc_8240C230;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240c230
	if (!cr6.eq) goto loc_8240C230;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240c230
	if (!cr6.eq) goto loc_8240C230;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240c230
	if (!cr6.eq) goto loc_8240C230;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240c230
	if (!cr6.eq) goto loc_8240C230;
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240c230
	if (!cr6.eq) goto loc_8240C230;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240c230
	if (!cr6.eq) goto loc_8240C230;
	// addi r4,r31,48
	ctx.r4.s64 = r31.s64 + 48;
	// addi r3,r30,48
	ctx.r3.s64 = r30.s64 + 48;
	// bl 0x82409890
	sub_82409890(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8240c230
	if (cr0.eq) goto loc_8240C230;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c1a8
	if (cr0.eq) goto loc_8240C1A8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240c1b4
	goto loc_8240C1B4;
loc_8240C1A8:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240C1B4:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240c230
	if (cr6.eq) goto loc_8240C230;
	// lwz r3,32(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c1e0
	if (cr0.eq) goto loc_8240C1E0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240c1ec
	goto loc_8240C1EC;
loc_8240C1E0:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240C1EC:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240c230
	if (cr6.eq) goto loc_8240C230;
	// lwz r3,36(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// lwz r4,36(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c218
	if (cr0.eq) goto loc_8240C218;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240c224
	goto loc_8240C224;
loc_8240C218:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240C224:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240c234
	if (!cr6.eq) goto loc_8240C234;
loc_8240C230:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240C234:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240C23C"))) PPC_WEAK_FUNC(sub_8240C23C);
PPC_FUNC_IMPL(__imp__sub_8240C23C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240C240"))) PPC_WEAK_FUNC(sub_8240C240);
PPC_FUNC_IMPL(__imp__sub_8240C240) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,80
	ctx.r4.s64 = 80;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c2d0
	if (cr0.eq) goto loc_8240C2D0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,14
	ctx.r9.s64 = 14;
	// addi r10,r11,-19652
	ctx.r10.s64 = r11.s64 + -19652;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// std r11,48(r3)
	PPC_STORE_U64(ctx.r3.u32 + 48, r11.u64);
	// std r11,56(r3)
	PPC_STORE_U64(ctx.r3.u32 + 56, r11.u64);
	// std r11,64(r3)
	PPC_STORE_U64(ctx.r3.u32 + 64, r11.u64);
	// std r11,72(r3)
	PPC_STORE_U64(ctx.r3.u32 + 72, r11.u64);
	// b 0x8240c2d4
	goto loc_8240C2D4;
loc_8240C2D0:
	// li r31,0
	r31.s64 = 0;
loc_8240C2D4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240c2e4
	if (!cr6.eq) goto loc_8240C2E4;
loc_8240C2DC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240c3bc
	goto loc_8240C3BC;
loc_8240C2E4:
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r11,r30,48
	r11.s64 = r30.s64 + 48;
	// addi r10,r31,48
	ctx.r10.s64 = r31.s64 + 48;
	// stw r9,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r9.u32);
	// lwz r9,24(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r9,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r9.u32);
	// lwz r9,28(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r9,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r9.u32);
	// lwz r9,40(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r9,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r9.u32);
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// std r9,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 16);
	// std r9,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	r11.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// std r11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, r11.u64);
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240c360
	if (cr6.eq) goto loc_8240C360;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq 0x8240c2dc
	if (cr0.eq) goto loc_8240C2DC;
loc_8240C360:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240c38c
	if (cr6.eq) goto loc_8240C38C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq 0x8240c2dc
	if (cr0.eq) goto loc_8240C2DC;
loc_8240C38C:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240c3b8
	if (cr6.eq) goto loc_8240C3B8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// beq 0x8240c2dc
	if (cr0.eq) goto loc_8240C2DC;
loc_8240C3B8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240C3BC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C3D4"))) PPC_WEAK_FUNC(sub_8240C3D4);
PPC_FUNC_IMPL(__imp__sub_8240C3D4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240C3D8"))) PPC_WEAK_FUNC(sub_8240C3D8);
PPC_FUNC_IMPL(__imp__sub_8240C3D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,15
	ctx.r9.s64 = 15;
	// addi r10,r11,-19640
	ctx.r10.s64 = r11.s64 + -19640;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,3
	ctx.r10.s64 = 3;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// std r11,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, r11.u64);
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// std r11,40(r3)
	PPC_STORE_U64(ctx.r3.u32 + 40, r11.u64);
	// std r11,48(r3)
	PPC_STORE_U64(ctx.r3.u32 + 48, r11.u64);
	// std r11,56(r3)
	PPC_STORE_U64(ctx.r3.u32 + 56, r11.u64);
	// stw r10,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C41C"))) PPC_WEAK_FUNC(sub_8240C41C);
PPC_FUNC_IMPL(__imp__sub_8240C41C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240C420"))) PPC_WEAK_FUNC(sub_8240C420);
PPC_FUNC_IMPL(__imp__sub_8240C420) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r9,r31,32
	ctx.r9.s64 = r31.s64 + 32;
	// addi r10,r11,-19640
	ctx.r10.s64 = r11.s64 + -19640;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,15
	ctx.r8.s64 = 15;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// stw r9,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r9.u32);
	// stw r8,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r8.u32);
	// ld r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 0);
	// std r10,16(r31)
	PPC_STORE_U64(r31.u32 + 16, ctx.r10.u64);
	// ld r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 8);
	// std r10,24(r31)
	PPC_STORE_U64(r31.u32 + 24, ctx.r10.u64);
	// ld r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 0);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// ld r10,8(r5)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// ld r10,16(r5)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 16);
	// std r10,16(r11)
	PPC_STORE_U64(r11.u32 + 16, ctx.r10.u64);
	// ld r10,24(r5)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 24);
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// bne cr6,0x8240c4b8
	if (!cr6.eq) goto loc_8240C4B8;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c4b8
	if (cr0.eq) goto loc_8240C4B8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
loc_8240C4B8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C4D0"))) PPC_WEAK_FUNC(sub_8240C4D0);
PPC_FUNC_IMPL(__imp__sub_8240C4D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// stw r5,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r5.u32);
	// addi r10,r11,-19640
	ctx.r10.s64 = r11.s64 + -19640;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,15
	ctx.r8.s64 = 15;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r8,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r8.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// ld r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 0);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// ld r10,8(r6)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 8);
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// ld r10,16(r6)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 16);
	// std r10,16(r11)
	PPC_STORE_U64(r11.u32 + 16, ctx.r10.u64);
	// ld r10,24(r6)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 24);
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C524"))) PPC_WEAK_FUNC(sub_8240C524);
PPC_FUNC_IMPL(__imp__sub_8240C524) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240C528"))) PPC_WEAK_FUNC(sub_8240C528);
PPC_FUNC_IMPL(__imp__sub_8240C528) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stfd f1,24(r3)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r3.u32 + 24, ctx.f1.u64);
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// addi r10,r11,-19640
	ctx.r10.s64 = r11.s64 + -19640;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,15
	ctx.r8.s64 = 15;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r8,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r8.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// ld r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 0);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// ld r10,8(r6)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 8);
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// ld r10,16(r6)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 16);
	// std r10,16(r11)
	PPC_STORE_U64(r11.u32 + 16, ctx.r10.u64);
	// ld r10,24(r6)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r6.u32 + 24);
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C57C"))) PPC_WEAK_FUNC(sub_8240C57C);
PPC_FUNC_IMPL(__imp__sub_8240C57C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240C580"))) PPC_WEAK_FUNC(sub_8240C580);
PPC_FUNC_IMPL(__imp__sub_8240C580) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// stw r5,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r5.u32);
	// addi r10,r11,-19640
	ctx.r10.s64 = r11.s64 + -19640;
	// stw r6,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r6.u32);
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,15
	ctx.r8.s64 = 15;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r8,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r8.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// ld r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r7.u32 + 0);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// ld r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// ld r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// std r10,16(r11)
	PPC_STORE_U64(r11.u32 + 16, ctx.r10.u64);
	// ld r10,24(r7)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r7.u32 + 24);
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C5D8"))) PPC_WEAK_FUNC(sub_8240C5D8);
PPC_FUNC_IMPL(__imp__sub_8240C5D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8240c68c
	if (cr6.eq) goto loc_8240C68C;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240c68c
	if (!cr6.eq) goto loc_8240C68C;
	// addi r11,r3,16
	r11.s64 = ctx.r3.s64 + 16;
	// addi r10,r4,16
	ctx.r10.s64 = ctx.r4.s64 + 16;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r7,r9
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240c68c
	if (!cr6.eq) goto loc_8240C68C;
	// addi r9,r11,16
	ctx.r9.s64 = r11.s64 + 16;
loc_8240C618:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r6,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r6.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240c638
	if (!cr0.eq) goto loc_8240C638;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240c618
	if (!cr6.eq) goto loc_8240C618;
loc_8240C638:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240c648
	if (!cr0.eq) goto loc_8240C648;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8240c690
	goto loc_8240C690;
loc_8240C648:
	// cmpwi cr6,r7,4
	cr6.compare<int32_t>(ctx.r7.s32, 4, xer);
	// bne cr6,0x8240c68c
	if (!cr6.eq) goto loc_8240C68C;
	// lwz r3,24(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r4,24(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c674
	if (cr0.eq) goto loc_8240C674;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240c680
	goto loc_8240C680;
loc_8240C674:
	// addi r11,r4,0
	r11.s64 = ctx.r4.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240C680:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240c690
	if (!cr6.eq) goto loc_8240C690;
loc_8240C68C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240C690:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C6A0"))) PPC_WEAK_FUNC(sub_8240C6A0);
PPC_FUNC_IMPL(__imp__sub_8240C6A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,64
	ctx.r4.s64 = 64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c71c
	if (cr0.eq) goto loc_8240C71C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,15
	ctx.r9.s64 = 15;
	// addi r10,r11,-19640
	ctx.r10.s64 = r11.s64 + -19640;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// li r10,3
	ctx.r10.s64 = 3;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// std r11,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, r11.u64);
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// std r11,40(r3)
	PPC_STORE_U64(ctx.r3.u32 + 40, r11.u64);
	// std r11,48(r3)
	PPC_STORE_U64(ctx.r3.u32 + 48, r11.u64);
	// std r11,56(r3)
	PPC_STORE_U64(ctx.r3.u32 + 56, r11.u64);
	// stw r10,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r10.u32);
	// b 0x8240c720
	goto loc_8240C720;
loc_8240C71C:
	// li r31,0
	r31.s64 = 0;
loc_8240C720:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240c730
	if (!cr6.eq) goto loc_8240C730;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240c7a0
	goto loc_8240C7A0;
loc_8240C730:
	// ld r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U64(r30.u32 + 16);
	// addi r11,r30,32
	r11.s64 = r30.s64 + 32;
	// std r10,16(r31)
	PPC_STORE_U64(r31.u32 + 16, ctx.r10.u64);
	// ld r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U64(r30.u32 + 24);
	// std r10,24(r31)
	PPC_STORE_U64(r31.u32 + 24, ctx.r10.u64);
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// std r10,32(r31)
	PPC_STORE_U64(r31.u32 + 32, ctx.r10.u64);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// std r10,40(r31)
	PPC_STORE_U64(r31.u32 + 40, ctx.r10.u64);
	// ld r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 16);
	// std r10,48(r31)
	PPC_STORE_U64(r31.u32 + 48, ctx.r10.u64);
	// ld r11,24(r11)
	r11.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// std r11,56(r31)
	PPC_STORE_U64(r31.u32 + 56, r11.u64);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x8240c79c
	if (!cr6.eq) goto loc_8240C79C;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c79c
	if (cr0.eq) goto loc_8240C79C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x8240c7a0
	if (cr0.eq) goto loc_8240C7A0;
loc_8240C79C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240C7A0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C7B8"))) PPC_WEAK_FUNC(sub_8240C7B8);
PPC_FUNC_IMPL(__imp__sub_8240C7B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r11,r11,-19628
	r11.s64 = r11.s64 + -19628;
	// stw r6,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r6.u32);
	// li r9,17
	ctx.r9.s64 = 17;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C7E8"))) PPC_WEAK_FUNC(sub_8240C7E8);
PPC_FUNC_IMPL(__imp__sub_8240C7E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240c8c4
	if (cr6.eq) goto loc_8240C8C4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240c8c4
	if (!cr6.eq) goto loc_8240C8C4;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c83c
	if (cr0.eq) goto loc_8240C83C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240c848
	goto loc_8240C848;
loc_8240C83C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240C848:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240c8c4
	if (cr6.eq) goto loc_8240C8C4;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c874
	if (cr0.eq) goto loc_8240C874;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240c880
	goto loc_8240C880;
loc_8240C874:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240C880:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240c8c4
	if (cr6.eq) goto loc_8240C8C4;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c8ac
	if (cr0.eq) goto loc_8240C8AC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240c8b8
	goto loc_8240C8B8;
loc_8240C8AC:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240C8B8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240c8c8
	if (!cr6.eq) goto loc_8240C8C8;
loc_8240C8C4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240C8C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240C8D0"))) PPC_WEAK_FUNC(sub_8240C8D0);
PPC_FUNC_IMPL(__imp__sub_8240C8D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,28
	ctx.r4.s64 = 28;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240c938
	if (cr0.eq) goto loc_8240C938;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,17
	ctx.r9.s64 = 17;
	// addi r10,r11,-19628
	ctx.r10.s64 = r11.s64 + -19628;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// b 0x8240c93c
	goto loc_8240C93C;
loc_8240C938:
	// li r31,0
	r31.s64 = 0;
loc_8240C93C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240c94c
	if (!cr6.eq) goto loc_8240C94C;
loc_8240C944:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240c9d4
	goto loc_8240C9D4;
loc_8240C94C:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240c978
	if (cr6.eq) goto loc_8240C978;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq 0x8240c944
	if (cr0.eq) goto loc_8240C944;
loc_8240C978:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240c9a4
	if (cr6.eq) goto loc_8240C9A4;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8240c944
	if (cr0.eq) goto loc_8240C944;
loc_8240C9A4:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240c9d0
	if (cr6.eq) goto loc_8240C9D0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8240c944
	if (cr0.eq) goto loc_8240C944;
loc_8240C9D0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240C9D4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C9EC"))) PPC_WEAK_FUNC(sub_8240C9EC);
PPC_FUNC_IMPL(__imp__sub_8240C9EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240C9F0"))) PPC_WEAK_FUNC(sub_8240C9F0);
PPC_FUNC_IMPL(__imp__sub_8240C9F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r9,r3,16
	ctx.r9.s64 = ctx.r3.s64 + 16;
	// addi r10,r11,-19616
	ctx.r10.s64 = r11.s64 + -19616;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,16
	ctx.r8.s64 = 16;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r8,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r8.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// ld r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 0);
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// ld r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 8);
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// ld r10,16(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 16);
	// std r10,16(r11)
	PPC_STORE_U64(r11.u32 + 16, ctx.r10.u64);
	// ld r10,24(r4)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r4.u32 + 24);
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// stw r5,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, ctx.r5.u32);
	// stw r6,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, ctx.r6.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240CA44"))) PPC_WEAK_FUNC(sub_8240CA44);
PPC_FUNC_IMPL(__imp__sub_8240CA44) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240CA48"))) PPC_WEAK_FUNC(sub_8240CA48);
PPC_FUNC_IMPL(__imp__sub_8240CA48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r7,r4
	ctx.r7.u64 = ctx.r4.u64;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8240ca74
	if (cr6.eq) goto loc_8240CA74;
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// lwz r10,4(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x8240ca7c
	if (cr6.eq) goto loc_8240CA7C;
loc_8240CA74:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240cab4
	goto loc_8240CAB4;
loc_8240CA7C:
	// addi r4,r7,16
	ctx.r4.s64 = ctx.r7.s64 + 16;
	// addi r3,r6,16
	ctx.r3.s64 = ctx.r6.s64 + 16;
	// bl 0x82409890
	sub_82409890(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8240ca74
	if (cr0.eq) goto loc_8240CA74;
	// lwz r11,48(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	// lwz r10,48(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240ca74
	if (!cr6.eq) goto loc_8240CA74;
	// lwz r11,52(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 52);
	// lwz r10,52(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 52);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240CAB4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240CAC4"))) PPC_WEAK_FUNC(sub_8240CAC4);
PPC_FUNC_IMPL(__imp__sub_8240CAC4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240CAC8"))) PPC_WEAK_FUNC(sub_8240CAC8);
PPC_FUNC_IMPL(__imp__sub_8240CAC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,56
	ctx.r4.s64 = 56;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240cb24
	if (cr0.eq) goto loc_8240CB24;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,16
	ctx.r9.s64 = 16;
	// addi r10,r11,-19616
	ctx.r10.s64 = r11.s64 + -19616;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, r11.u32);
	// b 0x8240cb28
	goto loc_8240CB28;
loc_8240CB24:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240CB28:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8240cb68
	if (cr6.eq) goto loc_8240CB68;
	// addi r11,r31,16
	r11.s64 = r31.s64 + 16;
	// addi r10,r3,16
	ctx.r10.s64 = ctx.r3.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// std r9,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 16);
	// std r9,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	r11.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// std r11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, r11.u64);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, r11.u32);
loc_8240CB68:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240CB7C"))) PPC_WEAK_FUNC(sub_8240CB7C);
PPC_FUNC_IMPL(__imp__sub_8240CB7C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240CB80"))) PPC_WEAK_FUNC(sub_8240CB80);
PPC_FUNC_IMPL(__imp__sub_8240CB80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r9,18
	ctx.r9.s64 = 18;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-19604
	ctx.r10.s64 = r11.s64 + -19604;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r9,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r9.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240CBB8"))) PPC_WEAK_FUNC(sub_8240CBB8);
PPC_FUNC_IMPL(__imp__sub_8240CBB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r5,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r5.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r6,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r6.u32);
	// addi r11,r11,-19604
	r11.s64 = r11.s64 + -19604;
	// stw r4,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r4.u32);
	// li r9,18
	ctx.r9.s64 = 18;
	// stw r7,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r7.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240CBEC"))) PPC_WEAK_FUNC(sub_8240CBEC);
PPC_FUNC_IMPL(__imp__sub_8240CBEC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240CBF0"))) PPC_WEAK_FUNC(sub_8240CBF0);
PPC_FUNC_IMPL(__imp__sub_8240CBF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240ccdc
	if (cr6.eq) goto loc_8240CCDC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240ccdc
	if (!cr6.eq) goto loc_8240CCDC;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240ccdc
	if (!cr6.eq) goto loc_8240CCDC;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240cc54
	if (cr0.eq) goto loc_8240CC54;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240cc60
	goto loc_8240CC60;
loc_8240CC54:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240CC60:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240ccdc
	if (cr6.eq) goto loc_8240CCDC;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240cc8c
	if (cr0.eq) goto loc_8240CC8C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240cc98
	goto loc_8240CC98;
loc_8240CC8C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240CC98:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240ccdc
	if (cr6.eq) goto loc_8240CCDC;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240ccc4
	if (cr0.eq) goto loc_8240CCC4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240ccd0
	goto loc_8240CCD0;
loc_8240CCC4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240CCD0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240cce0
	if (!cr6.eq) goto loc_8240CCE0;
loc_8240CCDC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240CCE0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240CCE8"))) PPC_WEAK_FUNC(sub_8240CCE8);
PPC_FUNC_IMPL(__imp__sub_8240CCE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,32
	ctx.r4.s64 = 32;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240cd58
	if (cr0.eq) goto loc_8240CD58;
	// li r9,18
	ctx.r9.s64 = 18;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r10,r11,-19604
	ctx.r10.s64 = r11.s64 + -19604;
	// li r11,0
	r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r9,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r9.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// b 0x8240cd5c
	goto loc_8240CD5C;
loc_8240CD58:
	// li r31,0
	r31.s64 = 0;
loc_8240CD5C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240cd6c
	if (!cr6.eq) goto loc_8240CD6C;
loc_8240CD64:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240cdfc
	goto loc_8240CDFC;
loc_8240CD6C:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240cda0
	if (cr6.eq) goto loc_8240CDA0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq 0x8240cd64
	if (cr0.eq) goto loc_8240CD64;
loc_8240CDA0:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240cdcc
	if (cr6.eq) goto loc_8240CDCC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8240cd64
	if (cr0.eq) goto loc_8240CD64;
loc_8240CDCC:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240cdf8
	if (cr6.eq) goto loc_8240CDF8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8240cd64
	if (cr0.eq) goto loc_8240CD64;
loc_8240CDF8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240CDFC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240CE14"))) PPC_WEAK_FUNC(sub_8240CE14);
PPC_FUNC_IMPL(__imp__sub_8240CE14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240CE18"))) PPC_WEAK_FUNC(sub_8240CE18);
PPC_FUNC_IMPL(__imp__sub_8240CE18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r5,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r5.u32);
	// addi r11,r11,-19592
	r11.s64 = r11.s64 + -19592;
	// stw r6,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r6.u32);
	// li r9,26
	ctx.r9.s64 = 26;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240CE48"))) PPC_WEAK_FUNC(sub_8240CE48);
PPC_FUNC_IMPL(__imp__sub_8240CE48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240cf24
	if (cr6.eq) goto loc_8240CF24;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x8240cf24
	if (!cr6.eq) goto loc_8240CF24;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r29,0
	r29.s64 = 0;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240ce9c
	if (cr0.eq) goto loc_8240CE9C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240cea8
	goto loc_8240CEA8;
loc_8240CE9C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240CEA8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240cf24
	if (cr6.eq) goto loc_8240CF24;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240ced4
	if (cr0.eq) goto loc_8240CED4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240cee0
	goto loc_8240CEE0;
loc_8240CED4:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240CEE0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8240cf24
	if (cr6.eq) goto loc_8240CF24;
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240cf0c
	if (cr0.eq) goto loc_8240CF0C;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240cf18
	goto loc_8240CF18;
loc_8240CF0C:
	// subf r11,r29,r4
	r11.s64 = ctx.r4.s64 - r29.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_8240CF18:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne cr6,0x8240cf28
	if (!cr6.eq) goto loc_8240CF28;
loc_8240CF24:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240CF28:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240CF30"))) PPC_WEAK_FUNC(sub_8240CF30);
PPC_FUNC_IMPL(__imp__sub_8240CF30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,28
	ctx.r4.s64 = 28;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240cf98
	if (cr0.eq) goto loc_8240CF98;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,26
	ctx.r9.s64 = 26;
	// addi r10,r11,-19592
	ctx.r10.s64 = r11.s64 + -19592;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// b 0x8240cf9c
	goto loc_8240CF9C;
loc_8240CF98:
	// li r31,0
	r31.s64 = 0;
loc_8240CF9C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240cfac
	if (!cr6.eq) goto loc_8240CFAC;
loc_8240CFA4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240d034
	goto loc_8240D034;
loc_8240CFAC:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240cfd8
	if (cr6.eq) goto loc_8240CFD8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq 0x8240cfa4
	if (cr0.eq) goto loc_8240CFA4;
loc_8240CFD8:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240d004
	if (cr6.eq) goto loc_8240D004;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8240cfa4
	if (cr0.eq) goto loc_8240CFA4;
loc_8240D004:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240d030
	if (cr6.eq) goto loc_8240D030;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8240cfa4
	if (cr0.eq) goto loc_8240CFA4;
loc_8240D030:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240D034:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D04C"))) PPC_WEAK_FUNC(sub_8240D04C);
PPC_FUNC_IMPL(__imp__sub_8240D04C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240D050"))) PPC_WEAK_FUNC(sub_8240D050);
PPC_FUNC_IMPL(__imp__sub_8240D050) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,24
	ctx.r4.s64 = 24;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240d0b4
	if (cr0.eq) goto loc_8240D0B4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r10,r11,-19848
	ctx.r10.s64 = r11.s64 + -19848;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// b 0x8240d0b8
	goto loc_8240D0B8;
loc_8240D0B4:
	// li r31,0
	r31.s64 = 0;
loc_8240D0B8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240d0c8
	if (!cr6.eq) goto loc_8240D0C8;
loc_8240D0C0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240d130
	goto loc_8240D130;
loc_8240D0C8:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240d0fc
	if (cr6.eq) goto loc_8240D0FC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// beq 0x8240d0c0
	if (cr0.eq) goto loc_8240D0C0;
loc_8240D0FC:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240d12c
	if (cr6.eq) goto loc_8240D12C;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x8240d130
	if (cr0.eq) goto loc_8240D130;
loc_8240D12C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240D130:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D148"))) PPC_WEAK_FUNC(sub_8240D148);
PPC_FUNC_IMPL(__imp__sub_8240D148) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8240d218
	sub_8240D218(ctx, base);
	// li r5,16
	ctx.r5.s64 = 16;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,24
	ctx.r4.s64 = 24;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240d1ac
	if (cr0.eq) goto loc_8240D1AC;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r9,13
	ctx.r9.s64 = 13;
	// addi r10,r11,-19664
	ctx.r10.s64 = r11.s64 + -19664;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// b 0x8240d1b0
	goto loc_8240D1B0;
loc_8240D1AC:
	// li r31,0
	r31.s64 = 0;
loc_8240D1B0:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240d1c0
	if (!cr6.eq) goto loc_8240D1C0;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240d1fc
	goto loc_8240D1FC;
loc_8240D1C0:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240d1f8
	if (cr6.eq) goto loc_8240D1F8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x8240d1fc
	if (cr0.eq) goto loc_8240D1FC;
loc_8240D1F8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240D1FC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D214"))) PPC_WEAK_FUNC(sub_8240D214);
PPC_FUNC_IMPL(__imp__sub_8240D214) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240D218"))) PPC_WEAK_FUNC(sub_8240D218);
PPC_FUNC_IMPL(__imp__sub_8240D218) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32139
	r11.s64 = -2106261504;
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,-10464(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -10464);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// b 0x826e4b9c
	__imp__KeTlsGetValue(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240D234"))) PPC_WEAK_FUNC(sub_8240D234);
PPC_FUNC_IMPL(__imp__sub_8240D234) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D238"))) PPC_WEAK_FUNC(sub_8240D238);
PPC_FUNC_IMPL(__imp__sub_8240D238) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32126
	r11.s64 = -2105409536;
	// li r28,0
	r28.s64 = 0;
	// addi r30,r11,-29488
	r30.s64 = r11.s64 + -29488;
	// mr r27,r28
	r27.u64 = r28.u64;
	// addi r8,r30,4
	ctx.r8.s64 = r30.s64 + 4;
	// li r31,1
	r31.s64 = 1;
loc_8240D25C:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// cmpw cr6,r10,r28
	cr6.compare<int32_t>(ctx.r10.s32, r28.s32, xer);
	// bne cr6,0x8240d2b0
	if (!cr6.eq) goto loc_8240D2B0;
	// stwcx. r31,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(r31.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8240d25c
	if (!cr0.eq) goto loc_8240D25C;
	// b 0x8240d2b8
	goto loc_8240D2B8;
loc_8240D280:
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x823b5498
	sub_823B5498(ctx, base);
	// addi r8,r30,4
	ctx.r8.s64 = r30.s64 + 4;
loc_8240D28C:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// cmpw cr6,r10,r28
	cr6.compare<int32_t>(ctx.r10.s32, r28.s32, xer);
	// bne cr6,0x8240d2b0
	if (!cr6.eq) goto loc_8240D2B0;
	// stwcx. r31,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(r31.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8240d28c
	if (!cr0.eq) goto loc_8240D28C;
	// b 0x8240d2b8
	goto loc_8240D2B8;
loc_8240D2B0:
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
loc_8240D2B8:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8240d280
	if (cr6.eq) goto loc_8240D280;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r29,-32139
	r29.s64 = -2106261504;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8240d2e0
	if (!cr6.eq) goto loc_8240D2E0;
	// bl 0x826e4b8c
	__imp__KeTlsAlloc(ctx, base);
	// stw r3,-10464(r29)
	PPC_STORE_U32(r29.u32 + -10464, ctx.r3.u32);
	// b 0x8240d2e4
	goto loc_8240D2E4;
loc_8240D2E0:
	// lwz r3,-10464(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + -10464);
loc_8240D2E4:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bne cr6,0x8240d304
	if (!cr6.eq) goto loc_8240D304;
	// lis r27,-32768
	r27.s64 = -2147483648;
	// ori r27,r27,16389
	r27.u64 = r27.u64 | 16389;
	// b 0x8240d358
	goto loc_8240D358;
loc_8240D304:
	// bl 0x826e4b9c
	__imp__KeTlsGetValue(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8240d34c
	if (!cr0.eq) goto loc_8240D34C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8240d330
	if (!cr0.eq) goto loc_8240D330;
	// lis r27,-32761
	r27.s64 = -2147024896;
	// ori r27,r27,14
	r27.u64 = r27.u64 | 14;
	// b 0x8240d358
	goto loc_8240D358;
loc_8240D330:
	// li r5,24
	ctx.r5.s64 = 24;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,-10464(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + -10464);
	// bl 0x826e4bac
	__imp__KeTlsSetValue(ctx, base);
loc_8240D34C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_8240D358:
	// addi r11,r30,4
	r11.s64 = r30.s64 + 4;
loc_8240D35C:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r11
	reserved.u32 = *(uint32_t*)(base + r11.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// stwcx. r28,0,r11
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r11.u32), reserved.s32, __builtin_bswap32(r28.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8240d35c
	if (!cr0.eq) goto loc_8240D35C;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_8240D380"))) PPC_WEAK_FUNC(sub_8240D380);
PPC_FUNC_IMPL(__imp__sub_8240D380) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister reserved{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32126
	r11.s64 = -2105409536;
	// li r29,0
	r29.s64 = 0;
	// addi r30,r11,-29488
	r30.s64 = r11.s64 + -29488;
	// li r31,1
	r31.s64 = 1;
	// addi r8,r30,4
	ctx.r8.s64 = r30.s64 + 4;
loc_8240D3A0:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// cmpw cr6,r10,r29
	cr6.compare<int32_t>(ctx.r10.s32, r29.s32, xer);
	// bne cr6,0x8240d3f4
	if (!cr6.eq) goto loc_8240D3F4;
	// stwcx. r31,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(r31.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8240d3a0
	if (!cr0.eq) goto loc_8240D3A0;
	// b 0x8240d3fc
	goto loc_8240D3FC;
loc_8240D3C4:
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x823b5498
	sub_823B5498(ctx, base);
	// addi r8,r30,4
	ctx.r8.s64 = r30.s64 + 4;
loc_8240D3D0:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r8
	reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// cmpw cr6,r10,r29
	cr6.compare<int32_t>(ctx.r10.s32, r29.s32, xer);
	// bne cr6,0x8240d3f4
	if (!cr6.eq) goto loc_8240D3F4;
	// stwcx. r31,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(r31.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8240d3d0
	if (!cr0.eq) goto loc_8240D3D0;
	// b 0x8240d3fc
	goto loc_8240D3FC;
loc_8240D3F4:
	// stwcx. r10,0,r8
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), reserved.s32, __builtin_bswap32(ctx.r10.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
loc_8240D3FC:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8240d3c4
	if (cr6.eq) goto loc_8240D3C4;
	// lis r31,-32139
	r31.s64 = -2106261504;
	// lwz r3,-10464(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -10464);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8240d44c
	if (cr6.eq) goto loc_8240D44C;
	// bl 0x826e4b9c
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240d448
	if (cr0.eq) goto loc_8240D448;
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// bne 0x8240d448
	if (!cr0.eq) goto loc_8240D448;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,-10464(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -10464);
	// bl 0x826e4bac
	__imp__KeTlsSetValue(ctx, base);
loc_8240D448:
	// lwz r3,-10464(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -10464);
loc_8240D44C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8240d478
	if (!cr6.eq) goto loc_8240D478;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8240d478
	if (cr6.eq) goto loc_8240D478;
	// bl 0x826e4bbc
	__imp__KeTlsFree(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,-10464(r31)
	PPC_STORE_U32(r31.u32 + -10464, r11.u32);
loc_8240D478:
	// addi r11,r30,4
	r11.s64 = r30.s64 + 4;
loc_8240D47C:
	// mfmsr r9
	// mtmsrd r13,1
	// lwarx r10,0,r11
	reserved.u32 = *(uint32_t*)(base + r11.u32);
	ctx.r10.u64 = __builtin_bswap32(reserved.u32);
	// stwcx. r29,0,r11
	cr0.lt = 0;
	cr0.gt = 0;
	cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + r11.u32), reserved.s32, __builtin_bswap32(r29.s32));
	cr0.so = xer.so;
	// mtmsrd r9,1
	// bne 0x8240d47c
	if (!cr0.eq) goto loc_8240D47C;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240D49C"))) PPC_WEAK_FUNC(sub_8240D49C);
PPC_FUNC_IMPL(__imp__sub_8240D49C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240D4A0"))) PPC_WEAK_FUNC(sub_8240D4A0);
PPC_FUNC_IMPL(__imp__sub_8240D4A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8240d4c4
	if (!cr6.eq) goto loc_8240D4C4;
	// addi r30,r1,88
	r30.s64 = ctx.r1.s64 + 88;
loc_8240D4C4:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8240d524
	if (!cr6.eq) goto loc_8240D524;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8240d510
	if (cr6.eq) goto loc_8240D510;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8240d510
	if (cr6.eq) goto loc_8240D510;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8240d4fc
	if (!cr6.eq) goto loc_8240D4FC;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// b 0x8240d51c
	goto loc_8240D51C;
loc_8240D4FC:
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8240d5c8
	if (!cr6.eq) goto loc_8240D5C8;
	// li r11,1
	r11.s64 = 1;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// b 0x8240d51c
	goto loc_8240D51C;
loc_8240D510:
	// li r11,1
	r11.s64 = 1;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
loc_8240D51C:
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// b 0x8240d5c0
	goto loc_8240D5C0;
loc_8240D524:
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x8240d558
	if (!cr6.eq) goto loc_8240D558;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8240d4a0
	sub_8240D4A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240d5d0
	if (cr0.lt) goto loc_8240D5D0;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// b 0x8240d5c0
	goto loc_8240D5C0;
loc_8240D558:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8240d5c8
	if (!cr6.eq) goto loc_8240D5C8;
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_8240D56C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r3,48(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// bl 0x8240d4a0
	sub_8240D4A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240d5d0
	if (cr0.lt) goto loc_8240D5D0;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x8240d5b0
	if (!cr6.gt) goto loc_8240D5B0;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8240D5B0:
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x8240d56c
	if (!cr0.eq) goto loc_8240D56C;
loc_8240D5C0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240d5d0
	goto loc_8240D5D0;
loc_8240D5C8:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8240D5D0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240D5D8"))) PPC_WEAK_FUNC(sub_8240D5D8);
PPC_FUNC_IMPL(__imp__sub_8240D5D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// ld r26,0(r29)
	r26.u64 = PPC_LOAD_U64(r29.u32 + 0);
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// ld r25,8(r29)
	r25.u64 = PPC_LOAD_U64(r29.u32 + 8);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// ld r24,16(r29)
	r24.u64 = PPC_LOAD_U64(r29.u32 + 16);
	// li r9,2
	ctx.r9.s64 = 2;
	// ld r23,24(r29)
	r23.u64 = PPC_LOAD_U64(r29.u32 + 24);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r8,4(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// std r26,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r26.u64);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// std r25,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r25.u64);
	// li r4,1
	ctx.r4.s64 = 1;
	// std r24,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r24.u64);
	// std r23,24(r11)
	PPC_STORE_U64(r11.u32 + 24, r23.u64);
	// li r11,10
	r11.s64 = 10;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// addi r11,r31,2
	r11.s64 = r31.s64 + 2;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// bl 0x82461280
	sub_82461280(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8240d66c
	if (cr0.eq) goto loc_8240D66C;
	// stw r30,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r30.u32);
loc_8240D660:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240D664:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8239bd34
	return;
loc_8240D66C:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,48(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// bl 0x8240d4a0
	sub_8240D4A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240d664
	if (cr0.lt) goto loc_8240D664;
	// mr r11,r31
	r11.u64 = r31.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
	// addi r10,r10,26084
	ctx.r10.s64 = ctx.r10.s64 + 26084;
loc_8240D698:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240d6b8
	if (!cr0.eq) goto loc_8240D6B8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240d698
	if (!cr6.eq) goto loc_8240D698;
loc_8240D6B8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240d728
	if (!cr0.eq) goto loc_8240D728;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8240d6f8
	if (!cr6.eq) goto loc_8240D6F8;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x8240d6f8
	if (!cr6.eq) goto loc_8240D6F8;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8240d6f8
	if (!cr6.eq) goto loc_8240D6F8;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8240d660
	if (cr6.eq) goto loc_8240D660;
loc_8240D6F8:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,2900
	ctx.r5.s64 = 2900;
	// addi r6,r11,-19488
	ctx.r6.s64 = r11.s64 + -19488;
loc_8240D704:
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8240d664
	goto loc_8240D664;
loc_8240D728:
	// mr r11,r31
	r11.u64 = r31.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
	// addi r10,r10,26088
	ctx.r10.s64 = ctx.r10.s64 + 26088;
loc_8240D738:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240d758
	if (!cr0.eq) goto loc_8240D758;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240d738
	if (!cr6.eq) goto loc_8240D738;
loc_8240D758:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240d660
	if (!cr0.eq) goto loc_8240D660;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8240d7a4
	if (!cr6.eq) goto loc_8240D7A4;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x8240d7a4
	if (!cr6.eq) goto loc_8240D7A4;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8240d7a4
	if (!cr6.eq) goto loc_8240D7A4;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x8240d7a4
	if (!cr6.eq) goto loc_8240D7A4;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bge cr6,0x8240d660
	if (!cr6.lt) goto loc_8240D660;
loc_8240D7A4:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,2901
	ctx.r5.s64 = 2901;
	// addi r6,r11,-19576
	ctx.r6.s64 = r11.s64 + -19576;
	// b 0x8240d704
	goto loc_8240D704;
}

__attribute__((alias("__imp__sub_8240D7B4"))) PPC_WEAK_FUNC(sub_8240D7B4);
PPC_FUNC_IMPL(__imp__sub_8240D7B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240D7B8"))) PPC_WEAK_FUNC(sub_8240D7B8);
PPC_FUNC_IMPL(__imp__sub_8240D7B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// li r31,0
	r31.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8240d8d4
	if (!cr6.eq) goto loc_8240D8D4;
	// lwz r28,32(r6)
	r28.u64 = PPC_LOAD_U32(ctx.r6.u32 + 32);
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8240d8c4
	if (!cr6.eq) goto loc_8240D8C4;
	// lis r10,16383
	ctx.r10.s64 = 1073676288;
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8240d814
	if (!cr6.gt) goto loc_8240D814;
	// li r3,-1
	ctx.r3.s64 = -1;
loc_8240D814:
	// bl 0x82354fd8
	sub_82354FD8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x8240d82c
	if (!cr0.eq) goto loc_8240D82C;
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x8240d8c4
	goto loc_8240D8C4;
loc_8240D82C:
	// rlwinm r31,r30,4,0,27
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 4) & 0xFFFFFFF0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240d8a4
	if (cr6.eq) goto loc_8240D8A4;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_8240D84C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8240d898
	if (cr6.eq) goto loc_8240D898;
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
loc_8240D85C:
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// bne cr6,0x8240d87c
	if (!cr6.eq) goto loc_8240D87C;
	// lfd f0,24(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// b 0x8240d888
	goto loc_8240D888;
loc_8240D87C:
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_8240D888:
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8240d85c
	if (!cr0.eq) goto loc_8240D85C;
loc_8240D898:
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r7,r7,16
	ctx.r7.s64 = ctx.r7.s64 + 16;
	// bne 0x8240d84c
	if (!cr0.eq) goto loc_8240D84C;
loc_8240D8A4:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// li r6,6
	ctx.r6.s64 = 6;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8240e360
	sub_8240E360(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_8240D8C4:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821e7b68
	sub_821E7B68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x8240d8d8
	goto loc_8240D8D8;
loc_8240D8D4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240D8D8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_8240D8E0"))) PPC_WEAK_FUNC(sub_8240D8E0);
PPC_FUNC_IMPL(__imp__sub_8240D8E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lis r10,16383
	ctx.r10.s64 = 1073676288;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// ble cr6,0x8240d914
	if (!cr6.gt) goto loc_8240D914;
	// li r3,-1
	ctx.r3.s64 = -1;
loc_8240D914:
	// bl 0x82354fd8
	sub_82354FD8(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x8240d92c
	if (!cr0.eq) goto loc_8240D92C;
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x8240d960
	goto loc_8240D960;
loc_8240D92C:
	// rlwinm r31,r31,4,0,27
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 4) & 0xFFFFFFF0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,6
	ctx.r6.s64 = 6;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8240e360
	sub_8240E360(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_8240D960:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821e7b68
	sub_821E7B68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8240D974"))) PPC_WEAK_FUNC(sub_8240D974);
PPC_FUNC_IMPL(__imp__sub_8240D974) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240D978"))) PPC_WEAK_FUNC(sub_8240D978);
PPC_FUNC_IMPL(__imp__sub_8240D978) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc8
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r20,0
	r20.s64 = 0;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// addi r11,r11,26096
	r11.s64 = r11.s64 + 26096;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r20.u32);
	// mr r16,r7
	r16.u64 = ctx.r7.u64;
	// oris r24,r8,32768
	r24.u64 = ctx.r8.u64 | 2147483648;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
loc_8240D9B4:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240d9d4
	if (!cr0.eq) goto loc_8240D9D4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240d9b4
	if (!cr6.eq) goto loc_8240D9B4;
loc_8240D9D4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r17,1
	r17.s64 = 1;
	// addi r18,r11,26088
	r18.s64 = r11.s64 + 26088;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r19,r11,26084
	r19.s64 = r11.s64 + 26084;
	// beq 0x8240dae0
	if (cr0.eq) goto loc_8240DAE0;
	// mr r11,r19
	r11.u64 = r19.u64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
loc_8240D9FC:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240da1c
	if (!cr0.eq) goto loc_8240DA1C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240d9fc
	if (!cr6.eq) goto loc_8240D9FC;
loc_8240DA1C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8240dae0
	if (cr0.eq) goto loc_8240DAE0;
	// mr r11,r18
	r11.u64 = r18.u64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
loc_8240DA30:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240da50
	if (!cr0.eq) goto loc_8240DA50;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240da30
	if (!cr6.eq) goto loc_8240DA30;
loc_8240DA50:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8240dae0
	if (cr0.eq) goto loc_8240DAE0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// addi r11,r11,26092
	r11.s64 = r11.s64 + 26092;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
loc_8240DA68:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240da88
	if (!cr0.eq) goto loc_8240DA88;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240da68
	if (!cr6.eq) goto loc_8240DA68;
loc_8240DA88:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8240dae0
	if (cr0.eq) goto loc_8240DAE0;
	// li r11,3
	r11.s64 = 3;
	// sth r17,128(r1)
	PPC_STORE_U16(ctx.r1.u32 + 128, r17.u16);
	// li r8,4
	ctx.r8.s64 = 4;
	// sth r17,132(r1)
	PPC_STORE_U16(ctx.r1.u32 + 132, r17.u16);
	// addi r7,r21,12
	ctx.r7.s64 = r21.s64 + 12;
	// sth r17,136(r1)
	PPC_STORE_U16(ctx.r1.u32 + 136, r17.u16);
	// li r6,6
	ctx.r6.s64 = 6;
	// sth r20,138(r1)
	PPC_STORE_U16(ctx.r1.u32 + 138, r20.u16);
	// li r5,16
	ctx.r5.s64 = 16;
	// stw r20,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r20.u32);
	// sth r11,130(r1)
	PPC_STORE_U16(ctx.r1.u32 + 130, r11.u16);
	// li r11,4
	r11.s64 = 4;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// sth r11,134(r1)
	PPC_STORE_U16(ctx.r1.u32 + 134, r11.u16);
	// bl 0x8240e360
	sub_8240E360(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240deb8
	if (cr0.lt) goto loc_8240DEB8;
	// stw r17,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r17.u32);
	// b 0x8240de08
	goto loc_8240DE08;
loc_8240DAE0:
	// li r11,10
	r11.s64 = 10;
	// lwz r8,4(r23)
	ctx.r8.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// addi r26,r25,2
	r26.s64 = r25.s64 + 2;
	// lwz r3,0(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// stw r20,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r20.u32);
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r20,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r20.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r20,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r20.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// stw r26,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r26.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// lwz r3,48(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// bl 0x8240d4a0
	sub_8240D4A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240deb8
	if (cr0.lt) goto loc_8240DEB8;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,64(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8240dd18
	if (cr6.eq) goto loc_8240DD18;
	// rotlwi r30,r10,0
	r30.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mr r29,r20
	r29.u64 = r20.u64;
	// mr r28,r20
	r28.u64 = r20.u64;
	// mr r27,r20
	r27.u64 = r20.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240dc4c
	if (cr0.eq) goto loc_8240DC4C;
loc_8240DB64:
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// bne cr6,0x8240dc34
	if (!cr6.eq) goto loc_8240DC34;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240db88
	if (cr0.eq) goto loc_8240DB88;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_8240DB88:
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// mr r31,r20
	r31.u64 = r20.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240db9c
	if (cr0.eq) goto loc_8240DB9C;
	// lwz r31,24(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_8240DB9C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8240dc0c
	if (cr6.eq) goto loc_8240DC0C;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240dc34
	if (cr0.lt) goto loc_8240DC34;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240dc34
	if (cr6.eq) goto loc_8240DC34;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x8239f330
	sub_8239F330(ctx, base);
	// lbz r11,0(r25)
	r11.u64 = PPC_LOAD_U8(r25.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// bne cr6,0x8240dc34
	if (!cr6.eq) goto loc_8240DC34;
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// bne cr6,0x8240dbf0
	if (!cr6.eq) goto loc_8240DBF0;
	// mr r29,r31
	r29.u64 = r31.u64;
	// b 0x8240dc34
	goto loc_8240DC34;
loc_8240DBF0:
	// xor r10,r11,r24
	ctx.r10.u64 = r11.u64 ^ r24.u64;
	// rlwinm. r10,r10,0,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF0000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240dc34
	if (!cr0.eq) goto loc_8240DC34;
	// clrlwi. r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240dc34
	if (!cr0.eq) goto loc_8240DC34;
	// mr r28,r31
	r28.u64 = r31.u64;
	// b 0x8240dc34
	goto loc_8240DC34;
loc_8240DC0C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240dc34
	if (cr6.eq) goto loc_8240DC34;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x8239f330
	sub_8239F330(ctx, base);
	// lbz r11,0(r25)
	r11.u64 = PPC_LOAD_U8(r25.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// bne cr6,0x8240dc34
	if (!cr6.eq) goto loc_8240DC34;
	// mr r27,r31
	r27.u64 = r31.u64;
loc_8240DC34:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x8240db64
	if (!cr0.eq) goto loc_8240DB64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x8240dc64
	if (!cr6.eq) goto loc_8240DC64;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_8240DC4C:
	// mr r29,r28
	r29.u64 = r28.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x8240dc64
	if (!cr6.eq) goto loc_8240DC64;
	// mr r29,r27
	r29.u64 = r27.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8240dd18
	if (cr6.eq) goto loc_8240DD18;
loc_8240DC64:
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x8239f330
	sub_8239F330(ctx, base);
	// lbz r11,0(r25)
	r11.u64 = PPC_LOAD_U8(r25.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpw cr6,r11,r3
	cr6.compare<int32_t>(r11.s32, ctx.r3.s32, xer);
	// bne cr6,0x8240dd14
	if (!cr6.eq) goto loc_8240DD14;
	// addi r30,r29,1
	r30.s64 = r29.s64 + 1;
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823a1220
	sub_823A1220(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8240dd14
	if (cr0.eq) goto loc_8240DD14;
	// addi r31,r29,2
	r31.s64 = r29.s64 + 2;
	// b 0x8240dca4
	goto loc_8240DCA4;
loc_8240DCA0:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_8240DCA4:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823a1220
	sub_823A1220(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8240dca0
	if (!cr0.eq) goto loc_8240DCA0;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240dd14
	if (!cr6.eq) goto loc_8240DD14;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823a0c30
	sub_823A0C30(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplwi cr6,r8,8191
	cr6.compare<uint32_t>(ctx.r8.u32, 8191, xer);
	// ble cr6,0x8240dd00
	if (!cr6.gt) goto loc_8240DD00;
	// lwz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// addi r6,r11,-19296
	ctx.r6.s64 = r11.s64 + -19296;
	// li r5,2902
	ctx.r5.s64 = 2902;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// b 0x8240ddb0
	goto loc_8240DDB0;
loc_8240DD00:
	// lhz r10,10(r21)
	ctx.r10.u64 = PPC_LOAD_U16(r21.u32 + 10);
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// sth r11,10(r21)
	PPC_STORE_U16(r21.u32 + 10, r11.u16);
loc_8240DD14:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_8240DD18:
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240dd30
	if (cr0.eq) goto loc_8240DD30;
	// lhz r10,10(r21)
	ctx.r10.u64 = PPC_LOAD_U16(r21.u32 + 10);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// sth r10,10(r21)
	PPC_STORE_U16(r21.u32 + 10, ctx.r10.u16);
loc_8240DD30:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne 0x8240ddbc
	if (!cr0.eq) goto loc_8240DDBC;
	// lwz r9,52(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240ddbc
	if (!cr6.eq) goto loc_8240DDBC;
	// lhz r10,10(r21)
	ctx.r10.u64 = PPC_LOAD_U16(r21.u32 + 10);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240dd70
	if (cr0.eq) goto loc_8240DD70;
	// addi r5,r21,16
	ctx.r5.s64 = r21.s64 + 16;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8240d8e0
	sub_8240D8E0(ctx, base);
loc_8240DD64:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240deb8
	if (cr0.lt) goto loc_8240DEB8;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_8240DD70:
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r9,9
	cr6.compare<int32_t>(ctx.r9.s32, 9, xer);
	// bne cr6,0x8240dde8
	if (!cr6.eq) goto loc_8240DDE8;
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// cmpwi cr6,r10,33
	cr6.compare<int32_t>(ctx.r10.s32, 33, xer);
	// bne cr6,0x8240dde8
	if (!cr6.eq) goto loc_8240DDE8;
	// lwz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// addi r6,r11,-19408
	ctx.r6.s64 = r11.s64 + -19408;
	// li r5,2905
	ctx.r5.s64 = 2905;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
loc_8240DDB0:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8240deb8
	goto loc_8240DEB8;
loc_8240DDBC:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8240ddcc
	if (cr6.eq) goto loc_8240DDCC;
	// lwz r6,56(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// b 0x8240ddd0
	goto loc_8240DDD0;
loc_8240DDCC:
	// lwz r6,52(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 52);
loc_8240DDD0:
	// addi r7,r21,16
	ctx.r7.s64 = r21.s64 + 16;
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// bl 0x8240d7b8
	sub_8240D7B8(ctx, base);
	// b 0x8240dd64
	goto loc_8240DD64;
loc_8240DDE8:
	// addi r7,r21,12
	ctx.r7.s64 = r21.s64 + 12;
	// lwz r4,48(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82431f58
	sub_82431F58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240deb8
	if (cr0.lt) goto loc_8240DEB8;
loc_8240DE08:
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// li r6,7
	ctx.r6.s64 = 7;
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8240e360
	sub_8240E360(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240deb8
	if (cr0.lt) goto loc_8240DEB8;
	// mr r11,r19
	r11.u64 = r19.u64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
loc_8240DE38:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240de58
	if (!cr0.eq) goto loc_8240DE58;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240de38
	if (!cr6.eq) goto loc_8240DE38;
loc_8240DE58:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240de68
	if (!cr0.eq) goto loc_8240DE68;
	// sth r20,4(r21)
	PPC_STORE_U16(r21.u32 + 4, r20.u16);
	// b 0x8240deac
	goto loc_8240DEAC;
loc_8240DE68:
	// mr r11,r18
	r11.u64 = r18.u64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
loc_8240DE74:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240de94
	if (!cr0.eq) goto loc_8240DE94;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240de74
	if (!cr6.eq) goto loc_8240DE74;
loc_8240DE94:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240dea4
	if (!cr0.eq) goto loc_8240DEA4;
	// sth r17,4(r21)
	PPC_STORE_U16(r21.u32 + 4, r17.u16);
	// b 0x8240deac
	goto loc_8240DEAC;
loc_8240DEA4:
	// li r11,2
	r11.s64 = 2;
	// sth r11,4(r21)
	PPC_STORE_U16(r21.u32 + 4, r11.u16);
loc_8240DEAC:
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// sth r16,6(r21)
	PPC_STORE_U16(r21.u32 + 6, r16.u16);
	// sth r10,8(r21)
	PPC_STORE_U16(r21.u32 + 8, ctx.r10.u16);
loc_8240DEB8:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x8239bd18
	return;
}

__attribute__((alias("__imp__sub_8240DEC0"))) PPC_WEAK_FUNC(sub_8240DEC0);
PPC_FUNC_IMPL(__imp__sub_8240DEC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,24
	ctx.r4.s64 = 24;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82409410
	sub_82409410(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r10,r11,-19220
	ctx.r10.s64 = r11.s64 + -19220;
	// li r11,0
	r11.s64 = 0;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// stw r11,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r11.u32);
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
	// stw r11,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r11.u32);
	// stw r11,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r11.u32);
	// std r11,16(r31)
	PPC_STORE_U64(r31.u32 + 16, r11.u64);
	// std r11,24(r31)
	PPC_STORE_U64(r31.u32 + 24, r11.u64);
	// std r11,32(r31)
	PPC_STORE_U64(r31.u32 + 32, r11.u64);
	// std r11,40(r31)
	PPC_STORE_U64(r31.u32 + 40, r11.u64);
	// stw r11,68(r31)
	PPC_STORE_U32(r31.u32 + 68, r11.u32);
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// stw r11,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r11.u32);
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240DF40"))) PPC_WEAK_FUNC(sub_8240DF40);
PPC_FUNC_IMPL(__imp__sub_8240DF40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r4,24
	ctx.r4.s64 = 24;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// bl 0x82409410
	sub_82409410(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r31,16
	ctx.r10.s64 = r31.s64 + 16;
	// addi r9,r11,-19220
	ctx.r9.s64 = r11.s64 + -19220;
	// li r11,0
	r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// ld r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// ld r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U64(r30.u32 + 8);
	// std r9,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r9.u64);
	// ld r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U64(r30.u32 + 16);
	// std r9,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r9.u64);
	// ld r9,24(r30)
	ctx.r9.u64 = PPC_LOAD_U64(r30.u32 + 24);
	// std r9,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r9.u64);
	// stw r29,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r29.u32);
	// stw r28,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r28.u32);
	// stw r27,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r27.u32);
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
	// stw r11,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r11.u32);
	// stw r11,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r11.u32);
	// stw r11,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r11.u32);
	// stw r11,68(r31)
	PPC_STORE_U32(r31.u32 + 68, r11.u32);
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// stw r11,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r11.u32);
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_8240DFD4"))) PPC_WEAK_FUNC(sub_8240DFD4);
PPC_FUNC_IMPL(__imp__sub_8240DFD4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240DFD8"))) PPC_WEAK_FUNC(sub_8240DFD8);
PPC_FUNC_IMPL(__imp__sub_8240DFD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240e004
	if (cr0.eq) goto loc_8240E004;
	// bl 0x8240dec0
	sub_8240DEC0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8240e008
	goto loc_8240E008;
loc_8240E004:
	// li r30,0
	r30.s64 = 0;
loc_8240E008:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8240e018
	if (!cr6.eq) goto loc_8240E018;
loc_8240E010:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240e10c
	goto loc_8240E10C;
loc_8240E018:
	// addi r11,r31,16
	r11.s64 = r31.s64 + 16;
	// addi r10,r30,16
	ctx.r10.s64 = r30.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// std r9,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 16);
	// std r9,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	r11.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// std r11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, r11.u64);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// stw r11,52(r30)
	PPC_STORE_U32(r30.u32 + 52, r11.u32);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// stw r11,56(r30)
	PPC_STORE_U32(r30.u32 + 56, r11.u32);
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// stw r11,84(r30)
	PPC_STORE_U32(r30.u32 + 84, r11.u32);
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// stw r11,88(r30)
	PPC_STORE_U32(r30.u32 + 88, r11.u32);
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240e094
	if (cr6.eq) goto loc_8240E094;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,60(r30)
	PPC_STORE_U32(r30.u32 + 60, ctx.r3.u32);
	// beq 0x8240e010
	if (cr0.eq) goto loc_8240E010;
loc_8240E094:
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240e0c0
	if (cr6.eq) goto loc_8240E0C0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,64(r30)
	PPC_STORE_U32(r30.u32 + 64, ctx.r3.u32);
	// beq 0x8240e010
	if (cr0.eq) goto loc_8240E010;
loc_8240E0C0:
	// addi r29,r31,68
	r29.s64 = r31.s64 + 68;
	// li r28,0
	r28.s64 = 0;
	// subf r31,r31,r30
	r31.s64 = r30.s64 - r31.s64;
loc_8240E0CC:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240e0f8
	if (cr6.eq) goto loc_8240E0F8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stwx r3,r31,r29
	PPC_STORE_U32(r31.u32 + r29.u32, ctx.r3.u32);
	// beq 0x8240e010
	if (cr0.eq) goto loc_8240E010;
loc_8240E0F8:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// blt cr6,0x8240e0cc
	if (cr6.lt) goto loc_8240E0CC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8240E10C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8240E114"))) PPC_WEAK_FUNC(sub_8240E114);
PPC_FUNC_IMPL(__imp__sub_8240E114) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240E118"))) PPC_WEAK_FUNC(sub_8240E118);
PPC_FUNC_IMPL(__imp__sub_8240E118) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,25
	ctx.r4.s64 = 25;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82409410
	sub_82409410(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r9,15
	ctx.r9.s64 = 983040;
	// addi r10,r11,-19208
	ctx.r10.s64 = r11.s64 + -19208;
	// li r11,0
	r11.s64 = 0;
	// lis r8,228
	ctx.r8.s64 = 14942208;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r9.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// stw r8,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r8.u32);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240E180"))) PPC_WEAK_FUNC(sub_8240E180);
PPC_FUNC_IMPL(__imp__sub_8240E180) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r4,25
	ctx.r4.s64 = 25;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// bl 0x82409410
	sub_82409410(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// lis r10,15
	ctx.r10.s64 = 983040;
	// stw r29,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r29.u32);
	// addi r11,r11,-19208
	r11.s64 = r11.s64 + -19208;
	// stw r28,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r28.u32);
	// lis r9,228
	ctx.r9.s64 = 14942208;
	// stw r27,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r27.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r26,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r26.u32);
	// stw r10,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r10.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r9,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r9.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8240E1E8"))) PPC_WEAK_FUNC(sub_8240E1E8);
PPC_FUNC_IMPL(__imp__sub_8240E1E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240e21c
	if (cr0.eq) goto loc_8240E21C;
	// bl 0x8240e118
	sub_8240E118(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8240e220
	goto loc_8240E220;
loc_8240E21C:
	// li r31,0
	r31.s64 = 0;
loc_8240E220:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240e230
	if (!cr6.eq) goto loc_8240E230;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240e294
	goto loc_8240E294;
loc_8240E230:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240e290
	if (cr6.eq) goto loc_8240E290;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq 0x8240e294
	if (cr0.eq) goto loc_8240E294;
loc_8240E290:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8240E294:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240E2AC"))) PPC_WEAK_FUNC(sub_8240E2AC);
PPC_FUNC_IMPL(__imp__sub_8240E2AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240E2B0"))) PPC_WEAK_FUNC(sub_8240E2B0);
PPC_FUNC_IMPL(__imp__sub_8240E2B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// addi r11,r3,8
	r11.s64 = ctx.r3.s64 + 8;
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240E2CC"))) PPC_WEAK_FUNC(sub_8240E2CC);
PPC_FUNC_IMPL(__imp__sub_8240E2CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240E2D0"))) PPC_WEAK_FUNC(sub_8240E2D0);
PPC_FUNC_IMPL(__imp__sub_8240E2D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// rlwinm r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r3,r11,2
	ctx.r3.s64 = r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240E2E4"))) PPC_WEAK_FUNC(sub_8240E2E4);
PPC_FUNC_IMPL(__imp__sub_8240E2E4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240E2E8"))) PPC_WEAK_FUNC(sub_8240E2E8);
PPC_FUNC_IMPL(__imp__sub_8240E2E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8240e33c
	goto loc_8240E33C;
loc_8240E304:
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240e324
	if (!cr0.eq) goto loc_8240E324;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240e330
	if (!cr0.eq) goto loc_8240E330;
loc_8240E324:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
loc_8240E330:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
loc_8240E33C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240e304
	if (!cr6.eq) goto loc_8240E304;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240E360"))) PPC_WEAK_FUNC(sub_8240E360);
PPC_FUNC_IMPL(__imp__sub_8240E360) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r25,r8
	r25.u64 = ctx.r8.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8240e3a0
	if (cr6.eq) goto loc_8240E3A0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x8240e3a0
	if (!cr6.eq) goto loc_8240E3A0;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8240e548
	goto loc_8240E548;
loc_8240E3A0:
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// bne cr6,0x8240e3d0
	if (!cr6.eq) goto loc_8240E3D0;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8240E3B0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240e3b0
	if (!cr6.eq) goto loc_8240E3B0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
loc_8240E3D0:
	// clrlwi. r11,r27,31
	r11.u64 = r27.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240e3dc
	if (!cr0.eq) goto loc_8240E3DC;
	// ori r27,r27,2
	r27.u64 = r27.u64 | 2;
loc_8240E3DC:
	// rlwinm. r11,r27,0,30,30
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240e450
	if (cr0.eq) goto loc_8240E450;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// b 0x8240e448
	goto loc_8240E448;
loc_8240E3EC:
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240e444
	if (cr0.eq) goto loc_8240E444;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x8240e444
	if (!cr6.eq) goto loc_8240E444;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// mr r11,r28
	r11.u64 = r28.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x8240e43c
	if (cr0.eq) goto loc_8240E43C;
	// add r7,r11,r30
	ctx.r7.u64 = r11.u64 + r30.u64;
loc_8240E41C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r9,r6,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r6.s64;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8240e43c
	if (!cr0.eq) goto loc_8240E43C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r7
	cr6.compare<int32_t>(r11.s32, ctx.r7.s32, xer);
	// bne cr6,0x8240e41c
	if (!cr6.eq) goto loc_8240E41C;
loc_8240E43C:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8240e470
	if (cr0.eq) goto loc_8240E470;
loc_8240E444:
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
loc_8240E448:
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne 0x8240e3ec
	if (!cr0.eq) goto loc_8240E3EC;
loc_8240E450:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8240e4a0
	if (!cr0.eq) goto loc_8240E4A0;
loc_8240E464:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8240e548
	goto loc_8240E548;
loc_8240E470:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8240e480
	if (cr6.eq) goto loc_8240E480;
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
loc_8240E480:
	// clrlwi. r11,r27,31
	r11.u64 = r27.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240e544
	if (cr0.eq) goto loc_8240E544;
	// rlwinm. r11,r27,0,28,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240e544
	if (cr0.eq) goto loc_8240E544;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// b 0x8240e544
	goto loc_8240E544;
loc_8240E4A0:
	// clrlwi. r11,r27,31
	r11.u64 = r27.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240e4e0
	if (!cr0.eq) goto loc_8240E4E0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// bne 0x8240e4d0
	if (!cr0.eq) goto loc_8240E4D0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// b 0x8240e464
	goto loc_8240E464;
loc_8240E4D0:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// b 0x8240e4e4
	goto loc_8240E4E4;
loc_8240E4E0:
	// stw r28,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r28.u32);
loc_8240E4E4:
	// rlwinm. r11,r27,0,29,29
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240e4fc
	if (!cr0.eq) goto loc_8240E4FC;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// rlwinm r11,r11,0,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
loc_8240E4FC:
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r11,r31,16
	r11.s64 = r31.s64 + 16;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r27,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r27.u32);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// stw r25,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r25.u32);
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// lwz r9,12(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + r30.u64;
	// stw r10,4(r29)
	PPC_STORE_U32(r29.u32 + 4, ctx.r10.u32);
	// stw r31,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r31.u32);
	// stw r11,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r11.u32);
	// beq cr6,0x8240e544
	if (cr6.eq) goto loc_8240E544;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
loc_8240E544:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240E548:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_8240E550"))) PPC_WEAK_FUNC(sub_8240E550);
PPC_FUNC_IMPL(__imp__sub_8240E550) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// cmpwi cr6,r28,-1
	cr6.compare<int32_t>(r28.s32, -1, xer);
	// rlwinm r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// bne cr6,0x8240e5a8
	if (!cr6.eq) goto loc_8240E5A8;
	// addi r28,r11,2
	r28.s64 = r11.s64 + 2;
loc_8240E578:
	// cmplwi cr6,r28,32768
	cr6.compare<uint32_t>(r28.u32, 32768, xer);
	// bgt cr6,0x8240e5b4
	if (cr6.gt) goto loc_8240E5B4;
	// addi r11,r28,-1
	r11.s64 = r28.s64 + -1;
	// addi r30,r4,8
	r30.s64 = ctx.r4.s64 + 8;
	// rlwinm r11,r11,16,1,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0x7FFF0000;
	// li r29,0
	r29.s64 = 0;
	// ori r11,r11,65534
	r11.u64 = r11.u64 | 65534;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, r11.u32);
	// lwz r31,8(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// b 0x8240e610
	goto loc_8240E610;
loc_8240E5A8:
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// bge cr6,0x8240e578
	if (!cr6.lt) goto loc_8240E578;
loc_8240E5B4:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8240e634
	goto loc_8240E634;
loc_8240E5C0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240e5f0
	if (!cr0.eq) goto loc_8240E5F0;
	// addi r11,r29,3
	r11.s64 = r29.s64 + 3;
	// li r4,171
	ctx.r4.s64 = 171;
	// rlwinm r11,r11,0,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// subf r27,r29,r11
	r27.s64 = r11.s64 - r29.s64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// add r30,r27,r30
	r30.u64 = r27.u64 + r30.u64;
	// add r29,r27,r29
	r29.u64 = r27.u64 + r29.u64;
loc_8240E5F0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r31,16(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
loc_8240E610:
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x8240e5c0
	if (!cr0.eq) goto loc_8240E5C0;
	// addi r11,r28,-2
	r11.s64 = r28.s64 + -2;
	// li r4,171
	ctx.r4.s64 = 171;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// subf r5,r29,r11
	ctx.r5.s64 = r11.s64 - r29.s64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240E634:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_8240E63C"))) PPC_WEAK_FUNC(sub_8240E63C);
PPC_FUNC_IMPL(__imp__sub_8240E63C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240E640"))) PPC_WEAK_FUNC(sub_8240E640);
PPC_FUNC_IMPL(__imp__sub_8240E640) {
	PPC_FUNC_PROLOGUE();
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x8240e550
	sub_8240E550(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240E648"))) PPC_WEAK_FUNC(sub_8240E648);
PPC_FUNC_IMPL(__imp__sub_8240E648) {
	PPC_FUNC_PROLOGUE();
	// li r6,1
	ctx.r6.s64 = 1;
	// b 0x8240e550
	sub_8240E550(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240E650"))) PPC_WEAK_FUNC(sub_8240E650);
PPC_FUNC_IMPL(__imp__sub_8240E650) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8240e660
	if (cr6.eq) goto loc_8240E660;
	// li r11,1
	r11.s64 = 1;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_8240E660:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240E668"))) PPC_WEAK_FUNC(sub_8240E668);
PPC_FUNC_IMPL(__imp__sub_8240E668) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r10,r3,1
	ctx.r10.s64 = ctx.r3.s64 + 1;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,111
	cr6.compare<int32_t>(r11.s32, 111, xer);
	// beq cr6,0x8240e694
	if (cr6.eq) goto loc_8240E694;
	// cmpwi cr6,r11,114
	cr6.compare<int32_t>(r11.s32, 114, xer);
	// beq cr6,0x8240e68c
	if (cr6.eq) goto loc_8240E68C;
	// cmpwi cr6,r11,101
	cr6.compare<int32_t>(r11.s32, 101, xer);
	// bne cr6,0x8240e754
	if (!cr6.eq) goto loc_8240E754;
loc_8240E68C:
	// cmpwi cr6,r11,111
	cr6.compare<int32_t>(r11.s32, 111, xer);
	// bne cr6,0x8240e718
	if (!cr6.eq) goto loc_8240E718;
loc_8240E694:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r9,r11,-8504
	ctx.r9.s64 = r11.s64 + -8504;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8240E6A0:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x8240e6c4
	if (cr0.eq) goto loc_8240E6C4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x8240e6a0
	if (cr6.eq) goto loc_8240E6A0;
loc_8240E6C4:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8240e77c
	if (cr0.eq) goto loc_8240E77C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r9,r11,-8508
	ctx.r9.s64 = r11.s64 + -8508;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8240E6D8:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x8240e6fc
	if (cr0.eq) goto loc_8240E6FC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x8240e6d8
	if (cr6.eq) goto loc_8240E6D8;
loc_8240E6FC:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8240e77c
	if (cr0.eq) goto loc_8240E77C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,67
	cr6.compare<uint32_t>(r11.u32, 67, xer);
	// bne cr6,0x8240e770
	if (!cr6.eq) goto loc_8240E770;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// b 0x8240e770
	goto loc_8240E770;
loc_8240E718:
	// cmpwi cr6,r11,101
	cr6.compare<int32_t>(r11.s32, 101, xer);
	// bne cr6,0x8240e770
	if (!cr6.eq) goto loc_8240E770;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,65
	cr6.compare<int32_t>(r11.s32, 65, xer);
	// bne cr6,0x8240e74c
	if (!cr6.eq) goto loc_8240E74C;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// blr 
	return;
loc_8240E74C:
	// cmpwi cr6,r11,77
	cr6.compare<int32_t>(r11.s32, 77, xer);
	// beq cr6,0x8240e770
	if (cr6.eq) goto loc_8240E770;
loc_8240E754:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_8240E75C:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r11,48
	cr6.compare<int32_t>(r11.s32, 48, xer);
	// blt cr6,0x8240e754
	if (cr6.lt) goto loc_8240E754;
	// cmpwi cr6,r11,57
	cr6.compare<int32_t>(r11.s32, 57, xer);
	// bgt cr6,0x8240e754
	if (cr6.gt) goto loc_8240E754;
loc_8240E770:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb. r11,r11
	r11.s64 = r11.s8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240e75c
	if (!cr0.eq) goto loc_8240E75C;
loc_8240E77C:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240E784"))) PPC_WEAK_FUNC(sub_8240E784);
PPC_FUNC_IMPL(__imp__sub_8240E784) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240E788"))) PPC_WEAK_FUNC(sub_8240E788);
PPC_FUNC_IMPL(__imp__sub_8240E788) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x823e4de0
	sub_823E4DE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240e7bc
	if (cr0.lt) goto loc_8240E7BC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8240e7bc
	if (!cr6.eq) goto loc_8240E7BC;
	// li r11,2
	r11.s64 = 2;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_8240E7BC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240E7D0"))) PPC_WEAK_FUNC(sub_8240E7D0);
PPC_FUNC_IMPL(__imp__sub_8240E7D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8240ec4c
	if (!cr6.eq) goto loc_8240EC4C;
	// lwz r4,8(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8240E7FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240e7fc
	if (!cr6.eq) goto loc_8240E7FC;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// cmplwi cr6,r11,20
	cr6.compare<uint32_t>(r11.u32, 20, xer);
	// bge cr6,0x8240ec4c
	if (!cr6.lt) goto loc_8240EC4C;
	// addi r5,r11,1
	ctx.r5.s64 = r11.s64 + 1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// addi r31,r1,80
	r31.s64 = ctx.r1.s64 + 80;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240e860
	if (cr0.eq) goto loc_8240E860;
loc_8240E83C:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823a1200
	sub_823A1200(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8240e860
	if (cr0.eq) goto loc_8240E860;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240e83c
	if (!cr6.eq) goto loc_8240E83C;
loc_8240E860:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240e87c
	if (cr6.eq) goto loc_8240E87C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823a0c30
	sub_823A0C30(ctx, base);
	// b 0x8240e880
	goto loc_8240E880;
loc_8240E87C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8240E880:
	// cmplwi cr6,r3,15
	cr6.compare<uint32_t>(ctx.r3.u32, 15, xer);
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
	// bgt cr6,0x8240ec4c
	if (cr6.gt) goto loc_8240EC4C;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240e8b0
	if (cr6.eq) goto loc_8240E8B0;
	// stb r30,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r30.u8);
	// b 0x8240e8ac
	goto loc_8240E8AC;
loc_8240E8A0:
	// bl 0x823a1220
	sub_823A1220(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8240e8bc
	if (cr0.eq) goto loc_8240E8BC;
loc_8240E8AC:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_8240E8B0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb. r3,r11
	ctx.r3.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8240e8a0
	if (!cr0.eq) goto loc_8240E8A0;
loc_8240E8BC:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240ec4c
	if (!cr6.eq) goto loc_8240EC4C;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
	// addi r10,r11,-11332
	ctx.r10.s64 = r11.s64 + -11332;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240E8D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240e8fc
	if (cr0.eq) goto loc_8240E8FC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240e8d8
	if (cr6.eq) goto loc_8240E8D8;
loc_8240E8FC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240e90c
	if (!cr0.eq) goto loc_8240E90C;
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
	// b 0x8240ec44
	goto loc_8240EC44;
loc_8240E90C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28164
	ctx.r10.s64 = r11.s64 + 28164;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240E918:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240e93c
	if (cr0.eq) goto loc_8240E93C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240e918
	if (cr6.eq) goto loc_8240E918;
loc_8240E93C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240e94c
	if (!cr0.eq) goto loc_8240E94C;
	// li r11,1
	r11.s64 = 1;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240E94C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28176
	ctx.r10.s64 = r11.s64 + 28176;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240E958:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240e97c
	if (cr0.eq) goto loc_8240E97C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240e958
	if (cr6.eq) goto loc_8240E958;
loc_8240E97C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240e98c
	if (!cr0.eq) goto loc_8240E98C;
	// li r11,2
	r11.s64 = 2;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240E98C:
	// lis r11,-32252
	r11.s64 = -2113667072;
	// addi r10,r11,6212
	ctx.r10.s64 = r11.s64 + 6212;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240E998:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240e9bc
	if (cr0.eq) goto loc_8240E9BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240e998
	if (cr6.eq) goto loc_8240E998;
loc_8240E9BC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240e9cc
	if (!cr0.eq) goto loc_8240E9CC;
	// li r11,3
	r11.s64 = 3;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240E9CC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28192
	ctx.r10.s64 = r11.s64 + 28192;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240E9D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240e9fc
	if (cr0.eq) goto loc_8240E9FC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240e9d8
	if (cr6.eq) goto loc_8240E9D8;
loc_8240E9FC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240ea0c
	if (!cr0.eq) goto loc_8240EA0C;
	// li r11,4
	r11.s64 = 4;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240EA0C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,14832
	ctx.r10.s64 = r11.s64 + 14832;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EA18:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240ea3c
	if (cr0.eq) goto loc_8240EA3C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240ea18
	if (cr6.eq) goto loc_8240EA18;
loc_8240EA3C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240ea4c
	if (!cr0.eq) goto loc_8240EA4C;
	// li r11,5
	r11.s64 = 5;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240EA4C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28200
	ctx.r10.s64 = r11.s64 + 28200;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EA58:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240ea7c
	if (cr0.eq) goto loc_8240EA7C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240ea58
	if (cr6.eq) goto loc_8240EA58;
loc_8240EA7C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240ea8c
	if (!cr0.eq) goto loc_8240EA8C;
	// li r11,6
	r11.s64 = 6;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240EA8C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28208
	ctx.r10.s64 = r11.s64 + 28208;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EA98:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240eabc
	if (cr0.eq) goto loc_8240EABC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240ea98
	if (cr6.eq) goto loc_8240EA98;
loc_8240EABC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240eacc
	if (!cr0.eq) goto loc_8240EACC;
	// li r11,7
	r11.s64 = 7;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240EACC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28220
	ctx.r10.s64 = r11.s64 + 28220;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EAD8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240eafc
	if (cr0.eq) goto loc_8240EAFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240ead8
	if (cr6.eq) goto loc_8240EAD8;
loc_8240EAFC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240eb0c
	if (!cr0.eq) goto loc_8240EB0C;
	// li r11,8
	r11.s64 = 8;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240EB0C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28232
	ctx.r10.s64 = r11.s64 + 28232;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EB18:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240eb3c
	if (cr0.eq) goto loc_8240EB3C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240eb18
	if (cr6.eq) goto loc_8240EB18;
loc_8240EB3C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8240ec4c
	if (cr0.eq) goto loc_8240EC4C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r10,r11,19376
	ctx.r10.s64 = r11.s64 + 19376;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EB50:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240eb74
	if (cr0.eq) goto loc_8240EB74;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240eb50
	if (cr6.eq) goto loc_8240EB50;
loc_8240EB74:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240eb84
	if (!cr0.eq) goto loc_8240EB84;
	// li r11,10
	r11.s64 = 10;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240EB84:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28316
	ctx.r10.s64 = r11.s64 + 28316;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EB90:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240ebb4
	if (cr0.eq) goto loc_8240EBB4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240eb90
	if (cr6.eq) goto loc_8240EB90;
loc_8240EBB4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240ebc4
	if (!cr0.eq) goto loc_8240EBC4;
	// li r11,11
	r11.s64 = 11;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240EBC4:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,2992
	ctx.r10.s64 = r11.s64 + 2992;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EBD0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240ebf4
	if (cr0.eq) goto loc_8240EBF4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240ebd0
	if (cr6.eq) goto loc_8240EBD0;
loc_8240EBF4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240ec04
	if (!cr0.eq) goto loc_8240EC04;
	// li r11,12
	r11.s64 = 12;
	// b 0x8240ec40
	goto loc_8240EC40;
loc_8240EC04:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r10,r11,-32680
	ctx.r10.s64 = r11.s64 + -32680;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
loc_8240EC10:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240ec34
	if (cr0.eq) goto loc_8240EC34;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240ec10
	if (cr6.eq) goto loc_8240EC10;
loc_8240EC34:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240ec4c
	if (!cr0.eq) goto loc_8240EC4C;
	// li r11,13
	r11.s64 = 13;
loc_8240EC40:
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_8240EC44:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8240ec50
	goto loc_8240EC50;
loc_8240EC4C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240EC50:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8240EC58"))) PPC_WEAK_FUNC(sub_8240EC58);
PPC_FUNC_IMPL(__imp__sub_8240EC58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8240ec80
	if (cr6.eq) goto loc_8240EC80;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// b 0x8240ecb4
	goto loc_8240ECB4;
loc_8240EC80:
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// li r30,1
	r30.s64 = 1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8240ecac
	if (!cr6.eq) goto loc_8240ECAC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,12304
	ctx.r6.s64 = r11.s64 + 12304;
	// addi r4,r31,16
	ctx.r4.s64 = r31.s64 + 16;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// stw r30,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r30.u32);
loc_8240ECAC:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r30.u32);
loc_8240ECB4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240ECCC"))) PPC_WEAK_FUNC(sub_8240ECCC);
PPC_FUNC_IMPL(__imp__sub_8240ECCC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240ECD0"))) PPC_WEAK_FUNC(sub_8240ECD0);
PPC_FUNC_IMPL(__imp__sub_8240ECD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8240ECF0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240ecf0
	if (!cr6.eq) goto loc_8240ECF0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r30,r11,0
	r30.u64 = __builtin_rotateleft32(r11.u32, 0);
	// b 0x8240ed50
	goto loc_8240ED50;
loc_8240ED10:
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8240ED18:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240ed18
	if (!cr6.eq) goto loc_8240ED18;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x8240ed4c
	if (!cr6.eq) goto loc_8240ED4C;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8240ed74
	if (cr0.eq) goto loc_8240ED74;
loc_8240ED4C:
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
loc_8240ED50:
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne 0x8240ed10
	if (!cr0.eq) goto loc_8240ED10;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// li r11,-1
	r11.s64 = -1;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8240ED68:
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
loc_8240ED74:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240ed68
	goto loc_8240ED68;
}

__attribute__((alias("__imp__sub_8240ED80"))) PPC_WEAK_FUNC(sub_8240ED80);
PPC_FUNC_IMPL(__imp__sub_8240ED80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// rlwinm r5,r29,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 3) & 0xFFFFFFF8;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8240ee10
	if (cr0.eq) goto loc_8240EE10;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_8240EDB0:
	// subf r11,r7,r8
	r11.s64 = ctx.r8.s64 - ctx.r7.s64;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// blt cr6,0x8240ee10
	if (cr6.lt) goto loc_8240EE10;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq 0x8240edf4
	if (cr0.eq) goto loc_8240EDF4;
	// add r6,r11,r5
	ctx.r6.u64 = r11.u64 + ctx.r5.u64;
loc_8240EDD4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r28,0(r10)
	r28.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r9,r28,r9
	ctx.r9.s64 = ctx.r9.s64 - r28.s64;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8240edf4
	if (!cr0.eq) goto loc_8240EDF4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r6
	cr6.compare<int32_t>(r11.s32, ctx.r6.s32, xer);
	// bne cr6,0x8240edd4
	if (!cr6.eq) goto loc_8240EDD4;
loc_8240EDF4:
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8240ee3c
	if (cr0.eq) goto loc_8240EE3C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r4,r4,8
	ctx.r4.s64 = ctx.r4.s64 + 8;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x8240edb0
	if (cr6.lt) goto loc_8240EDB0;
loc_8240EE10:
	// rlwinm r11,r8,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_8240EE34:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
loc_8240EE3C:
	// rlwinm r11,r7,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r31
	ctx.r3.u64 = r11.u64 + r31.u64;
	// b 0x8240ee34
	goto loc_8240EE34;
}

__attribute__((alias("__imp__sub_8240EE48"))) PPC_WEAK_FUNC(sub_8240EE48);
PPC_FUNC_IMPL(__imp__sub_8240EE48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r30{};
	PPCRegister r31{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lwz r31,0(r5)
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x8240eeb0
	if (cr0.eq) goto loc_8240EEB0;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
loc_8240EE68:
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// addi r7,r10,16
	ctx.r7.s64 = ctx.r10.s64 + 16;
loc_8240EE74:
	// lbz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r30,0(r9)
	r30.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r6,r30,r6
	ctx.r6.s64 = ctx.r6.s64 - r30.s64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x8240ee94
	if (!cr0.eq) goto loc_8240EE94;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r10,r7
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r7.s32, xer);
	// bne cr6,0x8240ee74
	if (!cr6.eq) goto loc_8240EE74;
loc_8240EE94:
	// cmpwi r6,0
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x8240eef0
	if (cr0.eq) goto loc_8240EEF0;
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r8,r8,16
	ctx.r8.s64 = ctx.r8.s64 + 16;
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// blt cr6,0x8240ee68
	if (cr6.lt) goto loc_8240EE68;
loc_8240EEB0:
	// rlwinm r10,r31,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 4) & 0xFFFFFFF0;
	// add r3,r10,r4
	ctx.r3.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
loc_8240EEE4:
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
loc_8240EEF0:
	// rlwinm r11,r3,4,0,27
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 4) & 0xFFFFFFF0;
	// add r3,r11,r4
	ctx.r3.u64 = r11.u64 + ctx.r4.u64;
	// b 0x8240eee4
	goto loc_8240EEE4;
}

__attribute__((alias("__imp__sub_8240EEFC"))) PPC_WEAK_FUNC(sub_8240EEFC);
PPC_FUNC_IMPL(__imp__sub_8240EEFC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240EF00"))) PPC_WEAK_FUNC(sub_8240EF00);
PPC_FUNC_IMPL(__imp__sub_8240EF00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r7,8(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x8240f060
	if (cr0.eq) goto loc_8240F060;
	// lbz r11,0(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240f060
	if (cr6.eq) goto loc_8240F060;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r10,r11,-1520
	ctx.r10.s64 = r11.s64 + -1520;
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
loc_8240EF3C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240ef60
	if (cr0.eq) goto loc_8240EF60;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240ef3c
	if (cr6.eq) goto loc_8240EF3C;
loc_8240EF60:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240ef70
	if (!cr0.eq) goto loc_8240EF70;
	// li r3,4095
	ctx.r3.s64 = 4095;
	// b 0x8240f064
	goto loc_8240F064;
loc_8240EF70:
	// li r3,0
	ctx.r3.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
	// li r31,1
	r31.s64 = 1;
loc_8240EF80:
	// cmplwi cr6,r10,12
	cr6.compare<uint32_t>(ctx.r10.u32, 12, xer);
	// bge cr6,0x8240f040
	if (!cr6.lt) goto loc_8240F040;
	// lbz r11,0(r9)
	r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,103
	cr6.compare<int32_t>(r11.s32, 103, xer);
	// bgt cr6,0x8240efe0
	if (cr6.gt) goto loc_8240EFE0;
	// beq cr6,0x8240f010
	if (cr6.eq) goto loc_8240F010;
	// cmpwi cr6,r11,48
	cr6.compare<int32_t>(r11.s32, 48, xer);
	// beq cr6,0x8240efd8
	if (cr6.eq) goto loc_8240EFD8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// beq cr6,0x8240efd0
	if (cr6.eq) goto loc_8240EFD0;
	// cmpwi cr6,r11,95
	cr6.compare<int32_t>(r11.s32, 95, xer);
	// beq cr6,0x8240efc4
	if (cr6.eq) goto loc_8240EFC4;
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// beq cr6,0x8240f018
	if (cr6.eq) goto loc_8240F018;
	// cmpwi cr6,r11,98
	cr6.compare<int32_t>(r11.s32, 98, xer);
	// b 0x8240f004
	goto loc_8240F004;
loc_8240EFC4:
	// li r11,7
	r11.s64 = 7;
loc_8240EFC8:
	// slw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
	// b 0x8240f024
	goto loc_8240F024;
loc_8240EFD0:
	// li r11,6
	r11.s64 = 6;
	// b 0x8240efc8
	goto loc_8240EFC8;
loc_8240EFD8:
	// li r11,5
	r11.s64 = 5;
	// b 0x8240efc8
	goto loc_8240EFC8;
loc_8240EFE0:
	// cmpwi cr6,r11,114
	cr6.compare<int32_t>(r11.s32, 114, xer);
	// beq cr6,0x8240f020
	if (cr6.eq) goto loc_8240F020;
	// cmpwi cr6,r11,119
	cr6.compare<int32_t>(r11.s32, 119, xer);
	// beq cr6,0x8240f018
	if (cr6.eq) goto loc_8240F018;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// beq cr6,0x8240f020
	if (cr6.eq) goto loc_8240F020;
	// cmpwi cr6,r11,121
	cr6.compare<int32_t>(r11.s32, 121, xer);
	// beq cr6,0x8240f010
	if (cr6.eq) goto loc_8240F010;
	// cmpwi cr6,r11,122
	cr6.compare<int32_t>(r11.s32, 122, xer);
loc_8240F004:
	// bne cr6,0x8240f040
	if (!cr6.eq) goto loc_8240F040;
	// li r11,3
	r11.s64 = 3;
	// b 0x8240efc8
	goto loc_8240EFC8;
loc_8240F010:
	// li r11,2
	r11.s64 = 2;
	// b 0x8240efc8
	goto loc_8240EFC8;
loc_8240F018:
	// li r11,4
	r11.s64 = 4;
	// b 0x8240efc8
	goto loc_8240EFC8;
loc_8240F020:
	// slw r11,r31,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r31.u32 << (ctx.r10.u8 & 0x3F));
loc_8240F024:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// or r3,r11,r3
	ctx.r3.u64 = r11.u64 | ctx.r3.u64;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// lbz r11,0(r9)
	r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240ef80
	if (!cr6.eq) goto loc_8240EF80;
	// b 0x8240f064
	goto loc_8240F064;
loc_8240F040:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r5,2003
	ctx.r5.s64 = 2003;
	// addi r6,r11,25612
	ctx.r6.s64 = r11.s64 + 25612;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,52(r30)
	PPC_STORE_U32(r30.u32 + 52, r31.u32);
	// b 0x8240f064
	goto loc_8240F064;
loc_8240F060:
	// li r3,2257
	ctx.r3.s64 = 2257;
loc_8240F064:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F07C"))) PPC_WEAK_FUNC(sub_8240F07C);
PPC_FUNC_IMPL(__imp__sub_8240F07C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240F080"))) PPC_WEAK_FUNC(sub_8240F080);
PPC_FUNC_IMPL(__imp__sub_8240F080) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r3,0
	ctx.r3.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
loc_8240F090:
	// srw r11,r4,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r4.u32 >> (ctx.r10.u8 & 0x3F));
	// clrlwi r11,r11,29
	r11.u64 = r11.u32 & 0x7;
	// addi r7,r11,-1
	ctx.r7.s64 = r11.s64 + -1;
	// cmplwi cr6,r7,3
	cr6.compare<uint32_t>(ctx.r7.u32, 3, xer);
	// bgt cr6,0x8240f0c0
	if (cr6.gt) goto loc_8240F0C0;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// ble cr6,0x8240f0f0
	if (!cr6.gt) goto loc_8240F0F0;
	// mulli r9,r11,3
	ctx.r9.s64 = r11.s64 * 3;
	// addi r7,r9,-3
	ctx.r7.s64 = ctx.r9.s64 + -3;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// slw r11,r11,r7
	r11.u64 = ctx.r7.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r7.u8 & 0x3F));
	// b 0x8240f0d8
	goto loc_8240F0D8;
loc_8240F0C0:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8240f0d4
	if (cr6.eq) goto loc_8240F0D4;
	// cmpw cr6,r8,r9
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, xer);
	// bne cr6,0x8240f0f0
	if (!cr6.eq) goto loc_8240F0F0;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
loc_8240F0D4:
	// slw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
loc_8240F0D8:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// or r3,r11,r3
	ctx.r3.u64 = r11.u64 | ctx.r3.u64;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmpwi cr6,r10,12
	cr6.compare<int32_t>(ctx.r10.s32, 12, xer);
	// blt cr6,0x8240f090
	if (cr6.lt) goto loc_8240F090;
	// blr 
	return;
loc_8240F0F0:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F0F8"))) PPC_WEAK_FUNC(sub_8240F0F8);
PPC_FUNC_IMPL(__imp__sub_8240F0F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r7,8(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x8240f1e8
	if (cr0.eq) goto loc_8240F1E8;
	// lbz r11,0(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240f1e8
	if (cr6.eq) goto loc_8240F1E8;
	// li r9,0
	ctx.r9.s64 = 0;
loc_8240F134:
	// lbz r11,0(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb. r11,r11
	r11.s64 = r11.s8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240f174
	if (cr0.eq) goto loc_8240F174;
	// cmpwi cr6,r11,119
	cr6.compare<int32_t>(r11.s32, 119, xer);
	// bgt cr6,0x8240f1c0
	if (cr6.gt) goto loc_8240F1C0;
	// beq cr6,0x8240f1b8
	if (cr6.eq) goto loc_8240F1B8;
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// beq cr6,0x8240f1b8
	if (cr6.eq) goto loc_8240F1B8;
	// cmpwi cr6,r11,98
	cr6.compare<int32_t>(r11.s32, 98, xer);
	// beq cr6,0x8240f1d8
	if (cr6.eq) goto loc_8240F1D8;
	// cmpwi cr6,r11,103
	cr6.compare<int32_t>(r11.s32, 103, xer);
	// beq cr6,0x8240f1e0
	if (cr6.eq) goto loc_8240F1E0;
	// cmpwi cr6,r11,114
	cr6.compare<int32_t>(r11.s32, 114, xer);
	// bne cr6,0x8240f194
	if (!cr6.eq) goto loc_8240F194;
loc_8240F16C:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8240F170:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_8240F174:
	// slw r11,r10,r9
	r11.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// or r3,r11,r3
	ctx.r3.u64 = r11.u64 | ctx.r3.u64;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x8240f134
	if (cr6.lt) goto loc_8240F134;
	// lbz r11,0(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240f1ec
	if (cr6.eq) goto loc_8240F1EC;
loc_8240F194:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r5,2004
	ctx.r5.s64 = 2004;
	// addi r6,r11,25632
	ctx.r6.s64 = r11.s64 + 25632;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// b 0x8240f1ec
	goto loc_8240F1EC;
loc_8240F1B8:
	// li r10,3
	ctx.r10.s64 = 3;
	// b 0x8240f170
	goto loc_8240F170;
loc_8240F1C0:
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// beq cr6,0x8240f16c
	if (cr6.eq) goto loc_8240F16C;
	// cmpwi cr6,r11,121
	cr6.compare<int32_t>(r11.s32, 121, xer);
	// beq cr6,0x8240f1e0
	if (cr6.eq) goto loc_8240F1E0;
	// cmpwi cr6,r11,122
	cr6.compare<int32_t>(r11.s32, 122, xer);
	// bne cr6,0x8240f194
	if (!cr6.eq) goto loc_8240F194;
loc_8240F1D8:
	// li r10,2
	ctx.r10.s64 = 2;
	// b 0x8240f170
	goto loc_8240F170;
loc_8240F1E0:
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x8240f170
	goto loc_8240F170;
loc_8240F1E8:
	// li r3,228
	ctx.r3.s64 = 228;
loc_8240F1EC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F200"))) PPC_WEAK_FUNC(sub_8240F200);
PPC_FUNC_IMPL(__imp__sub_8240F200) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-32139
	ctx.r10.s64 = -2106261504;
	// addi r8,r4,24
	ctx.r8.s64 = ctx.r4.s64 + 24;
	// addi r10,r10,-10112
	ctx.r10.s64 = ctx.r10.s64 + -10112;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r9,r8,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// lwz r3,36(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	// beq cr6,0x8240f2ac
	if (cr6.eq) goto loc_8240F2AC;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// beq cr6,0x8240f298
	if (cr6.eq) goto loc_8240F298;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// bnelr cr6
	if (!cr6.eq) return;
	// addi r10,r4,25
	ctx.r10.s64 = ctx.r4.s64 + 25;
	// clrlwi r8,r3,30
	ctx.r8.u64 = ctx.r3.u32 & 0x3;
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240f274
	if (cr0.eq) goto loc_8240F274;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240f26c
	if (!cr6.eq) goto loc_8240F26C;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_8240F26C:
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi r9,r11,30
	ctx.r9.u64 = r11.u32 & 0x3;
loc_8240F274:
	// rlwinm r11,r10,28,4,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
	// addi r7,r11,-2
	ctx.r7.s64 = r11.s64 + -2;
	// rlwinm r11,r10,0,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwimi r7,r8,2,0,29
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r8.u32, 2) & 0xFFFFFFFC) | (ctx.r7.u64 & 0xFFFFFFFF00000003);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwimi r11,r7,4,0,27
	r11.u64 = (__builtin_rotateleft32(ctx.r7.u32, 4) & 0xFFFFFFF0) | (r11.u64 & 0xFFFFFFFF0000000F);
	// rlwinm r11,r11,0,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFC;
	// or r3,r11,r9
	ctx.r3.u64 = r11.u64 | ctx.r9.u64;
	// blr 
	return;
loc_8240F298:
	// rlwinm r11,r3,30,30,31
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 30) & 0x3;
	// rlwinm r10,r3,6,24,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0xC0;
	// mulli r11,r11,21
	r11.s64 = r11.s64 * 21;
	// or r3,r11,r10
	ctx.r3.u64 = r11.u64 | ctx.r10.u64;
	// blr 
	return;
loc_8240F2AC:
	// clrlwi r11,r3,30
	r11.u64 = ctx.r3.u32 & 0x3;
	// mulli r3,r11,85
	ctx.r3.s64 = r11.s64 * 85;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F2B8"))) PPC_WEAK_FUNC(sub_8240F2B8);
PPC_FUNC_IMPL(__imp__sub_8240F2B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r6,r10,-24616
	ctx.r6.s64 = ctx.r10.s64 + -24616;
	// beq cr6,0x8240f2e4
	if (cr6.eq) goto loc_8240F2E4;
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r9,52(r11)
	PPC_STORE_U32(r11.u32 + 52, ctx.r9.u32);
	// b 0x823ebc20
	sub_823EBC20(ctx, base);
	return;
loc_8240F2E4:
	// b 0x823ebe20
	sub_823EBE20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240F2E8"))) PPC_WEAK_FUNC(sub_8240F2E8);
PPC_FUNC_IMPL(__imp__sub_8240F2E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240f324
	if (cr0.eq) goto loc_8240F324;
	// lwz r4,48(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// bl 0x82486258
	sub_82486258(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8240f328
	goto loc_8240F328;
loc_8240F324:
	// li r11,0
	r11.s64 = 0;
loc_8240F328:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240f33c
	if (!cr6.eq) goto loc_8240F33C;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8240f344
	goto loc_8240F344;
loc_8240F33C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_8240F344:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F35C"))) PPC_WEAK_FUNC(sub_8240F35C);
PPC_FUNC_IMPL(__imp__sub_8240F35C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240F360"))) PPC_WEAK_FUNC(sub_8240F360);
PPC_FUNC_IMPL(__imp__sub_8240F360) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x8240f37c
	if (!cr6.eq) goto loc_8240F37C;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,87
	ctx.r3.u64 = ctx.r3.u64 | 87;
	// blr 
	return;
loc_8240F37C:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8240f39c
	if (cr0.eq) goto loc_8240F39C;
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x8240f37c
	if (!cr0.eq) goto loc_8240F37C;
loc_8240F39C:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x8240f3b0
	if (!cr6.eq) goto loc_8240F3B0;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// ori r3,r3,122
	ctx.r3.u64 = ctx.r3.u64 | 122;
loc_8240F3B0:
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F3BC"))) PPC_WEAK_FUNC(sub_8240F3BC);
PPC_FUNC_IMPL(__imp__sub_8240F3BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240F3C0"))) PPC_WEAK_FUNC(sub_8240F3C0);
PPC_FUNC_IMPL(__imp__sub_8240F3C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8240f3f4
	if (cr6.eq) goto loc_8240F3F4;
loc_8240F3D4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8240f3ec
	if (cr6.eq) goto loc_8240F3EC;
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x8240f3d4
	if (!cr0.eq) goto loc_8240F3D4;
loc_8240F3EC:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x8240f400
	if (!cr6.eq) goto loc_8240F400;
loc_8240F3F4:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,87
	ctx.r3.u64 = ctx.r3.u64 | 87;
	// blr 
	return;
loc_8240F400:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// subf r11,r4,r10
	r11.s64 = ctx.r10.s64 - ctx.r4.s64;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F414"))) PPC_WEAK_FUNC(sub_8240F414);
PPC_FUNC_IMPL(__imp__sub_8240F414) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240F418"))) PPC_WEAK_FUNC(sub_8240F418);
PPC_FUNC_IMPL(__imp__sub_8240F418) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-8472
	r11.s64 = r11.s64 + -8472;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F428"))) PPC_WEAK_FUNC(sub_8240F428);
PPC_FUNC_IMPL(__imp__sub_8240F428) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// addi r7,r31,16
	ctx.r7.s64 = r31.s64 + 16;
	// lhz r11,8(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 8);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// stb r30,16(r11)
	PPC_STORE_U8(r11.u32 + 16, r30.u8);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r6,r11,-24616
	ctx.r6.s64 = r11.s64 + -24616;
	// beq cr6,0x8240f47c
	if (cr6.eq) goto loc_8240F47C;
	// li r5,7101
	ctx.r5.s64 = 7101;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// b 0x8240f484
	goto loc_8240F484;
loc_8240F47C:
	// li r5,7102
	ctx.r5.s64 = 7102;
	// bl 0x823ebe20
	sub_823EBE20(ctx, base);
loc_8240F484:
	// sth r30,8(r31)
	PPC_STORE_U16(r31.u32 + 8, r30.u16);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F4A0"))) PPC_WEAK_FUNC(sub_8240F4A0);
PPC_FUNC_IMPL(__imp__sub_8240F4A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240F4BC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8240f50c
	if (cr6.eq) goto loc_8240F50C;
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// beq cr6,0x8240f4fc
	if (cr6.eq) goto loc_8240F4FC;
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 8);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// stb r11,16(r10)
	PPC_STORE_U8(ctx.r10.u32 + 16, r11.u8);
	// lhz r11,8(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// cmplwi cr6,r11,511
	cr6.compare<uint32_t>(r11.u32, 511, xer);
	// sth r11,8(r31)
	PPC_STORE_U16(r31.u32 + 8, r11.u16);
	// blt cr6,0x8240f504
	if (cr6.lt) goto loc_8240F504;
loc_8240F4FC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8240f428
	sub_8240F428(ctx, base);
loc_8240F504:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge cr6,0x8240f4bc
	if (!cr6.lt) goto loc_8240F4BC;
loc_8240F50C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8240F514"))) PPC_WEAK_FUNC(sub_8240F514);
PPC_FUNC_IMPL(__imp__sub_8240F514) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240F518"))) PPC_WEAK_FUNC(sub_8240F518);
PPC_FUNC_IMPL(__imp__sub_8240F518) {
	PPC_FUNC_PROLOGUE();
	// b 0x8240f4a0
	sub_8240F4A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240F51C"))) PPC_WEAK_FUNC(sub_8240F51C);
PPC_FUNC_IMPL(__imp__sub_8240F51C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240F520"))) PPC_WEAK_FUNC(sub_8240F520);
PPC_FUNC_IMPL(__imp__sub_8240F520) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8240f5b4
	if (cr6.eq) goto loc_8240F5B4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x8240f54c
	if (cr6.eq) goto loc_8240F54C;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x8240f54c
	if (cr6.eq) goto loc_8240F54C;
	// ble cr6,0x8240f550
	if (!cr6.gt) goto loc_8240F550;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// ble cr6,0x8240f558
	if (!cr6.gt) goto loc_8240F558;
	// b 0x8240f550
	goto loc_8240F550;
loc_8240F54C:
	// li r11,2
	r11.s64 = 2;
loc_8240F550:
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bne cr6,0x8240f5c0
	if (!cr6.eq) goto loc_8240F5C0;
loc_8240F558:
	// extsw r11,r5
	r11.s64 = ctx.r5.s32;
	// lfd f0,8(r3)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r11.u64);
	// lfd f13,-16(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x8240f5b4
	if (cr6.lt) goto loc_8240F5B4;
	// extsw r11,r6
	r11.s64 = ctx.r6.s32;
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r11.u64);
	// lfd f13,-16(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x8240f5b4
	if (cr6.gt) goto loc_8240F5B4;
	// addi r11,r1,-16
	r11.s64 = ctx.r1.s64 + -16;
	// fctiwz f13,f0
	ctx.f13.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f13,0,r11
	PPC_STORE_U32(r11.u32, ctx.f13.u32);
	// lwz r11,-16(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// extsw r10,r11
	ctx.r10.s64 = r11.s32;
	// std r10,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r10.u64);
	// lfd f13,-16(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x8240f5fc
	if (cr6.eq) goto loc_8240F5FC;
loc_8240F5B4:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_8240F5C0:
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x8240f5e0
	if (!cr6.eq) goto loc_8240F5E0;
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8240f5b4
	if (cr6.gt) goto loc_8240F5B4;
	// b 0x8240f5ec
	goto loc_8240F5EC;
loc_8240F5E0:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x8240f5b4
	if (!cr6.eq) goto loc_8240F5B4;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
loc_8240F5EC:
	// cmpw cr6,r11,r5
	cr6.compare<int32_t>(r11.s32, ctx.r5.s32, xer);
	// blt cr6,0x8240f5b4
	if (cr6.lt) goto loc_8240F5B4;
	// cmpw cr6,r11,r6
	cr6.compare<int32_t>(r11.s32, ctx.r6.s32, xer);
	// bgt cr6,0x8240f5b4
	if (cr6.gt) goto loc_8240F5B4;
loc_8240F5FC:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F608"))) PPC_WEAK_FUNC(sub_8240F608);
PPC_FUNC_IMPL(__imp__sub_8240F608) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8240f6d0
	if (cr6.eq) goto loc_8240F6D0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x8240f520
	sub_8240F520(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240f63c
	if (cr0.lt) goto loc_8240F63C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8240f6d8
	goto loc_8240F6D8;
loc_8240F63C:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// bne cr6,0x8240f6d0
	if (!cr6.eq) goto loc_8240F6D0;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r9,r10,-24604
	ctx.r9.s64 = ctx.r10.s64 + -24604;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8240F658:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x8240f67c
	if (cr0.eq) goto loc_8240F67C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x8240f658
	if (cr6.eq) goto loc_8240F658;
loc_8240F67C:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x8240f68c
	if (!cr0.eq) goto loc_8240F68C;
	// li r11,1
	r11.s64 = 1;
	// b 0x8240f6c4
	goto loc_8240F6C4;
loc_8240F68C:
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r10,r10,-24612
	ctx.r10.s64 = ctx.r10.s64 + -24612;
loc_8240F694:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240f6b8
	if (cr0.eq) goto loc_8240F6B8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240f694
	if (cr6.eq) goto loc_8240F694;
loc_8240F6B8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8240f6d0
	if (!cr0.eq) goto loc_8240F6D0;
	// li r11,0
	r11.s64 = 0;
loc_8240F6C4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// b 0x8240f6d8
	goto loc_8240F6D8;
loc_8240F6D0:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8240F6D8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240F6E8"))) PPC_WEAK_FUNC(sub_8240F6E8);
PPC_FUNC_IMPL(__imp__sub_8240F6E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r30,0
	r30.s64 = 0;
	// stw r5,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, ctx.r5.u32);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r5,52(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r10,112(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// stw r6,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, ctx.r6.u32);
	// mr r27,r9
	r27.u64 = ctx.r9.u64;
	// stw r7,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r7.u32);
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// stb r30,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, r30.u8);
	// li r8,-1
	ctx.r8.s64 = -1;
	// std r30,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r30.u64);
	// stw r31,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, r31.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r5,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r5.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r30.u32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// stw r8,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r8.u32);
	// addi r8,r5,-1
	ctx.r8.s64 = ctx.r5.s64 + -1;
	// lwz r9,128(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cntlzw r11,r8
	r11.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// lwz r26,132(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// oris r29,r9,8
	r29.u64 = ctx.r9.u64 | 524288;
	// stw r4,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r4.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// rlwimi r26,r11,30,1,1
	r26.u64 = (__builtin_rotateleft32(r11.u32, 30) & 0x40000000) | (r26.u64 & 0xFFFFFFFFBFFFFFFF);
	// stw r29,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r29.u32);
	// beq 0x8240f93c
	if (cr0.eq) goto loc_8240F93C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r24,1
	r24.s64 = 1;
	// addi r19,r11,-7868
	r19.s64 = r11.s64 + -7868;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r25,r11,-7920
	r25.s64 = r11.s64 + -7920;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r18,r11,-7956
	r18.s64 = r11.s64 + -7956;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r21,r11,-7992
	r21.s64 = r11.s64 + -7992;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r17,r11,-8032
	r17.s64 = r11.s64 + -8032;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r16,r11,-8068
	r16.s64 = r11.s64 + -8068;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r15,r11,-8124
	r15.s64 = r11.s64 + -8124;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r14,r11,-8184
	r14.s64 = r11.s64 + -8184;
	// lis r11,-32139
	r11.s64 = -2106261504;
	// addi r23,r11,-9552
	r23.s64 = r11.s64 + -9552;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-8220
	r11.s64 = r11.s64 + -8220;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r22,r11,-8252
	r22.s64 = r11.s64 + -8252;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r20,r11,-8320
	r20.s64 = r11.s64 + -8320;
	// b 0x8240f7e8
	goto loc_8240F7E8;
loc_8240F7DC:
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r30,0
	r30.s64 = 0;
	// lwz r7,356(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
loc_8240F7E8:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r9,3
	cr6.compare<int32_t>(ctx.r9.s32, 3, xer);
	// beq cr6,0x8240f80c
	if (cr6.eq) goto loc_8240F80C;
loc_8240F804:
	// stb r24,0(r7)
	PPC_STORE_U8(ctx.r7.u32 + 0, r24.u8);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240F80C:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// lwz r31,24(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// bne cr6,0x8240f89c
	if (!cr6.eq) goto loc_8240F89C;
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x8240f89c
	if (!cr6.eq) goto loc_8240F89C;
	// lbz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne 0x8240f89c
	if (!cr0.eq) goto loc_8240F89C;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240f850
	if (cr6.eq) goto loc_8240F850;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240f87c
	goto loc_8240F87C;
loc_8240F850:
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r10,16
	ctx.r3.s64 = ctx.r10.s64 + 16;
	// bl 0x8240e7d0
	sub_8240E7D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8240f884
	if (!cr0.eq) goto loc_8240F884;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8240F87C:
	// stb r24,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, r24.u8);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240F884:
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240F89C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240f8ac
	if (!cr6.eq) goto loc_8240F8AC;
	// lwz r4,120(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// b 0x8240f90c
	goto loc_8240F90C;
loc_8240F8AC:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x8240f804
	if (!cr6.eq) goto loc_8240F804;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
loc_8240F8C4:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
loc_8240F8CC:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x8240f8f0
	if (cr0.eq) goto loc_8240F8F0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x8240f8cc
	if (cr6.eq) goto loc_8240F8CC;
loc_8240F8F0:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8240f974
	if (cr0.eq) goto loc_8240F974;
	// addi r6,r6,24
	ctx.r6.s64 = ctx.r6.s64 + 24;
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// cmplwi cr6,r6,216
	cr6.compare<uint32_t>(ctx.r6.u32, 216, xer);
	// blt cr6,0x8240f8c4
	if (cr6.lt) goto loc_8240F8C4;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
loc_8240F90C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8240F91C:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r5,108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240f7dc
	if (!cr6.eq) goto loc_8240F7DC;
	// lwz r30,104(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r29,128(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r31,332(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
loc_8240F93C:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8240fb84
	if (cr6.eq) goto loc_8240FB84;
	// rlwinm. r11,r4,0,27,27
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240fb84
	if (!cr0.eq) goto loc_8240FB84;
	// lis r11,-32139
	r11.s64 = -2106261504;
	// rlwinm r9,r5,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-9020
	r11.s64 = r11.s64 + -9020;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r4,r10,-8376
	ctx.r4.s64 = ctx.r10.s64 + -8376;
	// lwzx r5,r9,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240fba8
	goto loc_8240FBA8;
loc_8240F974:
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// bne cr6,0x8240f990
	if (!cr6.eq) goto loc_8240F990;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8240f9ac
	if (!cr6.eq) goto loc_8240F9AC;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// b 0x8240f90c
	goto loc_8240F90C;
loc_8240F990:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x8240f9ac
	if (!cr6.eq) goto loc_8240F9AC;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8240f9ac
	if (!cr6.eq) goto loc_8240F9AC;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// b 0x8240f90c
	goto loc_8240F90C;
loc_8240F9AC:
	// lbz r29,4(r11)
	r29.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// slw r9,r24,r29
	ctx.r9.u64 = r29.u8 & 0x20 ? 0 : (r24.u32 << (r29.u8 & 0x3F));
	// and. r10,r9,r4
	ctx.r10.u64 = ctx.r9.u64 & ctx.r4.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240f9c4
	if (cr0.eq) goto loc_8240F9C4;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x8240f90c
	goto loc_8240F90C;
loc_8240F9C4:
	// or r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 | ctx.r4.u64;
	// lbz r10,5(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 5);
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// stw r9,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// blt cr6,0x8240fa94
	if (cr6.lt) goto loc_8240FA94;
	// beq cr6,0x8240fa7c
	if (cr6.eq) goto loc_8240FA7C;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// blt cr6,0x8240fa30
	if (cr6.lt) goto loc_8240FA30;
	// bne cr6,0x8240fa4c
	if (!cr6.eq) goto loc_8240FA4C;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// slw r11,r24,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r24.u32 << (r11.u8 & 0x3F));
	// addi r6,r11,-1
	ctx.r6.s64 = r11.s64 + -1;
	// subfic r5,r6,-1
	xer.ca = ctx.r6.u32 <= 4294967295;
	ctx.r5.s64 = -1 - ctx.r6.s64;
	// bl 0x8240f520
	sub_8240F520(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8240fb14
	if (!cr0.lt) goto loc_8240FB14;
loc_8240FA18:
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FA30:
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x8240f520
	sub_8240F520(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240fa18
	if (cr0.lt) goto loc_8240FA18;
loc_8240FA48:
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_8240FA4C:
	// cmplwi cr6,r29,10
	cr6.compare<uint32_t>(r29.u32, 10, xer);
	// bgt cr6,0x8240f91c
	if (cr6.gt) goto loc_8240F91C;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,-9072
	r12.s64 = r12.s64 + -9072;
	// lbzx r0,r12,r29
	r0.u64 = PPC_LOAD_U8(r12.u32 + r29.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = __builtin_rotateleft64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32191
	r12.s64 = -2109669376;
	// addi r12,r12,-1764
	r12.s64 = r12.s64 + -1764;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r29.u64) {
	case 0:
		goto loc_8240FB1C;
	case 1:
		goto loc_8240FB30;
	case 2:
		goto loc_8240FB38;
	case 3:
		goto loc_8240FB40;
	case 4:
		goto loc_8240FB48;
	case 5:
		goto loc_8240FB50;
	case 6:
		goto loc_8240FB58;
	case 7:
		goto loc_8240FB60;
	case 8:
		goto loc_8240FB70;
	case 9:
		goto loc_8240F91C;
	case 10:
		goto loc_8240FB7C;
	default:
		__builtin_unreachable();
	}
loc_8240FA7C:
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// bl 0x8240f608
	sub_8240F608(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8240fa48
	if (!cr0.lt) goto loc_8240FA48;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// b 0x8240f90c
	goto loc_8240F90C;
loc_8240FA94:
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// beq cr6,0x8240faa8
	if (cr6.eq) goto loc_8240FAA8;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// b 0x8240f90c
	goto loc_8240F90C;
loc_8240FAA8:
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r5,8(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// b 0x8240fae8
	goto loc_8240FAE8;
loc_8240FAB4:
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
loc_8240FAB8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240fadc
	if (cr0.eq) goto loc_8240FADC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240fab8
	if (cr6.eq) goto loc_8240FAB8;
loc_8240FADC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8240fb0c
	if (cr0.eq) goto loc_8240FB0C;
	// addi r7,r7,8
	ctx.r7.s64 = ctx.r7.s64 + 8;
loc_8240FAE8:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8240fab4
	if (!cr0.eq) goto loc_8240FAB4;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB0C:
	// lbz r9,4(r7)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r7.u32 + 4);
	// b 0x8240fa4c
	goto loc_8240FA4C;
loc_8240FB14:
	// lwz r30,96(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// b 0x8240fa4c
	goto loc_8240FA4C;
loc_8240FB1C:
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r10,r9,-1
	ctx.r10.s64 = ctx.r9.s64 + -1;
	// rlwimi r11,r10,27,2,4
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 27) & 0x38000000) | (r11.u64 & 0xFFFFFFFFC7FFFFFF);
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r11.u32);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB30:
	// rlwimi r26,r9,12,19,19
	r26.u64 = (__builtin_rotateleft32(ctx.r9.u32, 12) & 0x1000) | (r26.u64 & 0xFFFFFFFFFFFFEFFF);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB38:
	// rlwimi r26,r9,13,18,18
	r26.u64 = (__builtin_rotateleft32(ctx.r9.u32, 13) & 0x2000) | (r26.u64 & 0xFFFFFFFFFFFFDFFF);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB40:
	// rlwimi r26,r9,15,16,16
	r26.u64 = (__builtin_rotateleft32(ctx.r9.u32, 15) & 0x8000) | (r26.u64 & 0xFFFFFFFFFFFF7FFF);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB48:
	// rlwimi r26,r9,16,10,15
	r26.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0x3F0000) | (r26.u64 & 0xFFFFFFFFFFC0FFFF);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB50:
	// rlwimi r26,r30,24,2,7
	r26.u64 = (__builtin_rotateleft32(r30.u32, 24) & 0x3F000000) | (r26.u64 & 0xFFFFFFFFC0FFFFFF);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB58:
	// rlwimi r26,r9,30,1,1
	r26.u64 = (__builtin_rotateleft32(ctx.r9.u32, 30) & 0x40000000) | (r26.u64 & 0xFFFFFFFFBFFFFFFF);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB60:
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// rlwimi r11,r9,0,24,31
	r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFF) | (r11.u64 & 0xFFFFFFFFFFFFFF00);
loc_8240FB68:
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r11.u32);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB70:
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// rlwimi r11,r30,8,1,23
	r11.u64 = (__builtin_rotateleft32(r30.u32, 8) & 0x7FFFFF00) | (r11.u64 & 0xFFFFFFFF800000FF);
	// b 0x8240fb68
	goto loc_8240FB68;
loc_8240FB7C:
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// b 0x8240f91c
	goto loc_8240F91C;
loc_8240FB84:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x8240fba8
	if (cr6.eq) goto loc_8240FBA8;
	// rlwinm. r11,r29,0,2,4
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0x38000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240fba8
	if (cr0.eq) goto loc_8240FBA8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r4,r11,-8456
	ctx.r4.s64 = r11.s64 + -8456;
	// mtctr r28
	ctr.u64 = r28.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8240FBA8:
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r10,340(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// stw r29,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r29.u32);
	// stw r26,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r26.u32);
	// lbz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,348(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_8240FBD8"))) PPC_WEAK_FUNC(sub_8240FBD8);
PPC_FUNC_IMPL(__imp__sub_8240FBD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// lwz r24,52(r3)
	r24.u64 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	// li r21,0
	r21.s64 = 0;
	// lwz r10,112(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// lwz r9,60(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// stw r4,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r4.u32);
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// stw r5,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, ctx.r5.u32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// std r21,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r21.u64);
	// stw r21,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r21.u32);
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lwz r25,168(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// oris r11,r11,8
	r11.u64 = r11.u64 | 524288;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r21.u32);
	// rlwimi r25,r9,14,16,17
	r25.u64 = (__builtin_rotateleft32(ctx.r9.u32, 14) & 0xC000) | (r25.u64 & 0xFFFFFFFFFFFF3FFF);
	// rlwimi r24,r11,0,0,26
	r24.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFE0) | (r24.u64 & 0xFFFFFFFF0000001F);
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// oris r20,r11,7967
	r20.u64 = r11.u64 | 522125312;
	// ori r20,r20,61440
	r20.u64 = r20.u64 | 61440;
	// beq 0x8240fd80
	if (cr0.eq) goto loc_8240FD80;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r23,r11,-8500
	r23.s64 = r11.s64 + -8500;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r17,r11,-7868
	r17.s64 = r11.s64 + -7868;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lfd f31,-31360(r10)
	f31.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// addi r16,r11,-7560
	r16.s64 = r11.s64 + -7560;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r15,r11,-7664
	r15.s64 = r11.s64 + -7664;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r14,r11,-7720
	r14.s64 = r11.s64 + -7720;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-7752
	r11.s64 = r11.s64 + -7752;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r19,r11,-7804
	r19.s64 = r11.s64 + -7804;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-7844
	r11.s64 = r11.s64 + -7844;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r18,r11,-7992
	r18.s64 = r11.s64 + -7992;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-8032
	r11.s64 = r11.s64 + -8032;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-8068
	r11.s64 = r11.s64 + -8068;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// lis r11,-32139
	r11.s64 = -2106261504;
	// addi r22,r11,-9200
	r22.s64 = r11.s64 + -9200;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-8220
	r11.s64 = r11.s64 + -8220;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
loc_8240FCC8:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r28,24(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// bne 0x8240fcf4
	if (!cr0.eq) goto loc_8240FCF4;
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// b 0x8240fd64
	goto loc_8240FD64;
loc_8240FCF4:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beq cr6,0x8240fd10
	if (cr6.eq) goto loc_8240FD10;
	// lwz r10,372(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// li r11,1
	r11.s64 = 1;
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, r11.u8);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_8240FD10:
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// mr r30,r22
	r30.u64 = r22.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
loc_8240FD1C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_8240FD24:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8240fd48
	if (cr0.eq) goto loc_8240FD48;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240fd24
	if (cr6.eq) goto loc_8240FD24;
loc_8240FD48:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8240fd9c
	if (cr0.eq) goto loc_8240FD9C;
	// addi r7,r7,12
	ctx.r7.s64 = ctx.r7.s64 + 12;
	// addi r30,r30,12
	r30.s64 = r30.s64 + 12;
	// cmplwi cr6,r7,180
	cr6.compare<uint32_t>(ctx.r7.u32, 180, xer);
	// blt cr6,0x8240fd1c
	if (cr6.lt) goto loc_8240FD1C;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
loc_8240FD64:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8240FD74:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240fcc8
	if (!cr6.eq) goto loc_8240FCC8;
loc_8240FD80:
	// lwz r11,364(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// stw r24,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r24.u32);
	// stw r20,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r20.u32);
	// stw r25,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r25.u32);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
loc_8240FD9C:
	// lbz r11,4(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 4);
	// li r10,1
	ctx.r10.s64 = 1;
	// slw r10,r10,r11
	ctx.r10.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r11.u8 & 0x3F));
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// and. r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240fdbc
	if (cr0.eq) goto loc_8240FDBC;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// b 0x8240fd64
	goto loc_8240FD64;
loc_8240FDBC:
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r29,r21
	r29.u64 = r21.u64;
	// lbz r11,5(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 5);
	// mr r31,r21
	r31.u64 = r21.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// blt cr6,0x8240ffd0
	if (cr6.lt) goto loc_8240FFD0;
	// beq cr6,0x8240ffb8
	if (cr6.eq) goto loc_8240FFB8;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8240ff80
	if (cr6.lt) goto loc_8240FF80;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x82410054
	if (!cr6.eq) goto loc_82410054;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8240fe18
	if (cr6.lt) goto loc_8240FE18;
	// bne cr6,0x8240fe20
	if (!cr6.eq) goto loc_8240FE20;
	// li r10,15
	ctx.r10.s64 = 15;
	// li r9,1
	ctx.r9.s64 = 1;
	// b 0x8240fe20
	goto loc_8240FE20;
loc_8240FE18:
	// li r10,63
	ctx.r10.s64 = 63;
	// li r9,4
	ctx.r9.s64 = 4;
loc_8240FE20:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x8240fe48
	if (cr6.eq) goto loc_8240FE48;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x8240fe48
	if (cr6.eq) goto loc_8240FE48;
	// ble cr6,0x8240fe4c
	if (!cr6.gt) goto loc_8240FE4C;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bgt cr6,0x8240fe4c
	if (cr6.gt) goto loc_8240FE4C;
loc_8240FE40:
	// lfd f0,8(r3)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// b 0x8240fe8c
	goto loc_8240FE8C;
loc_8240FE48:
	// li r11,2
	r11.s64 = 2;
loc_8240FE4C:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x8240fe7c
	if (cr6.eq) goto loc_8240FE7C;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x8240fe6c
	if (cr6.eq) goto loc_8240FE6C;
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// beq cr6,0x8240fe40
	if (cr6.eq) goto loc_8240FE40;
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// b 0x8240fd64
	goto loc_8240FD64;
loc_8240FE6C:
	// lwa r11,8(r3)
	r11.s64 = int32_t(PPC_LOAD_U32(ctx.r3.u32 + 8));
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// b 0x8240fe88
	goto loc_8240FE88;
loc_8240FE7C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
loc_8240FE88:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
loc_8240FE8C:
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// frsp f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(f0.f64));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r10.u64);
	// std r11,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, r11.u64);
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r9
	r11.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, r11.u64);
	// lfd f0,136(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// lfd f13,144(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f12,f0
	ctx.f12.f64 = double(f0.s64);
	// fcfid f11,f13
	ctx.f11.f64 = double(ctx.f13.s64);
	// lfd f0,152(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcfid f13,f0
	ctx.f13.f64 = double(f0.s64);
	// fdiv f0,f31,f13
	f0.f64 = f31.f64 / ctx.f13.f64;
	// fmul f11,f11,f0
	ctx.f11.f64 = ctx.f11.f64 * f0.f64;
	// fmul f3,f12,f0
	ctx.f3.f64 = ctx.f12.f64 * f0.f64;
	// fneg f2,f11
	ctx.f2.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f1,f2
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// blt cr6,0x8240ff50
	if (cr6.lt) goto loc_8240FF50;
	// fcmpu cr6,f1,f3
	cr6.compare(ctx.f1.f64, ctx.f3.f64);
	// bgt cr6,0x8240ff50
	if (cr6.gt) goto loc_8240FF50;
	// fmul f13,f13,f1
	ctx.f13.f64 = ctx.f13.f64 * ctx.f1.f64;
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// fctiwz f12,f13
	ctx.f12.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfiwx f12,0,r11
	PPC_STORE_U32(r11.u32, ctx.f12.u32);
	// lwz r31,104(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// extsw r11,r31
	r11.s64 = r31.s32;
	// std r11,160(r1)
	PPC_STORE_U64(ctx.r1.u32 + 160, r11.u64);
	// lfd f12,160(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// beq cr6,0x82410054
	if (cr6.eq) goto loc_82410054;
	// fmul f2,f12,f0
	ctx.f2.f64 = ctx.f12.f64 * f0.f64;
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// stfd f2,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.f2.u64);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// ld r7,48(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 48);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// fadd f3,f2,f0
	ctx.f3.f64 = ctx.f2.f64 + f0.f64;
	// stfd f3,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.f3.u64);
	// ld r8,56(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 56);
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82410054
	goto loc_82410054;
loc_8240FF50:
	// stfd f3,56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.f3.u64);
	// ld r8,56(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 56);
	// stfd f2,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.f2.u64);
	// ld r7,48(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 48);
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_8240FF80:
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x8240f520
	sub_8240F520(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82410050
	if (!cr0.lt) goto loc_82410050;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_8240FFB8:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8240f608
	sub_8240F608(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82410050
	if (!cr0.lt) goto loc_82410050;
	// lwz r4,108(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// b 0x8240fd64
	goto loc_8240FD64;
loc_8240FFD0:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x8240ffe4
	if (cr6.eq) goto loc_8240FFE4;
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// b 0x8240fd64
	goto loc_8240FD64;
loc_8240FFE4:
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r5,8(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// b 0x82410024
	goto loc_82410024;
loc_8240FFF0:
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
loc_8240FFF4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82410018
	if (cr0.eq) goto loc_82410018;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8240fff4
	if (cr6.eq) goto loc_8240FFF4;
loc_82410018:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82410048
	if (cr0.eq) goto loc_82410048;
	// addi r7,r7,8
	ctx.r7.s64 = ctx.r7.s64 + 8;
loc_82410024:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8240fff0
	if (!cr0.eq) goto loc_8240FFF0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mtctr r27
	ctr.u64 = r27.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410048:
	// lbz r29,4(r7)
	r29.u64 = PPC_LOAD_U8(ctx.r7.u32 + 4);
	// b 0x82410054
	goto loc_82410054;
loc_82410050:
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82410054:
	// clrlwi r11,r24,27
	r11.u64 = r24.u32 & 0x1F;
	// lbz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U8(r30.u32 + 4);
	// rlwinm r10,r25,18,30,31
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 18) & 0x3;
	// cmplwi cr6,r9,14
	cr6.compare<uint32_t>(ctx.r9.u32, 14, xer);
	// lbzx r11,r11,r23
	r11.u64 = PPC_LOAD_U8(r11.u32 + r23.u32);
	// bgt cr6,0x82410128
	if (cr6.gt) goto loc_82410128;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,-9024
	r12.s64 = r12.s64 + -9024;
	// lbzx r0,r12,r9
	r0.u64 = PPC_LOAD_U8(r12.u32 + ctx.r9.u32);
	// lis r12,-32191
	r12.s64 = -2109669376;
	// addi r12,r12,148
	r12.s64 = r12.s64 + 148;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82410094;
	case 1:
		goto loc_824100C8;
	case 2:
		goto loc_824100AC;
	case 3:
		goto loc_824100AC;
	case 4:
		goto loc_824100AC;
	case 5:
		goto loc_82410094;
	case 6:
		goto loc_824100B4;
	case 7:
		goto loc_824100B4;
	case 8:
		goto loc_82410094;
	case 9:
		goto loc_82410094;
	case 10:
		goto loc_824100F0;
	case 11:
		goto loc_824100AC;
	case 12:
		goto loc_824100AC;
	case 13:
		goto loc_824100F8;
	case 14:
		goto loc_82410108;
	default:
		__builtin_unreachable();
	}
loc_82410094:
	// andi. r11,r11,23
	r11.u64 = r11.u64 & 23;
	cr0.compare<int32_t>(r11.s32, 0, xer);
loc_82410098:
	// subf r11,r21,r11
	r11.s64 = r11.s64 - r21.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// b 0x82410120
	goto loc_82410120;
loc_824100AC:
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// b 0x82410098
	goto loc_82410098;
loc_824100B4:
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// blt cr6,0x82410128
	if (cr6.lt) goto loc_82410128;
	// andi. r11,r11,23
	r11.u64 = r11.u64 & 23;
	cr0.compare<int32_t>(r11.s32, 0, xer);
loc_824100C0:
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82410128
	if (cr0.eq) goto loc_82410128;
loc_824100C8:
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,-9056
	r12.s64 = r12.s64 + -9056;
	// rlwinm r0,r9,1,0,30
	r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32191
	r12.s64 = -2109669376;
	// addi r12,r12,-652
	r12.s64 = r12.s64 + -652;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82410130;
	case 1:
		goto loc_82410138;
	case 2:
		goto loc_82410140;
	case 3:
		goto loc_82410148;
	case 4:
		goto loc_82410150;
	case 5:
		goto loc_82410158;
	case 6:
		goto loc_82410160;
	case 7:
		goto loc_82410168;
	case 8:
		goto loc_82410170;
	case 9:
		goto loc_82410178;
	case 10:
		goto loc_82410180;
	case 11:
		goto loc_8241018C;
	case 12:
		goto loc_82410194;
	case 13:
		goto loc_8241019C;
	case 14:
		goto loc_824101A4;
	default:
		__builtin_unreachable();
	}
loc_824100F0:
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// b 0x82410098
	goto loc_82410098;
loc_824100F8:
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// blt cr6,0x82410128
	if (cr6.lt) goto loc_82410128;
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// b 0x824100c0
	goto loc_824100C0;
loc_82410108:
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// blt cr6,0x8241011c
	if (cr6.lt) goto loc_8241011C;
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824100c8
	if (!cr0.eq) goto loc_824100C8;
loc_8241011C:
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82410120:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x824100c8
	if (!cr6.eq) goto loc_824100C8;
loc_82410128:
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// b 0x8240fd64
	goto loc_8240FD64;
loc_82410130:
	// rlwimi r24,r29,25,6,6
	r24.u64 = (__builtin_rotateleft32(r29.u32, 25) & 0x2000000) | (r24.u64 & 0xFFFFFFFFFDFFFFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410138:
	// rlwimi r24,r29,19,12,12
	r24.u64 = (__builtin_rotateleft32(r29.u32, 19) & 0x80000) | (r24.u64 & 0xFFFFFFFFFFF7FFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410140:
	// rlwimi r20,r29,12,18,19
	r20.u64 = (__builtin_rotateleft32(r29.u32, 12) & 0x3000) | (r20.u64 & 0xFFFFFFFFFFFFCFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410148:
	// rlwimi r20,r29,14,16,17
	r20.u64 = (__builtin_rotateleft32(r29.u32, 14) & 0xC000) | (r20.u64 & 0xFFFFFFFFFFFF3FFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410150:
	// rlwimi r20,r29,16,14,15
	r20.u64 = (__builtin_rotateleft32(r29.u32, 16) & 0x30000) | (r20.u64 & 0xFFFFFFFFFFFCFFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410158:
	// rlwimi r20,r29,18,11,13
	r20.u64 = (__builtin_rotateleft32(r29.u32, 18) & 0x1C0000) | (r20.u64 & 0xFFFFFFFFFFE3FFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410160:
	// rlwimi r20,r29,24,6,7
	r20.u64 = (__builtin_rotateleft32(r29.u32, 24) & 0x3000000) | (r20.u64 & 0xFFFFFFFFFCFFFFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410168:
	// rlwimi r20,r29,26,4,5
	r20.u64 = (__builtin_rotateleft32(r29.u32, 26) & 0xC000000) | (r20.u64 & 0xFFFFFFFFF3FFFFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410170:
	// rlwimi r20,r29,28,3,3
	r20.u64 = (__builtin_rotateleft32(r29.u32, 28) & 0x10000000) | (r20.u64 & 0xFFFFFFFFEFFFFFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410178:
	// rlwimi r20,r29,29,2,2
	r20.u64 = (__builtin_rotateleft32(r29.u32, 29) & 0x20000000) | (r20.u64 & 0xFFFFFFFFDFFFFFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410180:
	// rlwimi r29,r25,0,0,30
	r29.u64 = (__builtin_rotateleft32(r25.u32, 0) & 0xFFFFFFFE) | (r29.u64 & 0xFFFFFFFF00000001);
	// mr r25,r29
	r25.u64 = r29.u64;
	// b 0x8240fd74
	goto loc_8240FD74;
loc_8241018C:
	// rlwimi r25,r31,2,23,29
	r25.u64 = (__builtin_rotateleft32(r31.u32, 2) & 0x1FC) | (r25.u64 & 0xFFFFFFFFFFFFFE03);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_82410194:
	// rlwimi r25,r31,16,11,15
	r25.u64 = (__builtin_rotateleft32(r31.u32, 16) & 0x1F0000) | (r25.u64 & 0xFFFFFFFFFFE0FFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_8241019C:
	// rlwimi r25,r31,21,6,10
	r25.u64 = (__builtin_rotateleft32(r31.u32, 21) & 0x3E00000) | (r25.u64 & 0xFFFFFFFFFC1FFFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
loc_824101A4:
	// rlwimi r25,r31,26,1,5
	r25.u64 = (__builtin_rotateleft32(r31.u32, 26) & 0x7C000000) | (r25.u64 & 0xFFFFFFFF83FFFFFF);
	// b 0x8240fd74
	goto loc_8240FD74;
}

__attribute__((alias("__imp__sub_824101AC"))) PPC_WEAK_FUNC(sub_824101AC);
PPC_FUNC_IMPL(__imp__sub_824101AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824101B0"))) PPC_WEAK_FUNC(sub_824101B0);
PPC_FUNC_IMPL(__imp__sub_824101B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,132
	ctx.r3.s64 = r31.s64 + 132;
	// lwz r11,296(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 296);
	// stw r30,288(r31)
	PPC_STORE_U32(r31.u32 + 288, r30.u32);
	// rlwinm r11,r11,0,11,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100000;
	// stw r30,292(r31)
	PPC_STORE_U32(r31.u32 + 292, r30.u32);
	// stw r30,304(r31)
	PPC_STORE_U32(r31.u32 + 304, r30.u32);
	// stw r11,296(r31)
	PPC_STORE_U32(r31.u32 + 296, r11.u32);
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// stw r30,164(r31)
	PPC_STORE_U32(r31.u32 + 164, r30.u32);
	// li r5,32
	ctx.r5.s64 = 32;
	// stw r30,168(r31)
	PPC_STORE_U32(r31.u32 + 168, r30.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r30,172(r31)
	PPC_STORE_U32(r31.u32 + 172, r30.u32);
	// addi r3,r31,180
	ctx.r3.s64 = r31.s64 + 180;
	// stw r30,176(r31)
	PPC_STORE_U32(r31.u32 + 176, r30.u32);
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// sth r30,212(r31)
	PPC_STORE_U16(r31.u32 + 212, r30.u16);
	// addi r3,r31,216
	ctx.r3.s64 = r31.s64 + 216;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r30,248(r31)
	PPC_STORE_U32(r31.u32 + 248, r30.u32);
	// addi r3,r31,252
	ctx.r3.s64 = r31.s64 + 252;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r11,300(r31)
	PPC_STORE_U32(r31.u32 + 300, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8241025C"))) PPC_WEAK_FUNC(sub_8241025C);
PPC_FUNC_IMPL(__imp__sub_8241025C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82410260"))) PPC_WEAK_FUNC(sub_82410260);
PPC_FUNC_IMPL(__imp__sub_82410260) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,24
	ctx.r3.s64 = 24;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x824102b0
	if (cr0.eq) goto loc_824102B0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824093f0
	sub_824093F0(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r10,r11,-8472
	ctx.r10.s64 = r11.s64 + -8472;
	// li r11,-1
	r11.s64 = -1;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// b 0x824102b4
	goto loc_824102B4;
loc_824102B0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824102B4:
	// stw r28,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r28.u32);
	// stw r29,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r29.u32);
	// lwz r11,328(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 328);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r3,328(r30)
	PPC_STORE_U32(r30.u32 + 328, ctx.r3.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_824102D0"))) PPC_WEAK_FUNC(sub_824102D0);
PPC_FUNC_IMPL(__imp__sub_824102D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// lwz r3,316(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 316);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82410300
	if (cr0.eq) goto loc_82410300;
	// bl 0x821df888
	sub_821DF888(ctx, base);
	// stw r30,316(r31)
	PPC_STORE_U32(r31.u32 + 316, r30.u32);
loc_82410300:
	// lwz r3,312(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 312);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82410314
	if (cr0.eq) goto loc_82410314;
	// bl 0x823ceee0
	sub_823CEEE0(ctx, base);
	// stw r30,312(r31)
	PPC_STORE_U32(r31.u32 + 312, r30.u32);
loc_82410314:
	// lwz r3,128(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82410334
	if (cr0.eq) goto loc_82410334;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r30,128(r31)
	PPC_STORE_U32(r31.u32 + 128, r30.u32);
loc_82410334:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8241034C"))) PPC_WEAK_FUNC(sub_8241034C);
PPC_FUNC_IMPL(__imp__sub_8241034C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82410350"))) PPC_WEAK_FUNC(sub_82410350);
PPC_FUNC_IMPL(__imp__sub_82410350) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// ld r12,-4096(r1)
	r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -4096);
	// stwu r1,-4192(r1)
	ea = -4192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r10,r11,12644
	ctx.r10.s64 = r11.s64 + 12644;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// stw r9,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r9.u32);
loc_82410380:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824103a4
	if (cr0.eq) goto loc_824103A4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82410380
	if (cr6.eq) goto loc_82410380;
loc_824103A4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824103c0
	if (!cr0.eq) goto loc_824103C0;
	// addi r5,r31,16
	ctx.r5.s64 = r31.s64 + 16;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r4,2000
	ctx.r4.s64 = 2000;
	// bl 0x823ec0b8
	sub_823EC0B8(ctx, base);
	// b 0x824103f4
	goto loc_824103F4;
loc_824103C0:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823defe0
	sub_823DEFE0(ctx, base);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r6,r11,-24616
	ctx.r6.s64 = r11.s64 + -24616;
	// li r11,0
	r11.s64 = 0;
	// li r5,7100
	ctx.r5.s64 = 7100;
	// addi r4,r31,16
	ctx.r4.s64 = r31.s64 + 16;
	// stb r11,4175(r1)
	PPC_STORE_U8(ctx.r1.u32 + 4175, r11.u8);
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
loc_824103F4:
	// addi r1,r1,4192
	ctx.r1.s64 = ctx.r1.s64 + 4192;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82410408"))) PPC_WEAK_FUNC(sub_82410408);
PPC_FUNC_IMPL(__imp__sub_82410408) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8241049c
	if (cr0.eq) goto loc_8241049C;
loc_82410430:
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82410438:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x8241045c
	if (cr0.eq) goto loc_8241045C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x82410438
	if (cr6.eq) goto loc_82410438;
loc_8241045C:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x824104ec
	if (cr0.eq) goto loc_824104EC;
	// mr r11,r31
	r11.u64 = r31.u64;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
loc_8241046C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x8241046c
	if (!cr6.eq) goto loc_8241046C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
	// bne 0x82410430
	if (!cr0.eq) goto loc_82410430;
loc_8241049C:
	// lis r11,32767
	r11.s64 = 2147418112;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// bgt cr6,0x824104b8
	if (cr6.gt) goto loc_824104B8;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8240f360
	sub_8240F360(ctx, base);
loc_824104B8:
	// mr r11,r30
	r11.u64 = r30.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_824104C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x824104c0
	if (!cr6.eq) goto loc_824104C0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_824104EC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_824104F8"))) PPC_WEAK_FUNC(sub_824104F8);
PPC_FUNC_IMPL(__imp__sub_824104F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r28,0
	r28.s64 = 0;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// mr r30,r9
	r30.u64 = ctx.r9.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// stb r28,0(r27)
	PPC_STORE_U8(r27.u32 + 0, r28.u8);
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// stb r28,0(r24)
	PPC_STORE_U8(r24.u32 + 0, r28.u8);
	// mr r29,r31
	r29.u64 = r31.u64;
	// stw r28,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r28.u32);
	// stw r28,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r28.u32);
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,46
	cr6.compare<int32_t>(r11.s32, 46, xer);
	// bne cr6,0x824105a8
	if (!cr6.eq) goto loc_824105A8;
	// li r11,1
	r11.s64 = 1;
	// addi r5,r31,1
	ctx.r5.s64 = r31.s64 + 1;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// b 0x8241056c
	goto loc_8241056C;
loc_82410558:
	// cmpwi cr6,r11,91
	cr6.compare<int32_t>(r11.s32, 91, xer);
	// beq cr6,0x8241057c
	if (cr6.eq) goto loc_8241057C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8241057c
	if (cr6.eq) goto loc_8241057C;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_8241056C:
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,46
	cr6.compare<int32_t>(r11.s32, 46, xer);
	// bne cr6,0x82410558
	if (!cr6.eq) goto loc_82410558;
loc_8241057C:
	// lis r11,32767
	r11.s64 = 2147418112;
	// ori r30,r11,65535
	r30.u64 = r11.u64 | 65535;
	// cmplw cr6,r26,r30
	cr6.compare<uint32_t>(r26.u32, r30.u32, xer);
	// bgt cr6,0x82410598
	if (cr6.gt) goto loc_82410598;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8240f360
	sub_8240F360(ctx, base);
loc_82410598:
	// subf r11,r31,r29
	r11.s64 = r29.s64 - r31.s64;
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// stb r28,-1(r11)
	PPC_STORE_U8(r11.u32 + -1, r28.u8);
	// b 0x82410654
	goto loc_82410654;
loc_824105A8:
	// cmpwi cr6,r11,91
	cr6.compare<int32_t>(r11.s32, 91, xer);
	// bne cr6,0x824105fc
	if (!cr6.eq) goto loc_824105FC;
	// li r11,2
	r11.s64 = 2;
	// addi r29,r31,1
	r29.s64 = r31.s64 + 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// bl 0x823a0c30
	sub_823A0C30(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// b 0x824105d8
	goto loc_824105D8;
loc_824105CC:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x824105e8
	if (cr6.eq) goto loc_824105E8;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_824105D8:
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,93
	cr6.compare<int32_t>(r11.s32, 93, xer);
	// bne cr6,0x824105cc
	if (!cr6.eq) goto loc_824105CC;
loc_824105E8:
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8241062c
	if (cr6.eq) goto loc_8241062C;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// b 0x8241062c
	goto loc_8241062C;
loc_824105FC:
	// stw r28,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r28.u32);
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// b 0x82410620
	goto loc_82410620;
loc_82410608:
	// cmpwi cr6,r11,91
	cr6.compare<int32_t>(r11.s32, 91, xer);
	// beq cr6,0x8241062c
	if (cr6.eq) goto loc_8241062C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8241062c
	if (cr6.eq) goto loc_8241062C;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
loc_82410620:
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,46
	cr6.compare<int32_t>(r11.s32, 46, xer);
	// bne cr6,0x82410608
	if (!cr6.eq) goto loc_82410608;
loc_8241062C:
	// lis r11,32767
	r11.s64 = 2147418112;
	// ori r30,r11,65535
	r30.u64 = r11.u64 | 65535;
	// cmplw cr6,r26,r30
	cr6.compare<uint32_t>(r26.u32, r30.u32, xer);
	// bgt cr6,0x8241064c
	if (cr6.gt) goto loc_8241064C;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8240f360
	sub_8240F360(ctx, base);
loc_8241064C:
	// subf r11,r31,r29
	r11.s64 = r29.s64 - r31.s64;
	// stbx r28,r11,r27
	PPC_STORE_U8(r11.u32 + r27.u32, r28.u8);
loc_82410654:
	// cmplw cr6,r25,r30
	cr6.compare<uint32_t>(r25.u32, r30.u32, xer);
	// bgt cr6,0x8241066c
	if (cr6.gt) goto loc_8241066C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8240f360
	sub_8240F360(ctx, base);
loc_8241066C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd38
	return;
}

__attribute__((alias("__imp__sub_82410674"))) PPC_WEAK_FUNC(sub_82410674);
PPC_FUNC_IMPL(__imp__sub_82410674) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82410678"))) PPC_WEAK_FUNC(sub_82410678);
PPC_FUNC_IMPL(__imp__sub_82410678) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// li r7,128
	ctx.r7.s64 = 128;
	// addi r6,r1,224
	ctx.r6.s64 = ctx.r1.s64 + 224;
	// li r5,128
	ctx.r5.s64 = 128;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x824104f8
	sub_824104F8(ctx, base);
	// lwz r23,84(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r23,2
	cr6.compare<int32_t>(r23.s32, 2, xer);
	// bne cr6,0x824106cc
	if (!cr6.eq) goto loc_824106CC;
	// li r4,128
	ctx.r4.s64 = 128;
	// lwz r5,0(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8240f360
	sub_8240F360(ctx, base);
loc_824106CC:
	// lbz r11,224(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 224);
	// li r28,0
	r28.s64 = 0;
	// lwz r24,80(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// extsb. r4,r11
	ctx.r4.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x8241075c
	if (cr0.eq) goto loc_8241075C;
	// lwz r11,56(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 56);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8241075c
	if (!cr6.gt) goto loc_8241075C;
	// addi r6,r25,60
	ctx.r6.s64 = r25.s64 + 60;
loc_824106F4:
	// lwz r7,0(r6)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
loc_82410700:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82410724
	if (cr0.eq) goto loc_82410724;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82410700
	if (cr6.eq) goto loc_82410700;
loc_82410724:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82410748
	if (!cr0.eq) goto loc_82410748;
	// lwz r11,52(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 52);
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82410748
	if (!cr6.eq) goto loc_82410748;
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x82410840
	if (cr6.eq) goto loc_82410840;
loc_82410748:
	// lwz r11,56(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 56);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x824106f4
	if (cr6.lt) goto loc_824106F4;
loc_8241075C:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// lwz r3,4(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,1084
	ctx.r4.s64 = 1084;
	// beq cr6,0x82410860
	if (cr6.eq) goto loc_82410860;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_82410780:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82410780
	if (!cr6.eq) goto loc_82410780;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwz r3,4(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r29,r11,1
	r29.s64 = r11.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// lis r11,32767
	r11.s64 = 2147418112;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// bgt cr6,0x824107d0
	if (cr6.gt) goto loc_824107D0;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8240f360
	sub_8240F360(ctx, base);
loc_824107D0:
	// li r11,-1
	r11.s64 = -1;
	// stw r27,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r27.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r24,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r24.u32);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// stw r23,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r23.u32);
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// stw r28,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r28.u32);
	// stw r28,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r28.u32);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// stw r28,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r28.u32);
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// stw r28,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r28.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r28,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r28.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// stw r10,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r10.u32);
	// stw r9,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r9.u32);
	// stw r8,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r8.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r28,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r28.u32);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// bl 0x82410678
	sub_82410678(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x82410924
	if (!cr6.eq) goto loc_82410924;
	// b 0x82410944
	goto loc_82410944;
loc_82410840:
	// addi r11,r5,15
	r11.s64 = ctx.r5.s64 + 15;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r6,r11,r25
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// bl 0x82410678
	sub_82410678(ctx, base);
	// b 0x82410944
	goto loc_82410944;
loc_82410860:
	// bl 0x82409268
	sub_82409268(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_82410870:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82410870
	if (!cr6.eq) goto loc_82410870;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwz r3,4(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r29,r11,1
	r29.s64 = r11.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// lis r11,32767
	r11.s64 = 2147418112;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// bgt cr6,0x824108c0
	if (cr6.gt) goto loc_824108C0;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8240f360
	sub_8240F360(ctx, base);
loc_824108C0:
	// stw r27,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r27.u32);
	// li r11,1
	r11.s64 = 1;
	// stw r24,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r24.u32);
	// stw r23,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r23.u32);
	// stw r28,56(r31)
	PPC_STORE_U32(r31.u32 + 56, r28.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r10,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r10.u32);
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// stw r10,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r10.u32);
	// lwz r10,44(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// stw r10,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r10.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r28,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r28.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_82410924:
	// lwz r11,56(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 56);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r11,r11,15
	r11.s64 = r11.s64 + 15;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r31,r11,r25
	PPC_STORE_U32(r11.u32 + r25.u32, r31.u32);
	// lwz r11,56(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 56);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,56(r25)
	PPC_STORE_U32(r25.u32 + 56, r11.u32);
loc_82410944:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_8241094C"))) PPC_WEAK_FUNC(sub_8241094C);
PPC_FUNC_IMPL(__imp__sub_8241094C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82410950"))) PPC_WEAK_FUNC(sub_82410950);
PPC_FUNC_IMPL(__imp__sub_82410950) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stwu r1,-2256(r1)
	ea = -2256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r25,r10
	r25.u64 = ctx.r10.u64;
	// mr r27,r8
	r27.u64 = ctx.r8.u64;
	// mr r26,r9
	r26.u64 = ctx.r9.u64;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r23,r7
	r23.u64 = ctx.r7.u64;
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// sth r10,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r10.u16);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// sth r9,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, ctx.r9.u16);
	// sth r8,84(r1)
	PPC_STORE_U16(ctx.r1.u32 + 84, ctx.r8.u16);
	// sth r11,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, r11.u16);
	// sth r10,86(r1)
	PPC_STORE_U16(ctx.r1.u32 + 86, ctx.r10.u16);
	// bne cr6,0x824109c4
	if (!cr6.eq) goto loc_824109C4;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824109c8
	if (!cr6.eq) goto loc_824109C8;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824109c8
	if (cr6.eq) goto loc_824109C8;
loc_824109C4:
	// lwz r31,60(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 60);
loc_824109C8:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x824109e0
	if (!cr0.eq) goto loc_824109E0;
	// sth r11,90(r1)
	PPC_STORE_U16(ctx.r1.u32 + 90, r11.u16);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// b 0x82410a78
	goto loc_82410A78;
loc_824109E0:
	// clrlwi r20,r11,16
	r20.u64 = r11.u32 & 0xFFFF;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// sth r20,90(r1)
	PPC_STORE_U16(ctx.r1.u32 + 90, r20.u16);
	// ble cr6,0x82410a60
	if (!cr6.gt) goto loc_82410A60;
	// addi r29,r1,100
	r29.s64 = ctx.r1.s64 + 100;
	// addi r30,r31,60
	r30.s64 = r31.s64 + 60;
loc_82410A00:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x82410408
	sub_82410408(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// stw r11,-4(r29)
	PPC_STORE_U32(r29.u32 + -4, r11.u32);
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// bl 0x82410950
	sub_82410950(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82410a00
	if (cr6.lt) goto loc_82410A00;
loc_82410A60:
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// clrlwi r4,r20,16
	ctx.r4.u64 = r20.u32 & 0xFFFF;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8240ed80
	sub_8240ED80(ctx, base);
	// stw r3,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r3.u32);
loc_82410A78:
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8240ee48
	sub_8240EE48(ctx, base);
	// addi r1,r1,2256
	ctx.r1.s64 = ctx.r1.s64 + 2256;
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_82410A90"))) PPC_WEAK_FUNC(sub_82410A90);
PPC_FUNC_IMPL(__imp__sub_82410A90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,32767
	r11.s64 = 2147418112;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// ble cr6,0x82410ac4
	if (!cr6.gt) goto loc_82410AC4;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,87
	ctx.r3.u64 = ctx.r3.u64 | 87;
	// b 0x82410af0
	goto loc_82410AF0;
loc_82410AC4:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8240f3c0
	sub_8240F3C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82410af0
	if (cr0.lt) goto loc_82410AF0;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// subf r4,r11,r31
	ctx.r4.s64 = r31.s64 - r11.s64;
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
	// bl 0x8240f360
	sub_8240F360(ctx, base);
loc_82410AF0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_82410AF8"))) PPC_WEAK_FUNC(sub_82410AF8);
PPC_FUNC_IMPL(__imp__sub_82410AF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,3032(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 3032);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82410350
	sub_82410350(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82410B44"))) PPC_WEAK_FUNC(sub_82410B44);
PPC_FUNC_IMPL(__imp__sub_82410B44) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82410B48"))) PPC_WEAK_FUNC(sub_82410B48);
PPC_FUNC_IMPL(__imp__sub_82410B48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82410350
	sub_82410350(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82410B90"))) PPC_WEAK_FUNC(sub_82410B90);
PPC_FUNC_IMPL(__imp__sub_82410B90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82410350
	sub_82410350(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82410BD8"))) PPC_WEAK_FUNC(sub_82410BD8);
PPC_FUNC_IMPL(__imp__sub_82410BD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// li r22,0
	r22.s64 = 0;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// li r24,277
	r24.s64 = 277;
	// mr r23,r11
	r23.u64 = r11.u64;
	// addi r31,r10,-11608
	r31.s64 = ctx.r10.s64 + -11608;
	// stw r22,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r22.u32);
	// stw r25,388(r1)
	PPC_STORE_U32(ctx.r1.u32 + 388, r25.u32);
	// mr r27,r22
	r27.u64 = r22.u64;
	// stw r22,60(r25)
	PPC_STORE_U32(r25.u32 + 60, r22.u32);
	// mr r29,r22
	r29.u64 = r22.u64;
	// lbz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// mr r26,r22
	r26.u64 = r22.u64;
	// stw r24,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r24.u32);
	// mr r30,r22
	r30.u64 = r22.u64;
	// stw r22,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r22.u32);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// stw r22,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r22.u32);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// stw r22,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r22.u32);
	// li r21,1
	r21.s64 = 1;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// stw r23,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r23.u32);
loc_82410C44:
	// lwz r5,0(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// extsb. r10,r4
	ctx.r10.s64 = ctx.r4.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r8,r5,1
	ctx.r8.s64 = ctx.r5.s64 + 1;
	// lbz r7,0(r5)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// beq 0x82410c90
	if (cr0.eq) goto loc_82410C90;
loc_82410C5C:
	// cmpwi cr6,r10,95
	cr6.compare<int32_t>(ctx.r10.s32, 95, xer);
	// bne cr6,0x82410c6c
	if (!cr6.eq) goto loc_82410C6C;
	// extsb. r28,r7
	r28.s64 = ctx.r7.s8;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82410ca4
	if (cr0.eq) goto loc_82410CA4;
loc_82410C6C:
	// extsb r7,r7
	ctx.r7.s64 = ctx.r7.s8;
	// cmpw cr6,r10,r7
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r7.s32, xer);
	// bne cr6,0x82410cac
	if (!cr6.eq) goto loc_82410CAC;
	// lbz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lbz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// extsb. r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82410c5c
	if (!cr0.eq) goto loc_82410C5C;
loc_82410C90:
	// extsb r10,r7
	ctx.r10.s64 = ctx.r7.s8;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// b 0x82410cb0
	goto loc_82410CB0;
loc_82410CA4:
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// b 0x82410cb0
	goto loc_82410CB0;
loc_82410CAC:
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_82410CB0:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82410ccc
	if (!cr0.eq) goto loc_82410CCC;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// cmpwi cr6,r30,128
	cr6.compare<int32_t>(r30.s32, 128, xer);
	// blt cr6,0x82410c44
	if (cr6.lt) goto loc_82410C44;
	// b 0x82410d10
	goto loc_82410D10;
loc_82410CCC:
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_82410CD4:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82410cd4
	if (!cr6.eq) goto loc_82410CD4;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// add r23,r10,r11
	r23.u64 = ctx.r10.u64 + r11.u64;
	// lbz r11,0(r23)
	r11.u64 = PPC_LOAD_U8(r23.u32 + 0);
	// stw r23,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r23.u32);
	// cmplwi cr6,r11,95
	cr6.compare<uint32_t>(r11.u32, 95, xer);
	// bne cr6,0x82410d0c
	if (!cr6.eq) goto loc_82410D0C;
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// stw r23,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r23.u32);
loc_82410D0C:
	// stw r23,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r23.u32);
loc_82410D10:
	// cmplwi cr6,r30,128
	cr6.compare<uint32_t>(r30.u32, 128, xer);
	// bne cr6,0x82410d20
	if (!cr6.eq) goto loc_82410D20;
loc_82410D18:
	// li r3,277
	ctx.r3.s64 = 277;
	// b 0x82411b7c
	goto loc_82411B7C;
loc_82410D20:
	// lwz r10,64(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 64);
	// rlwinm r11,r30,3,0,28
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r9,r31,8
	ctx.r9.s64 = r31.s64 + 8;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r11,r9
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r11,65535
	cr6.compare<uint32_t>(r11.u32, 65535, xer);
	// bne cr6,0x82410d58
	if (!cr6.eq) goto loc_82410D58;
	// lwz r9,72(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 72);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x8241105c
	if (cr6.eq) goto loc_8241105C;
	// rlwinm r11,r30,4,0,27
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r9,r31,10
	ctx.r9.s64 = r31.s64 + 10;
	// lhzx r11,r11,r9
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r9.u32);
loc_82410D58:
	// cmplwi cr6,r11,65526
	cr6.compare<uint32_t>(r11.u32, 65526, xer);
	// bgt cr6,0x8241105c
	if (cr6.gt) goto loc_8241105C;
	// beq cr6,0x82411054
	if (cr6.eq) goto loc_82411054;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bgt cr6,0x82411014
	if (cr6.gt) goto loc_82411014;
	// beq cr6,0x8241100c
	if (cr6.eq) goto loc_8241100C;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x82410db0
	if (cr6.lt) goto loc_82410DB0;
	// beq cr6,0x82410da8
	if (cr6.eq) goto loc_82410DA8;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x82410da0
	if (cr6.lt) goto loc_82410DA0;
	// beq cr6,0x82410d98
	if (cr6.eq) goto loc_82410D98;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bge cr6,0x82410db8
	if (!cr6.lt) goto loc_82410DB8;
	// li r24,262
	r24.s64 = 262;
	// b 0x82410db4
	goto loc_82410DB4;
loc_82410D98:
	// li r24,261
	r24.s64 = 261;
	// b 0x82410db4
	goto loc_82410DB4;
loc_82410DA0:
	// li r24,260
	r24.s64 = 260;
	// b 0x82410db4
	goto loc_82410DB4;
loc_82410DA8:
	// li r24,259
	r24.s64 = 259;
	// b 0x82410db4
	goto loc_82410DB4;
loc_82410DB0:
	// li r24,258
	r24.s64 = 258;
loc_82410DB4:
	// stw r24,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r24.u32);
loc_82410DB8:
	// rlwinm r11,r30,4,0,27
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r8,r31,4
	ctx.r8.s64 = r31.s64 + 4;
	// addi r9,r24,-259
	ctx.r9.s64 = r24.s64 + -259;
	// cmplwi cr6,r9,4
	cr6.compare<uint32_t>(ctx.r9.u32, 4, xer);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// rlwinm r9,r11,4,28,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xF;
	// rlwinm r28,r11,13,23,31
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 13) & 0x1FF;
	// rlwinm r11,r11,15,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 15) & 0x3;
	// stw r9,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r9.u32);
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r28.u32);
	// stw r11,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r11.u32);
	// bgt cr6,0x82410df4
	if (cr6.gt) goto loc_82410DF4;
	// cmplwi cr6,r28,248
	cr6.compare<uint32_t>(r28.u32, 248, xer);
	// beq cr6,0x82410df4
	if (cr6.eq) goto loc_82410DF4;
	// stw r21,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r21.u32);
loc_82410DF4:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82410e08
	if (!cr6.eq) goto loc_82410E08;
	// cmplwi cr6,r28,248
	cr6.compare<uint32_t>(r28.u32, 248, xer);
	// bne cr6,0x82410e14
	if (!cr6.eq) goto loc_82410E14;
	// stw r21,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r21.u32);
loc_82410E08:
	// cmplwi cr6,r28,248
	cr6.compare<uint32_t>(r28.u32, 248, xer);
	// bne cr6,0x82410e14
	if (!cr6.eq) goto loc_82410E14;
	// mr r29,r21
	r29.u64 = r21.u64;
loc_82410E14:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82410e28
	if (!cr6.eq) goto loc_82410E28;
	// cmplwi cr6,r28,248
	cr6.compare<uint32_t>(r28.u32, 248, xer);
	// bne cr6,0x82410e28
	if (!cr6.eq) goto loc_82410E28;
	// stw r21,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r21.u32);
loc_82410E28:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82410e3c
	if (!cr6.eq) goto loc_82410E3C;
	// cmplwi cr6,r28,248
	cr6.compare<uint32_t>(r28.u32, 248, xer);
	// bne cr6,0x82410e3c
	if (!cr6.eq) goto loc_82410E3C;
	// mr r26,r21
	r26.u64 = r21.u64;
loc_82410E3C:
	// li r11,2024
	r11.s64 = 2024;
	// stw r11,60(r25)
	PPC_STORE_U32(r25.u32 + 60, r11.u32);
	// lbz r11,0(r23)
	r11.u64 = PPC_LOAD_U8(r23.u32 + 0);
	// extsb. r10,r11
	ctx.r10.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82411b40
	if (cr0.eq) goto loc_82411B40;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r30,100(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r11,r11,-7356
	r11.s64 = r11.s64 + -7356;
	// stw r11,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r11.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-7368
	r11.s64 = r11.s64 + -7368;
	// stw r11,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r11.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-7376
	r11.s64 = r11.s64 + -7376;
	// stw r11,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, r11.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-7440
	r11.s64 = r11.s64 + -7440;
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r11.u32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r25,r11,-32680
	r25.s64 = r11.s64 + -32680;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r24,r11,2992
	r24.s64 = r11.s64 + 2992;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r23,r11,28316
	r23.s64 = r11.s64 + 28316;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r22,r11,19376
	r22.s64 = r11.s64 + 19376;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-7500
	r11.s64 = r11.s64 + -7500;
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r21,r11,28232
	r21.s64 = r11.s64 + 28232;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r20,r11,28220
	r20.s64 = r11.s64 + 28220;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r19,r11,28208
	r19.s64 = r11.s64 + 28208;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r18,r11,28200
	r18.s64 = r11.s64 + 28200;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r17,r11,14832
	r17.s64 = r11.s64 + 14832;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r16,r11,28192
	r16.s64 = r11.s64 + 28192;
	// lis r11,-32252
	r11.s64 = -2113667072;
	// addi r15,r11,6212
	r15.s64 = r11.s64 + 6212;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r14,r11,28176
	r14.s64 = r11.s64 + 28176;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,28164
	r11.s64 = r11.s64 + 28164;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r11.u32);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r11,r11,-11332
	r11.s64 = r11.s64 + -11332;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r11.u32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r11,r11,-15280
	r11.s64 = r11.s64 + -15280;
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,28152
	r11.s64 = r11.s64 + 28152;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,28148
	r11.s64 = r11.s64 + 28148;
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r11.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r11,r11,-7516
	r11.s64 = r11.s64 + -7516;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,28116
	r11.s64 = r11.s64 + 28116;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,28112
	r11.s64 = r11.s64 + 28112;
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r11.u32);
loc_82410F50:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82410f74
	if (cr6.eq) goto loc_82410F74;
loc_82410F58:
	// cmpwi cr6,r10,95
	cr6.compare<int32_t>(ctx.r10.s32, 95, xer);
	// beq cr6,0x82410f74
	if (cr6.eq) goto loc_82410F74;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// extsb. r10,r11
	ctx.r10.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82410f58
	if (!cr0.eq) goto loc_82410F58;
loc_82410F74:
	// lwz r4,116(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// subf r31,r4,r30
	r31.s64 = r30.s64 - ctx.r4.s64;
	// cmplwi cr6,r31,15
	cr6.compare<uint32_t>(r31.u32, 15, xer);
	// bgt cr6,0x82410d18
	if (cr6.gt) goto loc_82410D18;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// stbx r10,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, ctx.r10.u8);
	// beq cr6,0x82410fb0
	if (cr6.eq) goto loc_82410FB0;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
loc_82410FB0:
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r30.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x824110e4
	if (cr6.eq) goto loc_824110E4;
	// lwz r10,140(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_82410FC8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82410fec
	if (cr0.eq) goto loc_82410FEC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82410fc8
	if (cr6.eq) goto loc_82410FC8;
loc_82410FEC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824110e4
	if (!cr0.eq) goto loc_824110E4;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// b 0x82411b28
	goto loc_82411B28;
loc_8241100C:
	// li r24,263
	r24.s64 = 263;
	// b 0x82410db4
	goto loc_82410DB4;
loc_82411014:
	// cmplwi cr6,r11,65512
	cr6.compare<uint32_t>(r11.u32, 65512, xer);
	// beq cr6,0x8241104c
	if (cr6.eq) goto loc_8241104C;
	// cmplwi cr6,r11,65513
	cr6.compare<uint32_t>(r11.u32, 65513, xer);
	// beq cr6,0x82411044
	if (cr6.eq) goto loc_82411044;
	// cmplwi cr6,r11,65514
	cr6.compare<uint32_t>(r11.u32, 65514, xer);
	// beq cr6,0x8241103c
	if (cr6.eq) goto loc_8241103C;
	// cmplwi cr6,r11,65515
	cr6.compare<uint32_t>(r11.u32, 65515, xer);
	// bne cr6,0x82410db8
	if (!cr6.eq) goto loc_82410DB8;
	// li r24,273
	r24.s64 = 273;
	// b 0x82410db4
	goto loc_82410DB4;
loc_8241103C:
	// li r24,274
	r24.s64 = 274;
	// b 0x82410db4
	goto loc_82410DB4;
loc_82411044:
	// li r24,275
	r24.s64 = 275;
	// b 0x82410db4
	goto loc_82410DB4;
loc_8241104C:
	// li r24,276
	r24.s64 = 276;
	// b 0x82410db4
	goto loc_82410DB4;
loc_82411054:
	// li r24,272
	r24.s64 = 272;
	// b 0x82410db4
	goto loc_82410DB4;
loc_8241105C:
	// addis r11,r11,-1
	r11.s64 = r11.s64 + -65536;
	// addi r11,r11,9
	r11.s64 = r11.s64 + 9;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bgt cr6,0x82410db8
	if (cr6.gt) goto loc_82410DB8;
	// lis r12,-32248
	r12.s64 = -2113404928;
	// addi r12,r12,-9008
	r12.s64 = r12.s64 + -9008;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = __builtin_rotateleft64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32191
	r12.s64 = -2109669376;
	// addi r12,r12,3512
	r12.s64 = r12.s64 + 3512;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_824110BC;
	case 1:
		goto loc_824110AC;
	case 2:
		goto loc_824110CC;
	case 3:
		goto loc_824110C4;
	case 4:
		goto loc_824110B4;
	case 5:
		goto loc_824110A4;
	case 6:
		goto loc_8241109C;
	case 7:
		goto loc_82411094;
	case 8:
		goto loc_824110D4;
	default:
		__builtin_unreachable();
	}
loc_82411094:
	// li r24,265
	r24.s64 = 265;
	// b 0x82410db4
	goto loc_82410DB4;
loc_8241109C:
	// li r24,264
	r24.s64 = 264;
	// b 0x82410db4
	goto loc_82410DB4;
loc_824110A4:
	// li r24,266
	r24.s64 = 266;
	// b 0x82410db4
	goto loc_82410DB4;
loc_824110AC:
	// li r24,270
	r24.s64 = 270;
	// b 0x82410db4
	goto loc_82410DB4;
loc_824110B4:
	// li r24,267
	r24.s64 = 267;
	// b 0x82410db4
	goto loc_82410DB4;
loc_824110BC:
	// li r24,271
	r24.s64 = 271;
	// b 0x82410db4
	goto loc_82410DB4;
loc_824110C4:
	// li r24,268
	r24.s64 = 268;
	// b 0x82410db4
	goto loc_82410DB4;
loc_824110CC:
	// li r24,269
	r24.s64 = 269;
	// b 0x82410db4
	goto loc_82410DB4;
loc_824110D4:
	// li r11,2023
	r11.s64 = 2023;
	// li r3,277
	ctx.r3.s64 = 277;
	// stw r11,60(r25)
	PPC_STORE_U32(r25.u32 + 60, r11.u32);
	// b 0x82411b7c
	goto loc_82411B7C;
loc_824110E4:
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8241117c
	if (cr6.eq) goto loc_8241117C;
	// lwz r10,144(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_824110F8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241111c
	if (cr0.eq) goto loc_8241111C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824110f8
	if (cr6.eq) goto loc_824110F8;
loc_8241111C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411130
	if (!cr0.eq) goto loc_82411130;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// oris r11,r11,64
	r11.u64 = r11.u64 | 4194304;
	// b 0x8241116c
	goto loc_8241116C;
loc_82411130:
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_82411138:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241115c
	if (cr0.eq) goto loc_8241115C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411138
	if (cr6.eq) goto loc_82411138;
loc_8241115C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241117c
	if (!cr0.eq) goto loc_8241117C;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// oris r11,r11,128
	r11.u64 = r11.u64 | 8388608;
loc_8241116C:
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// b 0x82411b28
	goto loc_82411B28;
loc_8241117C:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82411254
	if (cr6.eq) goto loc_82411254;
	// li r29,0
	r29.s64 = 0;
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_82411194:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824111b8
	if (cr0.eq) goto loc_824111B8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411194
	if (cr6.eq) goto loc_82411194;
loc_824111B8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824111c8
	if (!cr0.eq) goto loc_824111C8;
	// lis r7,4096
	ctx.r7.s64 = 268435456;
	// b 0x8241123c
	goto loc_8241123C;
loc_824111C8:
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_824111D0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824111f4
	if (cr0.eq) goto loc_824111F4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824111d0
	if (cr6.eq) goto loc_824111D0;
loc_824111F4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411204
	if (!cr0.eq) goto loc_82411204;
	// lis r7,6144
	ctx.r7.s64 = 402653184;
	// b 0x8241123c
	goto loc_8241123C;
loc_82411204:
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_8241120C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411230
	if (cr0.eq) goto loc_82411230;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8241120c
	if (cr6.eq) goto loc_8241120C;
loc_82411230:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241123c
	if (!cr0.eq) goto loc_8241123C;
	// lis r7,8192
	ctx.r7.s64 = 536870912;
loc_8241123C:
	// or r27,r7,r27
	r27.u64 = ctx.r7.u64 | r27.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82411254
	if (cr6.eq) goto loc_82411254;
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// mr r26,r29
	r26.u64 = r29.u64;
	// b 0x82411b28
	goto loc_82411B28;
loc_82411254:
	// lwz r11,108(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82411354
	if (cr6.eq) goto loc_82411354;
	// lbz r11,192(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 192);
	// addi r31,r1,192
	r31.s64 = ctx.r1.s64 + 192;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82411294
	if (cr0.eq) goto loc_82411294;
loc_82411270:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823a1200
	sub_823A1200(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82411294
	if (cr0.eq) goto loc_82411294;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82411270
	if (!cr6.eq) goto loc_82411270;
loc_82411294:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824112b0
	if (cr6.eq) goto loc_824112B0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823a0c30
	sub_823A0C30(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x824112b4
	goto loc_824112B4;
loc_824112B0:
	// li r28,0
	r28.s64 = 0;
loc_824112B4:
	// cmplwi cr6,r28,15
	cr6.compare<uint32_t>(r28.u32, 15, xer);
	// bgt cr6,0x82411350
	if (cr6.gt) goto loc_82411350;
	// lbz r30,0(r31)
	r30.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// mr r29,r31
	r29.u64 = r31.u64;
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// beq 0x824112e8
	if (cr0.eq) goto loc_824112E8;
	// li r11,0
	r11.s64 = 0;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// b 0x824112e4
	goto loc_824112E4;
loc_824112D8:
	// bl 0x823a1220
	sub_823A1220(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824112f4
	if (cr0.eq) goto loc_824112F4;
loc_824112E4:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_824112E8:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb. r3,r11
	ctx.r3.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824112d8
	if (!cr0.eq) goto loc_824112D8;
loc_824112F4:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8241134c
	if (!cr6.eq) goto loc_8241134C;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_82411308:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241132c
	if (cr0.eq) goto loc_8241132C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411308
	if (cr6.eq) goto loc_82411308;
loc_8241132C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824113ac
	if (!cr0.eq) goto loc_824113AC;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x824113e4
	if (!cr6.eq) goto loc_824113E4;
	// lwz r4,164(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
loc_82411344:
	// lwz r3,388(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// bl 0x82410b48
	sub_82410B48(ctx, base);
loc_8241134C:
	// stb r30,0(r29)
	PPC_STORE_U8(r29.u32 + 0, r30.u8);
loc_82411350:
	// lwz r28,124(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
loc_82411354:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x82410d18
	if (cr6.eq) goto loc_82410D18;
	// lbz r11,192(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 192);
	// addi r31,r1,192
	r31.s64 = ctx.r1.s64 + 192;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82411390
	if (cr0.eq) goto loc_82411390;
loc_8241136C:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823a1200
	sub_823A1200(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82411390
	if (cr0.eq) goto loc_82411390;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8241136c
	if (!cr6.eq) goto loc_8241136C;
loc_82411390:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824116d4
	if (cr6.eq) goto loc_824116D4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823a0c30
	sub_823A0C30(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x824116d8
	goto loc_824116D8;
loc_824113AC:
	// lwz r10,132(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_824113B4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824113d8
	if (cr0.eq) goto loc_824113D8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824113b4
	if (cr6.eq) goto loc_824113B4;
loc_824113D8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411404
	if (!cr0.eq) goto loc_82411404;
	// li r11,1
	r11.s64 = 1;
loc_824113E4:
	// rlwinm r10,r28,16,12,15
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 16) & 0xF0000;
	// lwz r28,124(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// li r29,0
	r29.s64 = 0;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// or r27,r11,r27
	r27.u64 = r11.u64 | r27.u64;
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// b 0x82411b24
	goto loc_82411B24;
loc_82411404:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
loc_8241140C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411430
	if (cr0.eq) goto loc_82411430;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8241140c
	if (cr6.eq) goto loc_8241140C;
loc_82411430:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411440
	if (!cr0.eq) goto loc_82411440;
	// li r11,2
	r11.s64 = 2;
	// b 0x824113e4
	goto loc_824113E4;
loc_82411440:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_82411448:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241146c
	if (cr0.eq) goto loc_8241146C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411448
	if (cr6.eq) goto loc_82411448;
loc_8241146C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241147c
	if (!cr0.eq) goto loc_8241147C;
	// li r11,3
	r11.s64 = 3;
	// b 0x824113e4
	goto loc_824113E4;
loc_8241147C:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
loc_82411484:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824114a8
	if (cr0.eq) goto loc_824114A8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411484
	if (cr6.eq) goto loc_82411484;
loc_824114A8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824114b8
	if (!cr0.eq) goto loc_824114B8;
	// li r11,4
	r11.s64 = 4;
	// b 0x824113e4
	goto loc_824113E4;
loc_824114B8:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
loc_824114C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824114e4
	if (cr0.eq) goto loc_824114E4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824114c0
	if (cr6.eq) goto loc_824114C0;
loc_824114E4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824114f4
	if (!cr0.eq) goto loc_824114F4;
	// li r11,5
	r11.s64 = 5;
	// b 0x824113e4
	goto loc_824113E4;
loc_824114F4:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
loc_824114FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411520
	if (cr0.eq) goto loc_82411520;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824114fc
	if (cr6.eq) goto loc_824114FC;
loc_82411520:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411530
	if (!cr0.eq) goto loc_82411530;
	// li r11,6
	r11.s64 = 6;
	// b 0x824113e4
	goto loc_824113E4;
loc_82411530:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r19
	ctx.r10.u64 = r19.u64;
loc_82411538:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241155c
	if (cr0.eq) goto loc_8241155C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411538
	if (cr6.eq) goto loc_82411538;
loc_8241155C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241156c
	if (!cr0.eq) goto loc_8241156C;
	// li r11,7
	r11.s64 = 7;
	// b 0x824113e4
	goto loc_824113E4;
loc_8241156C:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r20
	ctx.r10.u64 = r20.u64;
loc_82411574:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411598
	if (cr0.eq) goto loc_82411598;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411574
	if (cr6.eq) goto loc_82411574;
loc_82411598:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824115a8
	if (!cr0.eq) goto loc_824115A8;
	// li r11,8
	r11.s64 = 8;
	// b 0x824113e4
	goto loc_824113E4;
loc_824115A8:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_824115B0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824115d4
	if (cr0.eq) goto loc_824115D4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824115b0
	if (cr6.eq) goto loc_824115B0;
loc_824115D4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824115e4
	if (!cr0.eq) goto loc_824115E4;
	// lwz r4,136(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// b 0x82411344
	goto loc_82411344;
loc_824115E4:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_824115EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411610
	if (cr0.eq) goto loc_82411610;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824115ec
	if (cr6.eq) goto loc_824115EC;
loc_82411610:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411620
	if (!cr0.eq) goto loc_82411620;
	// li r11,10
	r11.s64 = 10;
	// b 0x824113e4
	goto loc_824113E4;
loc_82411620:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
loc_82411628:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241164c
	if (cr0.eq) goto loc_8241164C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411628
	if (cr6.eq) goto loc_82411628;
loc_8241164C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241165c
	if (!cr0.eq) goto loc_8241165C;
	// li r11,11
	r11.s64 = 11;
	// b 0x824113e4
	goto loc_824113E4;
loc_8241165C:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82411664:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411688
	if (cr0.eq) goto loc_82411688;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411664
	if (cr6.eq) goto loc_82411664;
loc_82411688:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411698
	if (!cr0.eq) goto loc_82411698;
	// li r11,12
	r11.s64 = 12;
	// b 0x824113e4
	goto loc_824113E4;
loc_82411698:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_824116A0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824116c4
	if (cr0.eq) goto loc_824116C4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824116a0
	if (cr6.eq) goto loc_824116A0;
loc_824116C4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241134c
	if (!cr0.eq) goto loc_8241134C;
	// li r11,13
	r11.s64 = 13;
	// b 0x824113e4
	goto loc_824113E4;
loc_824116D4:
	// li r30,0
	r30.s64 = 0;
loc_824116D8:
	// cmplwi cr6,r30,15
	cr6.compare<uint32_t>(r30.u32, 15, xer);
	// bgt cr6,0x82410d18
	if (cr6.gt) goto loc_82410D18;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82411708
	if (cr6.eq) goto loc_82411708;
	// li r11,0
	r11.s64 = 0;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// b 0x82411704
	goto loc_82411704;
loc_824116F8:
	// bl 0x823a1220
	sub_823A1220(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82411714
	if (cr0.eq) goto loc_82411714;
loc_82411704:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82411708:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb. r3,r11
	ctx.r3.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824116f8
	if (!cr0.eq) goto loc_824116F8;
loc_82411714:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82410d18
	if (!cr6.eq) goto loc_82410D18;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_82411728:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241174c
	if (cr0.eq) goto loc_8241174C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411728
	if (cr6.eq) goto loc_82411728;
loc_8241174C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241175c
	if (!cr0.eq) goto loc_8241175C;
	// li r11,0
	r11.s64 = 0;
	// b 0x82411b10
	goto loc_82411B10;
loc_8241175C:
	// lwz r10,132(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_82411764:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411788
	if (cr0.eq) goto loc_82411788;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411764
	if (cr6.eq) goto loc_82411764;
loc_82411788:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411798
	if (!cr0.eq) goto loc_82411798;
	// li r11,1
	r11.s64 = 1;
	// b 0x82411b10
	goto loc_82411B10;
loc_82411798:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
loc_824117A0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824117c4
	if (cr0.eq) goto loc_824117C4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824117a0
	if (cr6.eq) goto loc_824117A0;
loc_824117C4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824117d4
	if (!cr0.eq) goto loc_824117D4;
	// li r11,2
	r11.s64 = 2;
	// b 0x82411b10
	goto loc_82411B10;
loc_824117D4:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_824117DC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411800
	if (cr0.eq) goto loc_82411800;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824117dc
	if (cr6.eq) goto loc_824117DC;
loc_82411800:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411810
	if (!cr0.eq) goto loc_82411810;
	// li r11,3
	r11.s64 = 3;
	// b 0x82411b10
	goto loc_82411B10;
loc_82411810:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
loc_82411818:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241183c
	if (cr0.eq) goto loc_8241183C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411818
	if (cr6.eq) goto loc_82411818;
loc_8241183C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241184c
	if (!cr0.eq) goto loc_8241184C;
	// li r11,4
	r11.s64 = 4;
	// b 0x82411b10
	goto loc_82411B10;
loc_8241184C:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
loc_82411854:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411878
	if (cr0.eq) goto loc_82411878;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411854
	if (cr6.eq) goto loc_82411854;
loc_82411878:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411888
	if (!cr0.eq) goto loc_82411888;
	// li r11,5
	r11.s64 = 5;
	// b 0x82411b10
	goto loc_82411B10;
loc_82411888:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
loc_82411890:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824118b4
	if (cr0.eq) goto loc_824118B4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411890
	if (cr6.eq) goto loc_82411890;
loc_824118B4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824118c4
	if (!cr0.eq) goto loc_824118C4;
	// li r11,6
	r11.s64 = 6;
	// b 0x82411b10
	goto loc_82411B10;
loc_824118C4:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r19
	ctx.r10.u64 = r19.u64;
loc_824118CC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824118f0
	if (cr0.eq) goto loc_824118F0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824118cc
	if (cr6.eq) goto loc_824118CC;
loc_824118F0:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411900
	if (!cr0.eq) goto loc_82411900;
	// li r11,7
	r11.s64 = 7;
	// b 0x82411b10
	goto loc_82411B10;
loc_82411900:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r20
	ctx.r10.u64 = r20.u64;
loc_82411908:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241192c
	if (cr0.eq) goto loc_8241192C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411908
	if (cr6.eq) goto loc_82411908;
loc_8241192C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8241193c
	if (!cr0.eq) goto loc_8241193C;
	// li r11,8
	r11.s64 = 8;
	// b 0x82411b10
	goto loc_82411B10;
loc_8241193C:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_82411944:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411968
	if (cr0.eq) goto loc_82411968;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411944
	if (cr6.eq) goto loc_82411944;
loc_82411968:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82411b84
	if (cr0.eq) goto loc_82411B84;
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_82411978:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8241199c
	if (cr0.eq) goto loc_8241199C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411978
	if (cr6.eq) goto loc_82411978;
loc_8241199C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824119ac
	if (!cr0.eq) goto loc_824119AC;
	// li r11,10
	r11.s64 = 10;
	// b 0x82411b10
	goto loc_82411B10;
loc_824119AC:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
loc_824119B4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824119d8
	if (cr0.eq) goto loc_824119D8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824119b4
	if (cr6.eq) goto loc_824119B4;
loc_824119D8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824119e8
	if (!cr0.eq) goto loc_824119E8;
	// li r11,11
	r11.s64 = 11;
	// b 0x82411b10
	goto loc_82411B10;
loc_824119E8:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_824119F0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411a14
	if (cr0.eq) goto loc_82411A14;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824119f0
	if (cr6.eq) goto loc_824119F0;
loc_82411A14:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411a24
	if (!cr0.eq) goto loc_82411A24;
	// li r11,12
	r11.s64 = 12;
	// b 0x82411b10
	goto loc_82411B10;
loc_82411A24:
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_82411A2C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411a50
	if (cr0.eq) goto loc_82411A50;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411a2c
	if (cr6.eq) goto loc_82411A2C;
loc_82411A50:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411a60
	if (!cr0.eq) goto loc_82411A60;
	// li r11,13
	r11.s64 = 13;
	// b 0x82411b10
	goto loc_82411B10;
loc_82411A60:
	// lwz r10,168(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_82411A68:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411a8c
	if (cr0.eq) goto loc_82411A8C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411a68
	if (cr6.eq) goto loc_82411A68;
loc_82411A8C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411a9c
	if (!cr0.eq) goto loc_82411A9C;
	// li r11,9
	r11.s64 = 9;
	// b 0x82411b10
	goto loc_82411B10;
loc_82411A9C:
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_82411AA4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411ac8
	if (cr0.eq) goto loc_82411AC8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411aa4
	if (cr6.eq) goto loc_82411AA4;
loc_82411AC8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411ad8
	if (!cr0.eq) goto loc_82411AD8;
	// li r11,14
	r11.s64 = 14;
	// b 0x82411b10
	goto loc_82411B10;
loc_82411AD8:
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
loc_82411AE0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411b04
	if (cr0.eq) goto loc_82411B04;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411ae0
	if (cr6.eq) goto loc_82411AE0;
loc_82411B04:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82410d18
	if (!cr0.eq) goto loc_82410D18;
	// li r11,15
	r11.s64 = 15;
loc_82411B10:
	// rlwinm r10,r30,16,12,15
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 16) & 0xF0000;
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// li r26,0
	r26.s64 = 0;
	// or r27,r10,r11
	r27.u64 = ctx.r10.u64 | r11.u64;
	// li r29,0
	r29.s64 = 0;
loc_82411B24:
	// lwz r30,100(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
loc_82411B28:
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// extsb. r10,r11
	ctx.r10.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82410f50
	if (!cr0.eq) goto loc_82410F50;
	// lwz r25,388(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// li r22,0
	r22.s64 = 0;
	// lwz r24,96(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82411B40:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x82410d18
	if (!cr6.eq) goto loc_82410D18;
	// lwz r11,108(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82410d18
	if (!cr6.eq) goto loc_82410D18;
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// stw r28,108(r25)
	PPC_STORE_U32(r25.u32 + 108, r28.u32);
	// stw r27,120(r25)
	PPC_STORE_U32(r25.u32 + 120, r27.u32);
	// stw r22,60(r25)
	PPC_STORE_U32(r25.u32 + 60, r22.u32);
	// stw r11,104(r25)
	PPC_STORE_U32(r25.u32 + 104, r11.u32);
	// lwz r11,184(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// stw r11,112(r25)
	PPC_STORE_U32(r25.u32 + 112, r11.u32);
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// stw r11,116(r25)
	PPC_STORE_U32(r25.u32 + 116, r11.u32);
loc_82411B7C:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// b 0x8239bd10
	return;
loc_82411B84:
	// lwz r3,388(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// lwz r4,136(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// bl 0x82410b48
	sub_82410B48(ctx, base);
	// b 0x82410d18
	goto loc_82410D18;
}

__attribute__((alias("__imp__sub_82411B94"))) PPC_WEAK_FUNC(sub_82411B94);
PPC_FUNC_IMPL(__imp__sub_82411B94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82411B98"))) PPC_WEAK_FUNC(sub_82411B98);
PPC_FUNC_IMPL(__imp__sub_82411B98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// li r20,1
	r20.s64 = 1;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824122a0
	if (cr0.eq) goto loc_824122A0;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r27,r29
	r27.u64 = r29.u64;
	// beq cr6,0x82411bf8
	if (cr6.eq) goto loc_82411BF8;
	// addi r30,r31,60
	r30.s64 = r31.s64 + 60;
loc_82411BD0:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82411b98
	sub_82411B98(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824121f0
	if (cr6.eq) goto loc_824121F0;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x82411bd0
	if (cr6.lt) goto loc_82411BD0;
loc_82411BF8:
	// addi r30,r31,60
	r30.s64 = r31.s64 + 60;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x824120a0
	if (!cr6.eq) goto loc_824120A0;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82411cbc
	if (!cr6.gt) goto loc_82411CBC;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82411C24:
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// bge cr6,0x82411c70
	if (!cr6.lt) goto loc_82411C70;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
loc_82411C38:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r7,52(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 52);
	// lwz r6,52(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 52);
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// beq cr6,0x82411c9c
	if (cr6.eq) goto loc_82411C9C;
	// ble cr6,0x82411c5c
	if (!cr6.gt) goto loc_82411C5C;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
loc_82411C5C:
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r4,r9
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r9.u32, xer);
	// blt cr6,0x82411c38
	if (cr6.lt) goto loc_82411C38;
loc_82411C70:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,52(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 52);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82411ca8
	if (cr6.eq) goto loc_82411CA8;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// blt cr6,0x82411c24
	if (cr6.lt) goto loc_82411C24;
	// b 0x82411cbc
	goto loc_82411CBC;
loc_82411C9C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-6764
	ctx.r5.s64 = r11.s64 + -6764;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411CA8:
	// addi r11,r3,15
	r11.s64 = ctx.r3.s64 + 15;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r26,r11,r31
	r26.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// cmplwi r26,0
	cr0.compare<uint32_t>(r26.u32, 0, xer);
	// bne 0x82411cc8
	if (!cr0.eq) goto loc_82411CC8;
loc_82411CBC:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-6804
	ctx.r5.s64 = r11.s64 + -6804;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411CC8:
	// lwz r24,4(r26)
	r24.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// lwz r23,28(r26)
	r23.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// lwz r22,24(r26)
	r22.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// cmpwi cr6,r24,2
	cr6.compare<int32_t>(r24.s32, 2, xer);
	// mullw r11,r22,r23
	r11.s64 = int64_t(r22.s32) * int64_t(r23.s32);
	// beq cr6,0x82411cf0
	if (cr6.eq) goto loc_82411CF0;
	// cmpwi cr6,r24,1
	cr6.compare<int32_t>(r24.s32, 1, xer);
	// beq cr6,0x82411cf0
	if (cr6.eq) goto loc_82411CF0;
	// mr r25,r11
	r25.u64 = r11.u64;
	// b 0x82411d08
	goto loc_82411D08;
loc_82411CF0:
	// clrlwi. r10,r11,30
	ctx.r10.u64 = r11.u32 & 0x3;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82411d00
	if (!cr0.eq) goto loc_82411D00;
	// rlwinm r25,r11,30,2,31
	r25.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// b 0x82411d08
	goto loc_82411D08;
loc_82411D00:
	// rlwinm r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r25,r11,1
	r25.s64 = r11.s64 + 1;
loc_82411D08:
	// lwz r4,56(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r27,r29
	r27.u64 = r29.u64;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// cmplwi cr6,r4,1
	cr6.compare<uint32_t>(ctx.r4.u32, 1, xer);
	// ble cr6,0x82411f08
	if (!cr6.gt) goto loc_82411F08;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r5,r31,64
	ctx.r5.s64 = r31.s64 + 64;
loc_82411D24:
	// lwz r7,0(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
loc_82411D30:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82411d54
	if (cr0.eq) goto loc_82411D54;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82411d30
	if (cr6.eq) goto loc_82411D30;
loc_82411D54:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82411f3c
	if (!cr0.eq) goto loc_82411F3C;
	// lwz r11,48(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	// lwz r10,48(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 48);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82411f48
	if (!cr6.eq) goto loc_82411F48;
	// lwz r11,56(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 56);
	// lwz r10,56(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 56);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82411f48
	if (!cr6.eq) goto loc_82411F48;
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82411f48
	if (!cr6.eq) goto loc_82411F48;
	// lwz r11,28(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 28);
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// bne cr6,0x82411f48
	if (!cr6.eq) goto loc_82411F48;
	// lwz r11,24(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bne cr6,0x82411f48
	if (!cr6.eq) goto loc_82411F48;
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// cmpw cr6,r11,r24
	cr6.compare<int32_t>(r11.s32, r24.s32, xer);
	// bne cr6,0x82411f48
	if (!cr6.eq) goto loc_82411F48;
	// lwz r11,20(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82411f48
	if (!cr6.eq) goto loc_82411F48;
	// clrlwi. r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,40(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 40);
	// beq 0x82411de0
	if (cr0.eq) goto loc_82411DE0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82411df8
	if (cr6.eq) goto loc_82411DF8;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-6888
	ctx.r5.s64 = r11.s64 + -6888;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411DE0:
	// lwz r10,40(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 40);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82411df8
	if (cr6.eq) goto loc_82411DF8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82411f48
	if (!cr6.eq) goto loc_82411F48;
	// mr r27,r20
	r27.u64 = r20.u64;
loc_82411DF8:
	// clrlwi. r10,r27,24
	ctx.r10.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82411e0c
	if (cr0.eq) goto loc_82411E0C;
	// lwz r11,44(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82411f54
	if (!cr6.eq) goto loc_82411F54;
loc_82411E0C:
	// lwz r11,44(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 44);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82411e24
	if (cr0.eq) goto loc_82411E24;
	// lwz r9,44(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 44);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x824121d8
	if (cr6.eq) goto loc_824121D8;
loc_82411E24:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82411e40
	if (!cr6.eq) goto loc_82411E40;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82411e40
	if (!cr6.eq) goto loc_82411E40;
	// lwz r11,44(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824121d8
	if (!cr6.eq) goto loc_824121D8;
loc_82411E40:
	// lwz r11,44(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82411e58
	if (cr6.eq) goto loc_82411E58;
	// lwz r11,52(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 52);
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bne cr6,0x82411f30
	if (!cr6.eq) goto loc_82411F30;
loc_82411E58:
	// lwz r9,12(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x82411ee8
	if (cr6.eq) goto loc_82411EE8;
	// cmplw cr6,r9,r25
	cr6.compare<uint32_t>(ctx.r9.u32, r25.u32, xer);
	// bne cr6,0x82411ee8
	if (!cr6.eq) goto loc_82411EE8;
	// lwz r8,12(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82411e80
	if (cr6.eq) goto loc_82411E80;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// ble cr6,0x82411eb4
	if (!cr6.gt) goto loc_82411EB4;
loc_82411E80:
	// addi r11,r6,1
	r11.s64 = ctx.r6.s64 + 1;
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// bge cr6,0x82411eb4
	if (!cr6.lt) goto loc_82411EB4;
	// addi r10,r5,4
	ctx.r10.s64 = ctx.r5.s64 + 4;
loc_82411E90:
	// lwz r28,0(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmpwi cr6,r28,-1
	cr6.compare<int32_t>(r28.s32, -1, xer);
	// bne cr6,0x82411f60
	if (!cr6.eq) goto loc_82411F60;
	// lwz r28,56(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// blt cr6,0x82411e90
	if (cr6.lt) goto loc_82411E90;
loc_82411EB4:
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82411ef4
	if (cr6.eq) goto loc_82411EF4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x82411f60
	if (cr6.lt) goto loc_82411F60;
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mullw r11,r9,r6
	r11.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r6.s32);
	// lwz r9,8(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x82411ef4
	if (cr6.eq) goto loc_82411EF4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-6940
	ctx.r5.s64 = r11.s64 + -6940;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411EE8:
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82411f60
	if (!cr6.eq) goto loc_82411F60;
loc_82411EF4:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x82411d24
	if (cr6.lt) goto loc_82411D24;
loc_82411F08:
	// addi r11,r4,14
	r11.s64 = ctx.r4.s64 + 14;
	// lwz r10,44(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 44);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// beq cr6,0x82411f6c
	if (cr6.eq) goto loc_82411F6C;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// beq cr6,0x82411f6c
	if (cr6.eq) goto loc_82411F6C;
loc_82411F30:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-7032
	ctx.r5.s64 = r11.s64 + -7032;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411F3C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-7080
	ctx.r5.s64 = r11.s64 + -7080;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411F48:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-7128
	ctx.r5.s64 = r11.s64 + -7128;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411F54:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-7192
	ctx.r5.s64 = r11.s64 + -7192;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411F60:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-7256
	ctx.r5.s64 = r11.s64 + -7256;
	// b 0x824121e0
	goto loc_824121E0;
loc_82411F6C:
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// lwz r11,52(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// stw r29,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r29.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// lwz r11,28(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lwz r11,40(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 40);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// lwz r11,44(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82412030
	if (cr6.eq) goto loc_82412030;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r10,40(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 40);
	// lwz r3,4(r21)
	ctx.r3.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// mullw r27,r11,r10
	r27.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r27,r29
	r27.u64 = r29.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82412034
	if (!cr6.gt) goto loc_82412034;
	// mr r25,r30
	r25.u64 = r30.u64;
loc_82411FF0:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// lwz r4,44(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x82412018
	if (cr0.eq) goto loc_82412018;
	// lwz r11,40(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 40);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// mullw r11,r11,r27
	r11.s64 = int64_t(r11.s32) * int64_t(r27.s32);
	// lwz r5,40(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_82412018:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x82411ff0
	if (cr6.lt) goto loc_82411FF0;
	// b 0x82412034
	goto loc_82412034;
loc_82412030:
	// stw r29,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r29.u32);
loc_82412034:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82412054
	if (!cr6.eq) goto loc_82412054;
	// li r11,-1
	r11.s64 = -1;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// b 0x824122a0
	goto loc_824122A0;
loc_82412054:
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r11,r29
	r11.u64 = r29.u64;
	// stw r29,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r29.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x824122a0
	if (!cr6.gt) goto loc_824122A0;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_8241206C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x824122a0
	if (cr6.eq) goto loc_824122A0;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stw r9,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r9.u32);
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8241206c
	if (cr6.lt) goto loc_8241206C;
	// b 0x824122a0
	goto loc_824122A0;
loc_824120A0:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x824122a0
	if (!cr6.eq) goto loc_824122A0;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8241211c
	if (!cr6.gt) goto loc_8241211C;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_824120BC:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bge cr6,0x82412104
	if (!cr6.lt) goto loc_82412104;
	// addi r11,r10,4
	r11.s64 = ctx.r10.s64 + 4;
loc_824120D0:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r4,8(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// ble cr6,0x824120f0
	if (!cr6.gt) goto loc_824120F0;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
loc_824120F0:
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// blt cr6,0x824120d0
	if (cr6.lt) goto loc_824120D0;
loc_82412104:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r7,-1
	ctx.r9.s64 = ctx.r7.s64 + -1;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x824120bc
	if (cr6.lt) goto loc_824120BC;
loc_8241211C:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// li r10,5
	ctx.r10.s64 = 5;
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// stw r29,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r29.u32);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// stw r20,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r20.u32);
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// stw r29,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r29.u32);
	// stw r20,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r20.u32);
	// stw r29,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r29.u32);
	// stw r29,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r29.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// beq 0x82412214
	if (cr0.eq) goto loc_82412214;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_82412160:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8241217c
	if (cr6.eq) goto loc_8241217C;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_8241217C:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,28(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r9,40(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r5,32(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r4,28(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mullw r5,r5,r4
	ctx.r5.s64 = int64_t(ctx.r5.s32) * int64_t(ctx.r4.s32);
	// mullw r11,r5,r11
	r11.s64 = int64_t(ctx.r5.s32) * int64_t(r11.s32);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// mullw r11,r8,r11
	r11.s64 = int64_t(ctx.r8.s32) * int64_t(r11.s32);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// lwz r11,44(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// beq cr6,0x824121f8
	if (cr6.eq) goto loc_824121F8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82412200
	if (!cr6.eq) goto loc_82412200;
loc_824121D8:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,-7328
	ctx.r5.s64 = r11.s64 + -7328;
loc_824121E0:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r4,r11,-7348
	ctx.r4.s64 = r11.s64 + -7348;
	// bl 0x82410b48
	sub_82410B48(ctx, base);
loc_824121F0:
	// li r20,-1
	r20.s64 = -1;
	// b 0x824122a0
	goto loc_824122A0;
loc_824121F8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824121d8
	if (!cr6.eq) goto loc_824121D8;
loc_82412200:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x82412160
	if (cr6.lt) goto loc_82412160;
loc_82412214:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82412228
	if (!cr6.eq) goto loc_82412228;
	// li r11,-1
	r11.s64 = -1;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_82412228:
	// lwz r11,44(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824122a0
	if (cr6.eq) goto loc_824122A0;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r3,4(r21)
	ctx.r3.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// bl 0x82409268
	sub_82409268(ctx, base);
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// mr r28,r29
	r28.u64 = r29.u64;
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824122a0
	if (!cr6.gt) goto loc_824122A0;
loc_82412258:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// add r3,r10,r28
	ctx.r3.u64 = ctx.r10.u64 + r28.u64;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// lwz r9,32(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r4,44(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// mullw r5,r10,r9
	ctx.r5.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwz r9,40(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// mullw r11,r9,r11
	r11.s64 = int64_t(ctx.r9.s32) * int64_t(r11.s32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// add r28,r11,r28
	r28.u64 = r11.u64 + r28.u64;
	// cmplw cr6,r29,r10
	cr6.compare<uint32_t>(r29.u32, ctx.r10.u32, xer);
	// blt cr6,0x82412258
	if (cr6.lt) goto loc_82412258;
loc_824122A0:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_824122AC"))) PPC_WEAK_FUNC(sub_824122AC);
PPC_FUNC_IMPL(__imp__sub_824122AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

