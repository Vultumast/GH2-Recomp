#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82442470"))) PPC_WEAK_FUNC(sub_82442470);
PPC_FUNC_IMPL(__imp__sub_82442470) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stw r5,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r5.u32);
	// lwz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x824424d8
	if (cr0.eq) goto loc_824424D8;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x824424d4
	if (cr6.eq) goto loc_824424D4;
	// stw r8,76(r11)
	PPC_STORE_U32(r11.u32 + 76, ctx.r8.u32);
	// lwzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r7,20(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r4,80(r8)
	PPC_STORE_U32(ctx.r8.u32 + 80, ctx.r4.u32);
loc_824424D4:
	// stwx r4,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r4.u32);
loc_824424D8:
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beqlr cr6
	if (cr6.eq) return;
	// b 0x824423d0
	sub_824423D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_824424E8"))) PPC_WEAK_FUNC(sub_824424E8);
PPC_FUNC_IMPL(__imp__sub_824424E8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824424EC"))) PPC_WEAK_FUNC(sub_824424EC);
PPC_FUNC_IMPL(__imp__sub_824424EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824424F0"))) PPC_WEAK_FUNC(sub_824424F0);
PPC_FUNC_IMPL(__imp__sub_824424F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82442630
	if (!cr6.gt) goto loc_82442630;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82442508:
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r11,r7,r10
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x824425c8
	if (cr6.eq) goto loc_824425C8;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r9,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r9.u32);
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// stw r9,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r9.u32);
	// lwz r9,72(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// stw r9,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r9.u32);
	// lwz r9,76(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	// stw r9,76(r11)
	PPC_STORE_U32(r11.u32 + 76, ctx.r9.u32);
	// lwz r9,80(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// stw r9,80(r11)
	PPC_STORE_U32(r11.u32 + 80, ctx.r9.u32);
	// lwz r9,84(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82442580
	if (!cr6.eq) goto loc_82442580;
	// lwz r9,84(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// stw r9,84(r10)
	PPC_STORE_U32(ctx.r10.u32 + 84, ctx.r9.u32);
	// lwz r9,88(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// stw r9,88(r10)
	PPC_STORE_U32(ctx.r10.u32 + 88, ctx.r9.u32);
	// lwz r11,92(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// b 0x824425c0
	goto loc_824425C0;
loc_82442580:
	// lwz r8,84(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x82442590
	if (cr6.lt) goto loc_82442590;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_82442590:
	// stw r9,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r9.u32);
	// stw r9,84(r10)
	PPC_STORE_U32(ctx.r10.u32 + 84, ctx.r9.u32);
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	// lwz r8,88(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bgt cr6,0x824425ac
	if (cr6.gt) goto loc_824425AC;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_824425AC:
	// stw r9,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r9.u32);
	// stw r9,88(r10)
	PPC_STORE_U32(ctx.r10.u32 + 88, ctx.r9.u32);
	// lwz r11,92(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// lwz r9,92(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 92);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
loc_824425C0:
	// stw r11,92(r10)
	PPC_STORE_U32(ctx.r10.u32 + 92, r11.u32);
	// li r8,1
	ctx.r8.s64 = 1;
loc_824425C8:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x82442508
	if (cr6.lt) goto loc_82442508;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82442630
	if (cr6.eq) goto loc_82442630;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82442630
	if (!cr6.gt) goto loc_82442630;
	// li r8,0
	ctx.r8.s64 = 0;
loc_824425F8:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r9,56(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x8244261c
	if (cr6.eq) goto loc_8244261C;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// stw r11,84(r10)
	PPC_STORE_U32(ctx.r10.u32 + 84, r11.u32);
loc_8244261C:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x824425f8
	if (cr6.lt) goto loc_824425F8;
loc_82442630:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82442638"))) PPC_WEAK_FUNC(sub_82442638);
PPC_FUNC_IMPL(__imp__sub_82442638) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// rlwinm r28,r29,2,0,29
	r28.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
loc_82442650:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// lwzx r31,r10,r9
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// beq cr6,0x824426e4
	if (cr6.eq) goto loc_824426E4;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824426e4
	if (cr0.eq) goto loc_824426E4;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x824426a4
	if (cr0.eq) goto loc_824426A4;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r8,72(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r8.u32);
loc_824426A4:
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x824426d8
	if (cr0.eq) goto loc_824426D8;
	// lwz r9,28(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r29,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, r29.u32);
loc_824426D8:
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
loc_824426E4:
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x82442700
	if (cr6.eq) goto loc_82442700;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82442638
	sub_82442638(ctx, base);
loc_82442700:
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x82442714
	if (cr6.eq) goto loc_82442714;
	// li r6,1
	ctx.r6.s64 = 1;
	// b 0x82442650
	goto loc_82442650;
loc_82442714:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8244271C"))) PPC_WEAK_FUNC(sub_8244271C);
PPC_FUNC_IMPL(__imp__sub_8244271C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82442720"))) PPC_WEAK_FUNC(sub_82442720);
PPC_FUNC_IMPL(__imp__sub_82442720) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82442758
	if (!cr6.gt) goto loc_82442758;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82442734:
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82442734
	if (cr6.lt) goto loc_82442734;
loc_82442758:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82442760"))) PPC_WEAK_FUNC(sub_82442760);
PPC_FUNC_IMPL(__imp__sub_82442760) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r11,20316
	r11.s64 = r11.s64 + 20316;
	// clrlwi. r10,r4,31
	ctx.r10.u64 = ctx.r4.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq 0x8244278c
	if (cr0.eq) goto loc_8244278C;
	// bl 0x821e7b68
	sub_821E7B68(ctx, base);
loc_8244278C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824427A4"))) PPC_WEAK_FUNC(sub_824427A4);
PPC_FUNC_IMPL(__imp__sub_824427A4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824427A8"))) PPC_WEAK_FUNC(sub_824427A8);
PPC_FUNC_IMPL(__imp__sub_824427A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r4,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwzx r29,r9,r11
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r8,r10,0,0,11
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// rlwinm r9,r11,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bge cr6,0x824427ec
	if (!cr6.lt) goto loc_824427EC;
loc_824427E4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x824429d0
	goto loc_824429D0;
loc_824427EC:
	// ble cr6,0x824427f8
	if (!cr6.gt) goto loc_824427F8;
loc_824427F0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x824429d0
	goto loc_824429D0;
loc_824427F8:
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x824427f0
	if (cr6.lt) goto loc_824427F0;
	// bgt cr6,0x824427e4
	if (cr6.gt) goto loc_824427E4;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82442894
	if (cr0.eq) goto loc_82442894;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r6,20(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// subf r5,r11,r10
	ctx.r5.s64 = ctx.r10.s64 - r11.s64;
loc_82442830:
	// lwzx r11,r5,r7
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r7.u32);
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x824427e4
	if (cr6.lt) goto loc_824427E4;
	// bgt cr6,0x824427f0
	if (cr6.gt) goto loc_824427F0;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r8,20(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x824427e4
	if (cr6.lt) goto loc_824427E4;
	// bgt cr6,0x824427f0
	if (cr6.gt) goto loc_824427F0;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// blt cr6,0x824427e4
	if (cr6.lt) goto loc_824427E4;
	// bgt cr6,0x824427f0
	if (cr6.gt) goto loc_824427F0;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r4,r3
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r3.u32, xer);
	// blt cr6,0x82442830
	if (cr6.lt) goto loc_82442830;
loc_82442894:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d178
	sub_8243D178(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82442970
	if (cr0.eq) goto loc_82442970;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r27,0
	r27.s64 = 0;
	// clrlwi. r28,r11,12
	r28.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x824429cc
	if (cr0.eq) goto loc_824429CC;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// add r7,r10,r11
	ctx.r7.u64 = ctx.r10.u64 + r11.u64;
	// subf r3,r11,r6
	ctx.r3.s64 = ctx.r6.s64 - r11.s64;
loc_824428D0:
	// lwzx r11,r3,r8
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r8.u32);
	// lwzx r10,r3,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// lwz r6,0(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,0(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwzx r6,r6,r9
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwzx r5,r5,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// mr r31,r11
	r31.u64 = r11.u64;
	// lwz r5,48(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x82442924
	if (cr6.lt) goto loc_82442924;
	// mr r31,r10
	r31.u64 = ctx.r10.u64;
	// bgt cr6,0x82442928
	if (cr6.gt) goto loc_82442928;
loc_82442924:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82442928:
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// blt cr6,0x8244293c
	if (cr6.lt) goto loc_8244293C;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bgt cr6,0x82442940
	if (cr6.gt) goto loc_82442940;
loc_8244293C:
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
loc_82442940:
	// cmplw cr6,r31,r4
	cr6.compare<uint32_t>(r31.u32, ctx.r4.u32, xer);
	// blt cr6,0x824427e4
	if (cr6.lt) goto loc_824427E4;
	// bgt cr6,0x824427f0
	if (cr6.gt) goto loc_824427F0;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// blt cr6,0x824427e4
	if (cr6.lt) goto loc_824427E4;
	// bgt cr6,0x824427f0
	if (cr6.gt) goto loc_824427F0;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r27,r28
	cr6.compare<uint32_t>(r27.u32, r28.u32, xer);
	// blt cr6,0x824428d0
	if (cr6.lt) goto loc_824428D0;
	// b 0x824429cc
	goto loc_824429CC;
loc_82442970:
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq 0x824429cc
	if (cr0.eq) goto loc_824429CC;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - r11.s64;
loc_82442990:
	// lwzx r10,r11,r7
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// lwz r9,48(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x824427e4
	if (cr6.lt) goto loc_824427E4;
	// bgt cr6,0x824427f0
	if (cr6.gt) goto loc_824427F0;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// blt cr6,0x82442990
	if (cr6.lt) goto loc_82442990;
loc_824429CC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824429D0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_824429D8"))) PPC_WEAK_FUNC(sub_824429D8);
PPC_FUNC_IMPL(__imp__sub_824429D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r4,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// lwzx r29,r9,r11
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// xor r9,r11,r10
	ctx.r9.u64 = r11.u64 ^ ctx.r10.u64;
	// rlwinm. r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82442a18
	if (cr0.eq) goto loc_82442A18;
loc_82442A10:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82442c20
	goto loc_82442C20;
loc_82442A18:
	// clrlwi r4,r11,12
	ctx.r4.u64 = r11.u32 & 0xFFFFF;
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bge cr6,0x82442a10
	if (!cr6.lt) goto loc_82442A10;
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x82442a10
	if (cr6.lt) goto loc_82442A10;
	// lis r10,16384
	ctx.r10.s64 = 1073741824;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x82442a10
	if (cr6.gt) goto loc_82442A10;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x82442abc
	if (cr0.eq) goto loc_82442ABC;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - r11.s64;
loc_82442A64:
	// lwzx r10,r7,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r30,4(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r3,r30
	cr6.compare<uint32_t>(ctx.r3.u32, r30.u32, xer);
	// bne cr6,0x82442a10
	if (!cr6.eq) goto loc_82442A10;
	// lwz r3,20(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r30,20(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplw cr6,r3,r30
	cr6.compare<uint32_t>(ctx.r3.u32, r30.u32, xer);
	// bne cr6,0x82442a10
	if (!cr6.eq) goto loc_82442A10;
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bne cr6,0x82442a10
	if (!cr6.eq) goto loc_82442A10;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// blt cr6,0x82442a64
	if (cr6.lt) goto loc_82442A64;
loc_82442ABC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// divwu r27,r11,r4
	r27.u32 = r11.u32 / ctx.r4.u32;
	// twllei r4,0
	// beq cr6,0x82442c1c
	if (cr6.eq) goto loc_82442C1C;
	// li r24,0
	r24.s64 = 0;
loc_82442AD8:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r23,0
	r23.s64 = 0;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82442bfc
	if (cr0.eq) goto loc_82442BFC;
	// li r28,0
	r28.s64 = 0;
loc_82442AEC:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82442b54
	if (cr6.eq) goto loc_82442B54;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// add r10,r10,r24
	ctx.r10.u64 = ctx.r10.u64 + r24.u64;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
loc_82442B18:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r7
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r7.u32);
	// lwzx r5,r5,r7
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r7.u32);
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// lwz r5,48(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x82442b54
	if (!cr6.eq) goto loc_82442B54;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// blt cr6,0x82442b18
	if (cr6.lt) goto loc_82442B18;
loc_82442B54:
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// beq cr6,0x82442bfc
	if (cr6.eq) goto loc_82442BFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d178
	sub_8243D178(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82442be0
	if (cr0.eq) goto loc_82442BE0;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82442be0
	if (cr6.eq) goto loc_82442BE0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r8,12(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// add r5,r11,r25
	ctx.r5.u64 = r11.u64 + r25.u64;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mulli r7,r11,-4
	ctx.r7.s64 = r11.s64 * -4;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r6,20(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + r28.u64;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
loc_82442BA4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// lwzx r5,r5,r6
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r6.u32);
	// lwz r9,48(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// lwz r5,48(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	// cmplw cr6,r9,r5
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r5.u32, xer);
	// bne cr6,0x82442be0
	if (!cr6.eq) goto loc_82442BE0;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r11,r7,r11
	r11.u64 = ctx.r7.u64 + r11.u64;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// blt cr6,0x82442ba4
	if (cr6.lt) goto loc_82442BA4;
loc_82442BE0:
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// beq cr6,0x82442bfc
	if (cr6.eq) goto loc_82442BFC;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// blt cr6,0x82442aec
	if (cr6.lt) goto loc_82442AEC;
loc_82442BFC:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// beq cr6,0x82442a10
	if (cr6.eq) goto loc_82442A10;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x82442ad8
	if (cr6.lt) goto loc_82442AD8;
loc_82442C1C:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82442C20:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_82442C28"))) PPC_WEAK_FUNC(sub_82442C28);
PPC_FUNC_IMPL(__imp__sub_82442C28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x824429d8
	sub_824429D8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824429d8
	sub_824429D8(ctx, base);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x82442c68
	if (cr6.eq) goto loc_82442C68;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82442ca4
	goto loc_82442CA4;
loc_82442C68:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82442c78
	if (cr6.eq) goto loc_82442C78;
loc_82442C70:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82442ca4
	goto loc_82442CA4;
loc_82442C78:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824427a8
	sub_824427A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82442ca4
	if (!cr0.eq) goto loc_82442CA4;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// blt cr6,0x82442c70
	if (cr6.lt) goto loc_82442C70;
	// subfc r11,r31,r30
	xer.ca = r30.u32 >= r31.u32;
	r11.s64 = r30.s64 - r31.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r3,r11,31
	ctx.r3.u64 = r11.u32 & 0x1;
loc_82442CA4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_82442CAC"))) PPC_WEAK_FUNC(sub_82442CAC);
PPC_FUNC_IMPL(__imp__sub_82442CAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82442CB0"))) PPC_WEAK_FUNC(sub_82442CB0);
PPC_FUNC_IMPL(__imp__sub_82442CB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r11,20284
	r11.s64 = r11.s64 + 20284;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,208(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82442cfc
	if (cr0.eq) goto loc_82442CFC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82442CFC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e668
	sub_8243E668(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82442D18"))) PPC_WEAK_FUNC(sub_82442D18);
PPC_FUNC_IMPL(__imp__sub_82442D18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82442d90
	if (cr6.eq) goto loc_82442D90;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_82442D40:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82442d40
	if (!cr6.eq) goto loc_82442D40;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x82442d80
	if (!cr0.eq) goto loc_82442D80;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82442da4
	goto loc_82442DA4;
loc_82442D80:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_82442D90:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,208(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 208);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,208(r28)
	PPC_STORE_U32(r28.u32 + 208, r31.u32);
loc_82442DA4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_82442DAC"))) PPC_WEAK_FUNC(sub_82442DAC);
PPC_FUNC_IMPL(__imp__sub_82442DAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82442DB0"))) PPC_WEAK_FUNC(sub_82442DB0);
PPC_FUNC_IMPL(__imp__sub_82442DB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82442e40
	if (cr6.eq) goto loc_82442E40;
loc_82442DD0:
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x82442df4
	if (cr6.eq) goto loc_82442DF4;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82442df4
	if (cr6.eq) goto loc_82442DF4;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
loc_82442DF4:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bge cr6,0x82442e10
	if (!cr6.lt) goto loc_82442E10;
	// stw r5,84(r31)
	PPC_STORE_U32(r31.u32 + 84, ctx.r5.u32);
loc_82442E10:
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x82442e28
	if (cr6.eq) goto loc_82442E28;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,84(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// bl 0x82442db0
	sub_82442DB0(ctx, base);
loc_82442E28:
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x82442e40
	if (cr6.eq) goto loc_82442E40;
	// lwz r5,84(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne 0x82442dd0
	if (!cr0.eq) goto loc_82442DD0;
loc_82442E40:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82442E58"))) PPC_WEAK_FUNC(sub_82442E58);
PPC_FUNC_IMPL(__imp__sub_82442E58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r26,0
	r26.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82442ecc
	if (!cr6.gt) goto loc_82442ECC;
	// li r27,0
	r27.s64 = 0;
	// li r28,0
	r28.s64 = 0;
loc_82442E84:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r29,r28,r11
	r29.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm. r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82442eac
	if (!cr0.eq) goto loc_82442EAC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// b 0x82442eb8
	goto loc_82442EB8;
loc_82442EAC:
	// stwx r29,r27,r11
	PPC_STORE_U32(r27.u32 + r11.u32, r29.u32);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
loc_82442EB8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x82442e84
	if (cr6.lt) goto loc_82442E84;
loc_82442ECC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x82442ee0
	if (!cr6.eq) goto loc_82442EE0;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82442f04
	goto loc_82442F04;
loc_82442EE0:
	// subf r9,r30,r11
	ctx.r9.s64 = r11.s64 - r30.s64;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,0
	ctx.r4.s64 = 0;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
loc_82442F04:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_82442F0C"))) PPC_WEAK_FUNC(sub_82442F0C);
PPC_FUNC_IMPL(__imp__sub_82442F0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82442F10"))) PPC_WEAK_FUNC(sub_82442F10);
PPC_FUNC_IMPL(__imp__sub_82442F10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x8239bcf8
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82442f88
	if (!cr6.gt) goto loc_82442F88;
	// li r8,0
	ctx.r8.s64 = 0;
loc_82442F2C:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r6,r10,0,26,27
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x30;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x82442f60
	if (cr0.eq) goto loc_82442F60;
	// rlwinm. r10,r10,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82442f60
	if (!cr0.eq) goto loc_82442F60;
	// lwz r10,116(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_82442F60:
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82442f74
	if (cr0.eq) goto loc_82442F74;
	// lwz r10,136(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_82442F74:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x82442f2c
	if (cr6.lt) goto loc_82442F2C;
loc_82442F88:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824431d8
	if (!cr6.gt) goto loc_824431D8;
	// li r29,0
	r29.s64 = 0;
loc_82442F9C:
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r5,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824431c4
	if (cr0.eq) goto loc_824431C4;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82442ff4
	if (cr0.eq) goto loc_82442FF4;
	// lwz r7,20(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rotlwi r9,r8,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_82442FCC:
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r7.u32);
	// lwz r4,0(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm. r4,r4,0,26,26
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x82442fe8
	if (cr0.eq) goto loc_82442FE8;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
loc_82442FE8:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82442fcc
	if (!cr0.eq) goto loc_82442FCC;
loc_82442FF4:
	// cmplw cr6,r6,r8
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, xer);
	// bne cr6,0x82443008
	if (!cr6.eq) goto loc_82443008;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x824431c4
	goto loc_824431C4;
loc_82443008:
	// bge cr6,0x82443148
	if (!cr6.lt) goto loc_82443148;
	// rlwinm r10,r5,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xF0000000;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82443148
	if (cr6.lt) goto loc_82443148;
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bgt cr6,0x82443148
	if (cr6.gt) goto loc_82443148;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi r10,r5,12
	ctx.r10.u64 = ctx.r5.u32 & 0xFFFFF;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// divwu r31,r9,r10
	r31.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// beq cr6,0x824430d0
	if (cr6.eq) goto loc_824430D0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
loc_82443050:
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r8,r6,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824430bc
	if (!cr0.eq) goto loc_824430BC;
	// lwzx r8,r6,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stwx r8,r4,r9
	PPC_STORE_U32(ctx.r4.u32 + ctx.r9.u32, ctx.r8.u32);
	// beq cr6,0x824430b4
	if (cr6.eq) goto loc_824430B4;
loc_82443084:
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mullw r8,r8,r10
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// add r30,r8,r5
	r30.u64 = ctx.r8.u64 + ctx.r5.u64;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r30,r30,2,0,29
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// lwzx r30,r30,r9
	r30.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// stwx r30,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, r30.u32);
	// blt cr6,0x82443084
	if (cr6.lt) goto loc_82443084;
loc_824430B4:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
loc_824430BC:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// blt cr6,0x82443050
	if (cr6.lt) goto loc_82443050;
loc_824430D0:
	// li r5,1
	ctx.r5.s64 = 1;
	// cmplwi cr6,r31,1
	cr6.compare<uint32_t>(r31.u32, 1, xer);
	// ble cr6,0x82443130
	if (!cr6.gt) goto loc_82443130;
	// rlwinm r30,r7,2,0,29
	r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_824430E4:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82443120
	if (cr6.eq) goto loc_82443120;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
loc_824430F4:
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mullw r6,r6,r5
	ctx.r6.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r5.s32);
	// add r6,r6,r10
	ctx.r6.u64 = ctx.r6.u64 + ctx.r10.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// lwzx r6,r6,r8
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// stwx r6,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r6.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// blt cr6,0x824430f4
	if (cr6.lt) goto loc_824430F4;
loc_82443120:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// add r4,r4,r30
	ctx.r4.u64 = ctx.r4.u64 + r30.u64;
	// cmplw cr6,r5,r31
	cr6.compare<uint32_t>(ctx.r5.u32, r31.u32, xer);
	// blt cr6,0x824430e4
	if (cr6.lt) goto loc_824430E4;
loc_82443130:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mullw r9,r7,r31
	ctx.r9.s64 = int64_t(ctx.r7.s32) * int64_t(r31.s32);
	// rlwimi r10,r7,0,12,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r7.u32, 0) & 0xFFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFF00000);
	// stw r7,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r7.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_82443148:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x824431c4
	if (!cr6.gt) goto loc_824431C4;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8244315C:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r6,20(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r8,24(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// b 0x824431a0
	goto loc_824431A0;
loc_8244317C:
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r5,r6
	r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r6.u32);
	// lwz r31,0(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r31,r31,0,26,26
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x824431a8
	if (cr0.eq) goto loc_824431A8;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r8,r5,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// lwz r10,20(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// lwz r8,24(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
loc_824431A0:
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244317c
	if (!cr6.eq) goto loc_8244317C;
loc_824431A8:
	// stw r8,24(r9)
	PPC_STORE_U32(ctx.r9.u32 + 24, ctx.r8.u32);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// stw r10,20(r9)
	PPC_STORE_U32(ctx.r9.u32 + 20, ctx.r10.u32);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244315c
	if (cr6.lt) goto loc_8244315C;
loc_824431C4:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82442f9c
	if (cr6.lt) goto loc_82442F9C;
loc_824431D8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_824431E0"))) PPC_WEAK_FUNC(sub_824431E0);
PPC_FUNC_IMPL(__imp__sub_824431E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x8239bcf4
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// li r27,0
	r27.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824433cc
	if (!cr6.gt) goto loc_824433CC;
	// li r29,0
	r29.s64 = 0;
loc_82443200:
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r5,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824433b8
	if (cr0.eq) goto loc_824433B8;
	// lis r9,4112
	ctx.r9.s64 = 269484032;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x824433b8
	if (cr6.eq) goto loc_824433B8;
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x824433b8
	if (cr0.eq) goto loc_824433B8;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rotlwi r9,r6,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r6.u32, 0);
	// lwz r7,20(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
loc_8244323C:
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r7.u32);
	// lwz r4,0(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm. r4,r4,0,26,26
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bne 0x82443258
	if (!cr0.eq) goto loc_82443258;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_82443258:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244323c
	if (!cr0.eq) goto loc_8244323C;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x824433b8
	if (cr6.eq) goto loc_824433B8;
	// li r27,1
	r27.s64 = 1;
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// bne cr6,0x82443280
	if (!cr6.eq) goto loc_82443280;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x824433b4
	goto loc_824433B4;
loc_82443280:
	// bge cr6,0x824433b8
	if (!cr6.lt) goto loc_824433B8;
	// rlwinm r10,r5,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xF0000000;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x824433b8
	if (cr6.lt) goto loc_824433B8;
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bgt cr6,0x824433b8
	if (cr6.gt) goto loc_824433B8;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi r10,r5,12
	ctx.r10.u64 = ctx.r5.u32 & 0xFFFFF;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// divwu r4,r9,r10
	ctx.r4.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
loc_824432C0:
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r8,r6,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244332c
	if (cr0.eq) goto loc_8244332C;
	// lwzx r8,r6,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// stwx r8,r31,r9
	PPC_STORE_U32(r31.u32 + ctx.r9.u32, ctx.r8.u32);
	// beq cr6,0x82443324
	if (cr6.eq) goto loc_82443324;
loc_824432F4:
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mullw r8,r10,r8
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// add r30,r8,r5
	r30.u64 = ctx.r8.u64 + ctx.r5.u64;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r30,r30,2,0,29
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// lwzx r30,r30,r9
	r30.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// stwx r30,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, r30.u32);
	// blt cr6,0x824432f4
	if (cr6.lt) goto loc_824432F4;
loc_82443324:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_8244332C:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// blt cr6,0x824432c0
	if (cr6.lt) goto loc_824432C0;
	// li r6,1
	ctx.r6.s64 = 1;
	// cmplwi cr6,r4,1
	cr6.compare<uint32_t>(ctx.r4.u32, 1, xer);
	// ble cr6,0x824433a0
	if (!cr6.gt) goto loc_824433A0;
	// rlwinm r30,r7,2,0,29
	r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_82443354:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82443390
	if (cr6.eq) goto loc_82443390;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
loc_82443364:
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mullw r5,r6,r5
	ctx.r5.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r5.s32);
	// add r5,r5,r10
	ctx.r5.u64 = ctx.r5.u64 + ctx.r10.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// lwzx r5,r5,r8
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// stwx r5,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r5.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// blt cr6,0x82443364
	if (cr6.lt) goto loc_82443364;
loc_82443390:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// add r31,r31,r30
	r31.u64 = r31.u64 + r30.u64;
	// cmplw cr6,r6,r4
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, xer);
	// blt cr6,0x82443354
	if (cr6.lt) goto loc_82443354;
loc_824433A0:
	// mullw r9,r7,r4
	ctx.r9.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r4.s32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r7,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r7.u32);
	// rlwimi r10,r7,0,12,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r7.u32, 0) & 0xFFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFF00000);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
loc_824433B4:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_824433B8:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82443200
	if (cr6.lt) goto loc_82443200;
loc_824433CC:
	// cntlzw r11,r27
	r11.u64 = r27.u32 == 0 ? 32 : __builtin_clz(r27.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_824433D8"))) PPC_WEAK_FUNC(sub_824433D8);
PPC_FUNC_IMPL(__imp__sub_824433D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d5d8
	sub_8243D5D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8244340c
	if (!cr0.eq) goto loc_8244340C;
loc_82443404:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82443544
	goto loc_82443544;
loc_8244340C:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r9,24704
	ctx.r9.s64 = 1619001344;
	// rlwinm r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// clrlwi r7,r10,12
	ctx.r7.u64 = ctx.r10.u32 & 0xFFFFF;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x82443480
	if (cr6.gt) goto loc_82443480;
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,4304
	ctx.r10.s64 = 282066944;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82443478
	if (cr6.eq) goto loc_82443478;
	// lis r10,4320
	ctx.r10.s64 = 283115520;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82443478
	if (cr6.eq) goto loc_82443478;
	// lis r10,24576
	ctx.r10.s64 = 1610612736;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24608
	ctx.r10.s64 = 1612709888;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24624
	ctx.r10.s64 = 1613758464;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24656
	ctx.r10.s64 = 1615855616;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24688
	ctx.r10.s64 = 1617952768;
	// b 0x824434c0
	goto loc_824434C0;
loc_82443478:
	// li r11,0
	r11.s64 = 0;
	// b 0x824434cc
	goto loc_824434CC;
loc_82443480:
	// lis r10,24736
	ctx.r10.s64 = 1621098496;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24768
	ctx.r10.s64 = 1623195648;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24784
	ctx.r10.s64 = 1624244224;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24816
	ctx.r10.s64 = 1626341376;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24848
	ctx.r10.s64 = 1628438528;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824434c8
	if (cr6.eq) goto loc_824434C8;
	// lis r10,24864
	ctx.r10.s64 = 1629487104;
loc_824434C0:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82443404
	if (!cr6.eq) goto loc_82443404;
loc_824434C8:
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
loc_824434CC:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r6,r10,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r6,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// andi. r8,r8,528
	ctx.r8.u64 = ctx.r8.u64 & 528;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82443404
	if (cr0.eq) goto loc_82443404;
	// li r8,1
	ctx.r8.s64 = 1;
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// ble cr6,0x82443540
	if (!cr6.gt) goto loc_82443540;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
loc_82443518:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r9
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// bne cr6,0x82443404
	if (!cr6.eq) goto loc_82443404;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// blt cr6,0x82443518
	if (cr6.lt) goto loc_82443518;
loc_82443540:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82443544:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8244355C"))) PPC_WEAK_FUNC(sub_8244355C);
PPC_FUNC_IMPL(__imp__sub_8244355C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82443560"))) PPC_WEAK_FUNC(sub_82443560);
PPC_FUNC_IMPL(__imp__sub_82443560) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// lwz r11,72(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824436f8
	if (cr6.eq) goto loc_824436F8;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824436f8
	if (cr6.eq) goto loc_824436F8;
	// li r29,1
	r29.s64 = 1;
	// b 0x824435bc
	goto loc_824435BC;
loc_82443598:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8243d2b8
	sub_8243D2B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824435d8
	if (cr0.eq) goto loc_824435D8;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824435dc
	if (cr6.eq) goto loc_824435DC;
loc_824435BC:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82443598
	if (!cr6.eq) goto loc_82443598;
	// b 0x824435dc
	goto loc_824435DC;
loc_824435D8:
	// li r29,0
	r29.s64 = 0;
loc_824435DC:
	// lwz r11,72(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 72);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d5d8
	sub_8243D5D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824436f8
	if (cr0.eq) goto loc_824436F8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824433d8
	sub_824433D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824436f8
	if (!cr0.eq) goto loc_824436F8;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x824436f8
	if (!cr6.eq) goto loc_824436F8;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r9
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// bl 0x8243d2b8
	sub_8243D2B8(ctx, base);
	// mr r29,r28
	r29.u64 = r28.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x824436a8
	if (!cr6.eq) goto loc_824436A8;
loc_82443648:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r11,20(r29)
	PPC_STORE_U32(r29.u32 + 20, r11.u32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,24(r29)
	PPC_STORE_U32(r29.u32 + 24, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824436a0
	if (cr6.eq) goto loc_824436A0;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244369c
	if (cr6.eq) goto loc_8244369C;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8243d2b8
	sub_8243D2B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82443648
	if (cr0.eq) goto loc_82443648;
	// b 0x824436a0
	goto loc_824436A0;
loc_8244369C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824436A0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x824436f8
	if (cr6.eq) goto loc_824436F8;
loc_824436A8:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r29,r30
	r29.u64 = r30.u64;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824436f0
	if (cr6.eq) goto loc_824436F0;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824436ec
	if (cr6.eq) goto loc_824436EC;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8243d2b8
	sub_8243D2B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824436a8
	if (!cr0.eq) goto loc_824436A8;
	// b 0x824436f0
	goto loc_824436F0;
loc_824436EC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824436F0:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82443648
	if (cr6.eq) goto loc_82443648;
loc_824436F8:
	// addi r5,r28,24
	ctx.r5.s64 = r28.s64 + 24;
	// lwz r7,24(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// addi r4,r28,20
	ctx.r4.s64 = r28.s64 + 20;
	// lwz r6,20(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243f398
	sub_8243F398(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_82443718"))) PPC_WEAK_FUNC(sub_82443718);
PPC_FUNC_IMPL(__imp__sub_82443718) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r8,r5,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r8,r10
	r30.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r31,r9,r10
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// bl 0x82443560
	sub_82443560(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824437a8
	if (cr0.lt) goto loc_824437A8;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r9,r11,0,7,3
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// rlwinm r10,r10,0,4,6
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	// rlwinm r11,r11,0,4,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// bgt cr6,0x82443780
	if (cr6.gt) goto loc_82443780;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82443780:
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824437a4
	if (!cr6.eq) goto loc_824437A4;
	// lwz r11,96(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 96);
	// stw r11,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r11.u32);
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
loc_824437A4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824437A8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824437C0"))) PPC_WEAK_FUNC(sub_824437C0);
PPC_FUNC_IMPL(__imp__sub_824437C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// lwz r3,0(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r4,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, ctx.r4.u32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r5,308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 308, ctx.r5.u32);
	// rlwinm r8,r7,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r7,16(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// lwzx r20,r10,r11
	r20.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r9,r8,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// stw r20,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r20.u32);
	// lwz r25,48(r10)
	r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// lwz r10,48(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// lwz r9,4(r20)
	ctx.r9.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// rlwinm r16,r25,2,0,29
	r16.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r25,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, r25.u32);
	// stw r10,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, ctx.r10.u32);
	// lwzx r15,r11,r16
	r15.u64 = PPC_LOAD_U32(r11.u32 + r16.u32);
	// lwzx r8,r9,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwzx r14,r9,r11
	r14.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444b90
	if (cr0.eq) goto loc_82444B90;
	// rlwinm. r11,r10,0,19,19
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82444b90
	if (!cr0.eq) goto loc_82444B90;
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// lis r29,8192
	r29.s64 = 536870912;
	// lwz r10,0(r15)
	ctx.r10.u64 = PPC_LOAD_U32(r15.u32 + 0);
	// lis r26,8208
	r26.s64 = 537919488;
	// lwz r9,0(r14)
	ctx.r9.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// rlwinm r28,r11,0,25,25
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// clrlwi r30,r10,27
	r30.u64 = ctx.r10.u32 & 0x1F;
	// clrlwi r22,r9,27
	r22.u64 = ctx.r9.u32 & 0x1F;
	// lis r21,8256
	r21.s64 = 541065216;
	// lis r7,8304
	ctx.r7.s64 = 544210944;
	// lis r6,8320
	ctx.r6.s64 = 545259520;
	// lis r31,8336
	r31.s64 = 546308096;
	// rlwinm. r8,r11,0,4,6
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824438e4
	if (!cr0.eq) goto loc_824438E4;
	// rlwinm r8,r3,0,0,11
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r8,r29
	cr6.compare<uint32_t>(ctx.r8.u32, r29.u32, xer);
	// beq cr6,0x824438b0
	if (cr6.eq) goto loc_824438B0;
	// cmplw cr6,r8,r26
	cr6.compare<uint32_t>(ctx.r8.u32, r26.u32, xer);
	// beq cr6,0x824438b0
	if (cr6.eq) goto loc_824438B0;
	// cmplw cr6,r8,r21
	cr6.compare<uint32_t>(ctx.r8.u32, r21.u32, xer);
	// beq cr6,0x824438b0
	if (cr6.eq) goto loc_824438B0;
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// beq cr6,0x824438b0
	if (cr6.eq) goto loc_824438B0;
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// beq cr6,0x824438b0
	if (cr6.eq) goto loc_824438B0;
	// cmplw cr6,r8,r31
	cr6.compare<uint32_t>(ctx.r8.u32, r31.u32, xer);
	// bne cr6,0x824438e4
	if (!cr6.eq) goto loc_824438E4;
loc_824438B0:
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// rlwinm. r9,r10,0,4,4
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824438c4
	if (cr0.eq) goto loc_824438C4;
	// oris r11,r11,2048
	r11.u64 = r11.u64 | 134217728;
	// b 0x824438e0
	goto loc_824438E0;
loc_824438C4:
	// rlwinm. r9,r10,0,5,5
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824438d4
	if (cr0.eq) goto loc_824438D4;
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// b 0x824438e0
	goto loc_824438E0;
loc_824438D4:
	// rlwinm. r10,r10,0,6,6
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824438e4
	if (cr0.eq) goto loc_824438E4;
	// oris r11,r11,512
	r11.u64 = r11.u64 | 33554432;
loc_824438E0:
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
loc_824438E4:
	// lwz r11,0(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// lis r27,8288
	r27.s64 = 543162368;
	// lwz r10,0(r15)
	ctx.r10.u64 = PPC_LOAD_U32(r15.u32 + 0);
	// lis r4,8272
	ctx.r4.s64 = 542113792;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443958
	if (cr0.eq) goto loc_82443958;
	// rlwinm r11,r3,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// bgt cr6,0x82443934
	if (cr6.gt) goto loc_82443934;
	// beq cr6,0x8244394c
	if (cr6.eq) goto loc_8244394C;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x8244394c
	if (cr6.eq) goto loc_8244394C;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// beq cr6,0x8244394c
	if (cr6.eq) goto loc_8244394C;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// beq cr6,0x8244394c
	if (cr6.eq) goto loc_8244394C;
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// beq cr6,0x8244394c
	if (cr6.eq) goto loc_8244394C;
	// b 0x82443958
	goto loc_82443958;
loc_82443934:
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beq cr6,0x8244394c
	if (cr6.eq) goto loc_8244394C;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// beq cr6,0x8244394c
	if (cr6.eq) goto loc_8244394C;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x82443958
	if (!cr6.eq) goto loc_82443958;
loc_8244394C:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
loc_82443958:
	// rlwinm r23,r3,0,0,11
	r23.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFF00000;
	// lis r18,8224
	r18.s64 = 538968064;
	// lis r17,8240
	r17.s64 = 540016640;
	// li r5,0
	ctx.r5.s64 = 0;
	// lis r24,4112
	r24.s64 = 269484032;
	// cmplw cr6,r23,r21
	cr6.compare<uint32_t>(r23.u32, r21.u32, xer);
	// bgt cr6,0x824439e0
	if (cr6.gt) goto loc_824439E0;
	// beq cr6,0x824439cc
	if (cr6.eq) goto loc_824439CC;
	// cmplw cr6,r23,r29
	cr6.compare<uint32_t>(r23.u32, r29.u32, xer);
	// beq cr6,0x824439c0
	if (cr6.eq) goto loc_824439C0;
	// cmplw cr6,r23,r26
	cr6.compare<uint32_t>(r23.u32, r26.u32, xer);
	// beq cr6,0x824439a4
	if (cr6.eq) goto loc_824439A4;
	// cmplw cr6,r23,r18
	cr6.compare<uint32_t>(r23.u32, r18.u32, xer);
	// beq cr6,0x82443998
	if (cr6.eq) goto loc_82443998;
	// cmplw cr6,r23,r17
	cr6.compare<uint32_t>(r23.u32, r17.u32, xer);
	// bne cr6,0x82443ba4
	if (!cr6.eq) goto loc_82443BA4;
loc_82443998:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// ori r11,r11,23
	r11.u64 = r11.u64 | 23;
	// b 0x82443ba0
	goto loc_82443BA0;
loc_824439A4:
	// ori r11,r30,4
	r11.u64 = r30.u64 | 4;
	// rlwinm r9,r30,0,29,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x4;
loc_824439AC:
	// and r11,r11,r22
	r11.u64 = r11.u64 & r22.u64;
	// lwz r10,0(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// b 0x82443ba0
	goto loc_82443BA0;
loc_824439C0:
	// ori r11,r30,8
	r11.u64 = r30.u64 | 8;
	// rlwinm r9,r30,0,28,28
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x8;
	// b 0x824439ac
	goto loc_824439AC;
loc_824439CC:
	// and r10,r22,r30
	ctx.r10.u64 = r22.u64 & r30.u64;
	// rlwinm r10,r10,0,28,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE;
loc_824439D4:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// b 0x82443ba0
	goto loc_82443BA0;
loc_824439E0:
	// cmplw cr6,r23,r4
	cr6.compare<uint32_t>(r23.u32, ctx.r4.u32, xer);
	// beq cr6,0x82443a08
	if (cr6.eq) goto loc_82443A08;
	// cmplw cr6,r23,r7
	cr6.compare<uint32_t>(r23.u32, ctx.r7.u32, xer);
	// beq cr6,0x82443a00
	if (cr6.eq) goto loc_82443A00;
	// cmplw cr6,r23,r6
	cr6.compare<uint32_t>(r23.u32, ctx.r6.u32, xer);
	// beq cr6,0x82443a00
	if (cr6.eq) goto loc_82443A00;
	// cmplw cr6,r23,r31
	cr6.compare<uint32_t>(r23.u32, r31.u32, xer);
	// bne cr6,0x82443ba4
	if (!cr6.eq) goto loc_82443BA4;
loc_82443A00:
	// and r10,r22,r30
	ctx.r10.u64 = r22.u64 & r30.u64;
	// b 0x824439d4
	goto loc_824439D4;
loc_82443A08:
	// and r9,r22,r30
	ctx.r9.u64 = r22.u64 & r30.u64;
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// rlwinm. r10,r30,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r9,r9,30
	ctx.r9.u64 = ctx.r9.u32 & 0x3;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
	// beq 0x82443a2c
	if (cr0.eq) goto loc_82443A2C;
	// rlwinm. r9,r22,0,29,29
	ctx.r9.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x82443a3c
	if (!cr0.eq) goto loc_82443A3C;
loc_82443A2C:
	// rlwinm. r9,r30,0,28,28
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82443a44
	if (cr0.eq) goto loc_82443A44;
	// rlwinm. r9,r22,0,28,28
	ctx.r9.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82443a44
	if (cr0.eq) goto loc_82443A44;
loc_82443A3C:
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
loc_82443A44:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82443a54
	if (cr6.eq) goto loc_82443A54;
	// rlwinm. r11,r22,0,28,28
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82443a64
	if (!cr0.eq) goto loc_82443A64;
loc_82443A54:
	// rlwinm. r11,r30,0,28,28
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443a70
	if (cr0.eq) goto loc_82443A70;
	// rlwinm. r11,r22,0,29,29
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443a70
	if (cr0.eq) goto loc_82443A70;
loc_82443A64:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
loc_82443A70:
	// cmplw cr6,r15,r14
	cr6.compare<uint32_t>(r15.u32, r14.u32, xer);
	// bne cr6,0x82443a84
	if (!cr6.eq) goto loc_82443A84;
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// b 0x82443ba0
	goto loc_82443BA0;
loc_82443A84:
	// lwz r10,4(r15)
	ctx.r10.u64 = PPC_LOAD_U32(r15.u32 + 4);
	// lwz r11,16(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82443b10
	if (cr0.eq) goto loc_82443B10;
	// lwz r10,72(r15)
	ctx.r10.u64 = PPC_LOAD_U32(r15.u32 + 72);
	// lwz r9,24(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r24
	cr6.compare<uint32_t>(ctx.r10.u32, r24.u32, xer);
	// bne cr6,0x82443b10
	if (!cr6.eq) goto loc_82443B10;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82443af0
	if (cr0.eq) goto loc_82443AF0;
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_82443AD4:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r7,r25
	cr6.compare<uint32_t>(ctx.r7.u32, r25.u32, xer);
	// beq cr6,0x82443af0
	if (cr6.eq) goto loc_82443AF0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82443ad4
	if (cr6.lt) goto loc_82443AD4;
loc_82443AF0:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x82443ba4
	if (!cr6.lt) goto loc_82443BA4;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// b 0x82443b94
	goto loc_82443B94;
loc_82443B10:
	// lwz r10,4(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443ba4
	if (cr0.eq) goto loc_82443BA4;
	// lwz r11,72(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 72);
	// lwz r10,24(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82443ba4
	if (!cr6.eq) goto loc_82443BA4;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82443b7c
	if (cr0.eq) goto loc_82443B7C;
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_82443B5C:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r6,324(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// beq cr6,0x82443b7c
	if (cr6.eq) goto loc_82443B7C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82443b5c
	if (cr6.lt) goto loc_82443B5C;
loc_82443B7C:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x82443ba4
	if (!cr6.lt) goto loc_82443BA4;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
loc_82443B94:
	// bne cr6,0x82443ba4
	if (!cr6.eq) goto loc_82443BA4;
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
loc_82443BA0:
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
loc_82443BA4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82443c34
	if (!cr6.eq) goto loc_82443C34;
	// rlwinm. r11,r30,0,29,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443c14
	if (cr0.eq) goto loc_82443C14;
	// rlwinm. r11,r22,0,28,28
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443c14
	if (cr0.eq) goto loc_82443C14;
	// cmplw cr6,r23,r29
	cr6.compare<uint32_t>(r23.u32, r29.u32, xer);
	// beq cr6,0x82443c0c
	if (cr6.eq) goto loc_82443C0C;
	// cmplw cr6,r23,r26
	cr6.compare<uint32_t>(r23.u32, r26.u32, xer);
	// beq cr6,0x82443c04
	if (cr6.eq) goto loc_82443C04;
	// cmplw cr6,r23,r18
	cr6.compare<uint32_t>(r23.u32, r18.u32, xer);
	// beq cr6,0x824440d0
	if (cr6.eq) goto loc_824440D0;
	// cmplw cr6,r23,r17
	cr6.compare<uint32_t>(r23.u32, r17.u32, xer);
	// bne cr6,0x82443c14
	if (!cr6.eq) goto loc_82443C14;
loc_82443BDC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f1,-31360(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_82443BE4:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82443BFC:
	// stw r11,48(r20)
	PPC_STORE_U32(r20.u32 + 48, r11.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82443C04:
	// stw r25,48(r20)
	PPC_STORE_U32(r20.u32 + 48, r25.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82443C0C:
	// lwz r11,324(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// b 0x82443bfc
	goto loc_82443BFC;
loc_82443C14:
	// rlwinm. r11,r30,0,28,28
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443c34
	if (cr0.eq) goto loc_82443C34;
	// rlwinm. r11,r22,0,29,29
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443c34
	if (cr0.eq) goto loc_82443C34;
	// cmplw cr6,r23,r29
	cr6.compare<uint32_t>(r23.u32, r29.u32, xer);
	// beq cr6,0x82443c04
	if (cr6.eq) goto loc_82443C04;
	// cmplw cr6,r23,r26
	cr6.compare<uint32_t>(r23.u32, r26.u32, xer);
	// beq cr6,0x82443c0c
	if (cr6.eq) goto loc_82443C0C;
loc_82443C34:
	// lwz r11,4(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 4);
	// lwz r25,16(r19)
	r25.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r7,0,23,23
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82443d0c
	if (cr0.eq) goto loc_82443D0C;
	// lwz r10,8(r15)
	ctx.r10.u64 = PPC_LOAD_U32(r15.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82443d0c
	if (!cr6.eq) goto loc_82443D0C;
	// lwz r10,4(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82443d0c
	if (cr0.eq) goto loc_82443D0C;
	// lwz r10,8(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82443d0c
	if (!cr6.eq) goto loc_82443D0C;
	// lfd f1,32(r15)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r15.u32 + 32);
	// cmplw cr6,r23,r29
	cr6.compare<uint32_t>(r23.u32, r29.u32, xer);
	// lfd f2,32(r14)
	ctx.f2.u64 = PPC_LOAD_U64(r14.u32 + 32);
	// beq cr6,0x82443cfc
	if (cr6.eq) goto loc_82443CFC;
	// cmplw cr6,r23,r26
	cr6.compare<uint32_t>(r23.u32, r26.u32, xer);
	// beq cr6,0x82443cf0
	if (cr6.eq) goto loc_82443CF0;
	// cmplw cr6,r23,r18
	cr6.compare<uint32_t>(r23.u32, r18.u32, xer);
	// beq cr6,0x82443ce4
	if (cr6.eq) goto loc_82443CE4;
	// cmplw cr6,r23,r17
	cr6.compare<uint32_t>(r23.u32, r17.u32, xer);
	// beq cr6,0x82443cd8
	if (cr6.eq) goto loc_82443CD8;
	// cmplw cr6,r23,r21
	cr6.compare<uint32_t>(r23.u32, r21.u32, xer);
	// beq cr6,0x82443cd0
	if (cr6.eq) goto loc_82443CD0;
	// cmplw cr6,r23,r4
	cr6.compare<uint32_t>(r23.u32, ctx.r4.u32, xer);
	// beq cr6,0x82443cc8
	if (cr6.eq) goto loc_82443CC8;
	// cmplw cr6,r23,r27
	cr6.compare<uint32_t>(r23.u32, r27.u32, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// bl 0x8239e050
	sub_8239E050(ctx, base);
	// b 0x82443be4
	goto loc_82443BE4;
loc_82443CC8:
	// fmul f1,f2,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f2.f64 * ctx.f1.f64;
	// b 0x82443be4
	goto loc_82443BE4;
loc_82443CD0:
	// fadd f1,f2,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f2.f64 + ctx.f1.f64;
	// b 0x82443be4
	goto loc_82443BE4;
loc_82443CD8:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// blt cr6,0x824440d0
	if (cr6.lt) goto loc_824440D0;
	// b 0x82443bdc
	goto loc_82443BDC;
loc_82443CE4:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// bge cr6,0x824440d0
	if (!cr6.lt) goto loc_824440D0;
	// b 0x82443bdc
	goto loc_82443BDC;
loc_82443CF0:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// bge cr6,0x82443be4
	if (!cr6.lt) goto loc_82443BE4;
	// b 0x82443d04
	goto loc_82443D04;
loc_82443CFC:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// blt cr6,0x82443be4
	if (cr6.lt) goto loc_82443BE4;
loc_82443D04:
	// fmr f1,f2
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f2.f64;
	// b 0x82443be4
	goto loc_82443BE4;
loc_82443D0C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x8244407c
	if (!cr6.eq) goto loc_8244407C;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82443d28
	if (cr6.eq) goto loc_82443D28;
	// lwz r10,8(r15)
	ctx.r10.u64 = PPC_LOAD_U32(r15.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82443d4c
	if (cr6.eq) goto loc_82443D4C;
loc_82443D28:
	// lwz r10,4(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244407c
	if (cr0.eq) goto loc_8244407C;
	// lwz r10,8(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244407c
	if (!cr6.eq) goto loc_8244407C;
loc_82443D4C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82443d74
	if (cr6.eq) goto loc_82443D74;
	// lwz r11,8(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82443d74
	if (!cr6.eq) goto loc_82443D74;
	// lwz r10,324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// lfd f0,32(r15)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r15.u32 + 32);
	// mr r11,r22
	r11.u64 = r22.u64;
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// b 0x82443d84
	goto loc_82443D84;
loc_82443D74:
	// lfd f0,32(r14)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r14.u32 + 32);
	// lwz r6,316(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// lwz r10,324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// mr r11,r30
	r11.u64 = r30.u64;
loc_82443D84:
	// cmplw cr6,r23,r29
	cr6.compare<uint32_t>(r23.u32, r29.u32, xer);
	// beq cr6,0x82444044
	if (cr6.eq) goto loc_82444044;
	// cmplw cr6,r23,r26
	cr6.compare<uint32_t>(r23.u32, r26.u32, xer);
	// beq cr6,0x82444014
	if (cr6.eq) goto loc_82444014;
	// cmplw cr6,r23,r18
	cr6.compare<uint32_t>(r23.u32, r18.u32, xer);
	// beq cr6,0x82443f74
	if (cr6.eq) goto loc_82443F74;
	// cmplw cr6,r23,r17
	cr6.compare<uint32_t>(r23.u32, r17.u32, xer);
	// beq cr6,0x82443ee4
	if (cr6.eq) goto loc_82443EE4;
	// cmplw cr6,r23,r21
	cr6.compare<uint32_t>(r23.u32, r21.u32, xer);
	// beq cr6,0x82443ec8
	if (cr6.eq) goto loc_82443EC8;
	// cmplw cr6,r23,r4
	cr6.compare<uint32_t>(r23.u32, ctx.r4.u32, xer);
	// beq cr6,0x82443ddc
	if (cr6.eq) goto loc_82443DDC;
	// cmplw cr6,r23,r27
	cr6.compare<uint32_t>(r23.u32, r27.u32, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// lwz r11,316(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// b 0x82443fb0
	goto loc_82443FB0;
loc_82443DDC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x82443fb0
	if (cr6.eq) goto loc_82443FB0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,-31360(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x82443e04
	if (!cr6.eq) goto loc_82443E04;
loc_82443DFC:
	// stw r6,48(r20)
	PPC_STORE_U32(r20.u32 + 48, ctx.r6.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82443E04:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lfd f13,-28592(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -28592);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// lwz r7,20(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82444b90
	if (cr0.eq) goto loc_82444B90;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r10,24(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82443e88
	if (cr0.eq) goto loc_82443E88;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82443E6C:
	// lwz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// beq cr6,0x82443e88
	if (cr6.eq) goto loc_82443E88;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82443e6c
	if (cr6.lt) goto loc_82443E6C;
loc_82443E88:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x82444b90
	if (!cr6.lt) goto loc_82444B90;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r8,r11
	r11.u64 = ctx.r8.u64 + r11.u64;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwzx r6,r11,r9
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82443bfc
	goto loc_82443BFC;
loc_82443EC8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfd f13,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x82444b94
	if (!cr6.eq) goto loc_82444B94;
	// stw r6,48(r20)
	PPC_STORE_U32(r20.u32 + 48, ctx.r6.u32);
	// b 0x82444b94
	goto loc_82444B94;
loc_82443EE4:
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,-31368(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// bne cr6,0x82443f28
	if (!cr6.eq) goto loc_82443F28;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x82443f04
	if (!cr6.lt) goto loc_82443F04;
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443fb0
	if (!cr0.eq) goto loc_82443FB0;
loc_82443F04:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x82443f14
	if (cr6.lt) goto loc_82443F14;
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443f94
	if (!cr0.eq) goto loc_82443F94;
loc_82443F14:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,-31360(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x82444b90
	if (cr6.lt) goto loc_82444B90;
	// b 0x82444008
	goto loc_82444008;
loc_82443F28:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x82443f38
	if (cr6.gt) goto loc_82443F38;
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443f94
	if (!cr0.eq) goto loc_82443F94;
loc_82443F38:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x82443f48
	if (!cr6.gt) goto loc_82443F48;
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443fb0
	if (!cr0.eq) goto loc_82443FB0;
loc_82443F48:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f12,-31360(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// ble cr6,0x82443f60
	if (!cr6.gt) goto loc_82443F60;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443fb0
	if (!cr0.eq) goto loc_82443FB0;
loc_82443F60:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f12.f64);
loc_82443F64:
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
loc_82443F6C:
	// beq 0x82444b90
	if (cr0.eq) goto loc_82444B90;
	// b 0x82443dfc
	goto loc_82443DFC;
loc_82443F74:
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,-31368(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// bne cr6,0x82443fd8
	if (!cr6.eq) goto loc_82443FD8;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x82443fa0
	if (!cr6.lt) goto loc_82443FA0;
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82443fa0
	if (cr0.eq) goto loc_82443FA0;
loc_82443F94:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// b 0x82444074
	goto loc_82444074;
loc_82443FA0:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x82443fb8
	if (cr6.lt) goto loc_82443FB8;
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82443fb8
	if (cr0.eq) goto loc_82443FB8;
loc_82443FB0:
	// fmr f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f13.f64;
	// b 0x82444074
	goto loc_82444074;
loc_82443FB8:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f12,-31360(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x82443fd0
	if (cr6.lt) goto loc_82443FD0;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443fb0
	if (!cr0.eq) goto loc_82443FB0;
loc_82443FD0:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// b 0x82443f64
	goto loc_82443F64;
loc_82443FD8:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x82443fe8
	if (cr6.gt) goto loc_82443FE8;
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443fb0
	if (!cr0.eq) goto loc_82443FB0;
loc_82443FE8:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x82443ff8
	if (!cr6.gt) goto loc_82443FF8;
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443f94
	if (!cr0.eq) goto loc_82443F94;
loc_82443FF8:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,-31360(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x82444b90
	if (!cr6.gt) goto loc_82444B90;
loc_82444008:
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444b90
	if (cr0.eq) goto loc_82444B90;
	// b 0x82443fb0
	goto loc_82443FB0;
loc_82444014:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,-31360(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x8244402c
	if (cr6.lt) goto loc_8244402C;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82444074
	if (!cr0.eq) goto loc_82444074;
loc_8244402C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,-31368(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x82444b90
	if (cr6.gt) goto loc_82444B90;
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// b 0x82443f6c
	goto loc_82443F6C;
loc_82444044:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,-31360(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x8244405c
	if (cr6.lt) goto loc_8244405C;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82443dfc
	if (!cr0.eq) goto loc_82443DFC;
loc_8244405C:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,-31368(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x82444b90
	if (cr6.gt) goto loc_82444B90;
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444b90
	if (cr0.eq) goto loc_82444B90;
loc_82444074:
	// fmr f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f0.f64;
	// b 0x82443be4
	goto loc_82443BE4;
loc_8244407C:
	// cmplw cr6,r15,r14
	cr6.compare<uint32_t>(r15.u32, r14.u32, xer);
	// bne cr6,0x824440dc
	if (!cr6.eq) goto loc_824440DC;
	// cmplw cr6,r23,r29
	cr6.compare<uint32_t>(r23.u32, r29.u32, xer);
	// beq cr6,0x824440b4
	if (cr6.eq) goto loc_824440B4;
	// cmplw cr6,r23,r26
	cr6.compare<uint32_t>(r23.u32, r26.u32, xer);
	// beq cr6,0x824440b4
	if (cr6.eq) goto loc_824440B4;
	// cmplw cr6,r23,r18
	cr6.compare<uint32_t>(r23.u32, r18.u32, xer);
	// beq cr6,0x824440c8
	if (cr6.eq) goto loc_824440C8;
	// cmplw cr6,r23,r17
	cr6.compare<uint32_t>(r23.u32, r17.u32, xer);
	// beq cr6,0x824440bc
	if (cr6.eq) goto loc_824440BC;
	// cmplw cr6,r23,r4
	cr6.compare<uint32_t>(r23.u32, ctx.r4.u32, xer);
	// bne cr6,0x824440dc
	if (!cr6.eq) goto loc_824440DC;
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824440dc
	if (cr0.eq) goto loc_824440DC;
loc_824440B4:
	// lwz r11,316(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// b 0x82443bfc
	goto loc_82443BFC;
loc_824440BC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// b 0x82443bdc
	goto loc_82443BDC;
loc_824440C8:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
loc_824440D0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f1,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// b 0x82443be4
	goto loc_82443BE4;
loc_824440DC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// cmplw cr6,r23,r21
	cr6.compare<uint32_t>(r23.u32, r21.u32, xer);
	// bne cr6,0x82444438
	if (!cr6.eq) goto loc_82444438;
	// lwz r11,4(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444184
	if (cr0.eq) goto loc_82444184;
	// lwz r11,72(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 72);
	// lwz r10,24(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82444184
	if (!cr6.eq) goto loc_82444184;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8244415c
	if (cr0.eq) goto loc_8244415C;
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_82444138:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r26,324(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// cmplw cr6,r6,r26
	cr6.compare<uint32_t>(ctx.r6.u32, r26.u32, xer);
	// beq cr6,0x82444160
	if (cr6.eq) goto loc_82444160;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82444138
	if (cr6.lt) goto loc_82444138;
	// b 0x82444160
	goto loc_82444160;
loc_8244415C:
	// lwz r26,324(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
loc_82444160:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x82444188
	if (!cr6.lt) goto loc_82444188;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82444188
	if (!cr6.eq) goto loc_82444188;
	// b 0x824440d0
	goto loc_824440D0;
loc_82444184:
	// lwz r26,324(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
loc_82444188:
	// rlwinm. r11,r7,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444200
	if (cr0.eq) goto loc_82444200;
	// lwz r11,72(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 72);
	// lwz r10,24(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82444200
	if (!cr6.eq) goto loc_82444200;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x824441e4
	if (cr0.eq) goto loc_824441E4;
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_824441C4:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r6,316(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// beq cr6,0x824441e4
	if (cr6.eq) goto loc_824441E4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x824441c4
	if (cr6.lt) goto loc_824441C4;
loc_824441E4:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x82444200
	if (!cr6.lt) goto loc_82444200;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// beq cr6,0x824440d0
	if (cr6.eq) goto loc_824440D0;
loc_82444200:
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
loc_82444204:
	// rlwinm. r11,r27,0,29,29
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// beq 0x82444220
	if (cr0.eq) goto loc_82444220;
	// lwz r30,316(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// b 0x82444228
	goto loc_82444228;
loc_82444220:
	// lwz r6,316(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// mr r30,r26
	r30.u64 = r26.u64;
loc_82444228:
	// rlwinm. r29,r27,0,30,30
	r29.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x824442c0
	if (cr0.eq) goto loc_824442C0;
	// lwz r7,20(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82444420
	if (cr0.eq) goto loc_82444420;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r10,24(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82444420
	if (!cr6.eq) goto loc_82444420;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x824442c0
	if (cr0.eq) goto loc_824442C0;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82444288:
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r30,r3
	cr6.compare<uint32_t>(r30.u32, ctx.r3.u32, xer);
	// beq cr6,0x824442a8
	if (cr6.eq) goto loc_824442A8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82444288
	if (cr6.lt) goto loc_82444288;
	// b 0x824442c0
	goto loc_824442C0;
loc_824442A8:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r30,48(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 48);
loc_824442C0:
	// lwz r3,20(r19)
	ctx.r3.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82444420
	if (cr0.eq) goto loc_82444420;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r7,24(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r7
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x82444420
	if (!cr6.eq) goto loc_82444420;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82444388
	if (cr0.eq) goto loc_82444388;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82444318:
	// lwz r26,0(r8)
	r26.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r6,r26
	cr6.compare<uint32_t>(ctx.r6.u32, r26.u32, xer);
	// beq cr6,0x82444338
	if (cr6.eq) goto loc_82444338;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82444318
	if (cr6.lt) goto loc_82444318;
	// b 0x82444384
	goto loc_82444384;
loc_82444338:
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// clrlwi. r8,r27,31
	ctx.r8.u64 = r27.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// beq 0x8244435c
	if (cr0.eq) goto loc_8244435C;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// b 0x82444368
	goto loc_82444368;
loc_8244435C:
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
loc_82444368:
	// lwz r11,20(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r31,48(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// lwz r28,48(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 48);
loc_82444384:
	// lwz r26,324(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
loc_82444388:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82444418
	if (!cr6.eq) goto loc_82444418;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82444420
	if (cr0.eq) goto loc_82444420;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r7
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82444420
	if (!cr6.eq) goto loc_82444420;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82444418
	if (cr0.eq) goto loc_82444418;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_824443E0:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r31,r7
	cr6.compare<uint32_t>(r31.u32, ctx.r7.u32, xer);
	// beq cr6,0x82444400
	if (cr6.eq) goto loc_82444400;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x824443e0
	if (cr6.lt) goto loc_824443E0;
	// b 0x82444418
	goto loc_82444418;
loc_82444400:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// lwz r31,48(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 48);
loc_82444418:
	// cmplw cr6,r30,r31
	cr6.compare<uint32_t>(r30.u32, r31.u32, xer);
	// beq cr6,0x82444430
	if (cr6.eq) goto loc_82444430;
loc_82444420:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmplwi cr6,r27,8
	cr6.compare<uint32_t>(r27.u32, 8, xer);
	// blt cr6,0x82444204
	if (cr6.lt) goto loc_82444204;
	// b 0x8244443c
	goto loc_8244443C;
loc_82444430:
	// stw r28,48(r20)
	PPC_STORE_U32(r20.u32 + 48, r28.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82444438:
	// lwz r26,324(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
loc_8244443C:
	// lis r29,4144
	r29.s64 = 271581184;
	// cmplw cr6,r23,r4
	cr6.compare<uint32_t>(r23.u32, ctx.r4.u32, xer);
	// bne cr6,0x824445a8
	if (!cr6.eq) goto loc_824445A8;
	// lwz r11,316(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// lwz r3,20(r19)
	ctx.r3.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r26.u32);
	// stw r5,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r5.u32);
	// stw r5,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r5.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r5,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r5.u32);
	// stw r5,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r5.u32);
loc_8244446C:
	// addi r11,r1,88
	r11.s64 = ctx.r1.s64 + 88;
	// add r31,r6,r11
	r31.u64 = ctx.r6.u64 + r11.u64;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82444550
	if (cr0.eq) goto loc_82444550;
	// lwz r30,24(r19)
	r30.u64 = PPC_LOAD_U32(r19.u32 + 24);
loc_8244449C:
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r30
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x824444c0
	if (!cr6.eq) goto loc_824444C0;
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// b 0x824444cc
	goto loc_824444CC;
loc_824444C0:
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bne cr6,0x82444550
	if (!cr6.eq) goto loc_82444550;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
loc_824444CC:
	// lwzx r10,r6,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stwx r10,r6,r11
	PPC_STORE_U32(ctx.r6.u32 + r11.u32, ctx.r10.u32);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// beq 0x82444528
	if (cr0.eq) goto loc_82444528;
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_824444F0:
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r4,r7
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r7.u32, xer);
	// beq cr6,0x82444510
	if (cr6.eq) goto loc_82444510;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x824444f0
	if (cr6.lt) goto loc_824444F0;
	// b 0x82444528
	goto loc_82444528;
loc_82444510:
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r3
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// lwz r7,48(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
loc_82444528:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x8244459c
	if (!cr6.lt) goto loc_8244459C;
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244449c
	if (!cr0.eq) goto loc_8244449C;
loc_82444550:
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// stw r7,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r7.u32);
	// cmplwi cr6,r6,8
	cr6.compare<uint32_t>(ctx.r6.u32, 8, xer);
	// blt cr6,0x8244446c
	if (cr6.lt) goto loc_8244446C;
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x824445a8
	if (!cr6.eq) goto loc_824445A8;
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x824445a8
	if (cr6.eq) goto loc_824445A8;
	// lwz r11,108(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x82443bdc
	if (cr6.eq) goto loc_82443BDC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f1,-30984(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -30984);
	// b 0x82443be4
	goto loc_82443BE4;
loc_8244459C:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82444b94
	goto loc_82444B94;
loc_824445A8:
	// cmplw cr6,r23,r18
	cr6.compare<uint32_t>(r23.u32, r18.u32, xer);
	// bne cr6,0x82444648
	if (!cr6.eq) goto loc_82444648;
	// lwz r11,20(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwzx r11,r16,r11
	r11.u64 = PPC_LOAD_U32(r16.u32 + r11.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82444648
	if (cr0.eq) goto loc_82444648;
	// clrlwi. r10,r22,31
	ctx.r10.u64 = r22.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82444648
	if (cr0.eq) goto loc_82444648;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r10,24(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82444648
	if (!cr6.eq) goto loc_82444648;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8244462c
	if (cr0.eq) goto loc_8244462C;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_8244460C:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r6,316(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// beq cr6,0x8244462c
	if (cr6.eq) goto loc_8244462C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244460c
	if (cr6.lt) goto loc_8244460C;
loc_8244462C:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bne cr6,0x82444648
	if (!cr6.eq) goto loc_82444648;
	// stw r26,48(r20)
	PPC_STORE_U32(r20.u32 + 48, r26.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82444648:
	// lwz r20,20(r19)
	r20.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwzx r9,r16,r20
	ctx.r9.u64 = PPC_LOAD_U32(r16.u32 + r20.u32);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444b90
	if (cr0.eq) goto loc_82444B90;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwzx r11,r8,r20
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r20.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444b90
	if (cr0.eq) goto loc_82444B90;
	// lis r3,8272
	ctx.r3.s64 = 542113792;
	// cmplw cr6,r23,r3
	cr6.compare<uint32_t>(r23.u32, ctx.r3.u32, xer);
	// beq cr6,0x824446a4
	if (cr6.eq) goto loc_824446A4;
	// cmplw cr6,r23,r18
	cr6.compare<uint32_t>(r23.u32, r18.u32, xer);
	// beq cr6,0x824446a4
	if (cr6.eq) goto loc_824446A4;
	// cmplw cr6,r23,r17
	cr6.compare<uint32_t>(r23.u32, r17.u32, xer);
	// bne cr6,0x82444808
	if (!cr6.eq) goto loc_82444808;
loc_824446A4:
	// lwz r11,20(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r10,24(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// lwzx r7,r16,r11
	ctx.r7.u64 = PPC_LOAD_U32(r16.u32 + r11.u32);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r8,72(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 72);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r8,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r6,r11,r10
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82444808
	if (!cr6.eq) goto loc_82444808;
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bne cr6,0x82444808
	if (!cr6.eq) goto loc_82444808;
	// lwz r5,300(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// li r31,0
	r31.s64 = 0;
	// lwz r10,12(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82444724
	if (cr0.eq) goto loc_82444724;
	// lwz r11,16(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
loc_82444704:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,308(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x82444724
	if (cr6.eq) goto loc_82444724;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r31,r10
	cr6.compare<uint32_t>(r31.u32, ctx.r10.u32, xer);
	// blt cr6,0x82444704
	if (cr6.lt) goto loc_82444704;
loc_82444724:
	// lwz r10,12(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82444758
	if (cr0.eq) goto loc_82444758;
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
loc_82444738:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r4,316(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// cmplw cr6,r4,r8
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r8.u32, xer);
	// beq cr6,0x82444758
	if (cr6.eq) goto loc_82444758;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x82444738
	if (cr6.lt) goto loc_82444738;
loc_82444758:
	// lwz r8,12(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8244478c
	if (cr0.eq) goto loc_8244478C;
	// lwz r10,16(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
loc_8244476C:
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r30,324(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// cmplw cr6,r30,r4
	cr6.compare<uint32_t>(r30.u32, ctx.r4.u32, xer);
	// beq cr6,0x8244478c
	if (cr6.eq) goto loc_8244478C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244476c
	if (cr6.lt) goto loc_8244476C;
loc_8244478C:
	// cmplw cr6,r23,r3
	cr6.compare<uint32_t>(r23.u32, ctx.r3.u32, xer);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// bne cr6,0x824447b0
	if (!cr6.eq) goto loc_824447B0;
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,8(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// lwzx r11,r9,r10
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r10,r7,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// b 0x824447c4
	goto loc_824447C4;
loc_824447B0:
	// lwz r10,8(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,8(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
loc_824447C4:
	// lwz r9,20(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r31,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,8(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// stwx r11,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, r11.u32);
	// lwz r9,20(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// lwz r8,8(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// stwx r10,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r10.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82444808:
	// lwz r31,316(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// cmplw cr6,r23,r3
	cr6.compare<uint32_t>(r23.u32, ctx.r3.u32, xer);
	// lwz r30,324(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// bne cr6,0x82444950
	if (!cr6.eq) goto loc_82444950;
	// lwz r11,72(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 72);
	// lis r4,4208
	ctx.r4.s64 = 275775488;
	// lwz r8,24(r19)
	ctx.r8.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r11,r8
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r5,r11,0,0,11
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r5,r29
	cr6.compare<uint32_t>(ctx.r5.u32, r29.u32, xer);
	// beq cr6,0x8244484c
	if (cr6.eq) goto loc_8244484C;
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x82444950
	if (!cr6.eq) goto loc_82444950;
loc_8244484C:
	// lwz r9,12(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8244487c
	if (cr0.eq) goto loc_8244487C;
	// lwz r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
loc_82444860:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r6,r31
	cr6.compare<uint32_t>(ctx.r6.u32, r31.u32, xer);
	// beq cr6,0x8244487c
	if (cr6.eq) goto loc_8244487C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82444860
	if (cr6.lt) goto loc_82444860;
loc_8244487C:
	// rlwinm r6,r11,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r20
	r11.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82444950
	if (cr0.eq) goto loc_82444950;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82444950
	if (!cr6.eq) goto loc_82444950;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// beq cr6,0x824448d8
	if (cr6.eq) goto loc_824448D8;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bne cr6,0x82444950
	if (!cr6.eq) goto loc_82444950;
loc_824448D8:
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x82444950
	if (cr6.eq) goto loc_82444950;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82444928
	if (!cr6.gt) goto loc_82444928;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// li r10,0
	ctx.r10.s64 = 0;
loc_824448F8:
	// lwz r5,8(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwzx r5,r5,r6
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r6.u32);
	// stwx r5,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r5.u32);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r5,r9,r10
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82444928
	if (!cr6.eq) goto loc_82444928;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r5
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, xer);
	// blt cr6,0x824448f8
	if (cr6.lt) goto loc_824448F8;
loc_82444928:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r19)
	ctx.r9.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
loc_82444944:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,48(r10)
	PPC_STORE_U32(ctx.r10.u32 + 48, r11.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82444950:
	// cmplw cr6,r23,r3
	cr6.compare<uint32_t>(r23.u32, ctx.r3.u32, xer);
	// bne cr6,0x82444b90
	if (!cr6.eq) goto loc_82444B90;
	// lwz r11,0(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 0);
	// clrlwi. r21,r11,31
	r21.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// beq 0x82444988
	if (cr0.eq) goto loc_82444988;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8243f4f8
	sub_8243F4F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82444988
	if (cr0.eq) goto loc_82444988;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r30,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r30.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82444988:
	// lwz r11,0(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// clrlwi. r22,r11,31
	r22.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// beq 0x824449b8
	if (cr0.eq) goto loc_824449B8;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8243f4f8
	sub_8243F4F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824449b8
	if (cr0.eq) goto loc_824449B8;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r31,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r31.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_824449B8:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r26,0
	r26.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// li r24,1
	r24.s64 = 1;
	// li r23,1
	r23.s64 = 1;
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r30,24(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82444b90
	if (cr6.eq) goto loc_82444B90;
	// lwz r28,24(r19)
	r28.u64 = PPC_LOAD_U32(r19.u32 + 24);
	// lwz r25,20(r19)
	r25.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r17,316(r1)
	r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// lwz r18,324(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
loc_824449EC:
	// rlwinm r29,r11,2,0,29
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r10,r29,r20
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r20.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r10,r28
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + r28.u32);
	// lwz r10,12(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82444a30
	if (cr0.eq) goto loc_82444A30;
	// lwz r9,16(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
loc_82444A14:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x82444a30
	if (cr6.eq) goto loc_82444A30;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x82444a14
	if (cr6.lt) goto loc_82444A14;
loc_82444A30:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82444a88
	if (cr6.eq) goto loc_82444A88;
	// lwz r11,8(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8243f4f8
	sub_8243F4F8(ctx, base);
	// and. r11,r3,r30
	r11.u64 = ctx.r3.u64 & r30.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444a60
	if (cr0.eq) goto loc_82444A60;
	// li r26,1
	r26.s64 = 1;
loc_82444A60:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x82444a88
	if (!cr6.eq) goto loc_82444A88;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8243f4f8
	sub_8243F4F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82444a88
	if (cr0.eq) goto loc_82444A88;
	// li r26,1
	r26.s64 = 1;
	// li r24,0
	r24.s64 = 0;
loc_82444A88:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82444ae0
	if (cr6.eq) goto loc_82444AE0;
	// lwz r11,8(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// bl 0x8243f4f8
	sub_8243F4F8(ctx, base);
	// and. r11,r3,r30
	r11.u64 = ctx.r3.u64 & r30.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444ab8
	if (cr0.eq) goto loc_82444AB8;
	// li r27,1
	r27.s64 = 1;
loc_82444AB8:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x82444ae0
	if (!cr6.eq) goto loc_82444AE0;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8243f4f8
	sub_8243F4F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82444ae0
	if (cr0.eq) goto loc_82444AE0;
	// li r27,1
	r27.s64 = 1;
	// li r23,0
	r23.s64 = 0;
loc_82444AE0:
	// lwzx r10,r25,r29
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + r29.u32);
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r30,24(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824449ec
	if (!cr6.eq) goto loc_824449EC;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x82444b40
	if (cr6.eq) goto loc_82444B40;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82444b38
	if (cr6.eq) goto loc_82444B38;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x82444b50
	if (cr6.eq) goto loc_82444B50;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x82444b38
	if (cr6.eq) goto loc_82444B38;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f1,-31360(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_82444B1C:
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r4,120(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x82444944
	goto loc_82444944;
loc_82444B38:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x82444b50
	if (cr6.eq) goto loc_82444B50;
loc_82444B40:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82444b5c
	if (cr6.eq) goto loc_82444B5C;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x82444b5c
	if (!cr6.eq) goto loc_82444B5C;
loc_82444B50:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f1,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// b 0x82444b1c
	goto loc_82444B1C;
loc_82444B5C:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x82444b78
	if (cr6.eq) goto loc_82444B78;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x82444b78
	if (cr6.eq) goto loc_82444B78;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r18,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r18.u32);
	// b 0x82444b90
	goto loc_82444B90;
loc_82444B78:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82444b90
	if (cr6.eq) goto loc_82444B90;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x82444b90
	if (cr6.eq) goto loc_82444B90;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r17,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r17.u32);
loc_82444B90:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82444B94:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_82444B9C"))) PPC_WEAK_FUNC(sub_82444B9C);
PPC_FUNC_IMPL(__imp__sub_82444B9C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82444BA0"))) PPC_WEAK_FUNC(sub_82444BA0);
PPC_FUNC_IMPL(__imp__sub_82444BA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bccc
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r18,r5
	r18.u64 = ctx.r5.u64;
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r18,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,16(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// mr r17,r4
	r17.u64 = ctx.r4.u64;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r9,r7,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r23,48(r10)
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r19,48(r8)
	r19.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// rlwinm r8,r23,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r20,48(r9)
	r20.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r7,r20,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r27,r8,r11
	r27.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// rlwinm r8,r9,0,25,25
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// rlwinm r6,r19,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r24,r7,r11
	r24.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwzx r30,r6,r11
	r30.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// clrlwi. r11,r10,31
	r11.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444d78
	if (cr0.eq) goto loc_82444D78;
	// rlwinm. r11,r10,0,19,19
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82444d78
	if (!cr0.eq) goto loc_82444D78;
	// rlwinm. r11,r9,0,4,6
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r10,12288
	ctx.r10.s64 = 805306368;
	// bne 0x82444ca0
	if (!cr0.eq) goto loc_82444CA0;
	// lwz r11,0(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82444ca0
	if (!cr6.eq) goto loc_82444CA0;
	// lwz r7,0(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// rlwinm. r7,r11,0,4,4
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82444c64
	if (cr0.eq) goto loc_82444C64;
	// oris r11,r9,2048
	r11.u64 = ctx.r9.u64 | 134217728;
	// b 0x82444c80
	goto loc_82444C80;
loc_82444C64:
	// rlwinm. r7,r11,0,5,5
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82444c74
	if (cr0.eq) goto loc_82444C74;
	// oris r11,r9,1024
	r11.u64 = ctx.r9.u64 | 67108864;
	// b 0x82444c80
	goto loc_82444C80;
loc_82444C74:
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444c84
	if (cr0.eq) goto loc_82444C84;
	// oris r11,r9,512
	r11.u64 = ctx.r9.u64 | 33554432;
loc_82444C80:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82444C84:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r9,0(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82444CA0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r9,0(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444cd4
	if (cr0.eq) goto loc_82444CD4;
	// lwz r11,0(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82444cd4
	if (!cr6.eq) goto loc_82444CD4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,64
	ctx.r8.s64 = 64;
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82444CD4:
	// lwz r11,0(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82444d50
	if (!cr6.eq) goto loc_82444D50;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444cf4
	if (cr0.eq) goto loc_82444CF4;
	// li r8,64
	ctx.r8.s64 = 64;
loc_82444CF4:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r23,r20
	cr6.compare<uint32_t>(r23.u32, r20.u32, xer);
	// lwz r9,0(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// and r11,r11,r9
	r11.u64 = r11.u64 & ctx.r9.u64;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bne cr6,0x82444d30
	if (!cr6.eq) goto loc_82444D30;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444d30
	if (cr0.eq) goto loc_82444D30;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82444D30:
	// cmplw cr6,r23,r19
	cr6.compare<uint32_t>(r23.u32, r19.u32, xer);
	// bne cr6,0x82444d50
	if (!cr6.eq) goto loc_82444D50;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444d50
	if (cr0.eq) goto loc_82444D50;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82444D50:
	// lwz r11,0(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82444d78
	if (!cr6.eq) goto loc_82444D78;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82444d84
	if (!cr6.eq) goto loc_82444D84;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444d84
	if (cr0.eq) goto loc_82444D84;
loc_82444D74:
	// stw r20,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r20.u32);
loc_82444D78:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82444D7C:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x8239bd1c
	return;
loc_82444D84:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// lwz r22,16(r25)
	r22.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r22
	r11.u64 = PPC_LOAD_U32(r11.u32 + r22.u32);
	// lwz r28,4(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r28,0,23,23
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444dd0
	if (cr0.eq) goto loc_82444DD0;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82444dd0
	if (!cr6.eq) goto loc_82444DD0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,32(r27)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r27.u32 + 32);
	// lfd f0,-31368(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// mr r11,r20
	r11.u64 = r20.u64;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x82444dc8
	if (!cr6.lt) goto loc_82444DC8;
	// mr r11,r19
	r11.u64 = r19.u64;
loc_82444DC8:
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// b 0x82444d78
	goto loc_82444D78;
loc_82444DD0:
	// cmplw cr6,r20,r19
	cr6.compare<uint32_t>(r20.u32, r19.u32, xer);
	// beq cr6,0x82444d74
	if (cr6.eq) goto loc_82444D74;
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r22
	r11.u64 = PPC_LOAD_U32(r11.u32 + r22.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r29,r11,0,23,23
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x82444e30
	if (cr0.eq) goto loc_82444E30;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82444e30
	if (!cr6.eq) goto loc_82444E30;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r22
	r11.u64 = PPC_LOAD_U32(r11.u32 + r22.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444e30
	if (cr0.eq) goto loc_82444E30;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82444e30
	if (!cr6.eq) goto loc_82444E30;
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// lfd f13,32(r30)
	ctx.f13.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x82444d74
	if (cr6.eq) goto loc_82444D74;
loc_82444E30:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82444d78
	if (!cr6.eq) goto loc_82444D78;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r21,4112
	r21.s64 = 269484032;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// lfd f12,-31360(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// lfd f13,-31368(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// bne cr6,0x82444d78
	if (!cr6.eq) goto loc_82444D78;
	// rlwinm. r11,r28,0,30,30
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444f38
	if (cr0.eq) goto loc_82444F38;
	// lwz r11,72(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 72);
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x82444f38
	if (!cr6.eq) goto loc_82444F38;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82444f38
	if (cr6.eq) goto loc_82444F38;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82444f38
	if (!cr6.eq) goto loc_82444F38;
	// lfd f0,32(r24)
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x82444f38
	if (!cr6.eq) goto loc_82444F38;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r22
	r11.u64 = PPC_LOAD_U32(r11.u32 + r22.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444f38
	if (cr0.eq) goto loc_82444F38;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82444f38
	if (!cr6.eq) goto loc_82444F38;
	// lfd f0,32(r30)
	f0.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bne cr6,0x82444f38
	if (!cr6.eq) goto loc_82444F38;
	// lwz r9,12(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82444f00
	if (cr0.eq) goto loc_82444F00;
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
loc_82444EE4:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r7,r23
	cr6.compare<uint32_t>(ctx.r7.u32, r23.u32, xer);
	// beq cr6,0x82444f00
	if (cr6.eq) goto loc_82444F00;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82444ee4
	if (cr6.lt) goto loc_82444EE4;
loc_82444F00:
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444f38
	if (cr0.eq) goto loc_82444F38;
	// stw r10,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r10.u32);
	// b 0x82444d78
	goto loc_82444D78;
loc_82444F38:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x82444d78
	if (!cr6.eq) goto loc_82444D78;
	// rlwinm. r11,r28,0,30,30
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82445098
	if (cr0.eq) goto loc_82445098;
	// lwz r11,72(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 72);
	// lis r9,8272
	ctx.r9.s64 = 542113792;
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x82445098
	if (!cr6.eq) goto loc_82445098;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82445098
	if (cr6.eq) goto loc_82445098;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82445098
	if (!cr6.eq) goto loc_82445098;
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x82445098
	if (!cr6.eq) goto loc_82445098;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r22
	r11.u64 = PPC_LOAD_U32(r11.u32 + r22.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82445098
	if (cr0.eq) goto loc_82445098;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82445098
	if (!cr6.eq) goto loc_82445098;
	// lfd f0,32(r30)
	f0.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bne cr6,0x82445098
	if (!cr6.eq) goto loc_82445098;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82444fec
	if (cr0.eq) goto loc_82444FEC;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82444FD0:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r7,r23
	cr6.compare<uint32_t>(ctx.r7.u32, r23.u32, xer);
	// beq cr6,0x82444fec
	if (cr6.eq) goto loc_82444FEC;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x82444fd0
	if (cr6.lt) goto loc_82444FD0;
loc_82444FEC:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// lwz r7,20(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r4,r11,-4
	ctx.r4.s64 = r11.s64 * -4;
	// add r11,r8,r10
	r11.u64 = ctx.r8.u64 + ctx.r10.u64;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
loc_82445018:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwzx r26,r8,r7
	r26.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,48(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// lwz r9,48(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 48);
	// rlwinm r26,r8,2,0,29
	r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r26,r26,r7
	r26.u64 = PPC_LOAD_U32(r26.u32 + ctx.r7.u32);
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r26,0(r26)
	r26.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// clrlwi. r26,r26,31
	r26.u64 = r26.u32 & 0x1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// beq 0x82445084
	if (cr0.eq) goto loc_82445084;
	// lwz r26,4(r9)
	r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r26,r26,2,0,29
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r26,r26,r22
	r26.u64 = PPC_LOAD_U32(r26.u32 + r22.u32);
	// lwz r26,4(r26)
	r26.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// rlwinm. r26,r26,0,23,23
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// beq 0x82445084
	if (cr0.eq) goto loc_82445084;
	// lwz r26,8(r9)
	r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r26,-1
	cr6.compare<int32_t>(r26.s32, -1, xer);
	// bne cr6,0x82445084
	if (!cr6.eq) goto loc_82445084;
	// lfd f0,32(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x82445128
	if (cr6.lt) goto loc_82445128;
loc_82445084:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// add r11,r5,r11
	r11.u64 = ctx.r5.u64 + r11.u64;
	// add r10,r4,r10
	ctx.r10.u64 = ctx.r4.u64 + ctx.r10.u64;
	// cmplwi cr6,r6,2
	cr6.compare<uint32_t>(ctx.r6.u32, 2, xer);
	// blt cr6,0x82445018
	if (cr6.lt) goto loc_82445018;
loc_82445098:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x82444d78
	if (!cr6.eq) goto loc_82444D78;
	// rlwinm. r11,r28,0,30,30
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82444d78
	if (cr0.eq) goto loc_82444D78;
	// lwz r11,72(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 72);
	// lis r9,8256
	ctx.r9.s64 = 541065216;
	// lwz r26,24(r25)
	r26.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r26
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x82444d78
	if (!cr6.eq) goto loc_82444D78;
	// li r31,-1
	r31.s64 = -1;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8244514c
	if (cr6.eq) goto loc_8244514C;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244514c
	if (!cr6.eq) goto loc_8244514C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r22
	r11.u64 = PPC_LOAD_U32(r11.u32 + r22.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244514c
	if (cr0.eq) goto loc_8244514C;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244514c
	if (!cr6.eq) goto loc_8244514C;
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x82445130
	if (!cr6.eq) goto loc_82445130;
	// lfd f11,32(r30)
	ctx.f11.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// fcmpu cr6,f11,f12
	cr6.compare(ctx.f11.f64, ctx.f12.f64);
	// bne cr6,0x82445130
	if (!cr6.eq) goto loc_82445130;
	// lis r31,8224
	r31.s64 = 538968064;
	// b 0x82445148
	goto loc_82445148;
loc_82445128:
	// stw r8,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r8.u32);
	// b 0x82444d78
	goto loc_82444D78;
loc_82445130:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f12.f64);
	// bne cr6,0x8244514c
	if (!cr6.eq) goto loc_8244514C;
	// lfd f0,32(r30)
	f0.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x8244514c
	if (!cr6.eq) goto loc_8244514C;
	// lis r31,8240
	r31.s64 = 540016640;
loc_82445148:
	// ori r31,r31,1
	r31.u64 = r31.u64 | 1;
loc_8244514C:
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8244517c
	if (cr0.eq) goto loc_8244517C;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82445160:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r7,r23
	cr6.compare<uint32_t>(ctx.r7.u32, r23.u32, xer);
	// beq cr6,0x8244517c
	if (cr6.eq) goto loc_8244517C;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x82445160
	if (cr6.lt) goto loc_82445160;
loc_8244517C:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// li r3,0
	ctx.r3.s64 = 0;
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// lwz r4,20(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r27,r11,-4
	r27.s64 = r11.s64 * -4;
	// add r7,r8,r10
	ctx.r7.u64 = ctx.r8.u64 + ctx.r10.u64;
	// add r6,r9,r10
	ctx.r6.u64 = ctx.r9.u64 + ctx.r10.u64;
loc_824451A8:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// lwzx r10,r10,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// lwz r5,48(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r29,48(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82445284
	if (!cr6.eq) goto loc_82445284;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r22
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r22.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82445284
	if (cr0.eq) goto loc_82445284;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r26
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x82445284
	if (!cr6.eq) goto loc_82445284;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82445240
	if (cr0.eq) goto loc_82445240;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82445224:
	// lwz r30,0(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r30,r5
	cr6.compare<uint32_t>(r30.u32, ctx.r5.u32, xer);
	// beq cr6,0x82445240
	if (cr6.eq) goto loc_82445240;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82445224
	if (cr6.lt) goto loc_82445224;
loc_82445240:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r30,48(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// bne cr6,0x824452ac
	if (!cr6.eq) goto loc_824452AC;
	// cmplw cr6,r20,r30
	cr6.compare<uint32_t>(r20.u32, r30.u32, xer);
	// bne cr6,0x82445274
	if (!cr6.eq) goto loc_82445274;
	// cmplw cr6,r19,r29
	cr6.compare<uint32_t>(r19.u32, r29.u32, xer);
	// beq cr6,0x8244529c
	if (cr6.eq) goto loc_8244529C;
loc_82445274:
	// cmplw cr6,r20,r29
	cr6.compare<uint32_t>(r20.u32, r29.u32, xer);
	// bne cr6,0x82445284
	if (!cr6.eq) goto loc_82445284;
	// cmplw cr6,r19,r30
	cr6.compare<uint32_t>(r19.u32, r30.u32, xer);
	// beq cr6,0x824452a4
	if (cr6.eq) goto loc_824452A4;
loc_82445284:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// add r7,r28,r7
	ctx.r7.u64 = r28.u64 + ctx.r7.u64;
	// add r6,r27,r6
	ctx.r6.u64 = r27.u64 + ctx.r6.u64;
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// blt cr6,0x824451a8
	if (cr6.lt) goto loc_824451A8;
	// b 0x82444d78
	goto loc_82444D78;
loc_8244529C:
	// lis r31,8192
	r31.s64 = 536870912;
	// b 0x824452a8
	goto loc_824452A8;
loc_824452A4:
	// lis r31,8208
	r31.s64 = 537919488;
loc_824452A8:
	// ori r31,r31,1
	r31.u64 = r31.u64 | 1;
loc_824452AC:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8243d018
	sub_8243D018(ctx, base);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8243d7a8
	sub_8243D7A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82445318
	if (cr0.lt) goto loc_82445318;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82445318
	if (cr0.lt) goto loc_82445318;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// stw r18,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r18.u32);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r29,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r29.u32);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r30,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r30.u32);
	// bl 0x824437c0
	sub_824437C0(ctx, base);
loc_82445318:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82444d7c
	goto loc_82444D7C;
}

__attribute__((alias("__imp__sub_8244532C"))) PPC_WEAK_FUNC(sub_8244532C);
PPC_FUNC_IMPL(__imp__sub_8244532C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82445330"))) PPC_WEAK_FUNC(sub_82445330);
PPC_FUNC_IMPL(__imp__sub_82445330) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stfd f31,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// lis r11,20480
	r11.s64 = 1342177280;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r20,r5
	r20.u64 = ctx.r5.u64;
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm r9,r10,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x82445ac8
	if (!cr6.eq) goto loc_82445AC8;
	// lwz r11,16(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 16);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r8,16(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r25,r11,r9
	r25.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82445ac8
	if (cr0.eq) goto loc_82445AC8;
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82445ac8
	if (!cr0.eq) goto loc_82445AC8;
	// clrlwi. r23,r10,12
	r23.u64 = ctx.r10.u32 & 0xFFFFF;
	cr0.compare<int32_t>(r23.s32, 0, xer);
	// li r3,14
	ctx.r3.s64 = 14;
	// li r22,0
	r22.s64 = 0;
	// beq 0x8244548c
	if (cr0.eq) goto loc_8244548C;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r10,r23,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + r11.u64;
loc_824453BC:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// beq cr6,0x824453f4
	if (cr6.eq) goto loc_824453F4;
	// lwzx r7,r7,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,48(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_824453F4:
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// rlwinm. r7,r5,0,29,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82445414
	if (cr0.eq) goto loc_82445414;
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r31,r31,0,29,29
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x82445430
	if (!cr0.eq) goto loc_82445430;
loc_82445414:
	// rlwinm. r31,r5,0,28,28
	r31.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x82445428
	if (cr0.eq) goto loc_82445428;
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r31,r31,0,28,28
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x82445430
	if (!cr0.eq) goto loc_82445430;
loc_82445428:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82445434
	if (!cr6.eq) goto loc_82445434;
loc_82445430:
	// li r6,4
	ctx.r6.s64 = 4;
loc_82445434:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82445448
	if (cr6.eq) goto loc_82445448;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244545c
	if (!cr0.eq) goto loc_8244545C;
loc_82445448:
	// rlwinm. r10,r5,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82445460
	if (cr0.eq) goto loc_82445460;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82445460
	if (cr0.eq) goto loc_82445460;
loc_8244545C:
	// ori r6,r6,8
	ctx.r6.u64 = ctx.r6.u64 | 8;
loc_82445460:
	// rlwinm. r10,r5,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82445478
	if (cr0.eq) goto loc_82445478;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82445478
	if (cr0.eq) goto loc_82445478;
	// ori r6,r6,2
	ctx.r6.u64 = ctx.r6.u64 | 2;
loc_82445478:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// and r3,r6,r3
	ctx.r3.u64 = ctx.r6.u64 & ctx.r3.u64;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x824453bc
	if (!cr0.eq) goto loc_824453BC;
loc_8244548C:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// or r11,r11,r3
	r11.u64 = r11.u64 | ctx.r3.u64;
	// li r21,1
	r21.s64 = 1;
	// lfd f31,-31360(r10)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31368(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// beq cr6,0x82445674
	if (cr6.eq) goto loc_82445674;
	// fmr f1,f0
	ctx.f1.f64 = f0.f64;
	// mr r28,r22
	r28.u64 = r22.u64;
	// li r27,-1
	r27.s64 = -1;
	// mr r30,r22
	r30.u64 = r22.u64;
	// mr r29,r22
	r29.u64 = r22.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82445634
	if (cr6.eq) goto loc_82445634;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r10,r23,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r31,16(r26)
	r31.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
loc_824454E8:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r7,48(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r6,48(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82445540
	if (cr0.eq) goto loc_82445540;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82445544
	if (cr6.eq) goto loc_82445544;
loc_82445540:
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
loc_82445544:
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244556c
	if (cr0.eq) goto loc_8244556C;
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// beq cr6,0x82445570
	if (cr6.eq) goto loc_82445570;
loc_8244556C:
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_82445570:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x82445584
	if (cr6.eq) goto loc_82445584;
	// lfd f13,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x82445598
	if (cr6.eq) goto loc_82445598;
loc_82445584:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x824455a0
	if (cr6.eq) goto loc_824455A0;
	// lfd f13,32(r8)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x824455a0
	if (!cr6.eq) goto loc_824455A0;
loc_82445598:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// b 0x824455f4
	goto loc_824455F4;
loc_824455A0:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x824455d8
	if (cr6.eq) goto loc_824455D8;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x824455c4
	if (cr6.eq) goto loc_824455C4;
	// lfd f13,32(r8)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + 32);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// lfd f12,32(r11)
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fmadd f1,f13,f12,f1
	ctx.f1.f64 = ctx.f13.f64 * ctx.f12.f64 + ctx.f1.f64;
	// b 0x824455f4
	goto loc_824455F4;
loc_824455C4:
	// lfd f13,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bne cr6,0x82445608
	if (!cr6.eq) goto loc_82445608;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// b 0x824455f0
	goto loc_824455F0;
loc_824455D8:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82445608
	if (cr6.eq) goto loc_82445608;
	// lfd f13,32(r8)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + 32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bne cr6,0x82445608
	if (!cr6.eq) goto loc_82445608;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
loc_824455F0:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_824455F4:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// cmplw cr6,r29,r23
	cr6.compare<uint32_t>(r29.u32, r23.u32, xer);
	// blt cr6,0x824454e8
	if (cr6.lt) goto loc_824454E8;
loc_82445608:
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// bne cr6,0x82445634
	if (!cr6.eq) goto loc_82445634;
	// addi r11,r23,-1
	r11.s64 = r23.s64 + -1;
	// cmplw cr6,r11,r28
	cr6.compare<uint32_t>(r11.u32, r28.u32, xer);
	// bne cr6,0x82445634
	if (!cr6.eq) goto loc_82445634;
	// fcmpu cr6,f1,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f0.f64);
	// bne cr6,0x82445634
	if (!cr6.eq) goto loc_82445634;
	// stw r22,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r22.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r27,48(r25)
	PPC_STORE_U32(r25.u32 + 48, r27.u32);
	// b 0x82445acc
	goto loc_82445ACC;
loc_82445634:
	// cmplw cr6,r23,r28
	cr6.compare<uint32_t>(r23.u32, r28.u32, xer);
	// bne cr6,0x82445674
	if (!cr6.eq) goto loc_82445674;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r22,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r22.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,120(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 120);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,48(r25)
	PPC_STORE_U32(r25.u32 + 48, r11.u32);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// stw r11,48(r10)
	PPC_STORE_U32(ctx.r10.u32 + 48, r11.u32);
	// b 0x82445acc
	goto loc_82445ACC;
loc_82445674:
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r31,r22
	r31.u64 = r22.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x824458e8
	if (cr6.eq) goto loc_824458E8;
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r30,r23,2,0,29
	r30.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,16(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// add r8,r10,r30
	ctx.r8.u64 = ctx.r10.u64 + r30.u64;
loc_824456A0:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r29,0(r8)
	r29.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r29,r29,2,0,29
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// beq cr6,0x824456d8
	if (cr6.eq) goto loc_824456D8;
	// lwzx r29,r29,r11
	r29.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// lwz r9,48(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r29,48(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// rlwinm r29,r29,2,0,29
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
loc_824456D8:
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// lwz r29,4(r9)
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r29,r29,2,0,29
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r29,r6
	r29.u64 = PPC_LOAD_U32(r29.u32 + ctx.r6.u32);
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm. r29,r29,0,23,23
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x8244570c
	if (cr0.eq) goto loc_8244570C;
	// lwz r29,8(r9)
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// bne cr6,0x8244570c
	if (!cr6.eq) goto loc_8244570C;
	// lfd f13,32(r9)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x8244573c
	if (cr6.eq) goto loc_8244573C;
loc_8244570C:
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82445748
	if (cr0.eq) goto loc_82445748;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82445748
	if (!cr6.eq) goto loc_82445748;
	// lfd f13,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x82445748
	if (!cr6.eq) goto loc_82445748;
loc_8244573C:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// b 0x82445750
	goto loc_82445750;
loc_82445748:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
loc_82445750:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x824456a0
	if (!cr0.eq) goto loc_824456A0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x824458e8
	if (cr6.eq) goto loc_824458E8;
	// cmplwi cr6,r3,2
	cr6.compare<uint32_t>(ctx.r3.u32, 2, xer);
	// bne cr6,0x8244577c
	if (!cr6.eq) goto loc_8244577C;
	// lwz r11,108(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824458e8
	if (cr0.eq) goto loc_824458E8;
loc_8244577C:
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// beq cr6,0x824457a0
	if (cr6.eq) goto loc_824457A0;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x824457a0
	if (cr6.eq) goto loc_824457A0;
	// lwz r11,108(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// rlwinm. r10,r11,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824458e8
	if (!cr0.eq) goto loc_824458E8;
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824458e8
	if (!cr0.eq) goto loc_824458E8;
loc_824457A0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82445948
	if (cr6.eq) goto loc_82445948;
	// mr r31,r22
	r31.u64 = r22.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
loc_824457C0:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r7,r11,r8
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwzx r6,r11,r9
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// beq cr6,0x824457fc
	if (cr6.eq) goto loc_824457FC;
	// lwz r7,48(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	// lwzx r6,r6,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
loc_824457FC:
	// lwzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r6,16(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwz r29,4(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r29,r29,2,0,29
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r29,r6
	r29.u64 = PPC_LOAD_U32(r29.u32 + ctx.r6.u32);
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// rlwinm. r29,r29,0,23,23
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x82445834
	if (cr0.eq) goto loc_82445834;
	// lwz r29,8(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// bne cr6,0x82445834
	if (!cr6.eq) goto loc_82445834;
	// lfd f13,32(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x82445884
	if (cr6.eq) goto loc_82445884;
loc_82445834:
	// lwz r10,4(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82445864
	if (cr0.eq) goto loc_82445864;
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82445864
	if (!cr6.eq) goto loc_82445864;
	// lfd f13,32(r7)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x82445884
	if (cr6.eq) goto loc_82445884;
loc_82445864:
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// stwx r10,r11,r5
	PPC_STORE_U32(r11.u32 + ctx.r5.u32, ctx.r10.u32);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwzx r10,r11,r8
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stwx r10,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r10.u32);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
loc_82445884:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x824457c0
	if (!cr0.eq) goto loc_824457C0;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r5,r31,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// add r3,r11,r5
	ctx.r3.u64 = r11.u64 + ctx.r5.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// cmplwi cr6,r31,1
	cr6.compare<uint32_t>(r31.u32, 1, xer);
	// bne cr6,0x824458bc
	if (!cr6.eq) goto loc_824458BC;
	// lis r11,8272
	r11.s64 = 542113792;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// b 0x824458c4
	goto loc_824458C4;
loc_824458BC:
	// clrlwi r11,r31,12
	r11.u64 = r31.u32 & 0xFFFFF;
	// oris r11,r11,20480
	r11.u64 = r11.u64 | 1342177280;
loc_824458C4:
	// subf r10,r23,r31
	ctx.r10.s64 = r31.s64 - r23.s64;
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// rlwinm r9,r31,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r21,12(r24)
	PPC_STORE_U32(r24.u32 + 12, r21.u32);
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// mr r23,r31
	r23.u64 = r31.u64;
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stw r9,4(r24)
	PPC_STORE_U32(r24.u32 + 4, ctx.r9.u32);
	// xori r31,r10,1
	r31.u64 = ctx.r10.u64 ^ 1;
loc_824458E8:
	// cmplwi cr6,r23,1
	cr6.compare<uint32_t>(r23.u32, 1, xer);
	// ble cr6,0x82445904
	if (!cr6.gt) goto loc_82445904;
	// cmplwi cr6,r23,2
	cr6.compare<uint32_t>(r23.u32, 2, xer);
	// bne cr6,0x82445abc
	if (!cr6.eq) goto loc_82445ABC;
	// lwz r11,108(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 108);
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82445abc
	if (!cr0.eq) goto loc_82445ABC;
loc_82445904:
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82445a00
	if (cr6.eq) goto loc_82445A00;
	// lwz r5,16(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// rlwinm r8,r23,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244591C:
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// bne cr6,0x82445954
	if (!cr6.eq) goto loc_82445954;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x8244598c
	goto loc_8244598C;
loc_82445948:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r22,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r22.u32);
	// b 0x82445acc
	goto loc_82445ACC;
loc_82445954:
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r7,r9,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r7,48(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_8244598C:
	// lwz r10,4(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824459bc
	if (cr0.eq) goto loc_824459BC;
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x824459bc
	if (!cr6.eq) goto loc_824459BC;
	// lfd f0,32(r7)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x824459ec
	if (cr6.eq) goto loc_824459EC;
loc_824459BC:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82445a00
	if (cr0.eq) goto loc_82445A00;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82445a00
	if (!cr6.eq) goto loc_82445A00;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x82445a00
	if (!cr6.eq) goto loc_82445A00;
loc_824459EC:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r6,r23
	cr6.compare<uint32_t>(ctx.r6.u32, r23.u32, xer);
	// blt cr6,0x8244591c
	if (cr6.lt) goto loc_8244591C;
loc_82445A00:
	// cmplw cr6,r6,r23
	cr6.compare<uint32_t>(ctx.r6.u32, r23.u32, xer);
	// bne cr6,0x82445abc
	if (!cr6.eq) goto loc_82445ABC;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82445a90
	if (cr6.eq) goto loc_82445A90;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// rlwinm r8,r23,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
loc_82445A1C:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r6,r10,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// beq cr6,0x82445a40
	if (cr6.eq) goto loc_82445A40;
	// lwzx r6,r6,r9
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
loc_82445A40:
	// lwzx r9,r6,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r5,16(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r5
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm. r6,r6,0,23,23
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x82445a80
	if (cr0.eq) goto loc_82445A80;
	// lwz r6,8(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// bne cr6,0x82445a80
	if (!cr6.eq) goto loc_82445A80;
	// lfd f0,32(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x82445a80
	if (!cr6.eq) goto loc_82445A80;
	// lwzx r9,r8,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
loc_82445A80:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82445a1c
	if (!cr0.eq) goto loc_82445A1C;
loc_82445A90:
	// cmplwi cr6,r23,2
	cr6.compare<uint32_t>(r23.u32, 2, xer);
	// bne cr6,0x82445aa8
	if (!cr6.eq) goto loc_82445AA8;
	// li r10,2
	ctx.r10.s64 = 2;
	// lis r11,8256
	r11.s64 = 541065216;
	// stw r10,4(r24)
	PPC_STORE_U32(r24.u32 + 4, ctx.r10.u32);
	// b 0x82445ab0
	goto loc_82445AB0;
loc_82445AA8:
	// lis r11,4096
	r11.s64 = 268435456;
	// stw r21,4(r24)
	PPC_STORE_U32(r24.u32 + 4, r21.u32);
loc_82445AB0:
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// mr r31,r21
	r31.u64 = r21.u64;
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
loc_82445ABC:
	// cntlzw r11,r31
	r11.u64 = r31.u32 == 0 ? 32 : __builtin_clz(r31.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x82445acc
	goto loc_82445ACC;
loc_82445AC8:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82445ACC:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-112(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_82445AD8"))) PPC_WEAK_FUNC(sub_82445AD8);
PPC_FUNC_IMPL(__imp__sub_82445AD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// li r27,0
	r27.s64 = 0;
	// clrlwi r10,r11,12
	ctx.r10.u64 = r11.u32 & 0xFFFFF;
	// divwu. r26,r9,r10
	r26.u32 = ctx.r9.u32 / ctx.r10.u32;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// twllei r10,0
	// beq 0x82445b90
	if (cr0.eq) goto loc_82445B90;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r5,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,20(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r29,16(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r28,r10,2,0,29
	r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r8,r11
	ctx.r6.u64 = ctx.r8.u64 + r11.u64;
	// add r7,r9,r11
	ctx.r7.u64 = ctx.r9.u64 + r11.u64;
loc_82445B24:
	// lwz r4,0(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// lwz r5,0(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82445b7c
	if (cr0.eq) goto loc_82445B7C;
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82445b7c
	if (cr0.eq) goto loc_82445B7C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82440158
	sub_82440158(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82445b9c
	if (cr0.eq) goto loc_82445B9C;
loc_82445B7C:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// add r7,r28,r7
	ctx.r7.u64 = r28.u64 + ctx.r7.u64;
	// add r6,r28,r6
	ctx.r6.u64 = r28.u64 + ctx.r6.u64;
	// cmplw cr6,r27,r26
	cr6.compare<uint32_t>(r27.u32, r26.u32, xer);
	// blt cr6,0x82445b24
	if (cr6.lt) goto loc_82445B24;
loc_82445B90:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82445B94:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
loc_82445B9C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82445b94
	goto loc_82445B94;
}

__attribute__((alias("__imp__sub_82445BA4"))) PPC_WEAK_FUNC(sub_82445BA4);
PPC_FUNC_IMPL(__imp__sub_82445BA4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82445BA8"))) PPC_WEAK_FUNC(sub_82445BA8);
PPC_FUNC_IMPL(__imp__sub_82445BA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc4
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r18,12(r31)
	r18.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// twllei r18,0
	// divwu r15,r11,r18
	r15.u32 = r11.u32 / r18.u32;
	// bl 0x8243d130
	sub_8243D130(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq 0x82445c90
	if (cr0.eq) goto loc_82445C90;
	// li r29,0
	r29.s64 = 0;
	// beq cr6,0x824460f8
	if (cr6.eq) goto loc_824460F8;
	// li r28,0
	r28.s64 = 0;
	// li r17,-1
	r17.s64 = -1;
loc_82445BF0:
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r11,1
	r11.s64 = 1;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// rlwimi r4,r11,0,12,31
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFF) | (ctx.r4.u64 & 0xFFFFFFFFFFF00000);
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82445e9c
	if (cr6.eq) goto loc_82445E9C;
	// lwz r11,24(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82445c6c
	if (cr6.eq) goto loc_82445C6C;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82445C3C:
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r9,r11,r9
	ctx.r9.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + r29.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stwx r9,r10,r7
	PPC_STORE_U32(ctx.r10.u32 + ctx.r7.u32, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x82445c3c
	if (cr6.lt) goto loc_82445C3C;
loc_82445C6C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplw cr6,r29,r18
	cr6.compare<uint32_t>(r29.u32, r18.u32, xer);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// blt cr6,0x82445bf0
	if (cr6.lt) goto loc_82445BF0;
	// b 0x824460f8
	goto loc_824460F8;
loc_82445C90:
	// mr r16,r18
	r16.u64 = r18.u64;
	// li r26,0
	r26.s64 = 0;
	// li r17,-1
	r17.s64 = -1;
	// beq cr6,0x82445e2c
	if (cr6.eq) goto loc_82445E2C;
	// li r27,0
	r27.s64 = 0;
loc_82445CA4:
	// lwz r29,16(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r29,r27
	r11.u64 = PPC_LOAD_U32(r29.u32 + r27.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82445e1c
	if (cr6.eq) goto loc_82445E1C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwz r9,16(r22)
	ctx.r9.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82445e1c
	if (cr0.eq) goto loc_82445E1C;
	// li r30,0
	r30.s64 = 0;
	// cmplw cr6,r26,r18
	cr6.compare<uint32_t>(r26.u32, r18.u32, xer);
	// bge cr6,0x82445d28
	if (!cr6.lt) goto loc_82445D28;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// subf r6,r26,r18
	ctx.r6.s64 = r18.s64 - r26.s64;
loc_82445CF0:
	// lwzx r11,r29,r7
	r11.u64 = PPC_LOAD_U32(r29.u32 + ctx.r7.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82445d1c
	if (cr6.eq) goto loc_82445D1C;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// lwzx r5,r11,r7
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwzx r4,r11,r27
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// bl 0x82440158
	sub_82440158(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82445d1c
	if (cr0.eq) goto loc_82445D1C;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_82445D1C:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x82445cf0
	if (!cr0.eq) goto loc_82445CF0;
loc_82445D28:
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// rlwimi r4,r30,0,12,31
	ctx.r4.u64 = (__builtin_rotateleft32(r30.u32, 0) & 0xFFFFF) | (ctx.r4.u64 & 0xFFFFFFFFFFF00000);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82445e9c
	if (cr6.eq) goto loc_82445E9C;
	// lwz r11,24(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplw cr6,r26,r18
	cr6.compare<uint32_t>(r26.u32, r18.u32, xer);
	// lwzx r4,r11,r27
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// bge cr6,0x82445e1c
	if (!cr6.lt) goto loc_82445E1C;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r28,0
	r28.s64 = 0;
loc_82445D80:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r5,r11,r6
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x82445e0c
	if (cr6.eq) goto loc_82445E0C;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82440158
	sub_82440158(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82445e0c
	if (cr0.eq) goto loc_82445E0C;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82445de8
	if (cr6.eq) goto loc_82445DE8;
loc_82445DAC:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mullw r9,r11,r10
	ctx.r9.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + r29.u64;
	// mullw r10,r11,r8
	ctx.r10.s64 = int64_t(r11.s32) * int64_t(ctx.r8.s32);
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// stwx r9,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r9.u32);
	// blt cr6,0x82445dac
	if (cr6.lt) goto loc_82445DAC;
loc_82445DE8:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r16,r16,-1
	r16.s64 = r16.s64 + -1;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// stwx r11,r10,r28
	PPC_STORE_U32(ctx.r10.u32 + r28.u32, r11.u32);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stwx r17,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, r17.u32);
loc_82445E0C:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r29,r18
	cr6.compare<uint32_t>(r29.u32, r18.u32, xer);
	// blt cr6,0x82445d80
	if (cr6.lt) goto loc_82445D80;
loc_82445E1C:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r26,r18
	cr6.compare<uint32_t>(r26.u32, r18.u32, xer);
	// blt cr6,0x82445ca4
	if (cr6.lt) goto loc_82445CA4;
loc_82445E2C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d420
	sub_8243D420(ctx, base);
	// li r20,1
	r20.s64 = 1;
	// li r19,1
	r19.s64 = 1;
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// bne 0x824460f0
	if (!cr0.eq) goto loc_824460F0;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x824460f0
	if (cr6.eq) goto loc_824460F0;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_82445E54:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x82445e88
	if (cr6.eq) goto loc_82445E88;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,20(r22)
	ctx.r8.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwz r7,16(r22)
	ctx.r7.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x82445ea8
	if (!cr0.eq) goto loc_82445EA8;
loc_82445E88:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r18
	cr6.compare<uint32_t>(ctx.r10.u32, r18.u32, xer);
	// blt cr6,0x82445e54
	if (cr6.lt) goto loc_82445E54;
	// b 0x824460f0
	goto loc_824460F0;
loc_82445E9C:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x824460fc
	goto loc_824460FC;
loc_82445EA8:
	// li r21,1
	r21.s64 = 1;
	// b 0x824460f0
	goto loc_824460F0;
loc_82445EB0:
	// cmplwi cr6,r16,4
	cr6.compare<uint32_t>(r16.u32, 4, xer);
	// bgt cr6,0x82445ec8
	if (cr6.gt) goto loc_82445EC8;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// bne cr6,0x82445ec8
	if (!cr6.eq) goto loc_82445EC8;
	// li r20,0
	r20.s64 = 0;
	// li r19,0
	r19.s64 = 0;
loc_82445EC8:
	// li r25,0
	r25.s64 = 0;
	// li r23,0
	r23.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x824460f8
	if (cr6.eq) goto loc_824460F8;
	// lwz r24,16(r31)
	r24.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r26,0
	r26.s64 = 0;
loc_82445EE4:
	// lwzx r11,r24,r26
	r11.u64 = PPC_LOAD_U32(r24.u32 + r26.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82445f98
	if (cr6.eq) goto loc_82445F98;
	// li r28,0
	r28.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// li r30,0
	r30.s64 = 0;
loc_82445EFC:
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// bge cr6,0x82445f88
	if (!cr6.lt) goto loc_82445F88;
	// lwzx r11,r24,r30
	r11.u64 = PPC_LOAD_U32(r24.u32 + r30.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82445f78
	if (cr6.eq) goto loc_82445F78;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x82445f50
	if (cr6.eq) goto loc_82445F50;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r11,r30
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82445f50
	if (cr6.eq) goto loc_82445F50;
	// lwz r9,20(r22)
	ctx.r9.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r11,64(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// lwz r10,64(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82445f78
	if (cr0.eq) goto loc_82445F78;
loc_82445F50:
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// beq cr6,0x82445f74
	if (cr6.eq) goto loc_82445F74;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82445ad8
	sub_82445AD8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82445f78
	if (!cr0.eq) goto loc_82445F78;
loc_82445F74:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
loc_82445F78:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r18
	cr6.compare<uint32_t>(r29.u32, r18.u32, xer);
	// blt cr6,0x82445efc
	if (cr6.lt) goto loc_82445EFC;
loc_82445F88:
	// cmplw cr6,r25,r28
	cr6.compare<uint32_t>(r25.u32, r28.u32, xer);
	// bge cr6,0x82445f98
	if (!cr6.lt) goto loc_82445F98;
	// mr r25,r28
	r25.u64 = r28.u64;
	// mr r23,r27
	r23.u64 = r27.u64;
loc_82445F98:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r27,r18
	cr6.compare<uint32_t>(r27.u32, r18.u32, xer);
	// blt cr6,0x82445ee4
	if (cr6.lt) goto loc_82445EE4;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x824460f8
	if (cr6.eq) goto loc_824460F8;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// rlwimi r4,r25,0,12,31
	ctx.r4.u64 = (__builtin_rotateleft32(r25.u32, 0) & 0xFFFFF) | (ctx.r4.u64 & 0xFFFFFFFFFFF00000);
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82445e9c
	if (cr6.eq) goto loc_82445E9C;
	// lwz r11,24(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r10,r23,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// li r29,0
	r29.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// lwzx r25,r10,r11
	r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_82446004:
	// cmplwi cr6,r26,16
	cr6.compare<uint32_t>(r26.u32, 16, xer);
	// bge cr6,0x824460f0
	if (!cr6.lt) goto loc_824460F0;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r11,r27
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824460e0
	if (cr6.eq) goto loc_824460E0;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x82446050
	if (cr6.eq) goto loc_82446050;
	// cmplw cr6,r25,r10
	cr6.compare<uint32_t>(r25.u32, ctx.r10.u32, xer);
	// beq cr6,0x82446050
	if (cr6.eq) goto loc_82446050;
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r25,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,64(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// lwz r11,64(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// and. r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824460e0
	if (cr0.eq) goto loc_824460E0;
loc_82446050:
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// beq cr6,0x82446074
	if (cr6.eq) goto loc_82446074;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82445ad8
	sub_82445AD8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824460e0
	if (!cr0.eq) goto loc_824460E0;
loc_82446074:
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x824460bc
	if (cr6.eq) goto loc_824460BC;
loc_82446080:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mullw r9,r11,r10
	ctx.r9.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r9,r9,r28
	ctx.r9.u64 = ctx.r9.u64 + r28.u64;
	// mullw r10,r8,r11
	ctx.r10.s64 = int64_t(ctx.r8.s32) * int64_t(r11.s32);
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + r29.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// stwx r9,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r9.u32);
	// blt cr6,0x82446080
	if (cr6.lt) goto loc_82446080;
loc_824460BC:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r16,r16,-1
	r16.s64 = r16.s64 + -1;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// stwx r11,r10,r26
	PPC_STORE_U32(ctx.r10.u32 + r26.u32, r11.u32);
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stwx r17,r11,r27
	PPC_STORE_U32(r11.u32 + r27.u32, r17.u32);
loc_824460E0:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r28,r18
	cr6.compare<uint32_t>(r28.u32, r18.u32, xer);
	// blt cr6,0x82446004
	if (cr6.lt) goto loc_82446004;
loc_824460F0:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x82445eb0
	if (!cr6.eq) goto loc_82445EB0;
loc_824460F8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824460FC:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8239bd14
	return;
}

__attribute__((alias("__imp__sub_82446104"))) PPC_WEAK_FUNC(sub_82446104);
PPC_FUNC_IMPL(__imp__sub_82446104) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82446108"))) PPC_WEAK_FUNC(sub_82446108);
PPC_FUNC_IMPL(__imp__sub_82446108) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// bl 0x8243e5e8
	sub_8243E5E8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x82446138
	if (!cr6.eq) goto loc_82446138;
loc_8244612C:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82446320
	goto loc_82446320;
loc_82446138:
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwzx r29,r11,r10
	r29.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r7,12(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// li r31,0
	r31.s64 = 0;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x8244618c
	if (cr0.eq) goto loc_8244618C;
	// lwz r6,16(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r4,0(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
loc_82446168:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,0(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// bl 0x82440158
	sub_82440158(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8244618c
	if (cr0.eq) goto loc_8244618C;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r31,r7
	cr6.compare<uint32_t>(r31.u32, ctx.r7.u32, xer);
	// blt cr6,0x82446168
	if (cr6.lt) goto loc_82446168;
loc_8244618C:
	// cmplw cr6,r31,r7
	cr6.compare<uint32_t>(r31.u32, ctx.r7.u32, xer);
	// beq cr6,0x8244631c
	if (cr6.eq) goto loc_8244631C;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// li r11,1
	r11.s64 = 1;
	// li r25,-1
	r25.s64 = -1;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244612c
	if (cr6.eq) goto loc_8244612C;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwzx r26,r10,r11
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82446300
	if (!cr6.gt) goto loc_82446300;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r31,0
	r31.s64 = 0;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_824461F0:
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r4,136(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// stwx r3,r11,r31
	PPC_STORE_U32(r11.u32 + r31.u32, ctx.r3.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244612c
	if (cr6.eq) goto loc_8244612C;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// lwzx r9,r31,r9
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r4,r9,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// bl 0x8243de18
	sub_8243DE18(ctx, base);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// lwzx r9,r31,r9
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// lwzx r9,r31,r9
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// lwzx r9,r31,r9
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x824461f0
	if (cr6.lt) goto loc_824461F0;
loc_82446300:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82445ba8
	sub_82445BA8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82446320
	if (cr0.lt) goto loc_82446320;
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
loc_8244631C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82446320:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_8244632C"))) PPC_WEAK_FUNC(sub_8244632C);
PPC_FUNC_IMPL(__imp__sub_8244632C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82446330"))) PPC_WEAK_FUNC(sub_82446330);
PPC_FUNC_IMPL(__imp__sub_82446330) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x8239bcec
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82446488
	if (cr0.eq) goto loc_82446488;
	// clrlwi r5,r11,12
	ctx.r5.u64 = r11.u32 & 0xFFFFF;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// divwu. r11,r11,r5
	r11.u32 = r11.u32 / ctx.r5.u32;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// twllei r5,0
	// beq 0x82446488
	if (cr0.eq) goto loc_82446488;
	// li r31,0
	r31.s64 = 0;
	// rlwinm r29,r5,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r30,r11
	r30.u64 = r11.u64;
	// li r28,1
	r28.s64 = 1;
loc_82446368:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8244647c
	if (cr6.eq) goto loc_8244647C;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
loc_8244637C:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824463fc
	if (cr6.eq) goto loc_824463FC;
	// lwz r27,8(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r27,-1
	cr6.compare<int32_t>(r27.s32, -1, xer);
	// bne cr6,0x824463fc
	if (!cr6.eq) goto loc_824463FC;
	// lwz r27,24(r3)
	r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r26,0(r4)
	r26.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lis r25,4400
	r25.s64 = 288358400;
	// rlwinm r26,r26,0,0,11
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFF00000;
	// lwzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// bne cr6,0x824463e4
	if (!cr6.eq) goto loc_824463E4;
	// lwz r10,16(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,64(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// stw r10,64(r11)
	PPC_STORE_U32(r11.u32 + 64, ctx.r10.u32);
	// b 0x824463fc
	goto loc_824463FC;
loc_824463E4:
	// lwz r9,36(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// lwz r27,64(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// slw r9,r28,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r9.u8 & 0x3F));
	// or r9,r9,r27
	ctx.r9.u64 = ctx.r9.u64 | r27.u64;
	// stw r9,64(r11)
	PPC_STORE_U32(r11.u32 + 64, ctx.r9.u32);
	// stw r28,40(r10)
	PPC_STORE_U32(ctx.r10.u32 + 40, r28.u32);
loc_824463FC:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x8244637c
	if (!cr0.eq) goto loc_8244637C;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
loc_82446414:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82446470
	if (cr6.eq) goto loc_82446470;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82446470
	if (!cr6.eq) goto loc_82446470;
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82446470
	if (cr6.eq) goto loc_82446470;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// stw r10,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r10.u32);
loc_82446470:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82446414
	if (!cr0.eq) goto loc_82446414;
loc_8244647C:
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// add r31,r29,r31
	r31.u64 = r29.u64 + r31.u64;
	// bne 0x82446368
	if (!cr0.eq) goto loc_82446368;
loc_82446488:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_82446490"))) PPC_WEAK_FUNC(sub_82446490);
PPC_FUNC_IMPL(__imp__sub_82446490) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r26,0
	r26.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x824464dc
	if (!cr6.gt) goto loc_824464DC;
	// li r10,0
	ctx.r10.s64 = 0;
loc_824464B8:
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r8,-1
	ctx.r8.s64 = -1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,48(r9)
	PPC_STORE_U32(ctx.r9.u32 + 48, ctx.r8.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x824464b8
	if (cr6.lt) goto loc_824464B8;
loc_824464DC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824466e4
	if (!cr6.gt) goto loc_824466E4;
	// li r28,0
	r28.s64 = 0;
loc_824464F0:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r30,r28,r11
	r30.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824466d0
	if (cr0.eq) goto loc_824466D0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// b 0x824465f0
	goto loc_824465F0;
loc_82446510:
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r7,r6
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824465e8
	if (cr6.eq) goto loc_824465E8;
	// li r8,1
	ctx.r8.s64 = 1;
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// ble cr6,0x824465a4
	if (!cr6.gt) goto loc_824465A4;
	// addi r9,r5,4
	ctx.r9.s64 = ctx.r5.s64 + 4;
loc_82446540:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r6
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244659c
	if (cr6.eq) goto loc_8244659C;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r4,r11,r7
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// lwz r4,48(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r4,r11
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + r11.u32);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244659c
	if (!cr6.eq) goto loc_8244659C;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r3
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r3.u32, xer);
	// blt cr6,0x82446540
	if (cr6.lt) goto loc_82446540;
loc_8244659C:
	// cmplw cr6,r8,r3
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r3.u32, xer);
	// blt cr6,0x824465e8
	if (cr6.lt) goto loc_824465E8;
loc_824465A4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824465e4
	if (cr6.eq) goto loc_824465E4;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x824465bc
	goto loc_824465BC;
loc_824465B8:
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_824465BC:
	// add r9,r10,r5
	ctx.r9.u64 = ctx.r10.u64 + ctx.r5.u64;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r8,48(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// bne 0x824465b8
	if (!cr0.eq) goto loc_824465B8;
loc_824465E4:
	// li r26,1
	r26.s64 = 1;
loc_824465E8:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
loc_824465F0:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x82446510
	if (!cr0.eq) goto loc_82446510;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824466d0
	if (!cr6.eq) goto loc_824466D0;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824466d0
	if (!cr6.gt) goto loc_824466D0;
	// li r9,0
	ctx.r9.s64 = 0;
loc_8244662C:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r6,8(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r9,r6
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// rlwinm r6,r8,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bne cr6,0x824466bc
	if (!cr6.eq) goto loc_824466BC;
	// lwz r6,8(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x824466bc
	if (!cr6.eq) goto loc_824466BC;
	// lwz r6,16(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x824466bc
	if (!cr6.eq) goto loc_824466BC;
	// lwz r6,20(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x824466bc
	if (!cr6.eq) goto loc_824466BC;
	// lwz r6,24(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpw cr6,r6,r5
	cr6.compare<int32_t>(ctx.r6.s32, ctx.r5.s32, xer);
	// bne cr6,0x824466bc
	if (!cr6.eq) goto loc_824466BC;
	// lwz r6,56(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// bne cr6,0x824466bc
	if (!cr6.eq) goto loc_824466BC;
	// lwz r10,60(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x824466bc
	if (!cr6.eq) goto loc_824466BC;
	// stw r8,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r8.u32);
loc_824466BC:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x8244662c
	if (cr6.lt) goto loc_8244662C;
loc_824466D0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x824464f0
	if (cr6.lt) goto loc_824464F0;
loc_824466E4:
	// cntlzw r11,r26
	r11.u64 = r26.u32 == 0 ? 32 : __builtin_clz(r26.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_824466F4"))) PPC_WEAK_FUNC(sub_824466F4);
PPC_FUNC_IMPL(__imp__sub_824466F4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824466F8"))) PPC_WEAK_FUNC(sub_824466F8);
PPC_FUNC_IMPL(__imp__sub_824466F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// mr r14,r9
	r14.u64 = ctx.r9.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// lwz r11,20(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// li r23,4
	r23.s64 = 4;
	// mr r15,r6
	r15.u64 = ctx.r6.u64;
	// lwz r9,8(r22)
	ctx.r9.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// mr r18,r7
	r18.u64 = ctx.r7.u64;
	// stw r31,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, r31.u32);
	// lwzx r19,r10,r11
	r19.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r23,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r23.u32);
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm. r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,12(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bne 0x82446798
	if (!cr0.eq) goto loc_82446798;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8244676c
	if (!cr6.eq) goto loc_8244676C;
	// lwz r10,108(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 108);
	// rlwinm. r10,r10,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82446798
	if (!cr0.eq) goto loc_82446798;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
loc_8244676C:
	// ble cr6,0x8244677c
	if (!cr6.gt) goto loc_8244677C;
	// lwz r11,108(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 108);
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82446798
	if (!cr0.eq) goto loc_82446798;
loc_8244677C:
	// lwz r11,72(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 72);
	// lwz r10,24(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8243d0e8
	sub_8243D0E8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824467a0
	if (cr0.eq) goto loc_824467A0;
loc_82446798:
	// li r11,1
	r11.s64 = 1;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_824467A0:
	// li r11,-1
	r11.s64 = -1;
	// lwz r8,12(r19)
	ctx.r8.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r16,24(r22)
	r16.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// li r27,0
	r27.s64 = 0;
	// addi r21,r1,112
	r21.s64 = ctx.r1.s64 + 112;
	// rlwinm r30,r8,4,0,27
	r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// std r11,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r11.u64);
	// std r11,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r11.u64);
	// std r11,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r11.u64);
	// std r11,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, r11.u64);
loc_824467D0:
	// lwzx r24,r30,r16
	r24.u64 = PPC_LOAD_U32(r30.u32 + r16.u32);
	// li r20,0
	r20.s64 = 0;
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// beq cr6,0x824468bc
	if (cr6.eq) goto loc_824468BC;
	// lwz r11,48(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 48);
	// li r26,0
	r26.s64 = 0;
	// lwzx r25,r11,r30
	r25.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// cmplwi r25,0
	cr0.compare<uint32_t>(r25.u32, 0, xer);
	// beq 0x824468bc
	if (cr0.eq) goto loc_824468BC;
	// lwz r11,52(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 52);
	// lwz r10,56(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 56);
	// lwz r28,16(r22)
	r28.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r10
	r29.u64 = r11.u64 + ctx.r10.u64;
loc_8244680C:
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r11,r10,0,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82446824
	if (cr6.eq) goto loc_82446824;
	// li r20,1
	r20.s64 = 1;
loc_82446824:
	// cmplw cr6,r15,r11
	cr6.compare<uint32_t>(r15.u32, r11.u32, xer);
	// bne cr6,0x82446888
	if (!cr6.eq) goto loc_82446888;
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// beq cr6,0x82446888
	if (cr6.eq) goto loc_82446888;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82446888
	if (!cr6.eq) goto loc_82446888;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82446868
	if (!cr6.eq) goto loc_82446868;
	// cmplw cr6,r27,r31
	cr6.compare<uint32_t>(r27.u32, r31.u32, xer);
	// bne cr6,0x82446888
	if (!cr6.eq) goto loc_82446888;
loc_82446868:
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x82442150
	sub_82442150(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244689c
	if (cr6.eq) goto loc_8244689C;
loc_82446888:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// blt cr6,0x8244680c
	if (cr6.lt) goto loc_8244680C;
	// b 0x824468b0
	goto loc_824468B0;
loc_8244689C:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r31,0(r21)
	PPC_STORE_U32(r21.u32 + 0, r31.u32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r23,r23,-1
	r23.s64 = r23.s64 + -1;
	// stwx r27,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r27.u32);
loc_824468B0:
	// lwz r31,348(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// bne cr6,0x824468c0
	if (!cr6.eq) goto loc_824468C0;
loc_824468BC:
	// addi r23,r23,-1
	r23.s64 = r23.s64 + -1;
loc_824468C0:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// addi r21,r21,4
	r21.s64 = r21.s64 + 4;
	// cmplwi cr6,r27,4
	cr6.compare<uint32_t>(r27.u32, 4, xer);
	// blt cr6,0x824467d0
	if (cr6.lt) goto loc_824467D0;
	// rlwinm r3,r23,29,0,2
	ctx.r3.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 29) & 0xE0000000;
	// cmplw cr6,r3,r14
	cr6.compare<uint32_t>(ctx.r3.u32, r14.u32, xer);
	// bge cr6,0x82446a7c
	if (!cr6.lt) goto loc_82446A7C;
	// li r11,0
	r11.s64 = 0;
	// cmpwi cr6,r18,0
	cr6.compare<int32_t>(r18.s32, 0, xer);
	// bge cr6,0x824468f8
	if (!cr6.lt) goto loc_824468F8;
	// clrlwi. r10,r15,31
	ctx.r10.u64 = r15.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82446908
	if (cr0.eq) goto loc_82446908;
	// b 0x82446904
	goto loc_82446904;
loc_824468F8:
	// ble cr6,0x82446908
	if (!cr6.gt) goto loc_82446908;
	// clrlwi. r10,r15,31
	ctx.r10.u64 = r15.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82446908
	if (!cr0.eq) goto loc_82446908;
loc_82446904:
	// li r11,1
	r11.s64 = 1;
loc_82446908:
	// rlwinm r11,r11,28,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0xF0000000;
	// or r27,r11,r3
	r27.u64 = r11.u64 | ctx.r3.u64;
	// cmplw cr6,r27,r14
	cr6.compare<uint32_t>(r27.u32, r14.u32, xer);
	// bge cr6,0x82446a78
	if (!cr6.lt) goto loc_82446A78;
	// li r28,0
	r28.s64 = 0;
	// addi r26,r1,112
	r26.s64 = ctx.r1.s64 + 112;
loc_82446920:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82446a3c
	if (!cr6.eq) goto loc_82446A3C;
	// lwz r11,12(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r11,r16
	r29.u64 = PPC_LOAD_U32(r11.u32 + r16.u32);
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x82446a3c
	if (cr6.eq) goto loc_82446A3C;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82446a04
	if (cr6.eq) goto loc_82446A04;
loc_82446958:
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// add r11,r30,r28
	r11.u64 = r30.u64 + r28.u64;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// clrlwi r31,r11,30
	r31.u64 = r11.u32 & 0x3;
	// bne cr6,0x824469ac
	if (!cr6.eq) goto loc_824469AC;
	// lwz r11,112(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 112);
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824469a8
	if (cr0.eq) goto loc_824469A8;
	// lwz r11,72(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 72);
	// lis r9,20480
	ctx.r9.s64 = 1342177280;
	// lwz r10,24(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x824469a8
	if (!cr6.eq) goto loc_824469A8;
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// blt cr6,0x824469ac
	if (cr6.lt) goto loc_824469AC;
loc_824469A8:
	// subfic r31,r31,3
	xer.ca = r31.u32 <= 3;
	r31.s64 = 3 - r31.s64;
loc_824469AC:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824469e0
	if (!cr6.eq) goto loc_824469E0;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x82442150
	sub_82442150(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824469f4
	if (cr6.eq) goto loc_824469F4;
loc_824469E0:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82446958
	if (cr6.lt) goto loc_82446958;
	// b 0x82446a04
	goto loc_82446A04;
loc_824469F4:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// stwx r28,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r28.u32);
loc_82446A04:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x82446a84
	if (cr6.eq) goto loc_82446A84;
	// lwz r11,96(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 96);
	// rlwinm. r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82446a28
	if (cr0.eq) goto loc_82446A28;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x82446a38
	if (!cr6.gt) goto loc_82446A38;
loc_82446A28:
	// rlwinm r11,r30,24,0,7
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 24) & 0xFF000000;
	// add r27,r11,r27
	r27.u64 = r11.u64 + r27.u64;
	// cmplw cr6,r27,r14
	cr6.compare<uint32_t>(r27.u32, r14.u32, xer);
	// bge cr6,0x82446a78
	if (!cr6.lt) goto loc_82446A78;
loc_82446A38:
	// lwz r31,348(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
loc_82446A3C:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplwi cr6,r28,4
	cr6.compare<uint32_t>(r28.u32, 4, xer);
	// blt cr6,0x82446920
	if (cr6.lt) goto loc_82446920;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82446a78
	if (cr6.eq) goto loc_82446A78;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// stw r8,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r8.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_82446A78:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_82446A7C:
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x8239bd10
	return;
loc_82446A84:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82446a7c
	goto loc_82446A7C;
}

__attribute__((alias("__imp__sub_82446A8C"))) PPC_WEAK_FUNC(sub_82446A8C);
PPC_FUNC_IMPL(__imp__sub_82446A8C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82446A90"))) PPC_WEAK_FUNC(sub_82446A90);
PPC_FUNC_IMPL(__imp__sub_82446A90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r30{};
	PPCRegister r31{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
loc_82446A98:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82446ab4
	if (cr6.eq) goto loc_82446AB4;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
loc_82446AB4:
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x82446c74
	if (!cr6.eq) goto loc_82446C74;
	// lwz r11,88(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// lwz r31,116(r8)
	r31.u64 = PPC_LOAD_U32(ctx.r8.u32 + 116);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82446c60
	if (cr6.eq) goto loc_82446C60;
	// lwz r10,80(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 80);
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,76(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 76);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,84(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 84);
	// lis r30,8304
	r30.s64 = 544210944;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r11,r10,12
	r11.s64 = ctx.r10.s64 * 12;
	// stwx r10,r5,r7
	PPC_STORE_U32(ctx.r5.u32 + ctx.r7.u32, ctx.r10.u32);
	// lwz r10,88(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// stwx r6,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r6.u32);
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// beq cr6,0x82446b44
	if (cr6.eq) goto loc_82446B44;
	// lis r7,8320
	ctx.r7.s64 = 545259520;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// beq cr6,0x82446b44
	if (cr6.eq) goto loc_82446B44;
	// lis r7,4432
	ctx.r7.s64 = 290455552;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x82446b5c
	if (!cr6.eq) goto loc_82446B5C;
loc_82446B44:
	// lwz r10,88(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// lwz r9,20(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// lwz r9,24(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// b 0x82446ba8
	goto loc_82446BA8;
loc_82446B5C:
	// lwz r7,24(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r5,20(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r10,88(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	// lwz r7,20(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// lwz r7,24(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r5,20(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r9,r7,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
loc_82446BA8:
	// lwz r10,88(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// lwz r10,88(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// add r9,r11,r10
	ctx.r9.u64 = r11.u64 + ctx.r10.u64;
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r7,8(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// b 0x82446c54
	goto loc_82446C54;
loc_82446BC8:
	// lwz r5,20(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,16(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwzx r5,r9,r5
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + r30.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm. r5,r5,0,16,16
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x82446c44
	if (cr0.eq) goto loc_82446C44;
	// lwz r5,88(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// add r5,r11,r5
	ctx.r5.u64 = r11.u64 + ctx.r5.u64;
	// stw r10,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r10.u32);
	// lwz r10,88(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r7,88(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,88(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	// stwx r10,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r10.u32);
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r7,88(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 88);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,88(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// bge cr6,0x82446c44
	if (!cr6.lt) goto loc_82446C44;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,88(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	// stw r10,88(r8)
	PPC_STORE_U32(ctx.r8.u32 + 88, ctx.r10.u32);
loc_82446C44:
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r7,24(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
loc_82446C54:
	// lwz r5,20(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82446bc8
	if (!cr6.eq) goto loc_82446BC8;
loc_82446C60:
	// lwz r11,76(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 76);
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_82446C74:
	// lwz r5,8(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// bne cr6,0x82446a98
	if (!cr6.eq) goto loc_82446A98;
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82446C8C"))) PPC_WEAK_FUNC(sub_82446C8C);
PPC_FUNC_IMPL(__imp__sub_82446C8C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82446C90"))) PPC_WEAK_FUNC(sub_82446C90);
PPC_FUNC_IMPL(__imp__sub_82446C90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,32(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,52(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,84(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,88(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r5,100
	ctx.r5.s64 = 100;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82446D98"))) PPC_WEAK_FUNC(sub_82446D98);
PPC_FUNC_IMPL(__imp__sub_82446D98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r27,0
	r27.s64 = 0;
	// li r25,-1
	r25.s64 = -1;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82446df0
	if (!cr6.gt) goto loc_82446DF0;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
loc_82446DC4:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stw r25,40(r11)
	PPC_STORE_U32(r11.u32 + 40, r25.u32);
	// stw r27,44(r11)
	PPC_STORE_U32(r11.u32 + 44, r27.u32);
	// stw r27,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r27.u32);
	// stw r27,32(r11)
	PPC_STORE_U32(r11.u32 + 32, r27.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82446dc4
	if (cr6.lt) goto loc_82446DC4;
loc_82446DF0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82446e40
	if (!cr6.gt) goto loc_82446E40;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
loc_82446E04:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stw r25,84(r11)
	PPC_STORE_U32(r11.u32 + 84, r25.u32);
	// stw r27,88(r11)
	PPC_STORE_U32(r11.u32 + 88, r27.u32);
	// stw r27,92(r11)
	PPC_STORE_U32(r11.u32 + 92, r27.u32);
	// stw r25,72(r11)
	PPC_STORE_U32(r11.u32 + 72, r25.u32);
	// stw r25,76(r11)
	PPC_STORE_U32(r11.u32 + 76, r25.u32);
	// stw r25,80(r11)
	PPC_STORE_U32(r11.u32 + 80, r25.u32);
	// stw r8,52(r11)
	PPC_STORE_U32(r11.u32 + 52, ctx.r8.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82446e04
	if (cr6.lt) goto loc_82446E04;
loc_82446E40:
	// lwz r11,220(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 220);
	// mr r26,r27
	r26.u64 = r27.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82446fbc
	if (cr6.eq) goto loc_82446FBC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82446e84
	if (!cr6.gt) goto loc_82446E84;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82446E64:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r27,16(r9)
	PPC_STORE_U32(ctx.r9.u32 + 16, r27.u32);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82446e64
	if (cr6.lt) goto loc_82446E64;
loc_82446E84:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82446ef0
	if (!cr6.gt) goto loc_82446EF0;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
loc_82446E98:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r6,r9,0,25,25
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x82446edc
	if (!cr0.eq) goto loc_82446EDC;
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82446edc
	if (cr0.eq) goto loc_82446EDC;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bge cr6,0x82446edc
	if (!cr6.lt) goto loc_82446EDC;
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
loc_82446EDC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x82446e98
	if (cr6.lt) goto loc_82446E98;
loc_82446EF0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82446f1c
	if (cr0.eq) goto loc_82446F1C;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_82446F04:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// bne 0x82446f04
	if (!cr0.eq) goto loc_82446F04;
loc_82446F1C:
	// rlwinm r30,r9,4,0,27
	r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// bne 0x82446f40
	if (!cr0.eq) goto loc_82446F40;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82447258
	goto loc_82447258;
loc_82446F40:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,255
	ctx.r4.s64 = 255;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82446fbc
	if (!cr6.gt) goto loc_82446FBC;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r11,r27
	r11.u64 = r27.u64;
loc_82446F6C:
	// lwz r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r7,r11,r7
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82446f8c
	if (cr6.eq) goto loc_82446F8C;
	// rlwinm r7,r9,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// add r7,r7,r26
	ctx.r7.u64 = ctx.r7.u64 + r26.u64;
	// b 0x82446f90
	goto loc_82446F90;
loc_82446F8C:
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_82446F90:
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stw r7,32(r10)
	PPC_STORE_U32(ctx.r10.u32 + 32, ctx.r7.u32);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r7,4(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// add r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 + ctx.r9.u64;
	// blt cr6,0x82446f6c
	if (cr6.lt) goto loc_82446F6C;
loc_82446FBC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447120
	if (!cr6.gt) goto loc_82447120;
	// mr r28,r27
	r28.u64 = r27.u64;
loc_82446FD0:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r6,r11,r28
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x8244710c
	if (cr0.eq) goto loc_8244710C;
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244710c
	if (cr0.eq) goto loc_8244710C;
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// mr r30,r27
	r30.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447024
	if (!cr6.gt) goto loc_82447024;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
loc_82447000:
	// lwz r11,8(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r4,r11,r7
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// bl 0x824423d0
	sub_824423D0(ctx, base);
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82447000
	if (cr6.lt) goto loc_82447000;
loc_82447024:
	// lwz r11,12(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// mr r29,r27
	r29.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244705c
	if (!cr6.gt) goto loc_8244705C;
	// mr r30,r27
	r30.u64 = r27.u64;
loc_82447038:
	// lwz r11,16(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r4,r30,r11
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// bl 0x82442470
	sub_82442470(ctx, base);
	// lwz r11,12(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82447038
	if (cr6.lt) goto loc_82447038;
loc_8244705C:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244710c
	if (!cr6.eq) goto loc_8244710C;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244710c
	if (!cr0.eq) goto loc_8244710C;
	// lwz r11,12(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244710c
	if (!cr6.gt) goto loc_8244710C;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
loc_82447090:
	// lwz r10,16(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// lwz r8,8(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// andi. r4,r11,4128
	ctx.r4.u64 = r11.u64 & 4128;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne 0x824470f8
	if (!cr0.eq) goto loc_824470F8;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824470f8
	if (cr0.eq) goto loc_824470F8;
	// lwz r11,60(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824470f8
	if (!cr6.eq) goto loc_824470F8;
	// lwz r4,52(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 52);
	// lwz r11,52(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 52);
	// stw r4,52(r10)
	PPC_STORE_U32(ctx.r10.u32 + 52, ctx.r4.u32);
	// stw r11,52(r8)
	PPC_STORE_U32(ctx.r8.u32 + 52, r11.u32);
loc_824470F8:
	// lwz r11,12(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x82447090
	if (cr6.lt) goto loc_82447090;
loc_8244710C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x82446fd0
	if (cr6.lt) goto loc_82446FD0;
loc_82447120:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447188
	if (!cr6.gt) goto loc_82447188;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
loc_82447134:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r6,84(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,40(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// ble cr6,0x82447160
	if (!cr6.gt) goto loc_82447160;
	// stw r10,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r10.u32);
loc_82447160:
	// lwz r10,44(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 44);
	// lwz r9,88(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bge cr6,0x82447174
	if (!cr6.lt) goto loc_82447174;
	// stw r10,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r10.u32);
loc_82447174:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x82447134
	if (cr6.lt) goto loc_82447134;
loc_82447188:
	// lwz r11,220(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 220);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82447234
	if (cr6.eq) goto loc_82447234;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447234
	if (!cr6.gt) goto loc_82447234;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
loc_824471A8:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r10,r8
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r9,76(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x824471e4
	if (cr6.eq) goto loc_824471E4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r9,88(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	// stw r9,76(r11)
	PPC_STORE_U32(r11.u32 + 76, ctx.r9.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bgt cr6,0x824471e8
	if (cr6.gt) goto loc_824471E8;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,76(r11)
	PPC_STORE_U32(r11.u32 + 76, ctx.r10.u32);
	// b 0x824471e8
	goto loc_824471E8;
loc_824471E4:
	// stw r27,76(r11)
	PPC_STORE_U32(r11.u32 + 76, r27.u32);
loc_824471E8:
	// lwz r10,80(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244721c
	if (cr6.eq) goto loc_8244721C;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,84(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// stw r9,80(r11)
	PPC_STORE_U32(r11.u32 + 80, ctx.r9.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// ble cr6,0x82447220
	if (!cr6.gt) goto loc_82447220;
	// stw r10,80(r11)
	PPC_STORE_U32(r11.u32 + 80, ctx.r10.u32);
	// b 0x82447220
	goto loc_82447220;
loc_8244721C:
	// stw r25,80(r11)
	PPC_STORE_U32(r11.u32 + 80, r25.u32);
loc_82447220:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x824471a8
	if (cr6.lt) goto loc_824471A8;
loc_82447234:
	// lwz r11,216(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 216);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82447248
	if (cr6.eq) goto loc_82447248;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824424f0
	sub_824424F0(ctx, base);
loc_82447248:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82447258:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_82447260"))) PPC_WEAK_FUNC(sub_82447260);
PPC_FUNC_IMPL(__imp__sub_82447260) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// li r26,0
	r26.s64 = 0;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824472b8
	if (!cr6.gt) goto loc_824472B8;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
loc_8244728C:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r26,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r26.u32);
	// stw r26,32(r11)
	PPC_STORE_U32(r11.u32 + 32, r26.u32);
	// stw r26,20(r11)
	PPC_STORE_U32(r11.u32 + 20, r26.u32);
	// stw r26,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r26.u32);
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x8244728c
	if (cr6.lt) goto loc_8244728C;
loc_824472B8:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244739c
	if (!cr6.gt) goto loc_8244739C;
	// mr r27,r26
	r27.u64 = r26.u64;
loc_824472CC:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwzx r7,r27,r11
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82447388
	if (cr0.eq) goto loc_82447388;
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// mr r30,r26
	r30.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447320
	if (!cr6.gt) goto loc_82447320;
	// mr r31,r26
	r31.u64 = r26.u64;
loc_824472F4:
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwzx r4,r11,r31
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// bl 0x82442638
	sub_82442638(ctx, base);
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x824472f4
	if (cr6.lt) goto loc_824472F4;
loc_82447320:
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// mr r30,r26
	r30.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447388
	if (!cr6.gt) goto loc_82447388;
	// mr r31,r26
	r31.u64 = r26.u64;
loc_82447334:
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82447360
	if (cr6.eq) goto loc_82447360;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82447360
	if (cr6.eq) goto loc_82447360;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82447360:
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82442638
	sub_82442638(ctx, base);
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82447334
	if (cr6.lt) goto loc_82447334;
loc_82447388:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x824472cc
	if (cr6.lt) goto loc_824472CC;
loc_8244739C:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244740c
	if (!cr6.gt) goto loc_8244740C;
	// mr r30,r26
	r30.u64 = r26.u64;
loc_824473B0:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwzx r31,r30,r11
	r31.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824473d4
	if (cr0.eq) goto loc_824473D4;
	// bl 0x8243d6d0
	sub_8243D6D0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x82447624
	if (cr0.eq) goto loc_82447624;
loc_824473D4:
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824473f0
	if (cr0.eq) goto loc_824473F0;
	// bl 0x8243d6d0
	sub_8243D6D0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq 0x82447624
	if (cr0.eq) goto loc_82447624;
loc_824473F0:
	// stw r26,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r26.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// stw r26,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r26.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x824473b0
	if (cr6.lt) goto loc_824473B0;
loc_8244740C:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824474f0
	if (!cr6.gt) goto loc_824474F0;
	// mr r27,r26
	r27.u64 = r26.u64;
loc_82447420:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwzx r7,r27,r11
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824474dc
	if (cr0.eq) goto loc_824474DC;
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// mr r30,r26
	r30.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447474
	if (!cr6.gt) goto loc_82447474;
	// mr r31,r26
	r31.u64 = r26.u64;
loc_82447448:
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwzx r4,r11,r31
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// bl 0x82442638
	sub_82442638(ctx, base);
	// lwz r11,12(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82447448
	if (cr6.lt) goto loc_82447448;
loc_82447474:
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// mr r30,r26
	r30.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824474dc
	if (!cr6.gt) goto loc_824474DC;
	// mr r31,r26
	r31.u64 = r26.u64;
loc_82447488:
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824474b4
	if (cr6.eq) goto loc_824474B4;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824474b4
	if (cr6.eq) goto loc_824474B4;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_824474B4:
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82442638
	sub_82442638(ctx, base);
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82447488
	if (cr6.lt) goto loc_82447488;
loc_824474DC:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82447420
	if (cr6.lt) goto loc_82447420;
loc_824474F0:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447618
	if (!cr6.gt) goto loc_82447618;
	// mr r30,r26
	r30.u64 = r26.u64;
loc_82447504:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwzx r31,r30,r11
	r31.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq 0x82447588
	if (cr0.eq) goto loc_82447588;
	// lis r11,-32188
	r11.s64 = -2109472768;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r3,r11,-5240
	ctx.r3.s64 = r11.s64 + -5240;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x82447584
	if (!cr6.gt) goto loc_82447584;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r9,4
	ctx.r9.s64 = 4;
loc_82447548:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r11,r9,r10
	r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r4,-4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// beq cr6,0x82447570
	if (cr6.eq) goto loc_82447570;
	// rotlwi r11,r5,0
	r11.u64 = __builtin_rotateleft32(ctx.r5.u32, 0);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// stwx r11,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, r11.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
loc_82447570:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x82447548
	if (cr6.lt) goto loc_82447548;
loc_82447584:
	// stw r7,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r7.u32);
loc_82447588:
	// lwz r5,28(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq 0x82447604
	if (cr0.eq) goto loc_82447604;
	// lis r11,-32188
	r11.s64 = -2109472768;
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r3,r11,-5240
	ctx.r3.s64 = r11.s64 + -5240;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x82447600
	if (!cr6.gt) goto loc_82447600;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r9,4
	ctx.r9.s64 = 4;
loc_824475C4:
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// add r11,r9,r10
	r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r4,-4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// beq cr6,0x824475ec
	if (cr6.eq) goto loc_824475EC;
	// rotlwi r11,r5,0
	r11.u64 = __builtin_rotateleft32(ctx.r5.u32, 0);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// stwx r11,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, r11.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
loc_824475EC:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x824475c4
	if (cr6.lt) goto loc_824475C4;
loc_82447600:
	// stw r7,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r7.u32);
loc_82447604:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82447504
	if (cr6.lt) goto loc_82447504;
loc_82447618:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8244761C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
loc_82447624:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8244761c
	goto loc_8244761C;
}

__attribute__((alias("__imp__sub_82447630"))) PPC_WEAK_FUNC(sub_82447630);
PPC_FUNC_IMPL(__imp__sub_82447630) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r31{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r4,-1
	ctx.r4.s64 = -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824476dc
	if (!cr6.gt) goto loc_824476DC;
	// li r8,0
	ctx.r8.s64 = 0;
loc_8244764C:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r9,r8,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82447670
	if (cr6.eq) goto loc_82447670;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82447674
	goto loc_82447674;
loc_82447670:
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_82447674:
	// stw r11,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, r11.u32);
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82447698
	if (cr6.eq) goto loc_82447698;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x8244769c
	goto loc_8244769C;
loc_82447698:
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_8244769C:
	// stw r11,20(r9)
	PPC_STORE_U32(ctx.r9.u32 + 20, r11.u32);
	// lwz r11,56(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824476c0
	if (cr6.eq) goto loc_824476C0;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x824476c4
	goto loc_824476C4;
loc_824476C0:
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_824476C4:
	// stw r11,56(r9)
	PPC_STORE_U32(ctx.r9.u32 + 56, r11.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x8244764c
	if (cr6.lt) goto loc_8244764C;
loc_824476DC:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824477c8
	if (!cr6.gt) goto loc_824477C8;
	// li r6,0
	ctx.r6.s64 = 0;
loc_824476F0:
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x824477b4
	if (cr6.eq) goto loc_824477B4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244775c
	if (!cr6.gt) goto loc_8244775C;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82447718:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82447740
	if (cr6.eq) goto loc_82447740;
	// lwz r31,20(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// b 0x82447744
	goto loc_82447744;
loc_82447740:
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82447744:
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x82447718
	if (cr6.lt) goto loc_82447718;
loc_8244775C:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x824477b4
	if (!cr6.gt) goto loc_824477B4;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82447770:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// add r8,r10,r9
	ctx.r8.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82447798
	if (cr6.eq) goto loc_82447798;
	// lwz r31,20(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// b 0x8244779c
	goto loc_8244779C;
loc_82447798:
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_8244779C:
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x82447770
	if (cr6.lt) goto loc_82447770;
loc_824477B4:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x824476f0
	if (cr6.lt) goto loc_824476F0;
loc_824477C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824477D4"))) PPC_WEAK_FUNC(sub_824477D4);
PPC_FUNC_IMPL(__imp__sub_824477D4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824477D8"))) PPC_WEAK_FUNC(sub_824477D8);
PPC_FUNC_IMPL(__imp__sub_824477D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r11,20316
	r11.s64 = r11.s64 + 20316;
	// clrlwi. r10,r4,31
	ctx.r10.u64 = ctx.r4.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq 0x82447804
	if (cr0.eq) goto loc_82447804;
	// bl 0x821e7b68
	sub_821E7B68(ctx, base);
loc_82447804:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8244781C"))) PPC_WEAK_FUNC(sub_8244781C);
PPC_FUNC_IMPL(__imp__sub_8244781C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82447820"))) PPC_WEAK_FUNC(sub_82447820);
PPC_FUNC_IMPL(__imp__sub_82447820) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x82442cb0
	sub_82442CB0(ctx, base);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82447854
	if (cr0.eq) goto loc_82447854;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
loc_82447854:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82447870"))) PPC_WEAK_FUNC(sub_82447870);
PPC_FUNC_IMPL(__imp__sub_82447870) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82447898
	if (!cr6.eq) goto loc_82447898;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82447b68
	goto loc_82447B68;
loc_82447898:
	// li r26,0
	r26.s64 = 0;
	// stw r4,192(r31)
	PPC_STORE_U32(r31.u32 + 192, ctx.r4.u32);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// stw r5,196(r31)
	PPC_STORE_U32(r31.u32 + 196, ctx.r5.u32);
	// li r30,-1
	r30.s64 = -1;
	// stw r6,200(r31)
	PPC_STORE_U32(r31.u32 + 200, ctx.r6.u32);
	// addi r4,r11,14828
	ctx.r4.s64 = r11.s64 + 14828;
	// stw r10,204(r31)
	PPC_STORE_U32(r31.u32 + 204, ctx.r10.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// stw r26,212(r31)
	PPC_STORE_U32(r31.u32 + 212, r26.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r26,216(r31)
	PPC_STORE_U32(r31.u32 + 216, r26.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r26,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r26.u32);
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r3,116(r31)
	PPC_STORE_U32(r31.u32 + 116, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,14412
	ctx.r4.s64 = r11.s64 + 14412;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,785
	ctx.r5.s64 = 785;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// stw r3,120(r31)
	PPC_STORE_U32(r31.u32 + 120, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r29,r11,23464
	r29.s64 = r11.s64 + 23464;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,593
	ctx.r5.s64 = 593;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r3,124(r31)
	PPC_STORE_U32(r31.u32 + 124, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,14496
	ctx.r4.s64 = r11.s64 + 14496;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,81
	ctx.r5.s64 = 81;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r3,128(r31)
	PPC_STORE_U32(r31.u32 + 128, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,14404
	ctx.r4.s64 = r11.s64 + 14404;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,98
	ctx.r5.s64 = 98;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r3,132(r31)
	PPC_STORE_U32(r31.u32 + 132, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,14492
	ctx.r4.s64 = r11.s64 + 14492;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// stw r3,136(r31)
	PPC_STORE_U32(r31.u32 + 136, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,31408
	ctx.r4.s64 = r11.s64 + 31408;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,6
	ctx.r5.s64 = 6;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r3,140(r31)
	PPC_STORE_U32(r31.u32 + 140, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r28,r11,14408
	r28.s64 = r11.s64 + 14408;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,10
	ctx.r5.s64 = 10;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r3,144(r31)
	PPC_STORE_U32(r31.u32 + 144, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r4,r11,14436
	ctx.r4.s64 = r11.s64 + 14436;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,721
	ctx.r5.s64 = 721;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r3,148(r31)
	PPC_STORE_U32(r31.u32 + 148, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r27,r11,14452
	r27.s64 = r11.s64 + 14452;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,4099
	ctx.r5.s64 = 4099;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// stw r3,152(r31)
	PPC_STORE_U32(r31.u32 + 152, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,8785
	ctx.r5.s64 = 8785;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// stw r3,156(r31)
	PPC_STORE_U32(r31.u32 + 156, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,16394
	ctx.r5.s64 = 16394;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r5,0
	ctx.r5.s64 = 0;
	// stw r3,160(r31)
	PPC_STORE_U32(r31.u32 + 160, ctx.r3.u32);
	// addi r4,r11,20344
	ctx.r4.s64 = r11.s64 + 20344;
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,49162
	ctx.r5.u64 = ctx.r5.u64 | 49162;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// lis r5,1
	ctx.r5.s64 = 65536;
	// stw r3,164(r31)
	PPC_STORE_U32(r31.u32 + 164, ctx.r3.u32);
	// addi r4,r11,23460
	ctx.r4.s64 = r11.s64 + 23460;
	// li r7,4
	ctx.r7.s64 = 4;
	// li r6,0
	ctx.r6.s64 = 0;
	// ori r5,r5,66
	ctx.r5.u64 = ctx.r5.u64 | 66;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lis r5,2
	ctx.r5.s64 = 131072;
	// stw r3,168(r31)
	PPC_STORE_U32(r31.u32 + 168, ctx.r3.u32);
	// addi r4,r11,21632
	ctx.r4.s64 = r11.s64 + 21632;
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,3
	ctx.r5.u64 = ctx.r5.u64 | 3;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r5,4
	ctx.r5.s64 = 262144;
	// stw r3,172(r31)
	PPC_STORE_U32(r31.u32 + 172, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,529
	ctx.r5.u64 = ctx.r5.u64 | 529;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r3,176(r31)
	PPC_STORE_U32(r31.u32 + 176, ctx.r3.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,8290
	ctx.r5.s64 = 8290;
	// addi r4,r11,20340
	ctx.r4.s64 = r11.s64 + 20340;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lis r5,4
	ctx.r5.s64 = 262144;
	// stw r3,180(r31)
	PPC_STORE_U32(r31.u32 + 180, ctx.r3.u32);
	// addi r4,r11,20336
	ctx.r4.s64 = r11.s64 + 20336;
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// ori r5,r5,98
	ctx.r5.u64 = ctx.r5.u64 | 98;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r3,184(r31)
	PPC_STORE_U32(r31.u32 + 184, ctx.r3.u32);
	// cmplwi cr6,r11,18
	cr6.compare<uint32_t>(r11.u32, 18, xer);
	// beq cr6,0x82447b28
	if (cr6.eq) goto loc_82447B28;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82447b68
	goto loc_82447B68;
loc_82447B28:
	// li r5,76
	ctx.r5.s64 = 76;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,40
	ctx.r3.s64 = r31.s64 + 40;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82447b68
	if (cr0.lt) goto loc_82447B68;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,208(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r26,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r26.u32);
loc_82447B68:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_82447B70"))) PPC_WEAK_FUNC(sub_82447B70);
PPC_FUNC_IMPL(__imp__sub_82447B70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// bl 0x8243e7b0
	sub_8243E7B0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82447c90
	if (cr0.lt) goto loc_82447C90;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// li r29,0
	r29.s64 = 0;
	// li r5,76
	ctx.r5.s64 = 76;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,40
	ctx.r3.s64 = r31.s64 + 40;
	// stw r11,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r11.u32);
	// lwz r11,196(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 196);
	// stw r28,200(r31)
	PPC_STORE_U32(r31.u32 + 200, r28.u32);
	// stw r27,204(r31)
	PPC_STORE_U32(r31.u32 + 204, r27.u32);
	// stw r29,212(r31)
	PPC_STORE_U32(r31.u32 + 212, r29.u32);
	// stw r29,216(r31)
	PPC_STORE_U32(r31.u32 + 216, r29.u32);
	// stw r11,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r11.u32);
	// stw r29,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r29.u32);
	// lwz r11,116(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 116);
	// stw r11,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r11.u32);
	// lwz r11,120(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 120);
	// stw r11,120(r31)
	PPC_STORE_U32(r31.u32 + 120, r11.u32);
	// lwz r11,124(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 124);
	// stw r11,124(r31)
	PPC_STORE_U32(r31.u32 + 124, r11.u32);
	// lwz r11,128(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 128);
	// stw r11,128(r31)
	PPC_STORE_U32(r31.u32 + 128, r11.u32);
	// lwz r11,132(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 132);
	// stw r11,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r11.u32);
	// lwz r11,136(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// stw r11,136(r31)
	PPC_STORE_U32(r31.u32 + 136, r11.u32);
	// lwz r11,140(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 140);
	// stw r11,140(r31)
	PPC_STORE_U32(r31.u32 + 140, r11.u32);
	// lwz r11,144(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 144);
	// stw r11,144(r31)
	PPC_STORE_U32(r31.u32 + 144, r11.u32);
	// lwz r11,148(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 148);
	// stw r11,148(r31)
	PPC_STORE_U32(r31.u32 + 148, r11.u32);
	// lwz r11,152(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 152);
	// stw r11,152(r31)
	PPC_STORE_U32(r31.u32 + 152, r11.u32);
	// lwz r11,156(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 156);
	// stw r11,156(r31)
	PPC_STORE_U32(r31.u32 + 156, r11.u32);
	// lwz r11,160(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 160);
	// stw r11,160(r31)
	PPC_STORE_U32(r31.u32 + 160, r11.u32);
	// lwz r11,164(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 164);
	// stw r11,164(r31)
	PPC_STORE_U32(r31.u32 + 164, r11.u32);
	// lwz r11,168(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 168);
	// stw r11,168(r31)
	PPC_STORE_U32(r31.u32 + 168, r11.u32);
	// lwz r11,172(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 172);
	// stw r11,172(r31)
	PPC_STORE_U32(r31.u32 + 172, r11.u32);
	// lwz r11,176(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 176);
	// stw r11,176(r31)
	PPC_STORE_U32(r31.u32 + 176, r11.u32);
	// lwz r11,180(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 180);
	// stw r11,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r11.u32);
	// lwz r11,184(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 184);
	// stw r11,184(r31)
	PPC_STORE_U32(r31.u32 + 184, r11.u32);
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82447c90
	if (cr0.lt) goto loc_82447C90;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,208(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r29,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r29.u32);
loc_82447C90:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_82447C98"))) PPC_WEAK_FUNC(sub_82447C98);
PPC_FUNC_IMPL(__imp__sub_82447C98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcdc
	// stfd f31,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82447ce8
	if (cr0.eq) goto loc_82447CE8;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_82447CC0:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// ble cr6,0x82447cdc
	if (!cr6.gt) goto loc_82447CDC;
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82447cdc
	if (cr6.eq) goto loc_82447CDC;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82447CDC:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82447cc0
	if (!cr0.eq) goto loc_82447CC0;
loc_82447CE8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r22,r8,1
	r22.s64 = ctx.r8.s64 + 1;
	// li r21,0
	r21.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447e78
	if (!cr6.gt) goto loc_82447E78;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r23,0
	r23.s64 = 0;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82447D08:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r28,r23,r11
	r28.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82447d70
	if (cr0.eq) goto loc_82447D70;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
loc_82447D2C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r5,68(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 68);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// bne cr6,0x82447d64
	if (!cr6.eq) goto loc_82447D64;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,26,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82447d64
	if (cr0.eq) goto loc_82447D64;
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
loc_82447D64:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82447d2c
	if (!cr0.eq) goto loc_82447D2C;
loc_82447D70:
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// beq cr6,0x82447e64
	if (cr6.eq) goto loc_82447E64;
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x82447dbc
	if (cr6.eq) goto loc_82447DBC;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// li r11,1
	r11.s64 = 1;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82447ee8
	if (cr6.eq) goto loc_82447EE8;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwzx r25,r10,r11
	r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
loc_82447DBC:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447e60
	if (!cr6.gt) goto loc_82447E60;
	// li r29,0
	r29.s64 = 0;
	// li r27,0
	r27.s64 = 0;
loc_82447DD4:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r26,r11,r9
	r26.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,68(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 68);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82447e28
	if (!cr6.eq) goto loc_82447E28;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82447e44
	if (!cr0.eq) goto loc_82447E44;
loc_82447E28:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// stwx r11,r10,r27
	PPC_STORE_U32(ctx.r10.u32 + r27.u32, r11.u32);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// stwx r3,r11,r27
	PPC_STORE_U32(r11.u32 + r27.u32, ctx.r3.u32);
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
loc_82447E44:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// stwx r3,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, ctx.r3.u32);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x82447dd4
	if (cr6.lt) goto loc_82447DD4;
loc_82447E60:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
loc_82447E64:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r23,r23,4
	r23.s64 = r23.s64 + 4;
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// blt cr6,0x82447d08
	if (cr6.lt) goto loc_82447D08;
loc_82447E78:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82447edc
	if (cr0.lt) goto loc_82447EDC;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82447ed8
	if (!cr6.gt) goto loc_82447ED8;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82447E9C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r8,72(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// bne cr6,0x82447ec4
	if (!cr6.eq) goto loc_82447EC4;
	// lwz r8,84(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// bne cr6,0x82447ec4
	if (!cr6.eq) goto loc_82447EC4;
	// lwz r8,116(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
loc_82447EC4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x82447e9c
	if (cr6.lt) goto loc_82447E9C;
loc_82447ED8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82447EDC:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-104(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x8239bd2c
	return;
loc_82447EE8:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82447edc
	goto loc_82447EDC;
}

__attribute__((alias("__imp__sub_82447EF4"))) PPC_WEAK_FUNC(sub_82447EF4);
PPC_FUNC_IMPL(__imp__sub_82447EF4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82447EF8"))) PPC_WEAK_FUNC(sub_82447EF8);
PPC_FUNC_IMPL(__imp__sub_82447EF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd4
	// stfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r19,0
	r19.s64 = 0;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r28,0
	r28.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244824c
	if (!cr6.gt) goto loc_8244824C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r27,0
	r27.s64 = 0;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82447F34:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r30,r27,r11
	r30.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82447fb0
	if (cr0.eq) goto loc_82447FB0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r3.u32);
	// beq cr6,0x8244826c
	if (cr6.eq) goto loc_8244826C;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,24(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r9,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r9.u32);
	// b 0x82447fb4
	goto loc_82447FB4;
loc_82447FB0:
	// stw r29,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r29.u32);
loc_82447FB4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82447f34
	if (cr6.lt) goto loc_82447F34;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8244824c
	if (cr6.eq) goto loc_8244824C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r28,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r19,r3
	r19.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r19.s32, 0, xer);
	// beq 0x8244826c
	if (cr0.eq) goto loc_8244826C;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r21,0
	r21.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244804c
	if (!cr6.gt) goto loc_8244804C;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
loc_82448008:
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,26,26
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82448038
	if (cr0.eq) goto loc_82448038;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
loc_82448038:
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82448008
	if (cr6.lt) goto loc_82448008;
loc_8244804C:
	// lis r11,-32188
	r11.s64 = -2109472768;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// addi r3,r11,-5448
	ctx.r3.s64 = r11.s64 + -5448;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8244824c
	if (cr6.eq) goto loc_8244824C;
	// li r20,-1
	r20.s64 = -1;
loc_82448074:
	// rlwinm r10,r22,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r22,1
	r11.s64 = r22.s64 + 1;
	// add r23,r10,r19
	r23.u64 = ctx.r10.u64 + r19.u64;
	// li r27,1
	r27.s64 = 1;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// lwz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// bge cr6,0x824480f0
	if (!cr6.lt) goto loc_824480F0;
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// addi r10,r23,4
	ctx.r10.s64 = r23.s64 + 4;
loc_824480A4:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r5,4(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x824480f0
	if (!cr6.eq) goto loc_824480F0;
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r4,8(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmplw cr6,r5,r4
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, xer);
	// bne cr6,0x824480f0
	if (!cr6.eq) goto loc_824480F0;
	// lwz r5,12(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r5,r8
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r8.u32, xer);
	// bne cr6,0x824480f0
	if (!cr6.eq) goto loc_824480F0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// blt cr6,0x824480a4
	if (cr6.lt) goto loc_824480A4;
loc_824480F0:
	// li r11,1
	r11.s64 = 1;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244826c
	if (cr6.eq) goto loc_8244826C;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// lwzx r24,r11,r10
	r24.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// beq cr6,0x82448240
	if (cr6.eq) goto loc_82448240;
	// mr r26,r23
	r26.u64 = r23.u64;
loc_82448130:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// lwz r28,48(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// b 0x824481d8
	goto loc_824481D8;
loc_8244814C:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,60(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82448178
	if (cr6.eq) goto loc_82448178;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x82448250
	if (cr0.lt) goto loc_82448250;
loc_82448178:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824481e0
	if (!cr6.eq) goto loc_824481E0;
	// lwz r9,12(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x824481bc
	if (cr0.eq) goto loc_824481BC;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
loc_824481A0:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// beq cr6,0x824481bc
	if (cr6.eq) goto loc_824481BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x824481a0
	if (cr6.lt) goto loc_824481A0;
loc_824481BC:
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r28,r11,r10
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r28,2,0,29
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
loc_824481D8:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244814c
	if (!cr6.eq) goto loc_8244814C;
loc_824481E0:
	// lwz r11,60(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824481fc
	if (!cr6.eq) goto loc_824481FC;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r25,r27
	cr6.compare<uint32_t>(r25.u32, r27.u32, xer);
	// blt cr6,0x82448130
	if (cr6.lt) goto loc_82448130;
loc_824481FC:
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
loc_82448208:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,8(r24)
	ctx.r6.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,48(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// stwx r8,r10,r6
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, ctx.r8.u32);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r7,16(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 16);
	// stwx r8,r10,r7
	PPC_STORE_U32(ctx.r10.u32 + ctx.r7.u32, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82448208
	if (!cr0.eq) goto loc_82448208;
loc_82448240:
	// add r22,r27,r22
	r22.u64 = r27.u64 + r22.u64;
	// cmplw cr6,r22,r21
	cr6.compare<uint32_t>(r22.u32, r21.u32, xer);
	// blt cr6,0x82448074
	if (cr6.lt) goto loc_82448074;
loc_8244824C:
	// li r29,0
	r29.s64 = 0;
loc_82448250:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x8239bd24
	return;
loc_8244826C:
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x82448250
	goto loc_82448250;
}

__attribute__((alias("__imp__sub_82448278"))) PPC_WEAK_FUNC(sub_82448278);
PPC_FUNC_IMPL(__imp__sub_82448278) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcdc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r24,0
	r24.s64 = 0;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r21,r24
	r21.u64 = r24.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824482f4
	if (!cr6.gt) goto loc_824482F4;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_824482A8:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r8,16(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r8,r8,0,15,26
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x1FFE0;
	// rlwinm. r8,r8,0,26,15
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF003F;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x824482dc
	if (cr0.eq) goto loc_824482DC;
	// li r8,2
	ctx.r8.s64 = 2;
	// stw r8,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r8.u32);
	// b 0x824482e0
	goto loc_824482E0;
loc_824482DC:
	// stw r24,84(r11)
	PPC_STORE_U32(r11.u32 + 84, r24.u32);
loc_824482E0:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x824482a8
	if (cr6.lt) goto loc_824482A8;
loc_824482F4:
	// lwz r8,12(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// lis r25,8336
	r25.s64 = 546308096;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82448380
	if (cr0.eq) goto loc_82448380;
	// rlwinm r6,r8,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
loc_82448308:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// addi r6,r6,-4
	ctx.r6.s64 = ctx.r6.s64 + -4;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r25
	cr6.compare<uint32_t>(ctx.r10.u32, r25.u32, xer);
	// bne cr6,0x82448378
	if (!cr6.eq) goto loc_82448378;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82448378
	if (!cr6.gt) goto loc_82448378;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_8244833C:
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r5,20(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwz r5,84(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 84);
	// cmplwi cr6,r5,2
	cr6.compare<uint32_t>(ctx.r5.u32, 2, xer);
	// beq cr6,0x82448364
	if (cr6.eq) goto loc_82448364;
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r5,84(r9)
	PPC_STORE_U32(ctx.r9.u32 + 84, ctx.r5.u32);
loc_82448364:
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244833c
	if (cr6.lt) goto loc_8244833C;
loc_82448378:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82448308
	if (!cr6.eq) goto loc_82448308;
loc_82448380:
	// lis r23,4096
	r23.s64 = 268435456;
	// lis r22,16384
	r22.s64 = 1073741824;
loc_82448388:
	// lwz r29,12(r26)
	r29.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r27,r24
	r27.u64 = r24.u64;
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x8244869c
	if (cr0.eq) goto loc_8244869C;
	// rlwinm r28,r29,2,0,29
	r28.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244839C:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// addi r28,r28,-4
	r28.s64 = r28.s64 + -4;
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// lwzx r9,r28,r11
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82448538
	if (cr0.eq) goto loc_82448538;
	// rlwinm r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r10,r23
	cr6.compare<uint32_t>(ctx.r10.u32, r23.u32, xer);
	// blt cr6,0x82448474
	if (cr6.lt) goto loc_82448474;
	// cmplw cr6,r10,r22
	cr6.compare<uint32_t>(ctx.r10.u32, r22.u32, xer);
	// bgt cr6,0x82448474
	if (cr6.gt) goto loc_82448474;
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// divwu r31,r10,r11
	r31.u32 = ctx.r10.u32 / r11.u32;
	// twllei r11,0
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82448538
	if (!cr6.gt) goto loc_82448538;
	// mr r30,r24
	r30.u64 = r24.u64;
loc_824483F0:
	// lwz r11,16(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r4,r30,r11
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r7,84(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x82448414
	if (!cr6.eq) goto loc_82448414;
	// li r27,1
	r27.s64 = 1;
loc_82448414:
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82442db0
	sub_82442DB0(ctx, base);
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8244845c
	if (cr6.eq) goto loc_8244845C;
loc_8244842C:
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mullw r11,r11,r8
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r8.s32);
	// add r11,r11,r6
	r11.u64 = r11.u64 + ctx.r6.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x82442db0
	sub_82442DB0(ctx, base);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r31
	cr6.compare<uint32_t>(ctx.r8.u32, r31.u32, xer);
	// blt cr6,0x8244842c
	if (cr6.lt) goto loc_8244842C;
loc_8244845C:
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x824483f0
	if (cr6.lt) goto loc_824483F0;
	// b 0x82448538
	goto loc_82448538;
loc_82448474:
	// lwz r6,12(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mr r31,r24
	r31.u64 = r24.u64;
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x824484c4
	if (cr0.eq) goto loc_824484C4;
	// lwz r7,20(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// lwz r11,16(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_82448490:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r10,84(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r31,r10
	cr6.compare<uint32_t>(r31.u32, ctx.r10.u32, xer);
	// bge cr6,0x824484ac
	if (!cr6.lt) goto loc_824484AC;
	// mr r31,r10
	r31.u64 = ctx.r10.u64;
loc_824484AC:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82448490
	if (!cr0.eq) goto loc_82448490;
	// cmplwi cr6,r31,1
	cr6.compare<uint32_t>(r31.u32, 1, xer);
	// bne cr6,0x824484c4
	if (!cr6.eq) goto loc_824484C4;
	// li r27,1
	r27.s64 = 1;
loc_824484C4:
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x824484fc
	if (cr6.eq) goto loc_824484FC;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
loc_824484D4:
	// lwz r11,16(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r4,r8,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// bl 0x82442db0
	sub_82442DB0(ctx, base);
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x824484d4
	if (cr6.lt) goto loc_824484D4;
loc_824484FC:
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82448538
	if (!cr6.gt) goto loc_82448538;
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
loc_82448510:
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// bl 0x82442db0
	sub_82442DB0(ctx, base);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x82448510
	if (cr6.lt) goto loc_82448510;
loc_82448538:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x8244839c
	if (!cr6.eq) goto loc_8244839C;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x8244869c
	if (cr6.eq) goto loc_8244869C;
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r28,r24
	r28.u64 = r24.u64;
	// mr r29,r24
	r29.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244869c
	if (!cr6.gt) goto loc_8244869C;
	// mr r30,r24
	r30.u64 = r24.u64;
loc_82448560:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// lwzx r5,r30,r11
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x82448680
	if (!cr6.eq) goto loc_82448680;
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82448680
	if (cr0.eq) goto loc_82448680;
	// mr r31,r24
	r31.u64 = r24.u64;
loc_8244858C:
	// lwz r10,16(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// lwz r6,20(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r10,r10,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r31.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r6
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,84(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 84);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x8244866c
	if (!cr6.eq) goto loc_8244866C;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lwz r10,8(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824485d8
	if (cr6.eq) goto loc_824485D8;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r7,56(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x824485dc
	if (!cr6.eq) goto loc_824485DC;
loc_824485D8:
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
loc_824485DC:
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,24(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// mr r11,r24
	r11.u64 = r24.u64;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82448624
	if (cr0.eq) goto loc_82448624;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82448608:
	// lwz r27,0(r8)
	r27.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r27,r7
	cr6.compare<uint32_t>(r27.u32, ctx.r7.u32, xer);
	// beq cr6,0x82448624
	if (cr6.eq) goto loc_82448624;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82448608
	if (cr6.lt) goto loc_82448608;
loc_82448624:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448650
	if (cr6.eq) goto loc_82448650;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82448650
	if (cr6.eq) goto loc_82448650;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82448650:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8244866c
	if (cr6.eq) goto loc_8244866C;
	// li r28,1
	r28.s64 = 1;
	// stw r11,84(r4)
	PPC_STORE_U32(ctx.r4.u32 + 84, r11.u32);
loc_8244866C:
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// blt cr6,0x8244858c
	if (cr6.lt) goto loc_8244858C;
loc_82448680:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82448560
	if (cr6.lt) goto loc_82448560;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x82448388
	if (!cr6.eq) goto loc_82448388;
loc_8244869C:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r29,r24
	r29.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244888c
	if (!cr6.gt) goto loc_8244888C;
	// mr r30,r24
	r30.u64 = r24.u64;
loc_824486B0:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r9,r10,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82448878
	if (cr0.eq) goto loc_82448878;
	// rlwinm r9,r10,0,0,3
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r9,r23
	cr6.compare<uint32_t>(ctx.r9.u32, r23.u32, xer);
	// blt cr6,0x8244881c
	if (cr6.lt) goto loc_8244881C;
	// cmplw cr6,r9,r22
	cr6.compare<uint32_t>(ctx.r9.u32, r22.u32, xer);
	// bgt cr6,0x8244881c
	if (cr6.gt) goto loc_8244881C;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// divwu r31,r9,r10
	r31.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// ble cr6,0x82448784
	if (!cr6.gt) goto loc_82448784;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
loc_82448704:
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r8,r9,r6
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwz r10,84(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x82448770
	if (!cr6.eq) goto loc_82448770;
	// lwzx r8,r9,r6
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stwx r8,r9,r4
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, ctx.r8.u32);
	// beq cr6,0x82448768
	if (cr6.eq) goto loc_82448768;
loc_82448738:
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mullw r8,r10,r8
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// add r3,r5,r8
	ctx.r3.u64 = ctx.r5.u64 + ctx.r8.u64;
	// add r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 + ctx.r8.u64;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// lwzx r3,r3,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r9.u32);
	// stwx r3,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, ctx.r3.u32);
	// blt cr6,0x82448738
	if (cr6.lt) goto loc_82448738;
loc_82448768:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
loc_82448770:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// blt cr6,0x82448704
	if (cr6.lt) goto loc_82448704;
loc_82448784:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// beq cr6,0x82448878
	if (cr6.eq) goto loc_82448878;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x824487a4
	if (cr6.eq) goto loc_824487A4;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwimi r10,r7,0,12,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r7.u32, 0) & 0xFFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFF00000);
	// b 0x824487a8
	goto loc_824487A8;
loc_824487A4:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_824487A8:
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r31,1
	cr6.compare<uint32_t>(r31.u32, 1, xer);
	// ble cr6,0x8244880c
	if (!cr6.gt) goto loc_8244880C;
	// rlwinm r3,r7,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
loc_824487C0:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x824487fc
	if (cr6.eq) goto loc_824487FC;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
loc_824487D0:
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mullw r5,r6,r5
	ctx.r5.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r5.s32);
	// add r5,r5,r10
	ctx.r5.u64 = ctx.r5.u64 + ctx.r10.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// lwzx r5,r5,r8
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// stwx r5,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r5.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// blt cr6,0x824487d0
	if (cr6.lt) goto loc_824487D0;
loc_824487FC:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// add r4,r3,r4
	ctx.r4.u64 = ctx.r3.u64 + ctx.r4.u64;
	// cmplw cr6,r6,r31
	cr6.compare<uint32_t>(ctx.r6.u32, r31.u32, xer);
	// blt cr6,0x824487c0
	if (cr6.lt) goto loc_824487C0;
loc_8244880C:
	// mullw r10,r7,r31
	ctx.r10.s64 = int64_t(ctx.r7.s32) * int64_t(r31.s32);
	// stw r7,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r7.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// b 0x82448874
	goto loc_82448874;
loc_8244881C:
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x82448860
	if (cr0.eq) goto loc_82448860;
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_82448834:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r8
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwz r6,84(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 84);
	// cmplwi cr6,r6,2
	cr6.compare<uint32_t>(ctx.r6.u32, 2, xer);
	// beq cr6,0x82448860
	if (cr6.eq) goto loc_82448860;
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// blt cr6,0x82448834
	if (cr6.lt) goto loc_82448834;
loc_82448860:
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// bne cr6,0x82448878
	if (!cr6.eq) goto loc_82448878;
	// stw r24,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r24.u32);
	// stw r24,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r24.u32);
	// stw r24,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r24.u32);
loc_82448874:
	// li r21,1
	r21.s64 = 1;
loc_82448878:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x824486b0
	if (cr6.lt) goto loc_824486B0;
loc_8244888C:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82448954
	if (!cr6.gt) goto loc_82448954;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
loc_824488A0:
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// lwzx r9,r10,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// beq cr6,0x824488bc
	if (cr6.eq) goto loc_824488BC;
	// lwz r11,56(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824488c0
	if (!cr6.eq) goto loc_824488C0;
loc_824488BC:
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_824488C0:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x82448940
	if (cr6.eq) goto loc_82448940;
	// lwz r10,116(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 116);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82448940
	if (cr6.eq) goto loc_82448940;
	// lwz r6,8(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// bne cr6,0x82448908
	if (!cr6.eq) goto loc_82448908;
	// lwz r6,16(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r5,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r6.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm. r6,r6,0,21,21
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x82448940
	if (!cr0.eq) goto loc_82448940;
loc_82448908:
	// lwz r6,16(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r6,r11,0,22,23
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x300;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x82448938
	if (cr0.eq) goto loc_82448938;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82448938
	if (cr0.eq) goto loc_82448938;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// oris r11,r11,4096
	r11.u64 = r11.u64 | 268435456;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// b 0x82448940
	goto loc_82448940;
loc_82448938:
	// li r21,1
	r21.s64 = 1;
	// stw r10,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r10.u32);
loc_82448940:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x824488a0
	if (cr6.lt) goto loc_824488A0;
loc_82448954:
	// cntlzw r11,r21
	r11.u64 = r21.u32 == 0 ? 32 : __builtin_clz(r21.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd2c
	return;
}

__attribute__((alias("__imp__sub_82448964"))) PPC_WEAK_FUNC(sub_82448964);
PPC_FUNC_IMPL(__imp__sub_82448964) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82448968"))) PPC_WEAK_FUNC(sub_82448968);
PPC_FUNC_IMPL(__imp__sub_82448968) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r25,0
	r25.s64 = 0;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// bne 0x824489a4
	if (!cr0.eq) goto loc_824489A4;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82448c0c
	goto loc_82448C0C;
loc_824489A4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r30,0
	r30.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82448a24
	if (!cr6.gt) goto loc_82448A24;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
loc_824489C4:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r7,r11,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82448a10
	if (cr0.eq) goto loc_82448A10;
	// rlwinm. r7,r11,0,21,21
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82448a10
	if (!cr0.eq) goto loc_82448A10;
	// rlwinm. r7,r11,0,20,20
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82448a10
	if (!cr0.eq) goto loc_82448A10;
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82448a10
	if (!cr0.eq) goto loc_82448A10;
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
loc_82448A10:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x824489c4
	if (cr6.lt) goto loc_824489C4;
loc_82448A24:
	// lis r11,-32188
	r11.s64 = -2109472768;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r11,-5584
	ctx.r3.s64 = r11.s64 + -5584;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// ble cr6,0x82448ad4
	if (!cr6.gt) goto loc_82448AD4;
	// addi r7,r26,4
	ctx.r7.s64 = r26.s64 + 4;
	// addi r6,r30,-1
	ctx.r6.s64 = r30.s64 + -1;
loc_82448A4C:
	// lwz r10,-4(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + -4);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,0(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r3,48(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// bl 0x8243ea30
	sub_8243EA30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82448ab4
	if (!cr0.eq) goto loc_82448AB4;
	// rotlwi r11,r4,0
	r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 0);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,116(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// li r29,1
	r29.s64 = 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// lwz r10,-4(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + -4);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
loc_82448AB4:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x82448a4c
	if (!cr0.eq) goto loc_82448A4C;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82448ad4
	if (cr6.eq) goto loc_82448AD4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// li r25,1
	r25.s64 = 1;
loc_82448AD4:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r28,0
	r28.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82448b54
	if (!cr6.gt) goto loc_82448B54;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
loc_82448AF4:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r11,48(r10)
	PPC_STORE_U32(ctx.r10.u32 + 48, r11.u32);
	// lwz r10,116(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x82448b40
	if (cr6.eq) goto loc_82448B40;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82448b34
	if (!cr0.eq) goto loc_82448B34;
	// lwz r10,220(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 220);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82448b40
	if (cr6.eq) goto loc_82448B40;
loc_82448B34:
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
loc_82448B40:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x82448af4
	if (cr6.lt) goto loc_82448AF4;
loc_82448B54:
	// lis r11,-32188
	r11.s64 = -2109472768;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r11,-5448
	ctx.r3.s64 = r11.s64 + -5448;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82448b7c
	if (cr6.eq) goto loc_82448B7C;
	// lwz r29,0(r26)
	r29.u64 = PPC_LOAD_U32(r26.u32 + 0);
loc_82448B7C:
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// ble cr6,0x82448bf8
	if (!cr6.gt) goto loc_82448BF8;
	// addi r30,r26,4
	r30.s64 = r26.s64 + 4;
	// addi r28,r28,-1
	r28.s64 = r28.s64 + -1;
loc_82448B8C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243eab8
	sub_8243EAB8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82448bd4
	if (!cr0.eq) goto loc_82448BD4;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82443718
	sub_82443718(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r27,1
	r27.s64 = 1;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,116(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// b 0x82448bd8
	goto loc_82448BD8;
loc_82448BD4:
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
loc_82448BD8:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x82448b8c
	if (!cr0.eq) goto loc_82448B8C;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82448bf8
	if (cr6.eq) goto loc_82448BF8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// li r25,1
	r25.s64 = 1;
loc_82448BF8:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// cntlzw r11,r25
	r11.u64 = r25.u32 == 0 ? 32 : __builtin_clz(r25.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82448C0C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_82448C14"))) PPC_WEAK_FUNC(sub_82448C14);
PPC_FUNC_IMPL(__imp__sub_82448C14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82448C18"))) PPC_WEAK_FUNC(sub_82448C18);
PPC_FUNC_IMPL(__imp__sub_82448C18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc8
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// li r17,0
	r17.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// lwz r10,8(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82448c64
	if (!cr6.gt) goto loc_82448C64;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82448C40:
	// lwz r8,20(r18)
	ctx.r8.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82448c40
	if (cr6.lt) goto loc_82448C40;
loc_82448C64:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// li r16,0
	r16.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82449268
	if (!cr6.gt) goto loc_82449268;
	// li r24,-1
	r24.s64 = -1;
loc_82448C78:
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// rlwinm r10,r16,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r16.u32 | (r16.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82449250
	if (cr6.lt) goto loc_82449250;
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bgt cr6,0x82449250
	if (cr6.gt) goto loc_82449250;
	// clrlwi r31,r11,12
	r31.u64 = r11.u32 & 0xFFFFF;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// divwu r19,r11,r31
	r19.u32 = r11.u32 / r31.u32;
	// twllei r31,0
	// bl 0x8243d178
	sub_8243D178(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// mr r22,r31
	r22.u64 = r31.u64;
	// li r27,1
	r27.s64 = 1;
	// cmplwi cr6,r31,1
	cr6.compare<uint32_t>(r31.u32, 1, xer);
	// ble cr6,0x82449250
	if (!cr6.gt) goto loc_82449250;
	// rlwinm r20,r31,2,0,29
	r20.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// li r30,4
	r30.s64 = 4;
	// addi r25,r20,4
	r25.s64 = r20.s64 + 4;
loc_82448CDC:
	// lwz r26,16(r29)
	r26.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r6,20(r18)
	ctx.r6.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r23,16(r18)
	r23.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// lwzx r5,r26,r30
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + r30.u32);
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// andi. r11,r11,4128
	r11.u64 = r11.u64 & 4128;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82449154
	if (!cr0.eq) goto loc_82449154;
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82449154
	if (cr6.eq) goto loc_82449154;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r28,r20
	r28.u64 = r20.u64;
loc_82448D24:
	// lwzx r11,r26,r3
	r11.u64 = PPC_LOAD_U32(r26.u32 + ctx.r3.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82449120
	if (cr6.eq) goto loc_82449120;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// andi. r11,r11,4128
	r11.u64 = r11.u64 & 4128;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82449120
	if (!cr0.eq) goto loc_82449120;
	// cmplwi cr6,r19,1
	cr6.compare<uint32_t>(r19.u32, 1, xer);
	// bne cr6,0x82448da8
	if (!cr6.eq) goto loc_82448DA8;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r11,r10,r30
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448d7c
	if (cr6.eq) goto loc_82448D7C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r9,48(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448d80
	goto loc_82448D80;
loc_82448D7C:
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
loc_82448D80:
	// lwzx r11,r10,r3
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448d9c
	if (cr6.eq) goto loc_82448D9C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448da0
	goto loc_82448DA0;
loc_82448D9C:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82448DA0:
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x82449138
	if (cr6.eq) goto loc_82449138;
loc_82448DA8:
	// cmplwi cr6,r19,2
	cr6.compare<uint32_t>(r19.u32, 2, xer);
	// bne cr6,0x82448ed4
	if (!cr6.eq) goto loc_82448ED4;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r8,r9,r30
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82448dd0
	if (cr6.eq) goto loc_82448DD0;
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448dd4
	goto loc_82448DD4;
loc_82448DD0:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82448DD4:
	// lwzx r7,r9,r3
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// beq cr6,0x82448df0
	if (cr6.eq) goto loc_82448DF0;
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448df4
	goto loc_82448DF4;
loc_82448DF0:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82448DF4:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82448e44
	if (!cr6.eq) goto loc_82448E44;
	// lwzx r11,r9,r25
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r25.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448e18
	if (cr6.eq) goto loc_82448E18;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448e1c
	goto loc_82448E1C;
loc_82448E18:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82448E1C:
	// lwzx r11,r9,r28
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r28.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448e38
	if (cr6.eq) goto loc_82448E38;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448e3c
	goto loc_82448E3C;
loc_82448E38:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82448E3C:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82449138
	if (cr6.eq) goto loc_82449138;
loc_82448E44:
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x82449120
	if (cr6.eq) goto loc_82449120;
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82448e64
	if (cr6.eq) goto loc_82448E64;
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448e68
	goto loc_82448E68;
loc_82448E64:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82448E68:
	// lwzx r11,r9,r28
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r28.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448e84
	if (cr6.eq) goto loc_82448E84;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448e88
	goto loc_82448E88;
loc_82448E84:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82448E88:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82449120
	if (!cr6.eq) goto loc_82449120;
	// lwzx r11,r9,r25
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r25.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448eac
	if (cr6.eq) goto loc_82448EAC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448eb0
	goto loc_82448EB0;
loc_82448EAC:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82448EB0:
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// beq cr6,0x82448ec8
	if (cr6.eq) goto loc_82448EC8;
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448ecc
	goto loc_82448ECC;
loc_82448EC8:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82448ECC:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82449138
	if (cr6.eq) goto loc_82449138;
loc_82448ED4:
	// cmplwi cr6,r19,3
	cr6.compare<uint32_t>(r19.u32, 3, xer);
	// bne cr6,0x82448fcc
	if (!cr6.eq) goto loc_82448FCC;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r11,r8,r30
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r30.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448efc
	if (cr6.eq) goto loc_82448EFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448f00
	goto loc_82448F00;
loc_82448EFC:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82448F00:
	// lwzx r11,r8,r3
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448f1c
	if (cr6.eq) goto loc_82448F1C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448f20
	goto loc_82448F20;
loc_82448F1C:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82448F20:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82449120
	if (!cr6.eq) goto loc_82449120;
	// lwzx r11,r8,r25
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r25.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448f44
	if (cr6.eq) goto loc_82448F44;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448f48
	goto loc_82448F48;
loc_82448F44:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82448F48:
	// lwzx r11,r8,r28
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r28.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448f64
	if (cr6.eq) goto loc_82448F64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448f68
	goto loc_82448F68;
loc_82448F64:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82448F68:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82449120
	if (!cr6.eq) goto loc_82449120;
	// rlwinm r10,r31,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r10,r27
	r11.u64 = ctx.r10.u64 + r27.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448f98
	if (cr6.eq) goto loc_82448F98;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r9,48(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448f9c
	goto loc_82448F9C;
loc_82448F98:
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
loc_82448F9C:
	// add r11,r10,r4
	r11.u64 = ctx.r10.u64 + ctx.r4.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448fc0
	if (cr6.eq) goto loc_82448FC0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448fc4
	goto loc_82448FC4;
loc_82448FC0:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82448FC4:
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x82449138
	if (cr6.eq) goto loc_82449138;
loc_82448FCC:
	// cmplwi cr6,r19,4
	cr6.compare<uint32_t>(r19.u32, 4, xer);
	// bne cr6,0x82449120
	if (!cr6.eq) goto loc_82449120;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r11,r8,r30
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r30.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82448ff4
	if (cr6.eq) goto loc_82448FF4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82448ff8
	goto loc_82448FF8;
loc_82448FF4:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82448FF8:
	// lwzx r11,r8,r3
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82449014
	if (cr6.eq) goto loc_82449014;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82449018
	goto loc_82449018;
loc_82449014:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82449018:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82449120
	if (!cr6.eq) goto loc_82449120;
	// lwzx r11,r8,r25
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r25.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244903c
	if (cr6.eq) goto loc_8244903C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82449040
	goto loc_82449040;
loc_8244903C:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_82449040:
	// lwzx r11,r8,r28
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r28.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244905c
	if (cr6.eq) goto loc_8244905C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82449060
	goto loc_82449060;
loc_8244905C:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82449060:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82449120
	if (!cr6.eq) goto loc_82449120;
	// rlwinm r10,r31,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r10,r27
	r11.u64 = ctx.r10.u64 + r27.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82449090
	if (cr6.eq) goto loc_82449090;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r9,48(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82449094
	goto loc_82449094;
loc_82449090:
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
loc_82449094:
	// add r11,r10,r4
	r11.u64 = ctx.r10.u64 + ctx.r4.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824490b8
	if (cr6.eq) goto loc_824490B8;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x824490bc
	goto loc_824490BC;
loc_824490B8:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_824490BC:
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x82449120
	if (!cr6.eq) goto loc_82449120;
	// mulli r10,r31,3
	ctx.r10.s64 = r31.s64 * 3;
	// add r11,r10,r27
	r11.u64 = ctx.r10.u64 + r27.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824490ec
	if (cr6.eq) goto loc_824490EC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r9,48(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x824490f0
	goto loc_824490F0;
loc_824490EC:
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
loc_824490F0:
	// add r11,r10,r4
	r11.u64 = ctx.r10.u64 + ctx.r4.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82449114
	if (cr6.eq) goto loc_82449114;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82449118
	goto loc_82449118;
loc_82449114:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82449118:
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x82449138
	if (cr6.eq) goto loc_82449138;
loc_82449120:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r4,r27
	cr6.compare<uint32_t>(ctx.r4.u32, r27.u32, xer);
	// blt cr6,0x82448d24
	if (cr6.lt) goto loc_82448D24;
	// b 0x82449154
	goto loc_82449154;
loc_82449138:
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// lwzx r4,r11,r26
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// bl 0x82443718
	sub_82443718(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// addi r22,r22,-1
	r22.s64 = r22.s64 + -1;
	// stwx r24,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, r24.u32);
loc_82449154:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r27,r31
	cr6.compare<uint32_t>(r27.u32, r31.u32, xer);
	// blt cr6,0x82448cdc
	if (cr6.lt) goto loc_82448CDC;
	// cmplw cr6,r22,r31
	cr6.compare<uint32_t>(r22.u32, r31.u32, xer);
	// bge cr6,0x82449250
	if (!cr6.lt) goto loc_82449250;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x824491dc
	if (cr6.eq) goto loc_824491DC;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
loc_82449184:
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r10,r11,r7
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824491d0
	if (cr6.eq) goto loc_824491D0;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// stwx r10,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r10.u32);
	// beq cr6,0x824491cc
	if (cr6.eq) goto loc_824491CC;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// mr r11,r19
	r11.u64 = r19.u64;
loc_824491B0:
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r4,r8,r10
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// add r10,r10,r20
	ctx.r10.u64 = ctx.r10.u64 + r20.u64;
	// stwx r4,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, ctx.r4.u32);
	// add r9,r9,r20
	ctx.r9.u64 = ctx.r9.u64 + r20.u64;
	// bne 0x824491b0
	if (!cr0.eq) goto loc_824491B0;
loc_824491CC:
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
loc_824491D0:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x82449184
	if (!cr0.eq) goto loc_82449184;
loc_824491DC:
	// cmplwi cr6,r19,1
	cr6.compare<uint32_t>(r19.u32, 1, xer);
	// ble cr6,0x82449234
	if (!cr6.gt) goto loc_82449234;
	// rlwinm r4,r22,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// addi r5,r19,-1
	ctx.r5.s64 = r19.s64 + -1;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
loc_824491F4:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82449224
	if (cr6.eq) goto loc_82449224;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// mr r11,r22
	r11.u64 = r22.u64;
loc_82449208:
	// lwz r6,8(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r3,r6,r10
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stwx r3,r6,r9
	PPC_STORE_U32(ctx.r6.u32 + ctx.r9.u32, ctx.r3.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82449208
	if (!cr0.eq) goto loc_82449208;
loc_82449224:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// add r8,r4,r8
	ctx.r8.u64 = ctx.r4.u64 + ctx.r8.u64;
	// add r7,r7,r20
	ctx.r7.u64 = ctx.r7.u64 + r20.u64;
	// bne 0x824491f4
	if (!cr0.eq) goto loc_824491F4;
loc_82449234:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mullw r10,r22,r19
	ctx.r10.s64 = int64_t(r22.s32) * int64_t(r19.s32);
	// rlwimi r11,r22,0,12,31
	r11.u64 = (__builtin_rotateleft32(r22.u32, 0) & 0xFFFFF) | (r11.u64 & 0xFFFFFFFFFFF00000);
	// stw r22,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r22.u32);
	// stw r10,4(r29)
	PPC_STORE_U32(r29.u32 + 4, ctx.r10.u32);
	// li r17,1
	r17.s64 = 1;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_82449250:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// addi r16,r16,1
	r16.s64 = r16.s64 + 1;
	// cmplw cr6,r16,r11
	cr6.compare<uint32_t>(r16.u32, r11.u32, xer);
	// blt cr6,0x82448c78
	if (cr6.lt) goto loc_82448C78;
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// bne cr6,0x82449270
	if (!cr6.eq) goto loc_82449270;
loc_82449268:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8244927c
	goto loc_8244927C;
loc_82449270:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_8244927C:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8239bd18
	return;
}

__attribute__((alias("__imp__sub_82449284"))) PPC_WEAK_FUNC(sub_82449284);
PPC_FUNC_IMPL(__imp__sub_82449284) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82449288"))) PPC_WEAK_FUNC(sub_82449288);
PPC_FUNC_IMPL(__imp__sub_82449288) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r16,0
	r16.s64 = 0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r15,r16
	r15.u64 = r16.u64;
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r14,r3
	r14.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r14.s32, 0, xer);
	// bne 0x824492c8
	if (!cr0.eq) goto loc_824492C8;
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x824497a0
	goto loc_824497A0;
loc_824492C8:
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824493f0
	if (!cr6.gt) goto loc_824493F0;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
loc_824492E0:
	// lwz r11,24(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 24);
	// lwzx r10,r5,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824493dc
	if (cr0.eq) goto loc_824493DC;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x82449308
	if (cr6.eq) goto loc_82449308;
	// lwz r9,36(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x824493dc
	if (!cr6.eq) goto loc_824493DC;
loc_82449308:
	// lis r9,4336
	ctx.r9.s64 = 284164096;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lis r9,8304
	ctx.r9.s64 = 544210944;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lis r9,4368
	ctx.r9.s64 = 286261248;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lis r9,4384
	ctx.r9.s64 = 287309824;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lis r9,4400
	ctx.r9.s64 = 288358400;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lis r9,4416
	ctx.r9.s64 = 289406976;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lis r9,8320
	ctx.r9.s64 = 545259520;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lis r9,8336
	ctx.r9.s64 = 546308096;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lis r9,4432
	ctx.r9.s64 = 290455552;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x824493dc
	if (cr6.eq) goto loc_824493DC;
	// lwz r6,12(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mr r9,r16
	ctx.r9.u64 = r16.u64;
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x824493c8
	if (cr0.eq) goto loc_824493C8;
	// lwz r8,20(r24)
	ctx.r8.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwz r7,16(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 16);
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82449390:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// andi. r10,r10,4128
	ctx.r10.u64 = ctx.r10.u64 & 4128;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne 0x824493c8
	if (!cr0.eq) goto loc_824493C8;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// blt cr6,0x82449390
	if (cr6.lt) goto loc_82449390;
loc_824493C8:
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// blt cr6,0x824493dc
	if (cr6.lt) goto loc_824493DC;
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// addi r15,r15,1
	r15.s64 = r15.s64 + 1;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
loc_824493DC:
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x824492e0
	if (cr6.lt) goto loc_824492E0;
loc_824493F0:
	// mr r29,r16
	r29.u64 = r16.u64;
loc_824493F4:
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// mr r30,r16
	r30.u64 = r16.u64;
	// mr r11,r16
	r11.u64 = r16.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82449430
	if (!cr6.gt) goto loc_82449430;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
loc_8244940C:
	// lwz r8,20(r24)
	ctx.r8.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244940c
	if (cr6.lt) goto loc_8244940C;
loc_82449430:
	// lis r11,-32188
	r11.s64 = -2109472768;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// addi r3,r11,11304
	ctx.r3.s64 = r11.s64 + 11304;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82449788
	if (cr6.eq) goto loc_82449788;
	// li r20,1
	r20.s64 = 1;
	// mr r19,r14
	r19.u64 = r14.u64;
	// mr r17,r15
	r17.u64 = r15.u64;
loc_8244945C:
	// lwz r21,0(r19)
	r21.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// cmpwi cr6,r21,-1
	cr6.compare<int32_t>(r21.s32, -1, xer);
	// beq cr6,0x824496d4
	if (cr6.eq) goto loc_824496D4;
	// mr r18,r20
	r18.u64 = r20.u64;
	// cmplw cr6,r20,r15
	cr6.compare<uint32_t>(r20.u32, r15.u32, xer);
	// bge cr6,0x824496d4
	if (!cr6.lt) goto loc_824496D4;
	// addi r22,r19,4
	r22.s64 = r19.s64 + 4;
loc_82449478:
	// lwz r31,0(r22)
	r31.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// beq cr6,0x824496c4
	if (cr6.eq) goto loc_824496C4;
	// cmplw cr6,r21,r31
	cr6.compare<uint32_t>(r21.u32, r31.u32, xer);
	// bge cr6,0x824496d4
	if (!cr6.lt) goto loc_824496D4;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x824427a8
	sub_824427A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824496d4
	if (!cr0.eq) goto loc_824496D4;
	// lwz r11,24(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 24);
	// rlwinm r10,r21,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r8,4096
	ctx.r8.s64 = 268435456;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r31,r9,r11
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// divwu r25,r9,r11
	r25.u32 = ctx.r9.u32 / r11.u32;
	// twllei r11,0
	// blt cr6,0x82449660
	if (cr6.lt) goto loc_82449660;
	// lis r11,16384
	r11.s64 = 1073741824;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bgt cr6,0x82449660
	if (cr6.gt) goto loc_82449660;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r23,r16
	r23.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824496a8
	if (!cr6.gt) goto loc_824496A8;
	// mr r28,r16
	r28.u64 = r16.u64;
loc_824494FC:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r27,r16
	r27.u64 = r16.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82449648
	if (cr0.eq) goto loc_82449648;
	// mr r26,r16
	r26.u64 = r16.u64;
loc_82449510:
	// mr r29,r16
	r29.u64 = r16.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82449578
	if (cr6.eq) goto loc_82449578;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// add r10,r10,r26
	ctx.r10.u64 = ctx.r10.u64 + r26.u64;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
loc_8244953C:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r7
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r7.u32);
	// lwzx r5,r5,r7
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r7.u32);
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// lwz r5,48(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bne cr6,0x82449578
	if (!cr6.eq) goto loc_82449578;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// add r11,r8,r11
	r11.u64 = ctx.r8.u64 + r11.u64;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// blt cr6,0x8244953c
	if (cr6.lt) goto loc_8244953C;
loc_82449578:
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// beq cr6,0x82449624
	if (cr6.eq) goto loc_82449624;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d178
	sub_8243D178(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82449604
	if (cr0.eq) goto loc_82449604;
	// mr r29,r16
	r29.u64 = r16.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82449604
	if (cr6.eq) goto loc_82449604;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r5,r11,r27
	ctx.r5.u64 = r11.u64 + r27.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mulli r7,r11,-4
	ctx.r7.s64 = r11.s64 * -4;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r6,20(r24)
	ctx.r6.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + r28.u64;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
loc_824495C8:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// lwzx r5,r5,r6
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r6.u32);
	// lwz r9,48(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// lwz r5,48(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	// cmplw cr6,r5,r9
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r9.u32, xer);
	// bne cr6,0x82449604
	if (!cr6.eq) goto loc_82449604;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// add r11,r7,r11
	r11.u64 = ctx.r7.u64 + r11.u64;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// blt cr6,0x824495c8
	if (cr6.lt) goto loc_824495C8;
loc_82449604:
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// beq cr6,0x82449624
	if (cr6.eq) goto loc_82449624;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x82449510
	if (cr6.lt) goto loc_82449510;
	// b 0x82449648
	goto loc_82449648;
loc_82449624:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r10,r27,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r8,20(r24)
	ctx.r8.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
loc_82449648:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// blt cr6,0x824494fc
	if (cr6.lt) goto loc_824494FC;
	// b 0x824496a8
	goto loc_824496A8;
loc_82449660:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824496a8
	if (!cr6.gt) goto loc_824496A8;
	// mr r11,r16
	r11.u64 = r16.u64;
loc_82449674:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r7,20(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// stw r8,48(r9)
	PPC_STORE_U32(ctx.r9.u32 + 48, ctx.r8.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82449674
	if (cr6.lt) goto loc_82449674;
loc_824496A8:
	// li r11,-1
	r11.s64 = -1;
	// li r29,1
	r29.s64 = 1;
	// li r30,1
	r30.s64 = 1;
	// stw r11,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r11.u32);
	// stw r16,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r16.u32);
	// stw r16,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r16.u32);
	// stw r16,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r16.u32);
loc_824496C4:
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r18,r15
	cr6.compare<uint32_t>(r18.u32, r15.u32, xer);
	// blt cr6,0x82449478
	if (cr6.lt) goto loc_82449478;
loc_824496D4:
	// addic. r17,r17,-1
	xer.ca = r17.u32 > 0;
	r17.s64 = r17.s64 + -1;
	cr0.compare<int32_t>(r17.s32, 0, xer);
	// addi r19,r19,4
	r19.s64 = r19.s64 + 4;
	// addi r20,r20,1
	r20.s64 = r20.s64 + 1;
	// bne 0x8244945c
	if (!cr0.eq) goto loc_8244945C;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x82449788
	if (cr6.eq) goto loc_82449788;
	// mr. r11,r15
	r11.u64 = r15.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r15,r16
	r15.u64 = r16.u64;
	// beq 0x8244977c
	if (cr0.eq) goto loc_8244977C;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
loc_82449704:
	// lwz r6,0(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// beq cr6,0x82449770
	if (cr6.eq) goto loc_82449770;
	// lwz r11,24(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 24);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8244975c
	if (cr0.eq) goto loc_8244975C;
	// lwz r7,20(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_82449734:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r31,r8,2,0,29
	r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r31,r7
	r31.u64 = PPC_LOAD_U32(r31.u32 + ctx.r7.u32);
	// lwz r31,48(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmplw cr6,r31,r8
	cr6.compare<uint32_t>(r31.u32, ctx.r8.u32, xer);
	// bne cr6,0x8244975c
	if (!cr6.eq) goto loc_8244975C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82449734
	if (cr6.lt) goto loc_82449734;
loc_8244975C:
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x82449770
	if (cr6.eq) goto loc_82449770;
	// stw r6,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r6.u32);
	// addi r15,r15,1
	r15.s64 = r15.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
loc_82449770:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x82449704
	if (!cr0.eq) goto loc_82449704;
loc_8244977C:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// b 0x824493f4
	goto loc_824493F4;
loc_82449788:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82449798
	if (cr6.eq) goto loc_82449798;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82448968
	sub_82448968(ctx, base);
loc_82449798:
	// cntlzw r11,r29
	r11.u64 = r29.u32 == 0 ? 32 : __builtin_clz(r29.u32);
	// rlwinm r31,r11,27,31,31
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_824497A0:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_824497B8"))) PPC_WEAK_FUNC(sub_824497B8);
PPC_FUNC_IMPL(__imp__sub_824497B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// stw r21,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r21.u32);
	// bne 0x824497f0
	if (!cr0.eq) goto loc_824497F0;
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x82449da0
	goto loc_82449DA0;
loc_824497F0:
	// li r11,0
	r11.s64 = 0;
loc_824497F4:
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// li r22,0
	r22.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// stw r22,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r22.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82449848
	if (!cr6.gt) goto loc_82449848;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82449824:
	// lwz r8,20(r24)
	ctx.r8.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82449824
	if (cr6.lt) goto loc_82449824;
loc_82449848:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824499e4
	if (!cr6.gt) goto loc_824499E4;
	// li r23,0
	r23.s64 = 0;
	// mr r25,r21
	r25.u64 = r21.u64;
	// lis r20,4416
	r20.s64 = 289406976;
loc_82449864:
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwzx r27,r23,r11
	r27.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824499cc
	if (!cr6.eq) goto loc_824499CC;
	// lwz r10,72(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// lwz r9,16(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r9,r11,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824499cc
	if (cr0.eq) goto loc_824499CC;
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824499cc
	if (!cr0.eq) goto loc_824499CC;
	// lwz r11,24(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r8,4096
	ctx.r8.s64 = 268435456;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r11,r9,0,0,3
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x824499cc
	if (cr6.lt) goto loc_824499CC;
	// lis r10,16384
	ctx.r10.s64 = 1073741824;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x824499cc
	if (cr6.gt) goto loc_824499CC;
	// rlwinm r31,r9,0,0,11
	r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r31,r20
	cr6.compare<uint32_t>(r31.u32, r20.u32, xer);
	// bgt cr6,0x82449910
	if (cr6.gt) goto loc_82449910;
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lis r11,4336
	r11.s64 = 284164096;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lis r11,4368
	r11.s64 = 286261248;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lis r11,4384
	r11.s64 = 287309824;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lis r11,4400
	r11.s64 = 288358400;
	// b 0x82449938
	goto loc_82449938;
loc_82449910:
	// lis r11,4432
	r11.s64 = 290455552;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lis r11,8304
	r11.s64 = 544210944;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lis r11,8320
	r11.s64 = 545259520;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lis r11,8336
	r11.s64 = 546308096;
loc_82449938:
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x824499cc
	if (cr6.eq) goto loc_824499CC;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82449970
	if (cr0.eq) goto loc_82449970;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
loc_82449954:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r26,r8
	cr6.compare<uint32_t>(r26.u32, ctx.r8.u32, xer);
	// beq cr6,0x82449970
	if (cr6.eq) goto loc_82449970;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// blt cr6,0x82449954
	if (cr6.lt) goto loc_82449954;
loc_82449970:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// clrlwi r10,r9,12
	ctx.r10.u64 = ctx.r9.u32 & 0xFFFFF;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// divwu r30,r11,r10
	r30.u32 = r11.u32 / ctx.r10.u32;
	// twllei r10,0
	// bl 0x8243d178
	sub_8243D178(ctx, base);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824499bc
	if (cr6.eq) goto loc_824499BC;
loc_82449998:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8243f2b8
	sub_8243F2B8(ctx, base);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// mulli r11,r31,2111
	r11.s64 = r31.s64 * 2111;
	// add r31,r3,r11
	r31.u64 = ctx.r3.u64 + r11.u64;
	// cmplw cr6,r5,r30
	cr6.compare<uint32_t>(ctx.r5.u32, r30.u32, xer);
	// blt cr6,0x82449998
	if (cr6.lt) goto loc_82449998;
loc_824499BC:
	// stw r31,64(r27)
	PPC_STORE_U32(r27.u32 + 64, r31.u32);
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// stw r26,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r26.u32);
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
loc_824499CC:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r23,r23,4
	r23.s64 = r23.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x82449864
	if (cr6.lt) goto loc_82449864;
	// stw r22,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r22.u32);
loc_824499E4:
	// lis r11,-32188
	r11.s64 = -2109472768;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// addi r3,r11,-4136
	ctx.r3.s64 = r11.s64 + -4136;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82449d94
	if (cr6.eq) goto loc_82449D94;
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r22,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r22.u32);
	// mr r14,r21
	r14.u64 = r21.u64;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
loc_82449A14:
	// lwz r11,0(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 0);
	// lwz r10,20(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,24(r24)
	ctx.r8.u64 = PPC_LOAD_U32(r24.u32 + 24);
	// lwzx r17,r7,r10
	r17.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r10,48(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 48);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// lwz r11,72(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r16,r11,r8
	r16.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// bne cr6,0x82449cf4
	if (!cr6.eq) goto loc_82449CF4;
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// cmplw cr6,r9,r22
	cr6.compare<uint32_t>(ctx.r9.u32, r22.u32, xer);
	// bge cr6,0x82449cf4
	if (!cr6.lt) goto loc_82449CF4;
	// addi r15,r14,4
	r15.s64 = r14.s64 + 4;
loc_82449A50:
	// lwz r11,0(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 0);
	// lwz r10,20(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,64(r17)
	ctx.r8.u64 = PPC_LOAD_U32(r17.u32 + 64);
	// lwzx r20,r7,r10
	r20.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r10,64(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 64);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// bne cr6,0x82449cf4
	if (!cr6.eq) goto loc_82449CF4;
	// lwz r10,48(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 48);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82449cdc
	if (!cr6.eq) goto loc_82449CDC;
	// lwz r11,72(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 72);
	// lwz r10,72(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 72);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82449cdc
	if (cr6.eq) goto loc_82449CDC;
	// lwz r11,4(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 4);
	// lwz r8,4(r20)
	ctx.r8.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bne cr6,0x82449cdc
	if (!cr6.eq) goto loc_82449CDC;
	// lwz r11,20(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwz r8,20(r20)
	ctx.r8.u64 = PPC_LOAD_U32(r20.u32 + 20);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bne cr6,0x82449cdc
	if (!cr6.eq) goto loc_82449CDC;
	// lwz r11,24(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 24);
	// lwz r8,24(r20)
	ctx.r8.u64 = PPC_LOAD_U32(r20.u32 + 24);
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x82449cdc
	if (!cr6.eq) goto loc_82449CDC;
	// lwz r8,24(r24)
	ctx.r8.u64 = PPC_LOAD_U32(r24.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,0(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 0);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// xor r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 ^ r11.u64;
	// rlwinm. r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82449cdc
	if (!cr0.eq) goto loc_82449CDC;
	// lwz r10,4(r16)
	ctx.r10.u64 = PPC_LOAD_U32(r16.u32 + 4);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// divwu r18,r10,r11
	r18.u32 = ctx.r10.u32 / r11.u32;
	// twllei r11,0
	// bl 0x8243d178
	sub_8243D178(ctx, base);
	// lwz r21,24(r24)
	r21.u64 = PPC_LOAD_U32(r24.u32 + 24);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// li r19,0
	r19.s64 = 0;
loc_82449B00:
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x82449b10
	if (cr6.eq) goto loc_82449B10;
	// lwz r22,72(r20)
	r22.u64 = PPC_LOAD_U32(r20.u32 + 72);
	// b 0x82449b14
	goto loc_82449B14;
loc_82449B10:
	// lwz r22,72(r17)
	r22.u64 = PPC_LOAD_U32(r17.u32 + 72);
loc_82449B14:
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x82449b24
	if (cr6.eq) goto loc_82449B24;
	// lwz r11,72(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 72);
	// b 0x82449b28
	goto loc_82449B28;
loc_82449B24:
	// lwz r11,72(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 72);
loc_82449B28:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r22,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// li r29,0
	r29.s64 = 0;
	// lwzx r31,r11,r21
	r31.u64 = PPC_LOAD_U32(r11.u32 + r21.u32);
	// lwzx r27,r10,r21
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + r21.u32);
	// lwz r25,12(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r25,0
	cr0.compare<uint32_t>(r25.u32, 0, xer);
	// beq 0x82449bf4
	if (cr0.eq) goto loc_82449BF4;
	// lwz r23,20(r24)
	r23.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwz r26,16(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_82449B50:
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,84(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// ble cr6,0x82449bf4
	if (!cr6.gt) goto loc_82449BF4;
	// lwz r28,12(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x82449bd8
	if (cr0.eq) goto loc_82449BD8;
loc_82449B78:
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82449bc4
	if (cr6.eq) goto loc_82449BC4;
loc_82449B84:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8243f2b8
	sub_8243F2B8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// bl 0x8243f2b8
	sub_8243F2B8(ctx, base);
	// lwz r11,108(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// bne cr6,0x82449bc4
	if (!cr6.eq) goto loc_82449BC4;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r5,r18
	cr6.compare<uint32_t>(ctx.r5.u32, r18.u32, xer);
	// blt cr6,0x82449b84
	if (cr6.lt) goto loc_82449B84;
loc_82449BC4:
	// cmplw cr6,r5,r18
	cr6.compare<uint32_t>(ctx.r5.u32, r18.u32, xer);
	// beq cr6,0x82449bd8
	if (cr6.eq) goto loc_82449BD8;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x82449b78
	if (cr6.lt) goto loc_82449B78;
loc_82449BD8:
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// beq cr6,0x82449bf4
	if (cr6.eq) goto loc_82449BF4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82449b50
	if (cr6.lt) goto loc_82449B50;
loc_82449BF4:
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// bge cr6,0x82449c0c
	if (!cr6.lt) goto loc_82449C0C;
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// cmplwi cr6,r19,2
	cr6.compare<uint32_t>(r19.u32, 2, xer);
	// blt cr6,0x82449b00
	if (cr6.lt) goto loc_82449B00;
	// b 0x82449cd0
	goto loc_82449CD0;
loc_82449C0C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82449cc0
	if (!cr6.gt) goto loc_82449CC0;
	// li r28,0
	r28.s64 = 0;
loc_82449C20:
	// lwz r26,12(r27)
	r26.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// cmplwi r26,0
	cr0.compare<uint32_t>(r26.u32, 0, xer);
	// beq 0x82449c88
	if (cr0.eq) goto loc_82449C88;
loc_82449C30:
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82449c74
	if (cr6.eq) goto loc_82449C74;
loc_82449C3C:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8243f2b8
	sub_8243F2B8(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8243f2b8
	sub_8243F2B8(ctx, base);
	// cmplw cr6,r3,r25
	cr6.compare<uint32_t>(ctx.r3.u32, r25.u32, xer);
	// bne cr6,0x82449c74
	if (!cr6.eq) goto loc_82449C74;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r5,r18
	cr6.compare<uint32_t>(ctx.r5.u32, r18.u32, xer);
	// blt cr6,0x82449c3c
	if (cr6.lt) goto loc_82449C3C;
loc_82449C74:
	// cmplw cr6,r5,r18
	cr6.compare<uint32_t>(ctx.r5.u32, r18.u32, xer);
	// beq cr6,0x82449c88
	if (cr6.eq) goto loc_82449C88;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// blt cr6,0x82449c30
	if (cr6.lt) goto loc_82449C30;
loc_82449C88:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwz r8,20(r24)
	ctx.r8.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82449c20
	if (cr6.lt) goto loc_82449C20;
loc_82449CC0:
	// li r11,1
	r11.s64 = 1;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82449CD0:
	// lwz r21,92(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82449CDC:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r15,r15,4
	r15.s64 = r15.s64 + 4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// blt cr6,0x82449a50
	if (cr6.lt) goto loc_82449A50;
loc_82449CF4:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r14,r14,4
	r14.s64 = r14.s64 + 4;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// bne 0x82449a14
	if (!cr0.eq) goto loc_82449A14;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82449d94
	if (cr6.eq) goto loc_82449D94;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82449d80
	if (!cr6.gt) goto loc_82449D80;
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
	// li r8,0
	ctx.r8.s64 = 0;
loc_82449D34:
	// lwzx r10,r11,r8
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// b 0x82449d54
	goto loc_82449D54;
loc_82449D3C:
	// lwz r9,48(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// stw r11,48(r10)
	PPC_STORE_U32(ctx.r10.u32 + 48, r11.u32);
	// lwz r11,20(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 20);
loc_82449D54:
	// lwz r9,48(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r6,r9,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// bne cr6,0x82449d3c
	if (!cr6.eq) goto loc_82449D3C;
	// lwz r10,8(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x82449d34
	if (cr6.lt) goto loc_82449D34;
loc_82449D80:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// b 0x824497f4
	goto loc_824497F4;
loc_82449D94:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r31,r11,27,31,31
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82449DA0:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_82449DB8"))) PPC_WEAK_FUNC(sub_82449DB8);
PPC_FUNC_IMPL(__imp__sub_82449DB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r10,8(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// li r15,0
	r15.s64 = 0;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82449e10
	if (!cr6.gt) goto loc_82449E10;
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_82449DEC:
	// lwz r8,20(r17)
	ctx.r8.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r17)
	ctx.r9.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82449dec
	if (cr6.lt) goto loc_82449DEC;
loc_82449E10:
	// lwz r11,12(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 12);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// li r14,-1
	r14.s64 = -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r16,r15
	r16.u64 = r15.u64;
	// lfd f31,-31368(r10)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// mr r20,r14
	r20.u64 = r14.u64;
	// mr r21,r14
	r21.u64 = r14.u64;
	// mr r19,r15
	r19.u64 = r15.u64;
	// lfd f30,-31360(r11)
	f30.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// ble cr6,0x8244a100
	if (!cr6.gt) goto loc_8244A100;
	// mr r18,r15
	r18.u64 = r15.u64;
loc_82449E44:
	// lwz r11,24(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 24);
	// lwzx r31,r18,r11
	r31.u64 = PPC_LOAD_U32(r18.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244a0ec
	if (cr0.eq) goto loc_8244A0EC;
	// rlwinm r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244a0ec
	if (cr6.lt) goto loc_8244A0EC;
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8244a0ec
	if (cr6.gt) goto loc_8244A0EC;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// mr r24,r15
	r24.u64 = r15.u64;
	// divwu. r22,r10,r11
	r22.u32 = ctx.r10.u32 / r11.u32;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// twllei r11,0
	// beq 0x8244a0ec
	if (cr0.eq) goto loc_8244A0EC;
loc_82449E8C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r23,r15
	r23.u64 = r15.u64;
	// mr r26,r15
	r26.u64 = r15.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82449fbc
	if (cr0.eq) goto loc_82449FBC;
	// mr r25,r15
	r25.u64 = r15.u64;
loc_82449EA4:
	// mullw r11,r11,r24
	r11.s64 = int64_t(r11.s32) * int64_t(r24.s32);
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// add r9,r11,r26
	ctx.r9.u64 = r11.u64 + r26.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r8,r25,r8
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + ctx.r8.u32);
	// lwz r11,20(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r27,r8,r11
	r27.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwzx r30,r9,r10
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82449fa8
	if (cr0.eq) goto loc_82449FA8;
	// lwz r9,20(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r5,24(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x82449fa8
	if (cr6.eq) goto loc_82449FA8;
	// lwz r29,20(r17)
	r29.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwz r28,24(r17)
	r28.u64 = PPC_LOAD_U32(r17.u32 + 24);
loc_82449EF8:
	// rlwinm r6,r9,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r15
	r11.u64 = r15.u64;
	// lwzx r10,r6,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + r29.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r28
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r28.u32);
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82449f3c
	if (cr0.eq) goto loc_82449F3C;
	// lwz r7,16(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82449F20:
	// lwz r4,0(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplw cr6,r4,r9
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r9.u32, xer);
	// beq cr6,0x82449f3c
	if (cr6.eq) goto loc_82449F3C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82449f20
	if (cr6.lt) goto loc_82449F20;
loc_82449F3C:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// beq cr6,0x82449f70
	if (cr6.eq) goto loc_82449F70;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwzx r5,r11,r10
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8243f4f8
	sub_8243F4F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82449f84
	if (cr0.eq) goto loc_82449F84;
	// li r11,1
	r11.s64 = 1;
	// stw r11,64(r27)
	PPC_STORE_U32(r27.u32 + 64, r11.u32);
	// b 0x82449fa4
	goto loc_82449FA4;
loc_82449F70:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8243f4f8
	sub_8243F4F8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82449fa0
	if (!cr0.eq) goto loc_82449FA0;
loc_82449F84:
	// lwz r11,20(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82449ef8
	if (!cr6.eq) goto loc_82449EF8;
	// b 0x82449fa8
	goto loc_82449FA8;
loc_82449FA0:
	// stw r15,64(r27)
	PPC_STORE_U32(r27.u32 + 64, r15.u32);
loc_82449FA4:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
loc_82449FA8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x82449ea4
	if (cr6.lt) goto loc_82449EA4;
loc_82449FBC:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r23,r10
	cr6.compare<uint32_t>(r23.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244a0e0
	if (!cr6.eq) goto loc_8244A0E0;
	// mr r30,r15
	r30.u64 = r15.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8244a0e0
	if (cr6.eq) goto loc_8244A0E0;
	// mr r29,r15
	r29.u64 = r15.u64;
loc_82449FD8:
	// mullw r10,r10,r24
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(r24.s32);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + r30.u64;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,20(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwzx r9,r29,r9
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,64(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 64);
	// lwz r9,16(r17)
	ctx.r9.u64 = PPC_LOAD_U32(r17.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8244a07c
	if (cr6.eq) goto loc_8244A07C;
	// beq 0x8244a03c
	if (cr0.eq) goto loc_8244A03C;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// beq cr6,0x8244a0cc
	if (cr6.eq) goto loc_8244A0CC;
loc_8244A03C:
	// cmpwi cr6,r20,-1
	cr6.compare<int32_t>(r20.s32, -1, xer);
	// bne cr6,0x8244a060
	if (!cr6.eq) goto loc_8244A060;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r17)
	ctx.r4.u64 = PPC_LOAD_U32(r17.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r20,r3
	r20.u64 = ctx.r3.u64;
loc_8244A060:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r11,r24,r11
	r11.s64 = int64_t(r24.s32) * int64_t(r11.s32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r20,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r20.u32);
	// b 0x8244a0c8
	goto loc_8244A0C8;
loc_8244A07C:
	// beq 0x8244a08c
	if (cr0.eq) goto loc_8244A08C;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x8244a0cc
	if (cr6.eq) goto loc_8244A0CC;
loc_8244A08C:
	// cmpwi cr6,r21,-1
	cr6.compare<int32_t>(r21.s32, -1, xer);
	// bne cr6,0x8244a0b0
	if (!cr6.eq) goto loc_8244A0B0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r17)
	ctx.r4.u64 = PPC_LOAD_U32(r17.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
loc_8244A0B0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r11,r24,r11
	r11.s64 = int64_t(r24.s32) * int64_t(r11.s32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r21,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r21.u32);
loc_8244A0C8:
	// li r16,1
	r16.s64 = 1;
loc_8244A0CC:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r30,r10
	cr6.compare<uint32_t>(r30.u32, ctx.r10.u32, xer);
	// blt cr6,0x82449fd8
	if (cr6.lt) goto loc_82449FD8;
loc_8244A0E0:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// cmplw cr6,r24,r22
	cr6.compare<uint32_t>(r24.u32, r22.u32, xer);
	// blt cr6,0x82449e8c
	if (cr6.lt) goto loc_82449E8C;
loc_8244A0EC:
	// lwz r11,12(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 12);
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// addi r18,r18,4
	r18.s64 = r18.s64 + 4;
	// cmplw cr6,r19,r11
	cr6.compare<uint32_t>(r19.u32, r11.u32, xer);
	// blt cr6,0x82449e44
	if (cr6.lt) goto loc_82449E44;
loc_8244A100:
	// lwz r10,8(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// mr r25,r15
	r25.u64 = r15.u64;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244a13c
	if (!cr6.gt) goto loc_8244A13C;
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_8244A118:
	// lwz r8,20(r17)
	ctx.r8.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r17)
	ctx.r9.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244a118
	if (cr6.lt) goto loc_8244A118;
loc_8244A13C:
	// lwz r11,12(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 12);
	// mr r24,r15
	r24.u64 = r15.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244a6f0
	if (!cr6.gt) goto loc_8244A6F0;
loc_8244A14C:
	// lwz r11,24(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 24);
	// rlwinm r10,r24,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244a6d0
	if (cr0.eq) goto loc_8244A6D0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244a1f0
	if (!cr6.gt) goto loc_8244A1F0;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
loc_8244A178:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r6,20(r17)
	ctx.r6.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwzx r11,r5,r11
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r6
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// b 0x8244a1cc
	goto loc_8244A1CC;
loc_8244A198:
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r6,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwz r3,0(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r3,r3,0,24,24
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8244a1d4
	if (cr0.eq) goto loc_8244A1D4;
	// lfd f0,32(r7)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + 32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8244a364
	if (!cr6.eq) goto loc_8244A364;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x8244a36c
	if (cr6.eq) goto loc_8244A36C;
loc_8244A1C0:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
	// mr r11,r14
	r11.u64 = r14.u64;
loc_8244A1C8:
	// li r16,1
	r16.s64 = 1;
loc_8244A1CC:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244a198
	if (!cr6.eq) goto loc_8244A198;
loc_8244A1D4:
	// stw r11,20(r9)
	PPC_STORE_U32(ctx.r9.u32 + 20, r11.u32);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// stw r10,24(r9)
	PPC_STORE_U32(ctx.r9.u32 + 24, ctx.r10.u32);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x8244a178
	if (cr6.lt) goto loc_8244A178;
loc_8244A1F0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r9,4336
	ctx.r9.s64 = 284164096;
	// rlwinm r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244a598
	if (cr6.eq) goto loc_8244A598;
	// lis r9,4416
	ctx.r9.s64 = 289406976;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244a598
	if (cr6.eq) goto loc_8244A598;
	// lis r9,8304
	ctx.r9.s64 = 544210944;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244a404
	if (cr6.eq) goto loc_8244A404;
	// lis r9,8320
	ctx.r9.s64 = 545259520;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244a404
	if (cr6.eq) goto loc_8244A404;
	// rlwinm r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244a394
	if (cr6.lt) goto loc_8244A394;
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8244a394
	if (cr6.gt) goto loc_8244A394;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// mr r27,r15
	r27.u64 = r15.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// divwu r26,r10,r11
	r26.u32 = ctx.r10.u32 / r11.u32;
	// twllei r11,0
	// ble cr6,0x8244a2fc
	if (!cr6.gt) goto loc_8244A2FC;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// mr r8,r15
	ctx.r8.u64 = r15.u64;
loc_8244A270:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwzx r9,r8,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x8244a29c
	if (!cr6.eq) goto loc_8244A29C;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8244a2e8
	if (cr6.eq) goto loc_8244A2E8;
loc_8244A29C:
	// lwzx r9,r8,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// stwx r9,r6,r10
	PPC_STORE_U32(ctx.r6.u32 + ctx.r10.u32, ctx.r9.u32);
	// beq cr6,0x8244a2e0
	if (cr6.eq) goto loc_8244A2E0;
loc_8244A2B0:
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r9,r11,r9
	ctx.r9.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// add r5,r9,r7
	ctx.r5.u64 = ctx.r9.u64 + ctx.r7.u64;
	// add r9,r9,r27
	ctx.r9.u64 = ctx.r9.u64 + r27.u64;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// lwzx r5,r5,r10
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// stwx r5,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r5.u32);
	// blt cr6,0x8244a2b0
	if (cr6.lt) goto loc_8244A2B0;
loc_8244A2E0:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
loc_8244A2E8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x8244a270
	if (cr6.lt) goto loc_8244A270;
loc_8244A2FC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// beq cr6,0x8244a6d0
	if (cr6.eq) goto loc_8244A6D0;
	// mr r30,r15
	r30.u64 = r15.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8244a34c
	if (cr6.eq) goto loc_8244A34C;
	// rlwinm r28,r27,2,0,29
	r28.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r29,r15
	r29.u64 = r15.u64;
loc_8244A31C:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r10,r30,r10
	ctx.r10.s64 = int64_t(r30.s32) * int64_t(ctx.r10.s32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r29,r11
	ctx.r3.u64 = r29.u64 + r11.u64;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r29,r29,r28
	r29.u64 = r29.u64 + r28.u64;
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// blt cr6,0x8244a31c
	if (cr6.lt) goto loc_8244A31C;
loc_8244A34C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8244a380
	if (cr6.eq) goto loc_8244A380;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r11,r27
	r11.u64 = r27.u64;
	// rlwimi r11,r10,0,0,11
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 0) & 0xFFF00000) | (r11.u64 & 0xFFFFFFFF000FFFFF);
	// b 0x8244a384
	goto loc_8244A384;
loc_8244A364:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x8244a1c0
	if (cr6.eq) goto loc_8244A1C0;
loc_8244A36C:
	// lwz r11,20(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// b 0x8244a1c8
	goto loc_8244A1C8;
loc_8244A380:
	// mr r11,r15
	r11.u64 = r15.u64;
loc_8244A384:
	// mullw r10,r26,r27
	ctx.r10.s64 = int64_t(r26.s32) * int64_t(r27.s32);
	// stw r27,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r27.u32);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// b 0x8244a6c8
	goto loc_8244A6C8;
loc_8244A394:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244a6d0
	if (cr0.eq) goto loc_8244A6D0;
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8244a3f4
	if (cr6.eq) goto loc_8244A3F4;
	// lwz r8,20(r17)
	ctx.r8.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_8244A3B8:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r6,20(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// bne cr6,0x8244a3dc
	if (!cr6.eq) goto loc_8244A3DC;
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8244a3e0
	if (cr6.eq) goto loc_8244A3E0;
loc_8244A3DC:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
loc_8244A3E0:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8244a3b8
	if (!cr0.eq) goto loc_8244A3B8;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x8244a6d0
	if (!cr6.eq) goto loc_8244A6D0;
loc_8244A3F4:
	// stw r15,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r15.u32);
	// stw r15,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r15.u32);
	// stw r15,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r15.u32);
	// b 0x8244a6cc
	goto loc_8244A6CC;
loc_8244A404:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// mr r27,r15
	r27.u64 = r15.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// divwu r26,r10,r11
	r26.u32 = ctx.r10.u32 / r11.u32;
	// twllei r11,0
	// ble cr6,0x8244a544
	if (!cr6.gt) goto loc_8244A544;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
loc_8244A430:
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwzx r10,r5,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r6.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,20(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244a45c
	if (!cr6.eq) goto loc_8244A45C;
	// lwz r10,24(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8244a530
	if (cr6.eq) goto loc_8244A530;
loc_8244A45C:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r10,r4,r10
	ctx.r10.u64 = ctx.r4.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r8,r5,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r30,20(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// bne cr6,0x8244a4b0
	if (!cr6.eq) goto loc_8244A4B0;
	// lwz r30,24(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x8244a4b0
	if (!cr6.eq) goto loc_8244A4B0;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,136(r17)
	ctx.r8.u64 = PPC_LOAD_U32(r17.u32 + 136);
	// li r25,1
	r25.s64 = 1;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,48(r7)
	PPC_STORE_U32(ctx.r7.u32 + 48, ctx.r10.u32);
	// b 0x8244a530
	goto loc_8244A530;
loc_8244A4B0:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244a4e4
	if (!cr6.eq) goto loc_8244A4E4;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8244a4e4
	if (!cr6.eq) goto loc_8244A4E4;
	// lwz r11,136(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 136);
	// li r25,1
	r25.s64 = 1;
	// stw r11,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, r11.u32);
	// stw r8,48(r7)
	PPC_STORE_U32(ctx.r7.u32 + 48, ctx.r8.u32);
	// b 0x8244a530
	goto loc_8244A530;
loc_8244A4E4:
	// lwzx r10,r5,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r6.u32);
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// stwx r10,r3,r6
	PPC_STORE_U32(ctx.r3.u32 + ctx.r6.u32, ctx.r10.u32);
	// beq cr6,0x8244a528
	if (cr6.eq) goto loc_8244A528;
loc_8244A4F8:
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r9,r11,r9
	ctx.r9.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// add r8,r9,r4
	ctx.r8.u64 = ctx.r9.u64 + ctx.r4.u64;
	// add r9,r9,r27
	ctx.r9.u64 = ctx.r9.u64 + r27.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// stwx r8,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r8.u32);
	// blt cr6,0x8244a4f8
	if (cr6.lt) goto loc_8244A4F8;
loc_8244A528:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
loc_8244A530:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x8244a430
	if (cr6.lt) goto loc_8244A430;
loc_8244A544:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// beq cr6,0x8244a6d0
	if (cr6.eq) goto loc_8244A6D0;
	// mr r30,r15
	r30.u64 = r15.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8244a34c
	if (cr6.eq) goto loc_8244A34C;
	// rlwinm r28,r27,2,0,29
	r28.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r29,r15
	r29.u64 = r15.u64;
loc_8244A564:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r10,r30,r10
	ctx.r10.s64 = int64_t(r30.s32) * int64_t(ctx.r10.s32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r29,r11
	ctx.r3.u64 = r29.u64 + r11.u64;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r29,r29,r28
	r29.u64 = r29.u64 + r28.u64;
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// blt cr6,0x8244a564
	if (cr6.lt) goto loc_8244A564;
	// b 0x8244a34c
	goto loc_8244A34C;
loc_8244A598:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r7,r15
	ctx.r7.u64 = r15.u64;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244a69c
	if (!cr6.gt) goto loc_8244A69C;
	// mr r8,r15
	ctx.r8.u64 = r15.u64;
	// mr r11,r15
	r11.u64 = r15.u64;
loc_8244A5B4:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,20(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 20);
	// lwz r5,16(r17)
	ctx.r5.u64 = PPC_LOAD_U32(r17.u32 + 16);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r10,r4,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r10.u32);
	// lwz r4,4(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r4,r5
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm. r5,r5,0,23,23
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8244a62c
	if (cr0.eq) goto loc_8244A62C;
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// bne cr6,0x8244a62c
	if (!cr6.eq) goto loc_8244A62C;
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// ori r5,r5,128
	ctx.r5.u64 = ctx.r5.u64 | 128;
	// stw r5,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r5.u32);
	// lfd f0,32(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x8244a620
	if (cr6.eq) goto loc_8244A620;
	// fmr f0,f30
	f0.f64 = f30.f64;
	// b 0x8244a624
	goto loc_8244A624;
loc_8244A620:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64;
loc_8244A624:
	// stfd f0,32(r10)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + 32, f0.u64);
	// b 0x8244a65c
	goto loc_8244A65C;
loc_8244A62C:
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r5,r9,0,29,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8244a650
	if (cr0.eq) goto loc_8244A650;
	// rlwinm. r9,r9,0,28,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8244a650
	if (cr0.eq) goto loc_8244A650;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stfd f31,32(r10)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + 32, f31.u64);
	// ori r9,r9,128
	ctx.r9.u64 = ctx.r9.u64 | 128;
	// b 0x8244a658
	goto loc_8244A658;
loc_8244A650:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,0,25,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
loc_8244A658:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
loc_8244A65C:
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244a688
	if (!cr0.eq) goto loc_8244A688;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stwx r9,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stwx r9,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
loc_8244A688:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244a5b4
	if (cr6.lt) goto loc_8244A5B4;
loc_8244A69C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// beq cr6,0x8244a6d0
	if (cr6.eq) goto loc_8244A6D0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8244a6bc
	if (cr6.eq) goto loc_8244A6BC;
	// clrlwi r11,r7,12
	r11.u64 = ctx.r7.u32 & 0xFFFFF;
	// oris r11,r11,4336
	r11.u64 = r11.u64 | 284164096;
	// b 0x8244a6c0
	goto loc_8244A6C0;
loc_8244A6BC:
	// mr r11,r15
	r11.u64 = r15.u64;
loc_8244A6C0:
	// stw r7,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r7.u32);
	// stw r7,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r7.u32);
loc_8244A6C8:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_8244A6CC:
	// li r16,1
	r16.s64 = 1;
loc_8244A6D0:
	// lwz r11,12(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 12);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x8244a14c
	if (cr6.lt) goto loc_8244A14C;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x8244a6f0
	if (cr6.eq) goto loc_8244A6F0;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
loc_8244A6F0:
	// cntlzw r11,r16
	r11.u64 = r16.u32 == 0 ? 32 : __builtin_clz(r16.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_8244A708"))) PPC_WEAK_FUNC(sub_8244A708);
PPC_FUNC_IMPL(__imp__sub_8244A708) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc4
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r16,0
	r16.s64 = 0;
	// li r22,-1
	r22.s64 = -1;
	// mr r17,r16
	r17.u64 = r16.u64;
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r15,1
	r15.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244a7a4
	if (!cr6.gt) goto loc_8244A7A4;
	// mr r9,r16
	ctx.r9.u64 = r16.u64;
loc_8244A73C:
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r7,20(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// stw r6,64(r11)
	PPC_STORE_U32(r11.u32 + 64, ctx.r6.u32);
	// stw r7,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r7.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r7,r10,0,27,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8244a778
	if (cr0.eq) goto loc_8244A778;
	// stw r15,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r15.u32);
	// b 0x8244a78c
	goto loc_8244A78C;
loc_8244A778:
	// lis r12,1
	r12.s64 = 65536;
	// ori r12,r12,4136
	r12.u64 = r12.u64 | 4136;
	// and. r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 & r12.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244a790
	if (!cr0.eq) goto loc_8244A790;
	// stw r16,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r16.u32);
loc_8244A78C:
	// stw r22,20(r11)
	PPC_STORE_U32(r11.u32 + 20, r22.u32);
loc_8244A790:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244a73c
	if (cr6.lt) goto loc_8244A73C;
loc_8244A7A4:
	// lwz r24,12(r28)
	r24.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// lis r21,8304
	r21.s64 = 544210944;
	// lis r18,8320
	r18.s64 = 545259520;
	// lis r19,4432
	r19.s64 = 290455552;
	// lis r20,4384
	r20.s64 = 287309824;
	// cmplwi r24,0
	cr0.compare<uint32_t>(r24.u32, 0, xer);
	// beq 0x8244abbc
	if (cr0.eq) goto loc_8244ABBC;
	// rlwinm r23,r24,2,0,29
	r23.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244A7C4:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// addi r23,r23,-4
	r23.s64 = r23.s64 + -4;
	// addi r24,r24,-1
	r24.s64 = r24.s64 + -1;
	// lwzx r31,r23,r11
	r31.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244abb4
	if (cr0.eq) goto loc_8244ABB4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r15
	r29.u64 = r15.u64;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x8244a830
	if (!cr6.gt) goto loc_8244A830;
	// li r30,4
	r30.s64 = 4;
loc_8244A7F4:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r9,r11,r30
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r9,r10
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x82443560
	sub_82443560(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8244a7f4
	if (cr6.lt) goto loc_8244A7F4;
loc_8244A830:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x8244a8a8
	if (!cr6.gt) goto loc_8244A8A8;
	// li r11,4
	r11.s64 = 4;
loc_8244A844:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r8,20(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// stw r8,20(r9)
	PPC_STORE_U32(ctx.r9.u32 + 20, ctx.r8.u32);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r8,24(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	// stw r8,24(r9)
	PPC_STORE_U32(ctx.r9.u32 + 24, ctx.r8.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244a844
	if (cr6.lt) goto loc_8244A844;
loc_8244A8A8:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// beq cr6,0x8244ab1c
	if (cr6.eq) goto loc_8244AB1C;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// beq cr6,0x8244ab1c
	if (cr6.eq) goto loc_8244AB1C;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x8244ab1c
	if (cr6.eq) goto loc_8244AB1C;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// bne cr6,0x8244a984
	if (!cr6.eq) goto loc_8244A984;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r27,r16
	r27.u64 = r16.u64;
	// divwu r25,r11,r10
	r25.u32 = r11.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// ble cr6,0x8244abb4
	if (!cr6.gt) goto loc_8244ABB4;
loc_8244A8F0:
	// mr r26,r16
	r26.u64 = r16.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8244a970
	if (cr6.eq) goto loc_8244A970;
loc_8244A8FC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r11,r26,r11
	r11.s64 = int64_t(r26.s32) * int64_t(r11.s32);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244a964
	if (cr6.eq) goto loc_8244A964;
	// rlwinm r29,r27,2,0,29
	r29.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244A920:
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// lwzx r4,r30,r10
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r11,r10
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x82443560
	sub_82443560(ctx, base);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244a920
	if (!cr6.eq) goto loc_8244A920;
loc_8244A964:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// blt cr6,0x8244a8fc
	if (cr6.lt) goto loc_8244A8FC;
loc_8244A970:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x8244a8f0
	if (cr6.lt) goto loc_8244A8F0;
	// b 0x8244abb4
	goto loc_8244ABB4;
loc_8244A984:
	// rlwinm r11,r10,0,0,3
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF0000000;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244aa48
	if (cr6.lt) goto loc_8244AA48;
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8244aa48
	if (cr6.gt) goto loc_8244AA48;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r27,r16
	r27.u64 = r16.u64;
	// divwu r25,r11,r10
	r25.u32 = r11.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// ble cr6,0x8244abb4
	if (!cr6.gt) goto loc_8244ABB4;
loc_8244A9C0:
	// mr r26,r16
	r26.u64 = r16.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8244aa34
	if (cr6.eq) goto loc_8244AA34;
loc_8244A9CC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r11,r26,r11
	r11.s64 = int64_t(r26.s32) * int64_t(r11.s32);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244aa28
	if (cr6.eq) goto loc_8244AA28;
	// rlwinm r29,r27,2,0,29
	r29.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244A9F0:
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// lwzx r4,r30,r10
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r11,r10
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x82443560
	sub_82443560(ctx, base);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244a9f0
	if (!cr6.eq) goto loc_8244A9F0;
loc_8244AA28:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// blt cr6,0x8244a9cc
	if (cr6.lt) goto loc_8244A9CC;
loc_8244AA34:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x8244a9c0
	if (cr6.lt) goto loc_8244A9C0;
	// b 0x8244abb4
	goto loc_8244ABB4;
loc_8244AA48:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// beq cr6,0x8244aac4
	if (cr6.eq) goto loc_8244AAC4;
	// mr r27,r16
	r27.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244abb4
	if (!cr6.gt) goto loc_8244ABB4;
	// mr r29,r16
	r29.u64 = r16.u64;
loc_8244AA68:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// b 0x8244aaa4
	goto loc_8244AAA4;
loc_8244AA74:
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwzx r4,r30,r10
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r11,r10
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x82443560
	sub_82443560(ctx, base);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r11,r11,r30
	r11.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_8244AAA4:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244aa74
	if (!cr6.eq) goto loc_8244AA74;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x8244aa68
	if (cr6.lt) goto loc_8244AA68;
	// b 0x8244abb4
	goto loc_8244ABB4;
loc_8244AAC4:
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244abb4
	if (!cr6.gt) goto loc_8244ABB4;
	// mr r11,r16
	r11.u64 = r16.u64;
loc_8244AAD4:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stw r22,20(r9)
	PPC_STORE_U32(ctx.r9.u32 + 20, r22.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stw r15,24(r9)
	PPC_STORE_U32(ctx.r9.u32 + 24, r15.u32);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244aad4
	if (cr6.lt) goto loc_8244AAD4;
	// b 0x8244abb4
	goto loc_8244ABB4;
loc_8244AB1C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r16
	r29.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244abb4
	if (!cr6.gt) goto loc_8244ABB4;
	// mr r30,r16
	r30.u64 = r16.u64;
loc_8244AB30:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r4,r9,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r10,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x82443560
	sub_82443560(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r5,r9,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x82443560
	sub_82443560(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8244ab30
	if (cr6.lt) goto loc_8244AB30;
loc_8244ABB4:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x8244a7c4
	if (!cr6.eq) goto loc_8244A7C4;
loc_8244ABBC:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r29,r16
	r29.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244ae3c
	if (!cr6.gt) goto loc_8244AE3C;
	// mr r30,r16
	r30.u64 = r16.u64;
loc_8244ABD8:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwzx r31,r30,r11
	r31.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244ae28
	if (cr0.eq) goto loc_8244AE28;
	// lis r10,4336
	ctx.r10.s64 = 284164096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// lis r10,4368
	ctx.r10.s64 = 286261248;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// lis r10,4400
	ctx.r10.s64 = 288358400;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// lis r10,4416
	ctx.r10.s64 = 289406976;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// lis r10,8336
	ctx.r10.s64 = 546308096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x8244ae28
	if (cr6.eq) goto loc_8244AE28;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244ae28
	if (!cr0.eq) goto loc_8244AE28;
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244acb4
	if (cr6.eq) goto loc_8244ACB4;
loc_8244AC90:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244ac90
	if (!cr6.eq) goto loc_8244AC90;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8244acb4
	if (cr6.eq) goto loc_8244ACB4;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
loc_8244ACB4:
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// b 0x8244acfc
	goto loc_8244ACFC;
loc_8244ACBC:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244acf8
	if (cr6.eq) goto loc_8244ACF8;
loc_8244ACD4:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244acd4
	if (!cr6.eq) goto loc_8244ACD4;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// bge cr6,0x8244acf8
	if (!cr6.lt) goto loc_8244ACF8;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
loc_8244ACF8:
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
loc_8244ACFC:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244acbc
	if (!cr6.eq) goto loc_8244ACBC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244ad74
	if (cr0.eq) goto loc_8244AD74;
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
loc_8244AD18:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// b 0x8244ad60
	goto loc_8244AD60;
loc_8244AD20:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244ad5c
	if (cr6.eq) goto loc_8244AD5C;
loc_8244AD38:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244ad38
	if (!cr6.eq) goto loc_8244AD38;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// bge cr6,0x8244ad5c
	if (!cr6.lt) goto loc_8244AD5C;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
loc_8244AD5C:
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
loc_8244AD60:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244ad20
	if (!cr6.eq) goto loc_8244AD20;
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x8244ad18
	if (!cr0.eq) goto loc_8244AD18;
loc_8244AD74:
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplw cr6,r3,r5
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r5.u32, xer);
	// ble cr6,0x8244ae28
	if (!cr6.gt) goto loc_8244AE28;
	// subf r7,r5,r3
	ctx.r7.s64 = ctx.r3.s64 - ctx.r5.s64;
loc_8244AD84:
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244ae14
	if (cr0.eq) goto loc_8244AE14;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244ae14
	if (!cr6.gt) goto loc_8244AE14;
	// mr r11,r16
	r11.u64 = r16.u64;
loc_8244ADC0:
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,20(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r6,r11,r6
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwzx r5,r9,r8
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r6,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r6,24(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// stw r6,24(r9)
	PPC_STORE_U32(ctx.r9.u32 + 24, ctx.r6.u32);
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,20(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r6,r11,r6
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwzx r5,r9,r8
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r6,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r6,20(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 20);
	// stw r6,20(r9)
	PPC_STORE_U32(ctx.r9.u32 + 20, ctx.r6.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244adc0
	if (cr6.lt) goto loc_8244ADC0;
loc_8244AE14:
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bne 0x8244ad84
	if (!cr0.eq) goto loc_8244AD84;
loc_8244AE28:
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8244abd8
	if (cr6.lt) goto loc_8244ABD8;
loc_8244AE3C:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244ae8c
	if (cr0.eq) goto loc_8244AE8C;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
loc_8244AE50:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,48(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// lwz r7,20(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x8244ae74
	if (!cr6.eq) goto loc_8244AE74;
	// lwz r8,64(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x8244ae78
	if (cr6.eq) goto loc_8244AE78;
loc_8244AE74:
	// mr r17,r15
	r17.u64 = r15.u64;
loc_8244AE78:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244ae50
	if (!cr0.eq) goto loc_8244AE50;
	// cmpwi cr6,r17,0
	cr6.compare<int32_t>(r17.s32, 0, xer);
	// bne cr6,0x8244aea4
	if (!cr6.eq) goto loc_8244AEA4;
loc_8244AE8C:
	// mr r31,r15
	r31.u64 = r15.u64;
loc_8244AE90:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// b 0x8239bd14
	return;
loc_8244AEA4:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
loc_8244AEAC:
	// lwz r31,12(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// mr r5,r15
	ctx.r5.u64 = r15.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x8244afd0
	if (cr0.eq) goto loc_8244AFD0;
	// rlwinm r30,r31,2,0,29
	r30.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244AEC0:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// lwzx r6,r11,r30
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244afc0
	if (cr0.eq) goto loc_8244AFC0;
	// lwz r11,12(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244af30
	if (cr0.eq) goto loc_8244AF30;
	// lwz r9,20(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r8,16(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
loc_8244AEF4:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244af24
	if (cr6.eq) goto loc_8244AF24;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// bge cr6,0x8244af24
	if (!cr6.lt) goto loc_8244AF24;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
loc_8244AF24:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x8244aef4
	if (!cr0.eq) goto loc_8244AEF4;
loc_8244AF30:
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244af78
	if (cr0.eq) goto loc_8244AF78;
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// lwz r10,8(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
loc_8244AF48:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244af6c
	if (cr6.eq) goto loc_8244AF6C;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bge cr6,0x8244af6c
	if (!cr6.lt) goto loc_8244AF6C;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
loc_8244AF6C:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244af48
	if (!cr0.eq) goto loc_8244AF48;
loc_8244AF78:
	// cmplw cr6,r31,r7
	cr6.compare<uint32_t>(r31.u32, ctx.r7.u32, xer);
	// beq cr6,0x8244afc0
	if (cr6.eq) goto loc_8244AFC0;
	// bge cr6,0x8244afa8
	if (!cr6.lt) goto loc_8244AFA8;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// subf r11,r31,r7
	r11.s64 = ctx.r7.s64 - r31.s64;
loc_8244AF8C:
	// lwz r9,24(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// bne 0x8244af8c
	if (!cr0.eq) goto loc_8244AF8C;
loc_8244AFA8:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stwx r6,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r6.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
loc_8244AFC0:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8244aec0
	if (!cr6.eq) goto loc_8244AEC0;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x8244aeac
	if (cr6.eq) goto loc_8244AEAC;
loc_8244AFD0:
	// mr r31,r16
	r31.u64 = r16.u64;
	// b 0x8244ae90
	goto loc_8244AE90;
}

__attribute__((alias("__imp__sub_8244AFD8"))) PPC_WEAK_FUNC(sub_8244AFD8);
PPC_FUNC_IMPL(__imp__sub_8244AFD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bccc
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r11,108(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244affc
	if (cr0.eq) goto loc_8244AFFC;
loc_8244AFF4:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8244b3c8
	goto loc_8244B3C8;
loc_8244AFFC:
	// li r19,0
	r19.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r20,r19
	r20.u64 = r19.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r18,12(r28)
	r18.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi r18,0
	cr0.compare<uint32_t>(r18.u32, 0, xer);
	// beq 0x8244aff4
	if (cr0.eq) goto loc_8244AFF4;
	// rlwinm r17,r18,2,0,29
	r17.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244B01C:
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// addi r17,r17,-4
	r17.s64 = r17.s64 + -4;
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// addi r18,r18,-1
	r18.s64 = r18.s64 + -1;
	// lwzx r30,r17,r11
	r30.u64 = PPC_LOAD_U32(r17.u32 + r11.u32);
	// lwz r6,0(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r6,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244b04c
	if (cr6.eq) goto loc_8244B04C;
	// lis r10,8304
	ctx.r10.s64 = 544210944;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244b3b4
	if (!cr6.eq) goto loc_8244B3B4;
loc_8244B04C:
	// lwz r7,12(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r10,r19
	ctx.r10.u64 = r19.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x8244b0a0
	if (cr0.eq) goto loc_8244B0A0;
	// lwz r9,20(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r8,16(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
loc_8244B068:
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r8
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm. r5,r5,0,26,26
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8244b0a0
	if (cr0.eq) goto loc_8244B0A0;
	// lwz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// blt cr6,0x8244b068
	if (cr6.lt) goto loc_8244B068;
loc_8244B0A0:
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244b3b4
	if (cr6.lt) goto loc_8244B3B4;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r10,r19
	ctx.r10.u64 = r19.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x8244b0fc
	if (cr0.eq) goto loc_8244B0FC;
	// lwz r9,20(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r8,16(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
loc_8244B0C4:
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r5,r8
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm. r5,r5,0,30,30
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8244b0fc
	if (cr0.eq) goto loc_8244B0FC;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// blt cr6,0x8244b0c4
	if (cr6.lt) goto loc_8244B0C4;
loc_8244B0FC:
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244b3b4
	if (cr6.lt) goto loc_8244B3B4;
	// clrlwi r22,r6,12
	r22.u64 = ctx.r6.u32 & 0xFFFFF;
	// mr r24,r19
	r24.u64 = r19.u64;
	// divwu. r21,r7,r22
	r21.u32 = ctx.r7.u32 / r22.u32;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// twllei r22,0
	// beq 0x8244b2ac
	if (cr0.eq) goto loc_8244B2AC;
	// mr r25,r19
	r25.u64 = r19.u64;
	// rlwinm r23,r22,2,0,29
	r23.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244B120:
	// mr r26,r19
	r26.u64 = r19.u64;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x8244b294
	if (cr6.eq) goto loc_8244B294;
	// mr r27,r19
	r27.u64 = r19.u64;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_8244B134:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r9,24(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r9
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d0e8
	sub_8243D0E8(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r10,24640
	ctx.r10.s64 = 1614807040;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244b190
	if (cr6.eq) goto loc_8244B190;
	// lis r10,24720
	ctx.r10.s64 = 1620049920;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244b190
	if (cr6.eq) goto loc_8244B190;
	// lis r10,24800
	ctx.r10.s64 = 1625292800;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244b194
	if (!cr6.eq) goto loc_8244B194;
loc_8244B190:
	// li r7,1
	ctx.r7.s64 = 1;
loc_8244B194:
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r8,24(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_8244B1C8:
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x8244b1d8
	if (!cr6.eq) goto loc_8244B1D8;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// beq cr6,0x8244b1fc
	if (cr6.eq) goto loc_8244B1FC;
loc_8244B1D8:
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244b1f8
	if (cr6.eq) goto loc_8244B1F8;
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,24(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// b 0x8244b1c8
	goto loc_8244B1C8;
loc_8244B1F8:
	// li r7,1
	ctx.r7.s64 = 1;
loc_8244B1FC:
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne cr6,0x8244b28c
	if (!cr6.eq) goto loc_8244B28C;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r11,r19
	r11.u64 = r19.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x8244b270
	if (cr0.eq) goto loc_8244B270;
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_8244B21C:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r5,92(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 92);
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// bgt cr6,0x8244b270
	if (cr6.gt) goto loc_8244B270;
	// lwz r10,84(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r10,r18
	cr6.compare<uint32_t>(ctx.r10.u32, r18.u32, xer);
	// bne cr6,0x8244b270
	if (!cr6.eq) goto loc_8244B270;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8244b260
	if (cr6.eq) goto loc_8244B260;
	// lwzx r10,r27,r6
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + ctx.r6.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244b270
	if (!cr6.eq) goto loc_8244B270;
loc_8244B260:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244b21c
	if (cr6.lt) goto loc_8244B21C;
loc_8244B270:
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244b28c
	if (cr6.lt) goto loc_8244B28C;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r26,r22
	cr6.compare<uint32_t>(r26.u32, r22.u32, xer);
	// blt cr6,0x8244b134
	if (cr6.lt) goto loc_8244B134;
loc_8244B28C:
	// cmplw cr6,r26,r22
	cr6.compare<uint32_t>(r26.u32, r22.u32, xer);
	// blt cr6,0x8244b2a4
	if (cr6.lt) goto loc_8244B2A4;
loc_8244B294:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// add r25,r23,r25
	r25.u64 = r23.u64 + r25.u64;
	// cmplw cr6,r24,r21
	cr6.compare<uint32_t>(r24.u32, r21.u32, xer);
	// blt cr6,0x8244b120
	if (cr6.lt) goto loc_8244B120;
loc_8244B2A4:
	// cmplw cr6,r24,r21
	cr6.compare<uint32_t>(r24.u32, r21.u32, xer);
	// blt cr6,0x8244b3b4
	if (cr6.lt) goto loc_8244B3B4;
loc_8244B2AC:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r31,r19
	r31.u64 = r19.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b3a4
	if (!cr6.gt) goto loc_8244B3A4;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
loc_8244B2C0:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// beq cr6,0x8244b388
	if (cr6.eq) goto loc_8244B388;
	// rlwinm r3,r22,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
loc_8244B2E8:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r9,20(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,0,4,6
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xE000000;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r9,0,7,3
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// rlwinm r9,r9,0,4,6
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// ble cr6,0x8244b320
	if (!cr6.gt) goto loc_8244B320;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_8244B320:
	// or r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 | ctx.r9.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r9,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r9.u32);
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// stw r9,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r9.u32);
	// lwz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8244b364
	if (!cr6.eq) goto loc_8244B364;
	// lwz r9,96(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 96);
	// stw r9,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r9.u32);
	// lwz r9,100(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 100);
	// stw r9,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r9.u32);
loc_8244B364:
	// lwz r9,104(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 104);
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// add r6,r6,r3
	ctx.r6.u64 = ctx.r6.u64 + ctx.r3.u64;
	// stw r9,104(r11)
	PPC_STORE_U32(r11.u32 + 104, ctx.r9.u32);
	// lwz r9,108(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// stw r9,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r9.u32);
	// lwz r9,112(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 112);
	// stw r9,112(r11)
	PPC_STORE_U32(r11.u32 + 112, ctx.r9.u32);
	// bne 0x8244b2e8
	if (!cr0.eq) goto loc_8244B2E8;
loc_8244B388:
	// lwz r11,116(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 116);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x8244b2c0
	if (cr6.lt) goto loc_8244B2C0;
loc_8244B3A4:
	// li r20,1
	r20.s64 = 1;
	// stw r19,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r19.u32);
	// stw r19,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r19.u32);
	// stw r19,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r19.u32);
loc_8244B3B4:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// bne cr6,0x8244b01c
	if (!cr6.eq) goto loc_8244B01C;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x8244aff4
	if (cr6.eq) goto loc_8244AFF4;
	// li r3,0
	ctx.r3.s64 = 0;
loc_8244B3C8:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8239bd1c
	return;
}

__attribute__((alias("__imp__sub_8244B3D0"))) PPC_WEAK_FUNC(sub_8244B3D0);
PPC_FUNC_IMPL(__imp__sub_8244B3D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b43c
	if (!cr6.gt) goto loc_8244B43C;
	// li r9,0
	ctx.r9.s64 = 0;
loc_8244B3FC:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r7,r10,0,21,21
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8244b428
	if (cr0.eq) goto loc_8244B428;
	// lwz r7,40(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x8244b428
	if (!cr6.eq) goto loc_8244B428;
	// rlwinm r10,r10,0,22,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFBFF;
	// li r30,1
	r30.s64 = 1;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_8244B428:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244b3fc
	if (cr6.lt) goto loc_8244B3FC;
loc_8244B43C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b4f8
	if (!cr6.gt) goto loc_8244B4F8;
	// li r8,0
	ctx.r8.s64 = 0;
loc_8244B454:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r10,84(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244b4ac
	if (!cr6.eq) goto loc_8244B4AC;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r9,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244b498
	if (!cr0.eq) goto loc_8244B498;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r5,r10,0,22,23
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x300;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8244b4b8
	if (cr0.eq) goto loc_8244B4B8;
	// rlwinm. r10,r10,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244b4b8
	if (cr0.eq) goto loc_8244B4B8;
loc_8244B498:
	// oris r10,r9,4096
	ctx.r10.u64 = ctx.r9.u64 | 268435456;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r10.u32);
	// b 0x8244b4b8
	goto loc_8244B4B8;
loc_8244B4AC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,4,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFEFFFFFFF;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_8244B4B8:
	// lwz r10,84(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 84);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244b4d8
	if (!cr6.eq) goto loc_8244B4D8;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244b4d8
	if (!cr6.eq) goto loc_8244B4D8;
	// li r10,-1
	ctx.r10.s64 = -1;
	// b 0x8244b4e0
	goto loc_8244B4E0;
loc_8244B4D8:
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
loc_8244B4E0:
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x8244b454
	if (cr6.lt) goto loc_8244B454;
loc_8244B4F8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bne cr6,0x8244b510
	if (!cr6.eq) goto loc_8244B510;
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x8244b5b0
	goto loc_8244B5B0;
loc_8244B510:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r29,0
	r29.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b588
	if (!cr6.gt) goto loc_8244B588;
	// li r27,0
	r27.s64 = 0;
	// li r28,0
	r28.s64 = 0;
loc_8244B534:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r30,r28,r11
	r30.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// lwz r10,84(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 84);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244b568
	if (!cr6.eq) goto loc_8244B568;
	// lwz r10,72(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244b568
	if (!cr6.eq) goto loc_8244B568;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243def8
	sub_8243DEF8(ctx, base);
	// b 0x8244b574
	goto loc_8244B574;
loc_8244B568:
	// stwx r30,r27,r11
	PPC_STORE_U32(r27.u32 + r11.u32, r30.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
loc_8244B574:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x8244b534
	if (cr6.lt) goto loc_8244B534;
loc_8244B588:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r4,0
	ctx.r4.s64 = 0;
	// subf r9,r29,r9
	ctx.r9.s64 = ctx.r9.s64 - r29.s64;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r29,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r29.u32);
loc_8244B5B0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8244B5B8"))) PPC_WEAK_FUNC(sub_8244B5B8);
PPC_FUNC_IMPL(__imp__sub_8244B5B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b64c
	if (!cr6.gt) goto loc_8244B64C;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8244B5E0:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r8,0,27,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFFDF;
	// lwzx r8,r5,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r9,4(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r5,r9,0,27,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8244b620
	if (cr0.eq) goto loc_8244B620;
	// rlwinm. r9,r9,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8244b620
	if (!cr0.eq) goto loc_8244B620;
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_8244B620:
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r10,r10,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244b638
	if (cr0.eq) goto loc_8244B638;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_8244B638:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x8244b5e0
	if (cr6.lt) goto loc_8244B5E0;
loc_8244B64C:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b944
	if (!cr6.gt) goto loc_8244B944;
	// li r27,0
	r27.s64 = 0;
loc_8244B660:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwzx r8,r27,r11
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm. r11,r10,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244b930
	if (cr0.eq) goto loc_8244B930;
	// lis r9,20496
	ctx.r9.s64 = 1343225856;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244b8e8
	if (cr6.eq) goto loc_8244B8E8;
	// lis r9,4352
	ctx.r9.s64 = 285212672;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244b8e8
	if (cr6.eq) goto loc_8244B8E8;
	// lis r9,4384
	ctx.r9.s64 = 287309824;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244b8e8
	if (cr6.eq) goto loc_8244B8E8;
	// rlwinm r10,r10,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF0000000;
	// lis r9,24576
	ctx.r9.s64 = 1610612736;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244b8e8
	if (cr6.eq) goto loc_8244B8E8;
	// lis r10,4336
	ctx.r10.s64 = 284164096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244b89c
	if (cr6.eq) goto loc_8244B89C;
	// lis r10,4368
	ctx.r10.s64 = 286261248;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244b89c
	if (cr6.eq) goto loc_8244B89C;
	// lis r10,4416
	ctx.r10.s64 = 289406976;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244b89c
	if (cr6.eq) goto loc_8244B89C;
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b758
	if (!cr6.gt) goto loc_8244B758;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8244B6E0:
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244b744
	if (cr0.eq) goto loc_8244B744;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x8243f338
	sub_8243F338(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8244b744
	if (cr0.eq) goto loc_8244B744;
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_8244B744:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x8244b6e0
	if (cr6.lt) goto loc_8244B6E0;
loc_8244B758:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// rlwinm r11,r10,0,0,3
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244b814
	if (cr6.lt) goto loc_8244B814;
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8244b814
	if (cr6.gt) goto loc_8244B814;
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// clrlwi r10,r10,12
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFF;
	// lwz r9,4(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// li r29,0
	r29.s64 = 0;
	// twllei r10,0
	// divwu r28,r9,r10
	r28.u32 = ctx.r9.u32 / ctx.r10.u32;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244b930
	if (cr0.eq) goto loc_8244B930;
	// li r6,0
	ctx.r6.s64 = 0;
loc_8244B79C:
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8244b7fc
	if (cr6.eq) goto loc_8244B7FC;
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r10,r6
	ctx.r7.u64 = ctx.r10.u64 + ctx.r6.u64;
loc_8244B7B4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,0(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// bl 0x8243f338
	sub_8243F338(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8244b7dc
	if (!cr0.eq) goto loc_8244B7DC;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// add r7,r5,r7
	ctx.r7.u64 = ctx.r5.u64 + ctx.r7.u64;
	// cmplw cr6,r31,r28
	cr6.compare<uint32_t>(r31.u32, r28.u32, xer);
	// blt cr6,0x8244b7b4
	if (cr6.lt) goto loc_8244B7B4;
	// b 0x8244b7fc
	goto loc_8244B7FC;
loc_8244B7DC:
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_8244B7FC:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8244b79c
	if (cr6.lt) goto loc_8244B79C;
	// b 0x8244b930
	goto loc_8244B930;
loc_8244B814:
	// lwz r5,4(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq 0x8244b930
	if (cr0.eq) goto loc_8244B930;
	// lwz r7,8(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
loc_8244B828:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,0(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// bl 0x8243f338
	sub_8243F338(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8244b850
	if (!cr0.eq) goto loc_8244B850;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// blt cr6,0x8244b828
	if (cr6.lt) goto loc_8244B828;
	// b 0x8244b930
	goto loc_8244B930;
loc_8244B850:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b930
	if (!cr6.gt) goto loc_8244B930;
	// li r11,0
	r11.s64 = 0;
loc_8244B864:
	// lwz r9,16(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r7,20(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// ori r7,r7,32
	ctx.r7.u64 = ctx.r7.u64 | 32;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// lwz r9,12(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244b864
	if (cr6.lt) goto loc_8244B864;
	// b 0x8244b930
	goto loc_8244B930;
loc_8244B89C:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b930
	if (!cr6.gt) goto loc_8244B930;
	// li r11,0
	r11.s64 = 0;
loc_8244B8B0:
	// lwz r9,16(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r7,20(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// ori r7,r7,32
	ctx.r7.u64 = ctx.r7.u64 | 32;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// lwz r9,12(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244b8b0
	if (cr6.lt) goto loc_8244B8B0;
	// b 0x8244b930
	goto loc_8244B930;
loc_8244B8E8:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b930
	if (!cr6.gt) goto loc_8244B930;
	// li r11,0
	r11.s64 = 0;
loc_8244B8FC:
	// lwz r9,16(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r7,20(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// ori r7,r7,32
	ctx.r7.u64 = ctx.r7.u64 | 32;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// lwz r9,12(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244b8fc
	if (cr6.lt) goto loc_8244B8FC;
loc_8244B930:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x8244b660
	if (cr6.lt) goto loc_8244B660;
loc_8244B944:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244b99c
	if (!cr6.gt) goto loc_8244B99C;
	// li r11,0
	r11.s64 = 0;
loc_8244B958:
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,26,26
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8244b988
	if (cr0.eq) goto loc_8244B988;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// ori r8,r8,32
	ctx.r8.u64 = ctx.r8.u64 | 32;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
loc_8244B988:
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244b958
	if (cr6.lt) goto loc_8244B958;
loc_8244B99C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8244B9A8"))) PPC_WEAK_FUNC(sub_8244B9A8);
PPC_FUNC_IMPL(__imp__sub_8244B9A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r23,0
	r23.s64 = 0;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244ba1c
	if (!cr6.gt) goto loc_8244BA1C;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// li r7,-1
	ctx.r7.s64 = -1;
loc_8244B9D8:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r6,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// stw r23,64(r11)
	PPC_STORE_U32(r11.u32 + 64, r23.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,25,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8244ba08
	if (!cr0.eq) goto loc_8244BA08;
	// stw r7,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r7.u32);
	// stw r7,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r7.u32);
loc_8244BA08:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244b9d8
	if (cr6.lt) goto loc_8244B9D8;
loc_8244BA1C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244ba5c
	if (!cr6.gt) goto loc_8244BA5C;
	// mr r11,r23
	r11.u64 = r23.u64;
loc_8244BA30:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stw r23,36(r9)
	PPC_STORE_U32(ctx.r9.u32 + 36, r23.u32);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r23,40(r9)
	PPC_STORE_U32(ctx.r9.u32 + 40, r23.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244ba30
	if (cr6.lt) goto loc_8244BA30;
loc_8244BA5C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r24,12(r31)
	r24.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr. r26,r24
	r26.u64 = r24.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// beq 0x8244bb6c
	if (cr0.eq) goto loc_8244BB6C;
	// rlwinm r25,r26,2,0,29
	r25.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244BA74:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r25,r25,-4
	r25.s64 = r25.s64 + -4;
	// addi r26,r26,-1
	r26.s64 = r26.s64 + -1;
	// lwzx r4,r25,r11
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244bb64
	if (cr0.eq) goto loc_8244BB64;
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// lwz r27,12(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244babc
	if (cr6.lt) goto loc_8244BABC;
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8244babc
	if (cr6.gt) goto loc_8244BABC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82445ba8
	sub_82445BA8(ctx, base);
	// b 0x8244bad8
	goto loc_8244BAD8;
loc_8244BABC:
	// lis r11,20480
	r11.s64 = 1342177280;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8244bad4
	if (!cr6.eq) goto loc_8244BAD4;
	// bl 0x824401f8
	sub_824401F8(ctx, base);
	// b 0x8244bad8
	goto loc_8244BAD8;
loc_8244BAD4:
	// bl 0x82446108
	sub_82446108(ctx, base);
loc_8244BAD8:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8244bd20
	if (cr0.lt) goto loc_8244BD20;
	// lwz r30,12(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r28,r27
	r28.u64 = r27.u64;
	// cmplw cr6,r27,r30
	cr6.compare<uint32_t>(r27.u32, r30.u32, xer);
	// bge cr6,0x8244bb1c
	if (!cr6.lt) goto loc_8244BB1C;
	// rlwinm r29,r27,2,0,29
	r29.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244BAF4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r4,r29,r11
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// bl 0x82446330
	sub_82446330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8244bd20
	if (cr0.lt) goto loc_8244BD20;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r30
	cr6.compare<uint32_t>(r28.u32, r30.u32, xer);
	// blt cr6,0x8244baf4
	if (cr6.lt) goto loc_8244BAF4;
loc_8244BB1C:
	// subf r11,r27,r30
	r11.s64 = r30.s64 - r27.s64;
	// rlwinm. r10,r11,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244bb64
	if (cr0.eq) goto loc_8244BB64;
	// rlwinm r9,r27,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244BB30:
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// add r7,r9,r8
	ctx.r7.u64 = ctx.r9.u64 + ctx.r8.u64;
	// add r8,r11,r8
	ctx.r8.u64 = r11.u64 + ctx.r8.u64;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r6,-4(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4);
	// lwz r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r7,r11,r7
	ctx.r7.u64 = r11.u64 + ctx.r7.u64;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// stw r8,-4(r7)
	PPC_STORE_U32(ctx.r7.u32 + -4, ctx.r8.u32);
	// bne 0x8244bb30
	if (!cr0.eq) goto loc_8244BB30;
loc_8244BB64:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x8244ba74
	if (!cr6.eq) goto loc_8244BA74;
loc_8244BB6C:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r11,r23
	r11.u64 = r23.u64;
	// subf r10,r24,r10
	ctx.r10.s64 = ctx.r10.s64 - r24.s64;
	// rlwinm. r7,r10,31,1,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8244bbd0
	if (cr0.eq) goto loc_8244BBD0;
	// rlwinm r10,r24,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244BB84:
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// subf r8,r11,r8
	ctx.r8.s64 = ctx.r8.s64 - r11.s64;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// rlwinm r6,r8,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r10,r9
	ctx.r8.u64 = ctx.r10.u64 + ctx.r9.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwzx r6,r6,r9
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r6,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r6.u32);
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// subf r8,r11,r8
	ctx.r8.s64 = ctx.r8.s64 - r11.s64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r8,r6
	PPC_STORE_U32(ctx.r8.u32 + ctx.r6.u32, ctx.r9.u32);
	// blt cr6,0x8244bb84
	if (cr6.lt) goto loc_8244BB84;
loc_8244BBD0:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8244bbf8
	if (cr6.eq) goto loc_8244BBF8;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_8244BBE0:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r23,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r23.u32);
	// bne 0x8244bbe0
	if (!cr0.eq) goto loc_8244BBE0;
loc_8244BBF8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8244bc10
	if (cr0.eq) goto loc_8244BC10;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8244bd20
	if (cr6.lt) goto loc_8244BD20;
loc_8244BC10:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244bc50
	if (!cr6.gt) goto loc_8244BC50;
	// mr r11,r23
	r11.u64 = r23.u64;
loc_8244BC24:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r8,r8,0,25,25
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8244bc3c
	if (!cr0.eq) goto loc_8244BC3C;
	// stw r23,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, r23.u32);
loc_8244BC3C:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244bc24
	if (cr6.lt) goto loc_8244BC24;
loc_8244BC50:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244bd1c
	if (!cr6.gt) goto loc_8244BD1C;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
loc_8244BC64:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r8,r6,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244bd08
	if (cr0.eq) goto loc_8244BD08;
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8244bd08
	if (cr0.eq) goto loc_8244BD08;
	// lwz r9,16(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244bd08
	if (!cr0.eq) goto loc_8244BD08;
	// mr r11,r23
	r11.u64 = r23.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8244bcfc
	if (cr6.eq) goto loc_8244BCFC;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
loc_8244BCC4:
	// lwz r9,16(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwz r30,16(r7)
	r30.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r3
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// stw r30,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, r30.u32);
	// stw r4,16(r9)
	PPC_STORE_U32(ctx.r9.u32 + 16, ctx.r4.u32);
	// lwz r9,12(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244bcc4
	if (cr6.lt) goto loc_8244BCC4;
loc_8244BCFC:
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,16(r7)
	PPC_STORE_U32(ctx.r7.u32 + 16, r11.u32);
loc_8244BD08:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x8244bc64
	if (cr6.lt) goto loc_8244BC64;
loc_8244BD1C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8244BD20:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_8244BD28"))) PPC_WEAK_FUNC(sub_8244BD28);
PPC_FUNC_IMPL(__imp__sub_8244BD28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r14,0
	r14.s64 = 0;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r20,r14
	r20.u64 = r14.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// mr r19,r14
	r19.u64 = r14.u64;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r21,r14
	r21.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r19,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r19.u32);
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r21.u32);
	// ble cr6,0x8244bda0
	if (!cr6.gt) goto loc_8244BDA0;
	// lwz r8,136(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
loc_8244BD70:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x8244bd90
	if (!cr6.eq) goto loc_8244BD90;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r19,r11
	cr6.compare<uint32_t>(r19.u32, r11.u32, xer);
	// bgt cr6,0x8244bd90
	if (cr6.gt) goto loc_8244BD90;
	// addi r19,r11,1
	r19.s64 = r11.s64 + 1;
loc_8244BD90:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244bd70
	if (!cr0.eq) goto loc_8244BD70;
	// stw r19,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r19.u32);
loc_8244BDA0:
	// lwz r11,108(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 108);
	// li r18,-1
	r18.s64 = -1;
	// li r17,1
	r17.s64 = 1;
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// bne 0x8244bfd8
	if (!cr0.eq) goto loc_8244BFD8;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r24,r14
	r24.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244bfd8
	if (!cr6.gt) goto loc_8244BFD8;
	// mr r26,r14
	r26.u64 = r14.u64;
loc_8244BDD0:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// lwzx r30,r11,r26
	r30.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244bfb4
	if (!cr6.eq) goto loc_8244BFB4;
	// lis r4,8272
	ctx.r4.s64 = 542113792;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// ori r4,r4,2
	ctx.r4.u64 = ctx.r4.u64 | 2;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lis r4,8256
	ctx.r4.s64 = 541065216;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r28,r9,r11
	r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r27,r14
	r27.u64 = r14.u64;
	// mr r31,r14
	r31.u64 = r14.u64;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_8244BE9C:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// lwz r4,136(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r31,8
	cr6.compare<uint32_t>(r31.u32, 8, xer);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// blt cr6,0x8244be9c
	if (cr6.lt) goto loc_8244BE9C;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// ble cr6,0x8244bf78
	if (!cr6.gt) goto loc_8244BF78;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r24,r11
	r11.s64 = r11.s64 - r24.s64;
loc_8244BF5C:
	// lwz r9,24(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// lwz r8,-4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + -4);
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// bne 0x8244bf5c
	if (!cr0.eq) goto loc_8244BF5C;
loc_8244BF78:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stwx r29,r11,r26
	PPC_STORE_U32(r11.u32 + r26.u32, r29.u32);
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// add r11,r11,r26
	r11.u64 = r11.u64 + r26.u64;
	// stw r28,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r28.u32);
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r20,r17
	r20.u64 = r17.u64;
	// stw r19,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r19.u32);
	// stw r11,12(r25)
	PPC_STORE_U32(r25.u32 + 12, r11.u32);
loc_8244BFB4:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x8244bdd0
	if (cr6.lt) goto loc_8244BDD0;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x8244bfd8
	if (cr6.eq) goto loc_8244BFD8;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
loc_8244BFD8:
	// lwz r11,108(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 108);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244c1cc
	if (cr0.eq) goto loc_8244C1CC;
	// lwz r22,12(r25)
	r22.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r23,r14
	r23.u64 = r14.u64;
	// cmplwi r22,0
	cr0.compare<uint32_t>(r22.u32, 0, xer);
	// beq 0x8244c1cc
	if (cr0.eq) goto loc_8244C1CC;
	// mr r24,r14
	r24.u64 = r14.u64;
loc_8244BFF8:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lwzx r29,r24,r11
	r29.u64 = PPC_LOAD_U32(r24.u32 + r11.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244c1bc
	if (cr0.eq) goto loc_8244C1BC;
	// lwz r4,12(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x8244c1bc
	if (cr0.eq) goto loc_8244C1BC;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r8,20(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244c1bc
	if (cr0.eq) goto loc_8244C1BC;
	// lwz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r11,r14
	r11.u64 = r14.u64;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8244c084
	if (cr0.eq) goto loc_8244C084;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
loc_8244C05C:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// bne cr6,0x8244c084
	if (!cr6.eq) goto loc_8244C084;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244c05c
	if (cr6.lt) goto loc_8244C05C;
loc_8244C084:
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244c1bc
	if (cr6.eq) goto loc_8244C1BC;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// rlwimi r4,r17,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r17.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// mr r28,r14
	r28.u64 = r14.u64;
	// lwz r9,12(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r27,24(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r26,20(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// ble cr6,0x8244c1b0
	if (!cr6.gt) goto loc_8244C1B0;
	// mr r31,r14
	r31.u64 = r14.u64;
loc_8244C0F0:
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r4,136(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r27,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r27.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r26,20(r11)
	PPC_STORE_U32(r11.u32 + 20, r26.u32);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// lwzx r9,r31,r9
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x8244c0f0
	if (cr6.lt) goto loc_8244C0F0;
loc_8244C1B0:
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// mr r20,r17
	r20.u64 = r17.u64;
	// stw r19,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r19.u32);
loc_8244C1BC:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmplw cr6,r23,r22
	cr6.compare<uint32_t>(r23.u32, r22.u32, xer);
	// blt cr6,0x8244bff8
	if (cr6.lt) goto loc_8244BFF8;
loc_8244C1CC:
	// lwz r11,76(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 76);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8244c2d8
	if (cr6.eq) goto loc_8244C2D8;
	// lwz r11,112(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 112);
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244c2d8
	if (!cr0.eq) goto loc_8244C2D8;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r29,r14
	r29.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244c2d8
	if (!cr6.gt) goto loc_8244C2D8;
loc_8244C1F4:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,24576
	ctx.r9.s64 = 1610612736;
	// lwzx r27,r10,r11
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x8244c2c4
	if (!cr6.eq) goto loc_8244C2C4;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r28,r17
	r28.u64 = r17.u64;
	// b 0x8244c2b0
	goto loc_8244C2B0;
loc_8244C220:
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r11,r14
	r11.u64 = r14.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8244c260
	if (cr6.eq) goto loc_8244C260;
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
loc_8244C238:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// bne cr6,0x8244c260
	if (!cr6.eq) goto loc_8244C260;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// blt cr6,0x8244c238
	if (cr6.lt) goto loc_8244C238;
loc_8244C260:
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x8244c2a8
	if (cr6.eq) goto loc_8244C2A8;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// lwz r30,12(r25)
	r30.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82440800
	sub_82440800(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x8244db80
	if (cr0.lt) goto loc_8244DB80;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x8244c2a4
	if (cr6.eq) goto loc_8244C2A4;
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
loc_8244C2A4:
	// mr r20,r17
	r20.u64 = r17.u64;
loc_8244C2A8:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
loc_8244C2B0:
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x8244c220
	if (!cr0.eq) goto loc_8244C220;
loc_8244C2C4:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8244c1f4
	if (cr6.lt) goto loc_8244C1F4;
	// lwz r19,80(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8244C2D8:
	// lwz r11,76(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 76);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8244c640
	if (cr6.eq) goto loc_8244C640;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r21,r14
	r21.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244c640
	if (!cr6.gt) goto loc_8244C640;
	// mr r22,r14
	r22.u64 = r14.u64;
loc_8244C2F8:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// lwzx r29,r22,r11
	r29.u64 = PPC_LOAD_U32(r22.u32 + r11.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244c62c
	if (!cr6.eq) goto loc_8244C62C;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x8244c3d8
	if (!cr6.eq) goto loc_8244C3D8;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r8,20(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244c3d8
	if (!cr0.eq) goto loc_8244C3D8;
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// li r11,4
	r11.s64 = 4;
loc_8244C358:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// slw r7,r17,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (r17.u32 << (ctx.r7.u8 & 0x3F));
	// or r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 | ctx.r9.u64;
	// bne 0x8244c358
	if (!cr0.eq) goto loc_8244C358;
	// cmplwi cr6,r9,15
	cr6.compare<uint32_t>(ctx.r9.u32, 15, xer);
	// bne cr6,0x8244c3d8
	if (!cr6.eq) goto loc_8244C3D8;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r11,4
	r11.s64 = 4;
loc_8244C38C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r6,r9,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwzx r6,r6,r8
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwz r6,16(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r6,r7
	PPC_STORE_U32(ctx.r6.u32 + ctx.r7.u32, ctx.r9.u32);
	// bne 0x8244c38c
	if (!cr0.eq) goto loc_8244C38C;
	// mr r11,r14
	r11.u64 = r14.u64;
loc_8244C3B8:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// blt cr6,0x8244c3b8
	if (cr6.lt) goto loc_8244C3B8;
	// b 0x8244c62c
	goto loc_8244C62C;
loc_8244C3D8:
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// ori r4,r4,4
	ctx.r4.u64 = ctx.r4.u64 | 4;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// lis r4,4352
	ctx.r4.s64 = 285212672;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// ori r4,r4,4
	ctx.r4.u64 = ctx.r4.u64 | 4;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r23,r24,2,0,29
	r23.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwzx r30,r23,r11
	r30.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// lwzx r26,r10,r11
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr r27,r14
	r27.u64 = r14.u64;
	// mr r31,r14
	r31.u64 = r14.u64;
loc_8244C450:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// bge cr6,0x8244c464
	if (!cr6.lt) goto loc_8244C464;
	// mr r11,r27
	r11.u64 = r27.u64;
	// b 0x8244c468
	goto loc_8244C468;
loc_8244C464:
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
loc_8244C468:
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r4,136(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r10,r28,r10
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + ctx.r10.u32);
	// lwzx r9,r31,r9
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r10,r28,r10
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + ctx.r10.u32);
	// lwzx r9,r31,r9
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// stwx r11,r10,r31
	PPC_STORE_U32(ctx.r10.u32 + r31.u32, r11.u32);
	// lwz r4,168(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 168);
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r9,16(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r10,r28,r10
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + ctx.r10.u32);
	// lwzx r9,r31,r9
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r9,r28,r9
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + ctx.r9.u32);
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r31,16
	cr6.compare<uint32_t>(r31.u32, 16, xer);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// blt cr6,0x8244c450
	if (cr6.lt) goto loc_8244C450;
	// lwz r11,168(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 168);
	// cmplw cr6,r24,r21
	cr6.compare<uint32_t>(r24.u32, r21.u32, xer);
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// ble cr6,0x8244c5f0
	if (!cr6.gt) goto loc_8244C5F0;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// subf r11,r21,r24
	r11.s64 = r24.s64 - r21.s64;
loc_8244C5D4:
	// lwz r9,24(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// lwz r8,-4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + -4);
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// bne 0x8244c5d4
	if (!cr0.eq) goto loc_8244C5D4;
loc_8244C5F0:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// stwx r30,r22,r11
	PPC_STORE_U32(r22.u32 + r11.u32, r30.u32);
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r20,r17
	r20.u64 = r17.u64;
	// stw r11,12(r25)
	PPC_STORE_U32(r25.u32 + 12, r11.u32);
	// stwx r26,r22,r10
	PPC_STORE_U32(r22.u32 + ctx.r10.u32, r26.u32);
loc_8244C62C:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// blt cr6,0x8244c2f8
	if (cr6.lt) goto loc_8244C2F8;
loc_8244C640:
	// lwz r11,108(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 108);
	// lis r15,4096
	r15.s64 = 268435456;
	// rlwinm. r10,r11,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244c658
	if (!cr0.eq) goto loc_8244C658;
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244cd40
	if (cr0.eq) goto loc_8244CD40;
loc_8244C658:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r24,r14
	r24.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244c928
	if (!cr6.gt) goto loc_8244C928;
loc_8244C668:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r23,r24,2,0,29
	r23.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r23,r11
	r31.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// bne cr6,0x8244c918
	if (!cr6.eq) goto loc_8244C918;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244c918
	if (!cr0.eq) goto loc_8244C918;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x8244c700
	if (cr0.eq) goto loc_8244C700;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r8,72(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
loc_8244C6D8:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r9
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r6,72(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 72);
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// bne cr6,0x8244c700
	if (!cr6.eq) goto loc_8244C700;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244c6d8
	if (cr6.lt) goto loc_8244C6D8;
loc_8244C700:
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// beq cr6,0x8244c918
	if (cr6.eq) goto loc_8244C918;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r28,r14
	r28.u64 = r14.u64;
	// mr r29,r14
	r29.u64 = r14.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244c87c
	if (cr0.eq) goto loc_8244C87C;
	// mr r26,r14
	r26.u64 = r14.u64;
loc_8244C720:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r8,r10,r26
	ctx.r8.u64 = ctx.r10.u64 + r26.u64;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244c840
	if (cr6.eq) goto loc_8244C840;
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r27,72(r10)
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// bge cr6,0x8244c788
	if (!cr6.lt) goto loc_8244C788;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// subf r8,r29,r11
	ctx.r8.s64 = r11.s64 - r29.s64;
loc_8244C758:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244c77c
	if (cr6.eq) goto loc_8244C77C;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// bne cr6,0x8244c77c
	if (!cr6.eq) goto loc_8244C77C;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_8244C77C:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244c758
	if (!cr0.eq) goto loc_8244C758;
loc_8244C788:
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// rlwimi r4,r17,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r17.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// bge cr6,0x8244c840
	if (!cr6.lt) goto loc_8244C840;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
loc_8244C7D8:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x8244c82c
	if (cr6.eq) goto loc_8244C82C;
	// lwz r7,20(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,72(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 72);
	// cmplw cr6,r27,r9
	cr6.compare<uint32_t>(r27.u32, ctx.r9.u32, xer);
	// bne cr6,0x8244c82c
	if (!cr6.eq) goto loc_8244C82C;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r9,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r7,16(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r9,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stwx r18,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, r18.u32);
loc_8244C82C:
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244c7d8
	if (cr6.lt) goto loc_8244C7D8;
loc_8244C840:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8244c720
	if (cr6.lt) goto loc_8244C720;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8244c87c
	if (cr6.eq) goto loc_8244C87C;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r5,r28,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r28,r11
	r11.s64 = r11.s64 - r28.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x8239d2a8
	sub_8239D2A8(ctx, base);
loc_8244C87C:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// subf r11,r28,r11
	r11.s64 = r11.s64 - r28.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// ble cr6,0x8244c8c0
	if (!cr6.gt) goto loc_8244C8C0;
	// add r9,r28,r11
	ctx.r9.u64 = r28.u64 + r11.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r24,r11
	r11.s64 = r11.s64 - r24.s64;
loc_8244C8A0:
	// lwz r8,24(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r7,r8,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// add r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 + ctx.r8.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// stw r7,-4(r8)
	PPC_STORE_U32(ctx.r8.u32 + -4, ctx.r7.u32);
	// bne 0x8244c8a0
	if (!cr0.eq) goto loc_8244C8A0;
loc_8244C8C0:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8244c8f0
	if (cr6.eq) goto loc_8244C8F0;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8244C8D4:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r7,24(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stwx r8,r7,r9
	PPC_STORE_U32(ctx.r7.u32 + ctx.r9.u32, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8244c8d4
	if (!cr0.eq) goto loc_8244C8D4;
loc_8244C8F0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// lwz r10,12(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// add r11,r28,r24
	r11.u64 = r28.u64 + r24.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r24,r11,-1
	r24.s64 = r11.s64 + -1;
	// mr r20,r17
	r20.u64 = r17.u64;
	// stw r10,12(r25)
	PPC_STORE_U32(r25.u32 + 12, ctx.r10.u32);
loc_8244C918:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x8244c668
	if (cr6.lt) goto loc_8244C668;
loc_8244C928:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r24,r14
	r24.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244cd40
	if (!cr6.gt) goto loc_8244CD40;
loc_8244C938:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r23,r24,2,0,29
	r23.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r23,r11
	r31.u64 = PPC_LOAD_U32(r23.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// bne cr6,0x8244cd30
	if (!cr6.eq) goto loc_8244CD30;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r5,20(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244cd30
	if (!cr0.eq) goto loc_8244CD30;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r29,r14
	r29.u64 = r14.u64;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8244ca38
	if (cr0.eq) goto loc_8244CA38;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// subf r30,r10,r11
	r30.s64 = r11.s64 - ctx.r10.s64;
loc_8244C9A8:
	// lwzx r11,r30,r10
	r11.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// lwzx r8,r8,r5
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r5.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bne cr6,0x8244c9d4
	if (!cr6.eq) goto loc_8244C9D4;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_8244C9D4:
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8244ca24
	if (cr6.eq) goto loc_8244CA24;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r5
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r5.u32);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
loc_8244C9F4:
	// lwz r28,0(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r28,r28,2,0,29
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r28,r5
	r28.u64 = PPC_LOAD_U32(r28.u32 + ctx.r5.u32);
	// lwz r28,16(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// beq cr6,0x8244ca20
	if (cr6.eq) goto loc_8244CA20;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244c9f4
	if (cr6.lt) goto loc_8244C9F4;
	// b 0x8244ca24
	goto loc_8244CA24;
loc_8244CA20:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_8244CA24:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r7,r3
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r3.u32, xer);
	// blt cr6,0x8244c9a8
	if (cr6.lt) goto loc_8244C9A8;
loc_8244CA38:
	// cmplw cr6,r4,r3
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r3.u32, xer);
	// beq cr6,0x8244cd30
	if (cr6.eq) goto loc_8244CD30;
	// addi r11,r29,1
	r11.s64 = r29.s64 + 1;
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x8244cd30
	if (cr6.eq) goto loc_8244CD30;
	// cmplwi cr6,r4,1
	cr6.compare<uint32_t>(ctx.r4.u32, 1, xer);
	// bgt cr6,0x8244ca5c
	if (cr6.gt) goto loc_8244CA5C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8244cd30
	if (cr6.eq) goto loc_8244CD30;
loc_8244CA5C:
	// mr r27,r14
	r27.u64 = r14.u64;
	// cmplwi cr6,r4,1
	cr6.compare<uint32_t>(ctx.r4.u32, 1, xer);
	// ble cr6,0x8244cb24
	if (!cr6.gt) goto loc_8244CB24;
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// rlwimi r4,r17,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r17.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r27,r17
	r27.u64 = r17.u64;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244cb24
	if (!cr6.gt) goto loc_8244CB24;
	// mr r11,r14
	r11.u64 = r14.u64;
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
loc_8244CAB8:
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r8,20(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r6,r11,r6
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r8
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwzx r8,r5,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// lwz r6,16(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// bne cr6,0x8244cb10
	if (!cr6.eq) goto loc_8244CB10;
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stwx r9,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stwx r9,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stwx r18,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, r18.u32);
loc_8244CB10:
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244cab8
	if (cr6.lt) goto loc_8244CAB8;
loc_8244CB24:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r29,r14
	r29.u64 = r14.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244cc6c
	if (cr0.eq) goto loc_8244CC6C;
	// mr r26,r14
	r26.u64 = r14.u64;
loc_8244CB38:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r8,r26,r10
	ctx.r8.u64 = r26.u64 + ctx.r10.u64;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244cc58
	if (cr6.eq) goto loc_8244CC58;
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r28,16(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// bge cr6,0x8244cba0
	if (!cr6.lt) goto loc_8244CBA0;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// subf r8,r29,r11
	ctx.r8.s64 = r11.s64 - r29.s64;
loc_8244CB70:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244cb94
	if (cr6.eq) goto loc_8244CB94;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// bne cr6,0x8244cb94
	if (!cr6.eq) goto loc_8244CB94;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
loc_8244CB94:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244cb70
	if (!cr0.eq) goto loc_8244CB70;
loc_8244CBA0:
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// rlwimi r4,r17,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r17.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// bge cr6,0x8244cc58
	if (!cr6.lt) goto loc_8244CC58;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
loc_8244CBF0:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x8244cc44
	if (cr6.eq) goto loc_8244CC44;
	// lwz r7,20(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,16(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// cmplw cr6,r28,r9
	cr6.compare<uint32_t>(r28.u32, ctx.r9.u32, xer);
	// bne cr6,0x8244cc44
	if (!cr6.eq) goto loc_8244CC44;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r7,16(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r9,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stwx r9,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stwx r18,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, r18.u32);
loc_8244CC44:
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244cbf0
	if (cr6.lt) goto loc_8244CBF0;
loc_8244CC58:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8244cb38
	if (cr6.lt) goto loc_8244CB38;
loc_8244CC6C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8244cc94
	if (cr6.eq) goto loc_8244CC94;
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r5,r27,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r27,r11
	r11.s64 = r11.s64 - r27.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x8239d2a8
	sub_8239D2A8(ctx, base);
loc_8244CC94:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// subf r11,r27,r11
	r11.s64 = r11.s64 - r27.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// ble cr6,0x8244ccd8
	if (!cr6.gt) goto loc_8244CCD8;
	// add r9,r11,r27
	ctx.r9.u64 = r11.u64 + r27.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r24,r11
	r11.s64 = r11.s64 - r24.s64;
loc_8244CCB8:
	// lwz r8,24(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r7,r10,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// add r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 + ctx.r8.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// stw r7,-4(r8)
	PPC_STORE_U32(ctx.r8.u32 + -4, ctx.r7.u32);
	// bne 0x8244ccb8
	if (!cr0.eq) goto loc_8244CCB8;
loc_8244CCD8:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8244cd08
	if (cr6.eq) goto loc_8244CD08;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// mr r11,r27
	r11.u64 = r27.u64;
loc_8244CCEC:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r7,24(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stwx r8,r9,r7
	PPC_STORE_U32(ctx.r9.u32 + ctx.r7.u32, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8244ccec
	if (!cr0.eq) goto loc_8244CCEC;
loc_8244CD08:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// lwz r10,12(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// add r11,r27,r24
	r11.u64 = r27.u64 + r24.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r24,r11,-1
	r24.s64 = r11.s64 + -1;
	// mr r20,r17
	r20.u64 = r17.u64;
	// stw r10,12(r25)
	PPC_STORE_U32(r25.u32 + 12, ctx.r10.u32);
loc_8244CD30:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x8244c938
	if (cr6.lt) goto loc_8244C938;
loc_8244CD40:
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x8244cd50
	if (cr6.eq) goto loc_8244CD50;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
loc_8244CD50:
	// rlwinm r31,r19,2,0,29
	r31.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r21.u32);
	// beq 0x8244db9c
	if (cr0.eq) goto loc_8244DB9C;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r8,r14
	ctx.r8.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244cde0
	if (!cr6.gt) goto loc_8244CDE0;
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
loc_8244CD90:
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r14,92(r11)
	PPC_STORE_U32(r11.u32 + 92, r14.u32);
	// lwz r10,136(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x8244cdcc
	if (!cr6.eq) goto loc_8244CDCC;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r10,r21
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r21.u32);
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244cdcc
	if (cr6.lt) goto loc_8244CDCC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r11,r10,r21
	PPC_STORE_U32(ctx.r10.u32 + r21.u32, r11.u32);
loc_8244CDCC:
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244cd90
	if (cr6.lt) goto loc_8244CD90;
loc_8244CDE0:
	// lwz r18,12(r25)
	r18.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplwi r18,0
	cr0.compare<uint32_t>(r18.u32, 0, xer);
	// beq 0x8244db7c
	if (cr0.eq) goto loc_8244DB7C;
	// lis r16,16384
	r16.s64 = 1073741824;
	// lis r17,8304
	r17.s64 = 544210944;
loc_8244CDF4:
	// addi r18,r18,-1
	r18.s64 = r18.s64 + -1;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r18,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r20,r10,r11
	r20.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244db70
	if (cr0.eq) goto loc_8244DB70;
	// lwz r10,4(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// clrlwi r31,r11,12
	r31.u64 = r11.u32 & 0xFFFFF;
	// lwz r9,12(r20)
	ctx.r9.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// divwu r29,r10,r31
	r29.u32 = ctx.r10.u32 / r31.u32;
	// twllei r31,0
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8244cec4
	if (cr6.eq) goto loc_8244CEC4;
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// blt cr6,0x8244cec4
	if (cr6.lt) goto loc_8244CEC4;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// bgt cr6,0x8244cec4
	if (cr6.gt) goto loc_8244CEC4;
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r4,16(r20)
	ctx.r4.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82442290
	sub_82442290(ctx, base);
	// mr r30,r14
	r30.u64 = r14.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8244cec4
	if (cr6.eq) goto loc_8244CEC4;
loc_8244CE64:
	// lwz r11,12(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// lwz r10,8(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// mullw r11,r30,r11
	r11.s64 = int64_t(r30.s32) * int64_t(r11.s32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// beq cr6,0x8244ceb8
	if (cr6.eq) goto loc_8244CEB8;
	// mr r11,r14
	r11.u64 = r14.u64;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_8244CE88:
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// addi r8,r1,208
	ctx.r8.s64 = ctx.r1.s64 + 208;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r3
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8244ce88
	if (!cr0.eq) goto loc_8244CE88;
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// rlwinm r5,r31,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239d2a8
	sub_8239D2A8(ctx, base);
loc_8244CEB8:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x8244ce64
	if (cr6.lt) goto loc_8244CE64;
loc_8244CEC4:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lwz r26,0(r20)
	r26.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// rlwinm r10,r26,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r15
	cr6.compare<uint32_t>(ctx.r10.u32, r15.u32, xer);
	// std r14,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r14.u64);
	// std r14,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r14.u64);
	// bne cr6,0x8244d0bc
	if (!cr6.eq) goto loc_8244D0BC;
	// lwz r11,16(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// lwz r6,20(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r10,16(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r11,r6
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r27,4(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r27,0,29,29
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244d0bc
	if (!cr0.eq) goto loc_8244D0BC;
	// lwz r11,108(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 108);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244cf24
	if (cr0.eq) goto loc_8244CF24;
	// rlwinm. r11,r27,0,26,26
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244d0bc
	if (!cr0.eq) goto loc_8244D0BC;
loc_8244CF24:
	// lwz r11,8(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// lwz r10,136(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x8244d0bc
	if (!cr6.eq) goto loc_8244D0BC;
	// lwz r10,4(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244d0bc
	if (!cr6.gt) goto loc_8244D0BC;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lwz r31,24(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lwz r29,4(r20)
	r29.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// subf r30,r10,r11
	r30.s64 = r11.s64 - ctx.r10.s64;
loc_8244CF64:
	// lwzx r11,r30,r3
	r11.u64 = PPC_LOAD_U32(r30.u32 + ctx.r3.u32);
	// lis r10,24640
	ctx.r10.s64 = 1614807040;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r5,72(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r9,r5,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r31
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r31.u32);
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r4,r9,0,0,11
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244cfa8
	if (cr6.eq) goto loc_8244CFA8;
	// lis r10,24720
	ctx.r10.s64 = 1620049920;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244cfa8
	if (cr6.eq) goto loc_8244CFA8;
	// lis r10,24800
	ctx.r10.s64 = 1625292800;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244cfb0
	if (!cr6.eq) goto loc_8244CFB0;
loc_8244CFA8:
	// rlwinm. r10,r27,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244d0b0
	if (!cr0.eq) goto loc_8244D0B0;
loc_8244CFB0:
	// lwz r10,204(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 204);
	// rlwinm. r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244cfdc
	if (cr0.eq) goto loc_8244CFDC;
	// lwz r9,96(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 96);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8244cfdc
	if (cr0.eq) goto loc_8244CFDC;
	// lwz r10,96(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8244cfdc
	if (cr0.eq) goto loc_8244CFDC;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244d0b0
	if (!cr6.eq) goto loc_8244D0B0;
loc_8244CFDC:
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bne cr6,0x8244d0b0
	if (!cr6.eq) goto loc_8244D0B0;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8244d0b0
	if (!cr6.eq) goto loc_8244D0B0;
	// lwz r8,12(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8244d044
	if (cr0.eq) goto loc_8244D044;
	// lwz r11,16(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
loc_8244D010:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r24,84(r10)
	r24.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r18,r24
	cr6.compare<uint32_t>(r18.u32, r24.u32, xer);
	// bne cr6,0x8244d044
	if (!cr6.eq) goto loc_8244D044;
	// lwz r10,88(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	// cmplw cr6,r18,r10
	cr6.compare<uint32_t>(r18.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244d044
	if (!cr6.eq) goto loc_8244D044;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244d010
	if (cr6.lt) goto loc_8244D010;
loc_8244D044:
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x8244d0b0
	if (!cr6.eq) goto loc_8244D0B0;
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8244d098
	if (cr6.eq) goto loc_8244D098;
	// lwz r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
loc_8244D05C:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244d088
	if (cr6.eq) goto loc_8244D088;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bge cr6,0x8244d098
	if (!cr6.lt) goto loc_8244D098;
loc_8244D088:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244d05c
	if (cr6.lt) goto loc_8244D05C;
loc_8244D098:
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x8244d0b0
	if (!cr6.eq) goto loc_8244D0B0;
	// cmplw cr6,r4,r17
	cr6.compare<uint32_t>(ctx.r4.u32, r17.u32, xer);
	// beq cr6,0x8244d0b0
	if (cr6.eq) goto loc_8244D0B0;
	// li r11,1
	r11.s64 = 1;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_8244D0B0:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// bne 0x8244cf64
	if (!cr0.eq) goto loc_8244CF64;
loc_8244D0BC:
	// rlwinm r11,r26,0,0,3
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// blt cr6,0x8244d118
	if (cr6.lt) goto loc_8244D118;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// bgt cr6,0x8244d118
	if (cr6.gt) goto loc_8244D118;
	// lwz r11,12(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244d138
	if (!cr6.gt) goto loc_8244D138;
	// lwz r8,16(r20)
	ctx.r8.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// subf r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
loc_8244D0F4:
	// lwzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8244d0f4
	if (!cr0.eq) goto loc_8244D0F4;
	// b 0x8244d138
	goto loc_8244D138;
loc_8244D118:
	// mr r11,r14
	r11.u64 = r14.u64;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
loc_8244D120:
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x8244d120
	if (cr6.lt) goto loc_8244D120;
loc_8244D138:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r19,r14
	r19.u64 = r14.u64;
	// b 0x8244da64
	goto loc_8244DA64;
loc_8244D144:
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r23,r14
	r23.u64 = r14.u64;
	// mr r24,r14
	r24.u64 = r14.u64;
	// mr r26,r14
	r26.u64 = r14.u64;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// std r14,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r14.u64);
	// std r14,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r14.u64);
	// beq cr6,0x8244d360
	if (cr6.eq) goto loc_8244D360;
	// mr r27,r14
	r27.u64 = r14.u64;
loc_8244D16C:
	// lwzx r28,r22,r27
	r28.u64 = PPC_LOAD_U32(r22.u32 + r27.u32);
	// lwz r29,20(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,136(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 136);
	// lwzx r30,r10,r29
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r29.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244d34c
	if (!cr6.eq) goto loc_8244D34C;
	// lwz r11,72(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244d34c
	if (cr6.eq) goto loc_8244D34C;
	// lwz r4,92(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 92);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x8244d1a8
	if (cr0.eq) goto loc_8244D1A8;
	// li r23,1
	r23.s64 = 1;
loc_8244D1A8:
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// rlwinm r6,r8,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r6,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8244d1c4
	if (!cr6.eq) goto loc_8244D1C4;
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
loc_8244D1C4:
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r9,24(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r7,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r7,0(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// rlwinm r11,r7,0,0,11
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// beq cr6,0x8244d3b8
	if (cr6.eq) goto loc_8244D3B8;
	// lis r10,8320
	ctx.r10.s64 = 545259520;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244d3b8
	if (cr6.eq) goto loc_8244D3B8;
	// lis r10,8336
	ctx.r10.s64 = 546308096;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244d3b8
	if (cr6.eq) goto loc_8244D3B8;
	// rlwinm r11,r7,0,0,3
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// blt cr6,0x8244d398
	if (cr6.lt) goto loc_8244D398;
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// bgt cr6,0x8244d398
	if (cr6.gt) goto loc_8244D398;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8244d310
	if (cr6.eq) goto loc_8244D310;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lwzx r6,r27,r11
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// cmplw cr6,r6,r8
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, xer);
	// beq cr6,0x8244d310
	if (cr6.eq) goto loc_8244D310;
	// lwz r8,12(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r11,r14
	r11.u64 = r14.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8244d310
	if (cr0.eq) goto loc_8244D310;
	// lwz r31,16(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
loc_8244D25C:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244d26c
	if (!cr6.eq) goto loc_8244D26C;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
loc_8244D26C:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r29.u32);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244d284
	if (!cr6.eq) goto loc_8244D284;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
loc_8244D284:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244d25c
	if (cr6.lt) goto loc_8244D25C;
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x8244d310
	if (cr6.eq) goto loc_8244D310;
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x8244d310
	if (cr6.eq) goto loc_8244D310;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi r10,r7,12
	ctx.r10.u64 = ctx.r7.u32 & 0xFFFFF;
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// divwu. r6,r11,r10
	ctx.r6.u32 = r11.u32 / ctx.r10.u32;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// twllei r10,0
	// beq 0x8244d2fc
	if (cr0.eq) goto loc_8244D2FC;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,12(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// rlwinm r9,r4,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
loc_8244D2D8:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r5
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r5.u32, xer);
	// bne cr6,0x8244d2fc
	if (!cr6.eq) goto loc_8244D2FC;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// add r11,r8,r11
	r11.u64 = ctx.r8.u64 + r11.u64;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// blt cr6,0x8244d2d8
	if (cr6.lt) goto loc_8244D2D8;
loc_8244D2FC:
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// bne cr6,0x8244d310
	if (!cr6.eq) goto loc_8244D310;
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// stwx r11,r22,r27
	PPC_STORE_U32(r22.u32 + r27.u32, r11.u32);
loc_8244D310:
	// bl 0x8243d130
	sub_8243D130(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8244d338
	if (cr0.eq) goto loc_8244D338;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x8244d338
	if (!cr6.gt) goto loc_8244D338;
	// li r23,1
	r23.s64 = 1;
loc_8244D338:
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8244D33C:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r26,r21
	cr6.compare<uint32_t>(r26.u32, r21.u32, xer);
	// blt cr6,0x8244d16c
	if (cr6.lt) goto loc_8244D16C;
loc_8244D34C:
	// cmplw cr6,r26,r21
	cr6.compare<uint32_t>(r26.u32, r21.u32, xer);
	// bge cr6,0x8244d358
	if (!cr6.lt) goto loc_8244D358;
	// li r23,1
	r23.s64 = 1;
loc_8244D358:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x8244d430
	if (!cr6.eq) goto loc_8244D430;
loc_8244D360:
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// beq cr6,0x8244d3cc
	if (cr6.eq) goto loc_8244D3CC;
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
loc_8244D378:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r21
	cr6.compare<uint32_t>(ctx.r9.u32, r21.u32, xer);
	// beq cr6,0x8244d3c0
	if (cr6.eq) goto loc_8244D3C0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// blt cr6,0x8244d378
	if (cr6.lt) goto loc_8244D378;
	// b 0x8244d3c4
	goto loc_8244D3C4;
loc_8244D398:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x8244d3ac
	if (!cr6.gt) goto loc_8244D3AC;
	// cmplw cr6,r26,r8
	cr6.compare<uint32_t>(r26.u32, ctx.r8.u32, xer);
	// bne cr6,0x8244d3b8
	if (!cr6.eq) goto loc_8244D3B8;
loc_8244D3AC:
	// lwzx r11,r6,r5
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r5.u32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x8244d33c
	if (!cr6.gt) goto loc_8244D33C;
loc_8244D3B8:
	// li r23,1
	r23.s64 = 1;
	// b 0x8244d33c
	goto loc_8244D33C;
loc_8244D3C0:
	// li r23,1
	r23.s64 = 1;
loc_8244D3C4:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x8244d430
	if (!cr6.eq) goto loc_8244D430;
loc_8244D3CC:
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// beq cr6,0x8244d430
	if (cr6.eq) goto loc_8244D430;
	// lwz r10,12(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// mr r11,r14
	r11.u64 = r14.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244d430
	if (!cr6.gt) goto loc_8244D430;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
loc_8244D408:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x8244d42c
	if (cr6.eq) goto loc_8244D42C;
	// lwz r9,12(r20)
	ctx.r9.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244d408
	if (cr6.lt) goto loc_8244D408;
	// b 0x8244d430
	goto loc_8244D430;
loc_8244D42C:
	// li r23,1
	r23.s64 = 1;
loc_8244D430:
	// mr r28,r14
	r28.u64 = r14.u64;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8244d59c
	if (cr6.eq) goto loc_8244D59C;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// mr r31,r14
	r31.u64 = r14.u64;
	// mr r30,r22
	r30.u64 = r22.u64;
	// subf r29,r22,r11
	r29.s64 = r11.s64 - r22.s64;
loc_8244D44C:
	// lwzx r11,r30,r29
	r11.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8244d588
	if (cr6.eq) goto loc_8244D588;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r7,20(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244d59c
	if (cr6.eq) goto loc_8244D59C;
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r20)
	ctx.r9.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r9,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r31.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r3,4(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// beq 0x8244d588
	if (cr0.eq) goto loc_8244D588;
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// mr r11,r22
	r11.u64 = r22.u64;
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r6,r10,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r7
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r7.u32);
	// lwz r5,4(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
loc_8244D4BC:
	// lwzx r6,r29,r11
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq cr6,0x8244d4d4
	if (cr6.eq) goto loc_8244D4D4;
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// beq cr6,0x8244d4e8
	if (cr6.eq) goto loc_8244D4E8;
loc_8244D4D4:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r21
	cr6.compare<uint32_t>(ctx.r9.u32, r21.u32, xer);
	// blt cr6,0x8244d4bc
	if (cr6.lt) goto loc_8244D4BC;
	// b 0x8244d4ec
	goto loc_8244D4EC;
loc_8244D4E8:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
loc_8244D4EC:
	// li r6,1
	ctx.r6.s64 = 1;
	// cmplwi cr6,r4,1
	cr6.compare<uint32_t>(ctx.r4.u32, 1, xer);
	// ble cr6,0x8244d580
	if (!cr6.gt) goto loc_8244D580;
	// addi r9,r8,4
	ctx.r9.s64 = ctx.r8.s64 + 4;
loc_8244D4FC:
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// mr r11,r22
	r11.u64 = r22.u64;
loc_8244D504:
	// lwzx r8,r11,r29
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8244d520
	if (cr6.eq) goto loc_8244D520;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r27,0(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r8,r27
	cr6.compare<uint32_t>(ctx.r8.u32, r27.u32, xer);
	// beq cr6,0x8244d534
	if (cr6.eq) goto loc_8244D534;
loc_8244D520:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// blt cr6,0x8244d504
	if (cr6.lt) goto loc_8244D504;
	// b 0x8244d540
	goto loc_8244D540;
loc_8244D534:
	// cmplw cr6,r5,r3
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r3.u32, xer);
	// beq cr6,0x8244d540
	if (cr6.eq) goto loc_8244D540;
	// li r23,1
	r23.s64 = 1;
loc_8244D540:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x8244d5a4
	if (!cr6.eq) goto loc_8244D5A4;
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// bne cr6,0x8244d568
	if (!cr6.eq) goto loc_8244D568;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r11,r5
	cr6.compare<uint32_t>(r11.u32, ctx.r5.u32, xer);
	// bne cr6,0x8244d57c
	if (!cr6.eq) goto loc_8244D57C;
loc_8244D568:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r6,r4
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, xer);
	// blt cr6,0x8244d4fc
	if (cr6.lt) goto loc_8244D4FC;
	// b 0x8244d588
	goto loc_8244D588;
loc_8244D57C:
	// li r23,1
	r23.s64 = 1;
loc_8244D580:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x8244d5a4
	if (!cr6.eq) goto loc_8244D5A4;
loc_8244D588:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r21
	cr6.compare<uint32_t>(r28.u32, r21.u32, xer);
	// blt cr6,0x8244d44c
	if (cr6.lt) goto loc_8244D44C;
loc_8244D59C:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x8244d5b4
	if (cr6.eq) goto loc_8244D5B4;
loc_8244D5A4:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// std r14,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r14.u64);
	// std r14,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r14.u64);
	// b 0x8244da5c
	goto loc_8244DA5C;
loc_8244D5B4:
	// mr r28,r14
	r28.u64 = r14.u64;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8244d744
	if (cr6.eq) goto loc_8244D744;
	// mr r30,r14
	r30.u64 = r14.u64;
loc_8244D5C4:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8244d650
	if (cr6.eq) goto loc_8244D650;
	// lwz r10,16(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r9,r30,r10
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r30,r8
	PPC_STORE_U32(r30.u32 + ctx.r8.u32, ctx.r9.u32);
	// lwzx r7,r7,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r9,96(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 96);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8244d734
	if (!cr6.eq) goto loc_8244D734;
	// lwz r9,8(r20)
	ctx.r9.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r30
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,96(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// stw r11,96(r10)
	PPC_STORE_U32(ctx.r10.u32 + 96, r11.u32);
	// lwz r10,8(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// lwz r9,16(r20)
	ctx.r9.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r10,r10,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,100(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 100);
	// stw r10,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r10.u32);
	// b 0x8244d730
	goto loc_8244D730;
loc_8244D650:
	// lwzx r11,r22,r30
	r11.u64 = PPC_LOAD_U32(r22.u32 + r30.u32);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r8,r9
	r31.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x8244d690
	if (!cr6.eq) goto loc_8244D690;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// stwx r11,r30,r9
	PPC_STORE_U32(r30.u32 + ctx.r9.u32, r11.u32);
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// b 0x8244d730
	goto loc_8244D730;
loc_8244D690:
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwzx r6,r30,r11
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stwx r3,r30,r11
	PPC_STORE_U32(r30.u32 + r11.u32, ctx.r3.u32);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r29,r3,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwzx r3,r29,r11
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// bl 0x8243de18
	sub_8243DE18(ctx, base);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r9,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r9.u32);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_8244D730:
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8244D734:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r21
	cr6.compare<uint32_t>(r28.u32, r21.u32, xer);
	// blt cr6,0x8244d5c4
	if (cr6.lt) goto loc_8244D5C4;
loc_8244D744:
	// mr r24,r14
	r24.u64 = r14.u64;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8244da5c
	if (cr6.eq) goto loc_8244DA5C;
	// mr r23,r14
	r23.u64 = r14.u64;
loc_8244D754:
	// lwzx r11,r23,r22
	r11.u64 = PPC_LOAD_U32(r23.u32 + r22.u32);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r26,r11,r10
	r26.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,92(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8244da00
	if (!cr6.eq) goto loc_8244DA00;
	// mr r28,r14
	r28.u64 = r14.u64;
	// cmplw cr6,r24,r21
	cr6.compare<uint32_t>(r24.u32, r21.u32, xer);
	// bge cr6,0x8244d7e0
	if (!cr6.lt) goto loc_8244D7E0;
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// mr r11,r14
	r11.u64 = r14.u64;
	// subf r7,r24,r21
	ctx.r7.s64 = r21.s64 - r24.s64;
loc_8244D788:
	// lwzx r9,r22,r10
	ctx.r9.u64 = PPC_LOAD_U32(r22.u32 + ctx.r10.u32);
	// lwz r8,20(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,72(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 72);
	// lwzx r8,r5,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// lwz r5,72(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x8244d7d4
	if (!cr6.eq) goto loc_8244D7D4;
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// stwx r9,r11,r5
	PPC_STORE_U32(r11.u32 + ctx.r5.u32, ctx.r9.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwzx r6,r10,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// stw r9,92(r8)
	PPC_STORE_U32(ctx.r8.u32 + 92, ctx.r9.u32);
	// stwx r6,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r6.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8244D7D4:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244d788
	if (!cr0.eq) goto loc_8244D788;
loc_8244D7E0:
	// lwz r10,72(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 72);
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r10,r15
	cr6.compare<uint32_t>(ctx.r10.u32, r15.u32, xer);
	// blt cr6,0x8244d994
	if (cr6.lt) goto loc_8244D994;
	// cmplw cr6,r10,r16
	cr6.compare<uint32_t>(ctx.r10.u32, r16.u32, xer);
	// bgt cr6,0x8244d994
	if (cr6.gt) goto loc_8244D994;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// divwu r27,r10,r11
	r27.u32 = ctx.r10.u32 / r11.u32;
	// twllei r11,0
	// beq cr6,0x8244d878
	if (cr6.eq) goto loc_8244D878;
	// lwz r7,12(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
loc_8244D82C:
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8244d86c
	if (cr6.eq) goto loc_8244D86C;
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
loc_8244D844:
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r5,r8
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r8.u32, xer);
	// beq cr6,0x8244d864
	if (cr6.eq) goto loc_8244D864;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244d844
	if (cr6.lt) goto loc_8244D844;
	// b 0x8244d86c
	goto loc_8244D86C;
loc_8244D864:
	// addi r11,r1,224
	r11.s64 = ctx.r1.s64 + 224;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
loc_8244D86C:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244d82c
	if (!cr0.eq) goto loc_8244D82C;
loc_8244D878:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x8243d710
	sub_8243D710(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8244d894
	if (cr0.eq) goto loc_8244D894;
	// bl 0x8243d018
	sub_8243D018(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8244d898
	goto loc_8244D898;
loc_8244D894:
	// mr r30,r14
	r30.u64 = r14.u64;
loc_8244D898:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8244db9c
	if (cr6.eq) goto loc_8244DB9C;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,0,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mullw r5,r27,r28
	ctx.r5.s64 = int64_t(r27.s32) * int64_t(r28.s32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d7a8
	sub_8243D7A8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x8244dbac
	if (cr0.lt) goto loc_8244DBAC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x8244dbac
	if (cr0.lt) goto loc_8244DBAC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8244d954
	if (cr6.eq) goto loc_8244D954;
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
loc_8244D8EC:
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r11,r14
	r11.u64 = r14.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stwx r10,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r10.u32);
	// beq cr6,0x8244d948
	if (cr6.eq) goto loc_8244D948;
	// addi r10,r1,224
	ctx.r10.s64 = ctx.r1.s64 + 224;
	// rlwinm r7,r28,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_8244D918:
	// lwz r8,12(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lwz r4,8(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mullw r8,r11,r8
	ctx.r8.s64 = int64_t(r11.s32) * int64_t(ctx.r8.s32);
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// add r8,r8,r6
	ctx.r8.u64 = ctx.r8.u64 + ctx.r6.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r27
	cr6.compare<uint32_t>(r11.u32, r27.u32, xer);
	// lwzx r8,r8,r4
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	// stwx r8,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, ctx.r8.u32);
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// blt cr6,0x8244d918
	if (cr6.lt) goto loc_8244D918;
loc_8244D948:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8244d8ec
	if (!cr0.eq) goto loc_8244D8EC;
loc_8244D954:
	// lwz r11,72(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 72);
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r11,r10
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x8244d97c
	if (cr0.eq) goto loc_8244D97C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
loc_8244D97C:
	// lwz r11,72(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 72);
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x8244da00
	goto loc_8244DA00;
loc_8244D994:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244da00
	if (!cr6.gt) goto loc_8244DA00;
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
loc_8244D9A8:
	// lwz r8,16(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r11,r14
	r11.u64 = r14.u64;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// lwzx r7,r8,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
loc_8244D9B8:
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// beq cr6,0x8244d9d8
	if (cr6.eq) goto loc_8244D9D8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// blt cr6,0x8244d9b8
	if (cr6.lt) goto loc_8244D9B8;
	// b 0x8244d9ec
	goto loc_8244D9EC;
loc_8244D9D8:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stwx r11,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, r11.u32);
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8244D9EC:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x8244d9a8
	if (cr6.lt) goto loc_8244D9A8;
loc_8244DA00:
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r23,r23,4
	r23.s64 = r23.s64 + 4;
	// cmplw cr6,r24,r21
	cr6.compare<uint32_t>(r24.u32, r21.u32, xer);
	// blt cr6,0x8244d754
	if (cr6.lt) goto loc_8244D754;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8244da5c
	if (cr6.eq) goto loc_8244DA5C;
	// mr r11,r14
	r11.u64 = r14.u64;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// b 0x8244da28
	goto loc_8244DA28;
loc_8244DA24:
	// lwz r22,80(r1)
	r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8244DA28:
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stwx r9,r11,r22
	PPC_STORE_U32(r11.u32 + r22.u32, ctx.r9.u32);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r8,20(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r8,92(r9)
	PPC_STORE_U32(ctx.r9.u32 + 92, ctx.r8.u32);
	// bne 0x8244da24
	if (!cr0.eq) goto loc_8244DA24;
loc_8244DA5C:
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
loc_8244DA64:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// bne 0x8244d144
	if (!cr0.eq) goto loc_8244D144;
	// lwz r11,0(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// bne cr6,0x8244db70
	if (!cr6.eq) goto loc_8244DB70;
	// lwz r11,12(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// mr r7,r14
	ctx.r7.u64 = r14.u64;
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244db60
	if (!cr6.gt) goto loc_8244DB60;
	// mr r11,r14
	r11.u64 = r14.u64;
	// mr r8,r14
	ctx.r8.u64 = r14.u64;
loc_8244DAA4:
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r10,16(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// bne cr6,0x8244dad8
	if (!cr6.eq) goto loc_8244DAD8;
	// lwzx r9,r8,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r10,8(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// lwzx r9,r8,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x8244db38
	goto loc_8244DB38;
loc_8244DAD8:
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r5,96(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 96);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x8244db38
	if (!cr6.eq) goto loc_8244DB38;
	// lwz r5,8(r20)
	ctx.r5.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// lwzx r5,r11,r5
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r5,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// lwz r10,96(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 96);
	// stw r10,96(r9)
	PPC_STORE_U32(ctx.r9.u32 + 96, ctx.r10.u32);
	// lwz r9,8(r20)
	ctx.r9.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// lwz r5,16(r20)
	ctx.r5.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwzx r5,r11,r5
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r10,r5,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// lwz r9,100(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 100);
	// stw r9,100(r10)
	PPC_STORE_U32(ctx.r10.u32 + 100, ctx.r9.u32);
loc_8244DB38:
	// lwz r10,12(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244daa4
	if (cr6.lt) goto loc_8244DAA4;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8244db60
	if (cr6.eq) goto loc_8244DB60;
	// clrlwi r11,r7,12
	r11.u64 = ctx.r7.u32 & 0xFFFFF;
	// oris r11,r11,4096
	r11.u64 = r11.u64 | 268435456;
	// b 0x8244db64
	goto loc_8244DB64;
loc_8244DB60:
	// mr r11,r14
	r11.u64 = r14.u64;
loc_8244DB64:
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
	// stw r7,4(r20)
	PPC_STORE_U32(r20.u32 + 4, ctx.r7.u32);
	// stw r7,12(r20)
	PPC_STORE_U32(r20.u32 + 12, ctx.r7.u32);
loc_8244DB70:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// bne cr6,0x8244cdf4
	if (!cr6.eq) goto loc_8244CDF4;
	// lwz r21,84(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_8244DB7C:
	// mr r31,r14
	r31.u64 = r14.u64;
loc_8244DB80:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
loc_8244DB9C:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
loc_8244DBA4:
	// lwz r21,84(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// b 0x8244db80
	goto loc_8244DB80;
loc_8244DBAC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// b 0x8244dba4
	goto loc_8244DBA4;
}

__attribute__((alias("__imp__sub_8244DBC0"))) PPC_WEAK_FUNC(sub_8244DBC0);
PPC_FUNC_IMPL(__imp__sub_8244DBC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// li r24,0
	r24.s64 = 0;
	// li r25,0
	r25.s64 = 0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244dc1c
	if (cr0.eq) goto loc_8244DC1C;
	// lwz r8,136(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_8244DBF0:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x8244dc10
	if (!cr6.eq) goto loc_8244DC10;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r25,r10
	cr6.compare<uint32_t>(r25.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8244dc10
	if (cr6.gt) goto loc_8244DC10;
	// addi r25,r10,1
	r25.s64 = ctx.r10.s64 + 1;
loc_8244DC10:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8244dbf0
	if (!cr0.eq) goto loc_8244DBF0;
loc_8244DC1C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244dd64
	if (!cr6.gt) goto loc_8244DD64;
	// li r27,0
	r27.s64 = 0;
loc_8244DC38:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r30,r27,r11
	r30.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244dd50
	if (cr0.eq) goto loc_8244DD50;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// li r29,0
	r29.s64 = 0;
	// divwu. r28,r10,r11
	r28.u32 = ctx.r10.u32 / r11.u32;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// twllei r11,0
	// li r11,0
	r11.s64 = 0;
	// stw r11,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r11.u32);
	// beq 0x8244dd50
	if (cr0.eq) goto loc_8244DD50;
loc_8244DC6C:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r8,136(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r11,r9
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// bne cr6,0x8244dd44
	if (!cr6.eq) goto loc_8244DD44;
	// li r7,1
	ctx.r7.s64 = 1;
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// ble cr6,0x8244dce8
	if (!cr6.gt) goto loc_8244DCE8;
	// addi r11,r5,4
	r11.s64 = ctx.r5.s64 + 4;
loc_8244DCB0:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r4,4(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r8,r4
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r4.u32, xer);
	// bne cr6,0x8244dcd8
	if (!cr6.eq) goto loc_8244DCD8;
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// lwz r4,72(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 72);
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bne cr6,0x8244dce8
	if (!cr6.eq) goto loc_8244DCE8;
loc_8244DCD8:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r7,r3
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r3.u32, xer);
	// blt cr6,0x8244dcb0
	if (cr6.lt) goto loc_8244DCB0;
loc_8244DCE8:
	// cmplw cr6,r7,r3
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r3.u32, xer);
	// beq cr6,0x8244dd44
	if (cr6.eq) goto loc_8244DD44;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8244dd44
	if (cr6.eq) goto loc_8244DD44;
	// li r10,0
	ctx.r10.s64 = 0;
loc_8244DCFC:
	// lwzx r11,r10,r5
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,136(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// bne cr6,0x8244dd38
	if (!cr6.eq) goto loc_8244DD38;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r9,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r9.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8244DD38:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8244dcfc
	if (!cr0.eq) goto loc_8244DCFC;
loc_8244DD44:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// blt cr6,0x8244dc6c
	if (cr6.lt) goto loc_8244DC6C;
loc_8244DD50:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x8244dc38
	if (cr6.lt) goto loc_8244DC38;
loc_8244DD64:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244df00
	if (!cr6.gt) goto loc_8244DF00;
	// li r5,0
	ctx.r5.s64 = 0;
loc_8244DD78:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r9,r5,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244deec
	if (cr0.eq) goto loc_8244DEEC;
	// lwz r11,36(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8244deec
	if (!cr6.eq) goto loc_8244DEEC;
	// lwz r7,16(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,136(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244deec
	if (!cr6.eq) goto loc_8244DEEC;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x8244de64
	if (cr6.eq) goto loc_8244DE64;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8244de00
	if (cr0.eq) goto loc_8244DE00;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_8244DDD8:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// bne cr6,0x8244de00
	if (!cr6.eq) goto loc_8244DE00;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244ddd8
	if (cr6.lt) goto loc_8244DDD8;
loc_8244DE00:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x8244deec
	if (cr6.eq) goto loc_8244DEEC;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8244dee4
	if (cr6.eq) goto loc_8244DEE4;
	// li r11,0
	r11.s64 = 0;
loc_8244DE18:
	// lwz r7,16(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r7,r7,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stw r25,12(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12, r25.u32);
	// lwz r7,16(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r7,r7,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stw r8,16(r7)
	PPC_STORE_U32(ctx.r7.u32 + 16, ctx.r8.u32);
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244de18
	if (cr6.lt) goto loc_8244DE18;
	// b 0x8244dee4
	goto loc_8244DEE4;
loc_8244DE64:
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244dea0
	if (cr0.eq) goto loc_8244DEA0;
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
loc_8244DE78:
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8244dea0
	if (cr6.eq) goto loc_8244DEA0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x8244de78
	if (cr6.lt) goto loc_8244DE78;
loc_8244DEA0:
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x8244deec
	if (cr6.lt) goto loc_8244DEEC;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8244dee4
	if (cr6.eq) goto loc_8244DEE4;
	// li r11,0
	r11.s64 = 0;
loc_8244DEB8:
	// lwz r8,16(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r25,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, r25.u32);
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244deb8
	if (cr6.lt) goto loc_8244DEB8;
loc_8244DEE4:
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// li r24,1
	r24.s64 = 1;
loc_8244DEEC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x8244dd78
	if (cr6.lt) goto loc_8244DD78;
loc_8244DF00:
	// cntlzw r11,r24
	r11.u64 = r24.u32 == 0 ? 32 : __builtin_clz(r24.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_8244DF10"))) PPC_WEAK_FUNC(sub_8244DF10);
PPC_FUNC_IMPL(__imp__sub_8244DF10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd0
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r21,0
	r21.s64 = 0;
	// mr r28,r21
	r28.u64 = r21.u64;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244df70
	if (!cr6.gt) goto loc_8244DF70;
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// rotlwi r8,r11,0
	ctx.r8.u64 = __builtin_rotateleft32(r11.u32, 0);
loc_8244DF3C:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r7,r11,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8244df64
	if (cr0.eq) goto loc_8244DF64;
	// rlwinm. r7,r11,0,21,21
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x8244df5c
	if (!cr0.eq) goto loc_8244DF5C;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244df64
	if (cr0.eq) goto loc_8244DF64;
loc_8244DF5C:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r28,r11,r28
	r28.u64 = r11.u64 + r28.u64;
loc_8244DF64:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8244df3c
	if (!cr0.eq) goto loc_8244DF3C;
loc_8244DF70:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// rlwinm r31,r11,4,0,27
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r20,r3
	r20.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r20.s32, 0, xer);
	// bne 0x8244dfa0
	if (!cr0.eq) goto loc_8244DFA0;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8244e754
	goto loc_8244E754;
loc_8244DFA0:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,255
	ctx.r4.s64 = 255;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r18,r21
	r18.u64 = r21.u64;
	// mr r11,r21
	r11.u64 = r21.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244dfec
	if (!cr6.gt) goto loc_8244DFEC;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_8244DFC8:
	// lwz r8,20(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244dfc8
	if (cr6.lt) goto loc_8244DFC8;
loc_8244DFEC:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r31,r21
	r31.u64 = r21.u64;
	// li r19,1
	r19.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244e1d4
	if (!cr6.gt) goto loc_8244E1D4;
	// mr r30,r21
	r30.u64 = r21.u64;
loc_8244E004:
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r4,0,23,23
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244e1b0
	if (cr0.eq) goto loc_8244E1B0;
	// rlwinm. r11,r4,0,21,21
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244e028
	if (!cr0.eq) goto loc_8244E028;
	// rlwinm. r11,r4,0,20,20
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244e1b0
	if (cr0.eq) goto loc_8244E1B0;
loc_8244E028:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8244e0d4
	if (cr6.eq) goto loc_8244E0D4;
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 8);
loc_8244E038:
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8244e0c0
	if (cr6.eq) goto loc_8244E0C0;
	// lwz r6,20(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
loc_8244E04C:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x8244e0ac
	if (!cr6.eq) goto loc_8244E0AC;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244e0ac
	if (!cr6.eq) goto loc_8244E0AC;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r20
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r20.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244e0ac
	if (cr6.eq) goto loc_8244E0AC;
	// rlwinm. r9,r4,0,20,20
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8244e0c0
	if (!cr0.eq) goto loc_8244E0C0;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// lwzx r11,r10,r6
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lfd f13,32(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x8244e0c0
	if (!cr6.eq) goto loc_8244E0C0;
loc_8244E0AC:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x8244e04c
	if (cr6.lt) goto loc_8244E04C;
loc_8244E0C0:
	// cmplw cr6,r7,r5
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, xer);
	// beq cr6,0x8244e0d4
	if (cr6.eq) goto loc_8244E0D4;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplw cr6,r3,r28
	cr6.compare<uint32_t>(ctx.r3.u32, r28.u32, xer);
	// blt cr6,0x8244e038
	if (cr6.lt) goto loc_8244E038;
loc_8244E0D4:
	// rlwinm. r11,r4,0,20,20
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244e1b0
	if (!cr6.gt) goto loc_8244E1B0;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// bne 0x8244e16c
	if (!cr0.eq) goto loc_8244E16C;
loc_8244E0F0:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x8244e154
	if (!cr6.eq) goto loc_8244E154;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// bne cr6,0x8244e154
	if (!cr6.eq) goto loc_8244E154;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r20
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r20.u32);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x8244e140
	if (!cr6.eq) goto loc_8244E140;
	// stwx r8,r10,r20
	PPC_STORE_U32(ctx.r10.u32 + r20.u32, ctx.r8.u32);
	// b 0x8244e154
	goto loc_8244E154;
loc_8244E140:
	// lwz r9,116(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 116);
	// mr r18,r19
	r18.u64 = r19.u64;
	// stw r9,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r9.u32);
	// lwzx r10,r10,r20
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r20.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
loc_8244E154:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244e0f0
	if (cr6.lt) goto loc_8244E0F0;
	// b 0x8244e1b0
	goto loc_8244E1B0;
loc_8244E16C:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x8244e19c
	if (!cr6.eq) goto loc_8244E19C;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// add r11,r9,r3
	r11.u64 = ctx.r9.u64 + ctx.r3.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r8,r11,r20
	PPC_STORE_U32(r11.u32 + r20.u32, ctx.r8.u32);
loc_8244E19C:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244e16c
	if (cr6.lt) goto loc_8244E16C;
loc_8244E1B0:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x8244e004
	if (cr6.lt) goto loc_8244E004;
	// cmpwi cr6,r18,0
	cr6.compare<int32_t>(r18.s32, 0, xer);
	// beq cr6,0x8244e1d4
	if (cr6.eq) goto loc_8244E1D4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
loc_8244E1D4:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// li r22,-1
	r22.s64 = -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244e240
	if (!cr6.gt) goto loc_8244E240;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
loc_8244E1EC:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r7,r10,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8244e22c
	if (cr0.eq) goto loc_8244E22C;
	// rlwinm. r7,r10,0,21,21
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x8244e22c
	if (!cr0.eq) goto loc_8244E22C;
	// rlwinm. r10,r10,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244e22c
	if (!cr0.eq) goto loc_8244E22C;
	// stw r22,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r22.u32);
	// lwz r10,120(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_8244E22C:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244e1ec
	if (cr6.lt) goto loc_8244E1EC;
loc_8244E240:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r23,r21
	r23.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244e5d4
	if (!cr6.gt) goto loc_8244E5D4;
	// mr r24,r21
	r24.u64 = r21.u64;
	// li r25,-1
	r25.s64 = -1;
loc_8244E258:
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwzx r26,r24,r11
	r26.u64 = PPC_LOAD_U32(r24.u32 + r11.u32);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244e5c0
	if (cr0.eq) goto loc_8244E5C0;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// std r25,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r25.u64);
	// mr r31,r21
	r31.u64 = r21.u64;
	// std r21,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r21.u64);
	// mr r27,r21
	r27.u64 = r21.u64;
	// std r25,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r25.u64);
	// mr r28,r21
	r28.u64 = r21.u64;
	// std r21,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r21.u64);
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8244e420
	if (cr0.eq) goto loc_8244E420;
	// addi r30,r1,128
	r30.s64 = ctx.r1.s64 + 128;
loc_8244E2AC:
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r5,20(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r10,120(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r5
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8244e3f8
	if (!cr6.eq) goto loc_8244E3F8;
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244e3f8
	if (!cr6.eq) goto loc_8244E3F8;
	// lwz r11,108(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 108);
	// mr r10,r19
	ctx.r10.u64 = r19.u64;
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm r11,r11,4,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0x1;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// ble cr6,0x8244e338
	if (!cr6.gt) goto loc_8244E338;
	// addi r11,r8,4
	r11.s64 = ctx.r8.s64 + 4;
loc_8244E2FC:
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x8244e338
	if (cr6.eq) goto loc_8244E338;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lfd f0,32(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	// lfd f13,32(r7)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x8244e328
	if (cr6.eq) goto loc_8244E328;
	// stw r21,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r21.u32);
loc_8244E328:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r3
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r3.u32, xer);
	// blt cr6,0x8244e2fc
	if (cr6.lt) goto loc_8244E2FC;
loc_8244E338:
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8244e3f0
	if (cr6.eq) goto loc_8244E3F0;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// add r6,r11,r10
	ctx.r6.u64 = r11.u64 + ctx.r10.u64;
loc_8244E350:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// mr r11,r21
	r11.u64 = r21.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// beq cr6,0x8244e3a0
	if (cr6.eq) goto loc_8244E3A0;
	// lfd f0,32(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
loc_8244E370:
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r5
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// lfd f13,32(r4)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r4.u32 + 32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x8244e398
	if (cr6.eq) goto loc_8244E398;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// blt cr6,0x8244e370
	if (cr6.lt) goto loc_8244E370;
loc_8244E398:
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x8244e3ec
	if (cr6.eq) goto loc_8244E3EC;
loc_8244E3A0:
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x8244e3b4
	if (!cr6.eq) goto loc_8244E3B4;
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
loc_8244E3B4:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8244e3d8
	if (!cr6.eq) goto loc_8244E3D8;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// slw r9,r19,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x20 ? 0 : (r19.u32 << (ctx.r7.u8 & 0x3F));
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// or r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 | ctx.r4.u64;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_8244E3D8:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r3
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r3.u32, xer);
	// blt cr6,0x8244e350
	if (cr6.lt) goto loc_8244E350;
	// b 0x8244e3f0
	goto loc_8244E3F0;
loc_8244E3EC:
	// mr r27,r19
	r27.u64 = r19.u64;
loc_8244E3F0:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x8244e4ac
	if (!cr6.eq) goto loc_8244E4AC;
loc_8244E3F8:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x8244e2ac
	if (!cr0.eq) goto loc_8244E2AC;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x8244e4ac
	if (!cr6.eq) goto loc_8244E4AC;
loc_8244E420:
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82441658
	sub_82441658(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8244e4ac
	if (cr0.lt) goto loc_8244E4AC;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r21
	r31.u64 = r21.u64;
	// b 0x8244e490
	goto loc_8244E490;
loc_8244E448:
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r9,120(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244e488
	if (!cr6.eq) goto loc_8244E488;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244e488
	if (!cr6.eq) goto loc_8244E488;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82441478
	sub_82441478(ctx, base);
loc_8244E488:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_8244E490:
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x8244e448
	if (!cr0.eq) goto loc_8244E448;
	// mr r18,r19
	r18.u64 = r19.u64;
	// b 0x8244e5c0
	goto loc_8244E5C0;
loc_8244E4AC:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r28,r21
	r28.u64 = r21.u64;
	// b 0x8244e5ac
	goto loc_8244E5AC;
loc_8244E4B8:
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r9,120(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244e5a4
	if (!cr6.eq) goto loc_8244E5A4;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244e5a4
	if (!cr6.eq) goto loc_8244E5A4;
	// mr r30,r21
	r30.u64 = r21.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8244e520
	if (cr6.eq) goto loc_8244E520;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// rlwinm r5,r31,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239d2a8
	sub_8239D2A8(ctx, base);
	// mr r11,r21
	r11.u64 = r21.u64;
loc_8244E504:
	// slw r9,r19,r30
	ctx.r9.u64 = r30.u8 & 0x20 ? 0 : (r19.u32 << (r30.u8 & 0x3F));
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r31
	cr6.compare<uint32_t>(r30.u32, r31.u32, xer);
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// blt cr6,0x8244e504
	if (cr6.lt) goto loc_8244E504;
loc_8244E520:
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// bge cr6,0x8244e57c
	if (!cr6.lt) goto loc_8244E57C;
	// subfic r10,r31,4
	xer.ca = r31.u32 <= 4;
	ctx.r10.s64 = 4 - r31.s64;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// add r8,r11,r9
	ctx.r8.u64 = r11.u64 + ctx.r9.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// rlwinm. r9,r10,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8244e560
	if (cr0.eq) goto loc_8244E560;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_8244E554:
	// stw r6,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r6.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bdnz 0x8244e554
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8244E554;
loc_8244E560:
	// rlwinm. r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// beq 0x8244e57c
	if (cr0.eq) goto loc_8244E57C;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_8244E570:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8244e570
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8244E570;
loc_8244E57C:
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82441658
	sub_82441658(ctx, base);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82441478
	sub_82441478(ctx, base);
loc_8244E5A4:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
loc_8244E5AC:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8244e4b8
	if (!cr0.eq) goto loc_8244E4B8;
loc_8244E5C0:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// blt cr6,0x8244e258
	if (cr6.lt) goto loc_8244E258;
loc_8244E5D4:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244e66c
	if (!cr6.gt) goto loc_8244E66C;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
loc_8244E5EC:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r5,16(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r9,120(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// lwzx r11,r4,r5
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// bne cr6,0x8244e628
	if (!cr6.eq) goto loc_8244E628;
	// lwz r5,12(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// bne cr6,0x8244e628
	if (!cr6.eq) goto loc_8244E628;
	// lwz r11,116(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 116);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// b 0x8244e658
	goto loc_8244E658;
loc_8244E628:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r5,r11,0,23,23
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8244e658
	if (cr0.eq) goto loc_8244E658;
	// rlwinm. r5,r11,0,25,25
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8244e658
	if (cr0.eq) goto loc_8244E658;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244e658
	if (!cr0.eq) goto loc_8244E658;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244e658
	if (cr6.eq) goto loc_8244E658;
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
loc_8244E658:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x8244e5ec
	if (cr6.lt) goto loc_8244E5EC;
loc_8244E66C:
	// lwz r11,120(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,64
	ctx.r10.u64 = ctx.r10.u64 | 64;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// beq cr6,0x8244e6ac
	if (cr6.eq) goto loc_8244E6AC;
	// lwz r11,120(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// ori r10,r10,1024
	ctx.r10.u64 = ctx.r10.u64 | 1024;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_8244E6AC:
	// lwz r11,120(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r21,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r21.u32);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244e730
	if (!cr6.gt) goto loc_8244E730;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
loc_8244E6D4:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r10,120(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 120);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x8244e71c
	if (!cr6.eq) goto loc_8244E71C;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x8244e71c
	if (!cr6.eq) goto loc_8244E71C;
	// lwz r7,16(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r7,8(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bgt cr6,0x8244e71c
	if (cr6.gt) goto loc_8244E71C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
loc_8244E71C:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244e6d4
	if (cr6.lt) goto loc_8244E6D4;
loc_8244E730:
	// cmpwi cr6,r18,0
	cr6.compare<int32_t>(r18.s32, 0, xer);
	// beq cr6,0x8244e740
	if (cr6.eq) goto loc_8244E740;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82448968
	sub_82448968(ctx, base);
loc_8244E740:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// stw r19,220(r29)
	PPC_STORE_U32(r29.u32 + 220, r19.u32);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_8244E754:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x8239bd20
	return;
}

__attribute__((alias("__imp__sub_8244E75C"))) PPC_WEAK_FUNC(sub_8244E75C);
PPC_FUNC_IMPL(__imp__sub_8244E75C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8244E760"))) PPC_WEAK_FUNC(sub_8244E760);
PPC_FUNC_IMPL(__imp__sub_8244E760) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r25,0
	r25.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r23,r25
	r23.u64 = r25.u64;
	// mr r26,r25
	r26.u64 = r25.u64;
	// mr r24,r25
	r24.u64 = r25.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8244ec04
	if (cr0.lt) goto loc_8244EC04;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447260
	sub_82447260(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8244ec04
	if (cr0.lt) goto loc_8244EC04;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244e7b0
	if (!cr0.eq) goto loc_8244E7B0;
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244e890
	if (cr0.eq) goto loc_8244E890;
loc_8244E7B0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244e7e4
	if (!cr6.gt) goto loc_8244E7E4;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8244E7C4:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r25,44(r9)
	PPC_STORE_U32(ctx.r9.u32 + 44, r25.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244e7c4
	if (cr6.lt) goto loc_8244E7C4;
loc_8244E7E4:
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq 0x8244e890
	if (cr0.eq) goto loc_8244E890;
	// rlwinm r6,r5,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
loc_8244E7F4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r6,r6,-4
	ctx.r6.s64 = ctx.r6.s64 + -4;
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r9,r10,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8244e888
	if (cr0.eq) goto loc_8244E888;
	// lis r8,24576
	ctx.r8.s64 = 1610612736;
	// rlwinm r10,r10,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// lwz r8,44(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// beq cr6,0x8244e830
	if (cr6.eq) goto loc_8244E830;
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244e83c
	if (!cr6.eq) goto loc_8244E83C;
loc_8244E830:
	// addi r10,r8,1
	ctx.r10.s64 = ctx.r8.s64 + 1;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// stw r10,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r10.u32);
loc_8244E83C:
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244e888
	if (!cr6.gt) goto loc_8244E888;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
loc_8244E850:
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// lwz r4,44(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 44);
	// cmplw cr6,r4,r8
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r8.u32, xer);
	// bge cr6,0x8244e874
	if (!cr6.lt) goto loc_8244E874;
	// stw r8,44(r10)
	PPC_STORE_U32(ctx.r10.u32 + 44, ctx.r8.u32);
loc_8244E874:
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244e850
	if (cr6.lt) goto loc_8244E850;
loc_8244E888:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x8244e7f4
	if (!cr6.eq) goto loc_8244E7F4;
loc_8244E890:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244e954
	if (!cr6.gt) goto loc_8244E954;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
loc_8244E8A8:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r7,r10,0,0,11
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8244e940
	if (cr0.eq) goto loc_8244E940;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r30,4(r8)
	r30.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r30,r30,2,0,29
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r30,r3
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + ctx.r3.u32);
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm. r3,r3,0,28,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8244e92c
	if (!cr0.eq) goto loc_8244E92C;
	// lis r10,8304
	ctx.r10.s64 = 544210944;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244e918
	if (cr6.eq) goto loc_8244E918;
	// lis r10,8320
	ctx.r10.s64 = 545259520;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244e918
	if (cr6.eq) goto loc_8244E918;
	// lis r10,4432
	ctx.r10.s64 = 290455552;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244e918
	if (cr6.eq) goto loc_8244E918;
	// lwz r10,20(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// b 0x8244e92c
	goto loc_8244E92C;
loc_8244E918:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
loc_8244E92C:
	// stw r10,52(r11)
	PPC_STORE_U32(r11.u32 + 52, ctx.r10.u32);
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244e940
	if (cr6.eq) goto loc_8244E940;
	// li r4,1
	ctx.r4.s64 = 1;
loc_8244E940:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x8244e8a8
	if (cr6.lt) goto loc_8244E8A8;
loc_8244E954:
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244e968
	if (cr0.eq) goto loc_8244E968;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8244ec2c
	goto loc_8244EC2C;
loc_8244E968:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// beq cr6,0x8244eabc
	if (cr6.eq) goto loc_8244EABC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// beq 0x8244ebfc
	if (cr0.eq) goto loc_8244EBFC;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r24,r3
	r24.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// beq 0x8244ebfc
	if (cr0.eq) goto loc_8244EBFC;
loc_8244E9A0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r29,1
	r29.s64 = 1;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8244ec04
	if (cr0.lt) goto loc_8244EC04;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r11,r25
	r11.u64 = r25.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244e9e4
	if (!cr6.gt) goto loc_8244E9E4;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
loc_8244E9C8:
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244e9c8
	if (cr6.lt) goto loc_8244E9C8;
loc_8244E9E4:
	// lis r11,-32188
	r11.s64 = -2109472768;
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r11,-5128
	ctx.r3.s64 = r11.s64 + -5128;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244ea48
	if (!cr6.gt) goto loc_8244EA48;
	// mr r11,r26
	r11.u64 = r26.u64;
	// subf r8,r26,r24
	ctx.r8.s64 = r24.s64 - r26.s64;
loc_8244EA14:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244ea24
	if (cr6.eq) goto loc_8244EA24;
	// mr r29,r25
	r29.u64 = r25.u64;
loc_8244EA24:
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// stwx r9,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244ea14
	if (cr6.lt) goto loc_8244EA14;
loc_8244EA48:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x8244e9a0
	if (cr6.eq) goto loc_8244E9A0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447260
	sub_82447260(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8244ec04
	if (cr0.lt) goto loc_8244EC04;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r11,r11,20324
	r11.s64 = r11.s64 + 20324;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r11,r11,20316
	r11.s64 = r11.s64 + 20316;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm. r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244ec04
	if (!cr0.eq) goto loc_8244EC04;
	// b 0x8244ebf4
	goto loc_8244EBF4;
loc_8244EABC:
	// mr r27,r25
	r27.u64 = r25.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r23,r3
	r23.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r23.s32, 0, xer);
	// beq 0x8244ebfc
	if (cr0.eq) goto loc_8244EBFC;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r26,r3
	r26.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// beq 0x8244ebfc
	if (cr0.eq) goto loc_8244EBFC;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r24,r3
	r24.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// beq 0x8244ebfc
	if (cr0.eq) goto loc_8244EBFC;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244eb60
	if (!cr6.gt) goto loc_8244EB60;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
loc_8244EB14:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r7,-1
	ctx.r7.s64 = -1;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r25,36(r11)
	PPC_STORE_U32(r11.u32 + 36, r25.u32);
	// stw r7,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r7.u32);
	// rlwinm. r6,r6,0,0,11
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x8244eb4c
	if (cr0.eq) goto loc_8244EB4C;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8244eb4c
	if (!cr6.eq) goto loc_8244EB4C;
	// stw r9,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r9.u32);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
loc_8244EB4C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x8244eb14
	if (cr6.lt) goto loc_8244EB14;
loc_8244EB60:
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// mr r28,r25
	r28.u64 = r25.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8244eba0
	if (cr6.eq) goto loc_8244EBA0;
	// mr r29,r23
	r29.u64 = r23.u64;
loc_8244EB74:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441068
	sub_82441068(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8244ec04
	if (cr0.lt) goto loc_8244EC04;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r27
	cr6.compare<uint32_t>(r28.u32, r27.u32, xer);
	// blt cr6,0x8244eb74
	if (cr6.lt) goto loc_8244EB74;
loc_8244EBA0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244ebe0
	if (!cr6.gt) goto loc_8244EBE0;
	// mr r11,r24
	r11.u64 = r24.u64;
	// subf r9,r24,r26
	ctx.r9.s64 = r26.s64 - r24.s64;
loc_8244EBB8:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244ebb8
	if (cr6.lt) goto loc_8244EBB8;
loc_8244EBE0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_8244EBF4:
	// mr r30,r25
	r30.u64 = r25.u64;
	// b 0x8244ec04
	goto loc_8244EC04;
loc_8244EBFC:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
loc_8244EC04:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8244EC2C:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_8244EC34"))) PPC_WEAK_FUNC(sub_8244EC34);
PPC_FUNC_IMPL(__imp__sub_8244EC34) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8244EC38"))) PPC_WEAK_FUNC(sub_8244EC38);
PPC_FUNC_IMPL(__imp__sub_8244EC38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244ef08
	if (!cr6.gt) goto loc_8244EF08;
	// li r25,0
	r25.s64 = 0;
	// li r26,-1
	r26.s64 = -1;
loc_8244EC64:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lwzx r30,r25,r11
	r30.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244eef4
	if (cr0.eq) goto loc_8244EEF4;
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi r31,r11,12
	r31.u64 = r11.u32 & 0xFFFFF;
	// lis r8,20480
	ctx.r8.s64 = 1342177280;
	// divwu r28,r9,r31
	r28.u32 = ctx.r9.u32 / r31.u32;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// twllei r31,0
	// bne cr6,0x8244ecfc
	if (!cr6.eq) goto loc_8244ECFC;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x82442290
	sub_82442290(ctx, base);
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8244ed9c
	if (cr6.eq) goto loc_8244ED9C;
	// li r11,0
	r11.s64 = 0;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_8244ECC8:
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r3
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8244ecc8
	if (!cr0.eq) goto loc_8244ECC8;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// rlwinm r5,r31,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239d2a8
	sub_8239D2A8(ctx, base);
	// b 0x8244ed9c
	goto loc_8244ED9C;
loc_8244ECFC:
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244ed9c
	if (cr6.lt) goto loc_8244ED9C;
	// lis r10,16384
	ctx.r10.s64 = 1073741824;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8244ed9c
	if (cr6.gt) goto loc_8244ED9C;
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82442290
	sub_82442290(ctx, base);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8244ed9c
	if (cr6.eq) goto loc_8244ED9C;
loc_8244ED3C:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mullw r11,r29,r11
	r11.s64 = int64_t(r29.s32) * int64_t(r11.s32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// beq cr6,0x8244ed90
	if (cr6.eq) goto loc_8244ED90;
	// li r11,0
	r11.s64 = 0;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_8244ED60:
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r3
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8244ed60
	if (!cr0.eq) goto loc_8244ED60;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// rlwinm r5,r31,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239d2a8
	sub_8239D2A8(ctx, base);
loc_8244ED90:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// blt cr6,0x8244ed3c
	if (cr6.lt) goto loc_8244ED3C;
loc_8244ED9C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r10,8192
	ctx.r10.s64 = 536870912;
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244eef4
	if (!cr6.eq) goto loc_8244EEF4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d178
	sub_8243D178(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8244eef4
	if (cr0.eq) goto loc_8244EEF4;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r8,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwzx r29,r10,r9
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// beq cr6,0x8244ee58
	if (cr6.eq) goto loc_8244EE58;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rotlwi r7,r9,0
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
loc_8244EE04:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,72(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// cmplw cr6,r8,r4
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r4.u32, xer);
	// bge cr6,0x8244ee20
	if (!cr6.lt) goto loc_8244EE20;
	// mr r4,r8
	ctx.r4.u64 = ctx.r8.u64;
loc_8244EE20:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,72(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// cmplw cr6,r8,r5
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, xer);
	// bge cr6,0x8244ee3c
	if (!cr6.lt) goto loc_8244EE3C;
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
loc_8244EE3C:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8244ee04
	if (!cr0.eq) goto loc_8244EE04;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// blt cr6,0x8244eef4
	if (cr6.lt) goto loc_8244EEF4;
	// bne cr6,0x8244eebc
	if (!cr6.eq) goto loc_8244EEBC;
loc_8244EE58:
	// lwz r7,4(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// lwz r6,4(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r10,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// blt cr6,0x8244eef4
	if (cr6.lt) goto loc_8244EEF4;
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,4(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244eebc
	if (!cr6.eq) goto loc_8244EEBC;
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244eef4
	if (cr6.lt) goto loc_8244EEF4;
	// bne cr6,0x8244eebc
	if (!cr6.eq) goto loc_8244EEBC;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r9,12(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8244eef4
	if (cr6.lt) goto loc_8244EEF4;
loc_8244EEBC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8244eef4
	if (cr6.eq) goto loc_8244EEF4;
	// li r10,0
	ctx.r10.s64 = 0;
loc_8244EEC8:
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// add r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stwx r9,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8244eec8
	if (!cr0.eq) goto loc_8244EEC8;
loc_8244EEF4:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x8244ec64
	if (cr6.lt) goto loc_8244EC64;
loc_8244EF08:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8239bd38
	return;
}

__attribute__((alias("__imp__sub_8244EF14"))) PPC_WEAK_FUNC(sub_8244EF14);
PPC_FUNC_IMPL(__imp__sub_8244EF14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8244EF18"))) PPC_WEAK_FUNC(sub_8244EF18);
PPC_FUNC_IMPL(__imp__sub_8244EF18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8244ef4c
	if (!cr6.eq) goto loc_8244EF4C;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8244f868
	goto loc_8244F868;
loc_8244EF4C:
	// li r5,100
	ctx.r5.s64 = 100;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// stw r21,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r21.u32);
	// stw r30,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r30.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r11,108(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 108);
	// lwz r10,96(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// rlwimi r10,r11,31,0,0
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 31) & 0x80000000) | (ctx.r10.u64 & 0xFFFFFFFF7FFFFFFF);
	// stw r10,96(r31)
	PPC_STORE_U32(r31.u32 + 96, ctx.r10.u32);
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244efe8
	if (!cr6.gt) goto loc_8244EFE8;
	// li r9,0
	ctx.r9.s64 = 0;
loc_8244EF88:
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r21,r10
	cr6.compare<uint32_t>(r21.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244efd4
	if (!cr6.eq) goto loc_8244EFD4;
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244efd4
	if (!cr6.eq) goto loc_8244EFD4;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r7,40(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x8244efc0
	if (cr6.lt) goto loc_8244EFC0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r10.u32);
loc_8244EFC0:
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// stw r10,116(r11)
	PPC_STORE_U32(r11.u32 + 116, ctx.r10.u32);
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
loc_8244EFD4:
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x8244ef88
	if (cr6.lt) goto loc_8244EF88;
loc_8244EFE8:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,64(r31)
	PPC_STORE_U32(r31.u32 + 64, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,76(r31)
	PPC_STORE_U32(r31.u32 + 76, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// li r23,0
	r23.s64 = 0;
loc_8244F158:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r5,r11,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// li r26,0
	r26.s64 = 0;
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244f440
	if (!cr6.gt) goto loc_8244F440;
	// li r25,0
	r25.s64 = 0;
loc_8244F184:
	// lwz r11,24(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// lwzx r30,r25,r11
	r30.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d1c8
	sub_8243D1C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8244f42c
	if (cr0.eq) goto loc_8244F42C;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// bne cr6,0x8244f42c
	if (!cr6.eq) goto loc_8244F42C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi r3,r11,12
	ctx.r3.u64 = r11.u32 & 0xFFFFF;
	// divwu. r11,r10,r3
	r11.u32 = ctx.r10.u32 / ctx.r3.u32;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// twllei r3,0
	// beq 0x8244f42c
	if (cr0.eq) goto loc_8244F42C;
	// li r29,0
	r29.s64 = 0;
	// rlwinm r27,r3,2,0,29
	r27.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r28,r11
	r28.u64 = r11.u64;
loc_8244F1E0:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// add r4,r11,r29
	ctx.r4.u64 = r11.u64 + r29.u64;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244f20c
	if (cr6.eq) goto loc_8244F20C;
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x8244f210
	if (!cr6.eq) goto loc_8244F210;
loc_8244F20C:
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8244F210:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,20(r22)
	ctx.r6.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwz r9,16(r22)
	ctx.r9.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,14,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244f274
	if (cr0.eq) goto loc_8244F274;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244f258
	if (cr6.eq) goto loc_8244F258;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244f258
	if (cr6.eq) goto loc_8244F258;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8244F258:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,24(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_8244F274:
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244f298
	if (cr6.eq) goto loc_8244F298;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244f298
	if (cr6.eq) goto loc_8244F298;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8244F298:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// bne cr6,0x8244f420
	if (!cr6.eq) goto loc_8244F420;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8244f420
	if (cr6.eq) goto loc_8244F420;
	// mr r7,r4
	ctx.r7.u64 = ctx.r4.u64;
loc_8244F2C0:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244f2e4
	if (cr6.eq) goto loc_8244F2E4;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244f2e4
	if (cr6.eq) goto loc_8244F2E4;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8244F2E4:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// slw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r11.u8 & 0x3F));
	// and. r10,r11,r9
	ctx.r10.u64 = r11.u64 & ctx.r9.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244f314
	if (!cr0.eq) goto loc_8244F314;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// or r9,r11,r9
	ctx.r9.u64 = r11.u64 | ctx.r9.u64;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r8,r3
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r3.u32, xer);
	// blt cr6,0x8244f2c0
	if (cr6.lt) goto loc_8244F2C0;
loc_8244F314:
	// cmplw cr6,r8,r3
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r3.u32, xer);
	// blt cr6,0x8244f420
	if (cr6.lt) goto loc_8244F420;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
loc_8244F324:
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwzx r11,r6,r4
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r4.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// lwzx r9,r6,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// beq cr6,0x8244f35c
	if (cr6.eq) goto loc_8244F35C;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwz r8,56(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 56);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x8244f35c
	if (cr6.eq) goto loc_8244F35C;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_8244F35C:
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r8,16(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r7,12(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244f414
	if (cr6.eq) goto loc_8244F414;
	// lwz r9,60(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8244f414
	if (!cr6.eq) goto loc_8244F414;
	// cmplwi cr6,r23,1
	cr6.compare<uint32_t>(r23.u32, 1, xer);
	// bne cr6,0x8244f3e8
	if (!cr6.eq) goto loc_8244F3E8;
	// lwz r7,52(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r20,48(r31)
	r20.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwzx r9,r9,r20
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r20.u32);
	// lwz r20,56(r31)
	r20.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// add r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 + ctx.r9.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r9,r20
	PPC_STORE_U32(ctx.r9.u32 + r20.u32, ctx.r10.u32);
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// lwz r7,48(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r20,56(r31)
	r20.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r11,r9,r20
	PPC_STORE_U32(ctx.r9.u32 + r20.u32, r11.u32);
loc_8244F3E8:
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r26,r26,2
	r26.s64 = r26.s64 + 2;
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r10,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r10.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_8244F414:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// bne 0x8244f324
	if (!cr0.eq) goto loc_8244F324;
loc_8244F420:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// add r29,r27,r29
	r29.u64 = r27.u64 + r29.u64;
	// bne 0x8244f1e0
	if (!cr0.eq) goto loc_8244F1E0;
loc_8244F42C:
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x8244f184
	if (cr6.lt) goto loc_8244F184;
loc_8244F440:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x8244f4a4
	if (!cr6.eq) goto loc_8244F4A4;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm. r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244f48c
	if (cr0.eq) goto loc_8244F48C;
	// li r11,0
	r11.s64 = 0;
loc_8244F460:
	// lwz r8,52(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r9,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r9.u32);
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r7,40(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// blt cr6,0x8244f460
	if (cr6.lt) goto loc_8244F460;
loc_8244F48C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r26,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,56(r31)
	PPC_STORE_U32(r31.u32 + 56, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
loc_8244F4A4:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// cmplwi cr6,r23,2
	cr6.compare<uint32_t>(r23.u32, 2, xer);
	// blt cr6,0x8244f158
	if (cr6.lt) goto loc_8244F158;
	// li r26,0
	r26.s64 = 0;
loc_8244F4B4:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244f644
	if (!cr6.gt) goto loc_8244F644;
	// li r28,0
	r28.s64 = 0;
loc_8244F4E0:
	// lwz r11,24(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// lwzx r30,r28,r11
	r30.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d228
	sub_8243D228(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8244f504
	if (!cr0.eq) goto loc_8244F504;
	// lwz r11,112(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 112);
	// rlwinm. r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244f630
	if (cr0.eq) goto loc_8244F630;
loc_8244F504:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// bne cr6,0x8244f630
	if (!cr6.eq) goto loc_8244F630;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// lwz r7,12(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// divwu. r10,r9,r11
	ctx.r10.u32 = ctx.r9.u32 / r11.u32;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// twllei r11,0
	// beq 0x8244f630
	if (cr0.eq) goto loc_8244F630;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
loc_8244F54C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244f578
	if (cr6.eq) goto loc_8244F578;
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8244f578
	if (cr6.eq) goto loc_8244F578;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8244F578:
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r21,r10
	cr6.compare<uint32_t>(r21.u32, ctx.r10.u32, xer);
	// bne cr6,0x8244f624
	if (!cr6.eq) goto loc_8244F624;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// beq cr6,0x8244f624
	if (cr6.eq) goto loc_8244F624;
	// cmplwi cr6,r26,1
	cr6.compare<uint32_t>(r26.u32, 1, xer);
	// bne cr6,0x8244f5f4
	if (!cr6.eq) goto loc_8244F5F4;
	// lwz r9,64(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,60(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r3.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r9,64(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,60(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r7,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, ctx.r7.u32);
loc_8244F5F4:
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r29,r29,2
	r29.s64 = r29.s64 + 2;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stwx r8,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r8.u32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_8244F624:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// add r6,r4,r6
	ctx.r6.u64 = ctx.r4.u64 + ctx.r6.u64;
	// bne 0x8244f54c
	if (!cr0.eq) goto loc_8244F54C;
loc_8244F630:
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x8244f4e0
	if (cr6.lt) goto loc_8244F4E0;
loc_8244F644:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x8244f6a4
	if (!cr6.eq) goto loc_8244F6A4;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244f68c
	if (!cr6.gt) goto loc_8244F68C;
	// li r11,0
	r11.s64 = 0;
loc_8244F664:
	// lwz r8,64(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r9,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r9.u32);
	// lwz r8,60(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwz r7,40(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// blt cr6,0x8244f664
	if (cr6.lt) goto loc_8244F664;
loc_8244F68C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r29,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,68(r31)
	PPC_STORE_U32(r31.u32 + 68, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
loc_8244F6A4:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmplwi cr6,r26,2
	cr6.compare<uint32_t>(r26.u32, 2, xer);
	// blt cr6,0x8244f4b4
	if (cr6.lt) goto loc_8244F4B4;
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244f7e8
	if (!cr6.gt) goto loc_8244F7E8;
	// li r26,0
	r26.s64 = 0;
loc_8244F6D8:
	// lwz r11,24(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// lwzx r30,r26,r11
	r30.u64 = PPC_LOAD_U32(r26.u32 + r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8244f7d4
	if (cr0.eq) goto loc_8244F7D4;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244f744
	if (!cr6.gt) goto loc_8244F744;
	// li r29,0
	r29.s64 = 0;
loc_8244F700:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x8244f730
	if (cr6.eq) goto loc_8244F730;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82446a90
	sub_82446A90(ctx, base);
loc_8244F730:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x8244f700
	if (cr6.lt) goto loc_8244F700;
loc_8244F744:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244f784
	if (!cr6.gt) goto loc_8244F784;
	// li r29,0
	r29.s64 = 0;
loc_8244F758:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// lwzx r5,r11,r29
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// bl 0x82446a90
	sub_82446A90(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x8244f758
	if (cr6.lt) goto loc_8244F758;
loc_8244F784:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d0e8
	sub_8243D0E8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8244f7d4
	if (cr0.eq) goto loc_8244F7D4;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244f7d4
	if (!cr6.gt) goto loc_8244F7D4;
	// li r29,0
	r29.s64 = 0;
loc_8244F7A8:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// lwzx r5,r11,r29
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// bl 0x82446a90
	sub_82446A90(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x8244f7a8
	if (cr6.lt) goto loc_8244F7A8;
loc_8244F7D4:
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x8244f6d8
	if (cr6.lt) goto loc_8244F6D8;
loc_8244F7E8:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// li r30,0
	r30.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244f828
	if (!cr6.gt) goto loc_8244F828;
	// li r11,0
	r11.s64 = 0;
loc_8244F800:
	// lwz r9,80(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r30,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, r30.u32);
	// lwz r9,76(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// lwz r8,72(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// add r30,r9,r30
	r30.u64 = ctx.r9.u64 + r30.u64;
	// blt cr6,0x8244f800
	if (cr6.lt) goto loc_8244F800;
loc_8244F828:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,84(r31)
	PPC_STORE_U32(r31.u32 + 84, ctx.r3.u32);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mulli r3,r30,12
	ctx.r3.s64 = r30.s64 * 12;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// stw r3,88(r31)
	PPC_STORE_U32(r31.u32 + 88, ctx.r3.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8244f860
	if (cr0.eq) goto loc_8244F860;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8244f868
	goto loc_8244F868;
loc_8244F860:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
loc_8244F868:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_8244F870"))) PPC_WEAK_FUNC(sub_8244F870);
PPC_FUNC_IMPL(__imp__sub_8244F870) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// lwz r9,16(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,56(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 56);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bne cr6,0x8244f8a8
	if (!cr6.eq) goto loc_8244F8A8;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// b 0x8244f8b4
	goto loc_8244F8B4;
loc_8244F8A8:
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r11,r9
	r29.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_8244F8B4:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lbz r11,0(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8244f8dc
	if (cr6.eq) goto loc_8244F8DC;
	// lbz r11,1(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8244f8dc
	if (!cr6.eq) goto loc_8244F8DC;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r5,r11,-24616
	ctx.r5.s64 = r11.s64 + -24616;
	// b 0x8244f8e4
	goto loc_8244F8E4;
loc_8244F8DC:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r5,r11,20352
	ctx.r5.s64 = r11.s64 + 20352;
loc_8244F8E4:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823df1b0
	sub_823DF1B0(ctx, base);
	// mr r11,r31
	r11.u64 = r31.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8244F8F8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8244f8f8
	if (!cr6.eq) goto loc_8244F8F8;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwz r6,12(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// subf r4,r11,r30
	ctx.r4.s64 = r30.s64 - r11.s64;
	// add r3,r11,r31
	ctx.r3.u64 = r11.u64 + r31.u64;
	// beq cr6,0x8244f938
	if (cr6.eq) goto loc_8244F938;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r5,r10,18988
	ctx.r5.s64 = ctx.r10.s64 + 18988;
	// bl 0x823df1b0
	sub_823DF1B0(ctx, base);
	// b 0x8244f944
	goto loc_8244F944;
loc_8244F938:
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// addi r5,r10,20348
	ctx.r5.s64 = ctx.r10.s64 + 20348;
	// bl 0x823df1b0
	sub_823DF1B0(ctx, base);
loc_8244F944:
	// add r11,r31,r30
	r11.u64 = r31.u64 + r30.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r10,-1(r11)
	PPC_STORE_U8(r11.u32 + -1, ctx.r10.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8244F958"))) PPC_WEAK_FUNC(sub_8244F958);
PPC_FUNC_IMPL(__imp__sub_8244F958) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,432
	ctx.r10.s64 = ctx.r1.s64 + 432;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x823defe0
	sub_823DEFE0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stb r4,351(r1)
	PPC_STORE_U8(ctx.r1.u32 + 351, ctx.r4.u8);
	// beq cr6,0x8244f9e4
	if (cr6.eq) goto loc_8244F9E4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x8244f9e0
	if (cr6.eq) goto loc_8244F9E0;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8244f9d4
	if (cr6.eq) goto loc_8244F9D4;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8244f9e4
	if (!cr6.eq) goto loc_8244F9E4;
	// addi r4,r31,48
	ctx.r4.s64 = r31.s64 + 48;
	// b 0x8244f9e4
	goto loc_8244F9E4;
loc_8244F9D4:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// b 0x8244f9e4
	goto loc_8244F9E4;
loc_8244F9E0:
	// addi r4,r31,16
	ctx.r4.s64 = r31.s64 + 16;
loc_8244F9E4:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// lwz r3,196(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 196);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r11,-24616
	ctx.r6.s64 = r11.s64 + -24616;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,212(r30)
	PPC_STORE_U32(r30.u32 + 212, r11.u32);
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8244FA10"))) PPC_WEAK_FUNC(sub_8244FA10);
PPC_FUNC_IMPL(__imp__sub_8244FA10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,432
	ctx.r10.s64 = ctx.r1.s64 + 432;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x823defe0
	sub_823DEFE0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stb r4,351(r1)
	PPC_STORE_U8(ctx.r1.u32 + 351, ctx.r4.u8);
	// beq cr6,0x8244fa9c
	if (cr6.eq) goto loc_8244FA9C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x8244fa98
	if (cr6.eq) goto loc_8244FA98;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8244fa8c
	if (cr6.eq) goto loc_8244FA8C;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8244fa9c
	if (!cr6.eq) goto loc_8244FA9C;
	// addi r4,r31,48
	ctx.r4.s64 = r31.s64 + 48;
	// b 0x8244fa9c
	goto loc_8244FA9C;
loc_8244FA8C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// b 0x8244fa9c
	goto loc_8244FA9C;
loc_8244FA98:
	// addi r4,r31,16
	ctx.r4.s64 = r31.s64 + 16;
loc_8244FA9C:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// lwz r3,196(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 196);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r11,-24616
	ctx.r6.s64 = r11.s64 + -24616;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823ebe20
	sub_823EBE20(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8244FAC0"))) PPC_WEAK_FUNC(sub_8244FAC0);
PPC_FUNC_IMPL(__imp__sub_8244FAC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r20,0
	r20.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r11,-1
	r11.s64 = -1;
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// ble cr6,0x8244fb10
	if (!cr6.gt) goto loc_8244FB10;
	// li r9,0
	ctx.r9.s64 = 0;
loc_8244FAEC:
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r8,r9,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stw r11,40(r8)
	PPC_STORE_U32(ctx.r8.u32 + 40, r11.u32);
	// stw r11,36(r8)
	PPC_STORE_U32(ctx.r8.u32 + 36, r11.u32);
	// lwz r8,4(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244faec
	if (cr6.lt) goto loc_8244FAEC;
loc_8244FB10:
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244fb48
	if (!cr6.gt) goto loc_8244FB48;
	// li r10,0
	ctx.r10.s64 = 0;
loc_8244FB24:
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r11,84(r8)
	PPC_STORE_U32(ctx.r8.u32 + 84, r11.u32);
	// stw r11,72(r8)
	PPC_STORE_U32(ctx.r8.u32 + 72, r11.u32);
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x8244fb24
	if (cr6.lt) goto loc_8244FB24;
loc_8244FB48:
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244fd6c
	if (!cr6.gt) goto loc_8244FD6C;
	// li r4,0
	ctx.r4.s64 = 0;
loc_8244FB5C:
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwzx r5,r4,r10
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r10.u32);
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm. r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8244fd58
	if (cr0.eq) goto loc_8244FD58;
	// lwz r10,4(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244fc50
	if (!cr6.gt) goto loc_8244FC50;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8244FB84:
	// lwz r10,8(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,84(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 84);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8244fba8
	if (!cr6.lt) goto loc_8244FBA8;
	// stw r11,84(r8)
	PPC_STORE_U32(ctx.r8.u32 + 84, r11.u32);
loc_8244FBA8:
	// addi r9,r8,8
	ctx.r9.s64 = ctx.r8.s64 + 8;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// b 0x8244fbf8
	goto loc_8244FBF8;
loc_8244FBB4:
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r3
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// lwz r3,40(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// bge cr6,0x8244fbd4
	if (!cr6.lt) goto loc_8244FBD4;
	// stw r11,40(r10)
	PPC_STORE_U32(ctx.r10.u32 + 40, r11.u32);
loc_8244FBD4:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,84(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x8244fbf4
	if (!cr6.lt) goto loc_8244FBF4;
	// stw r11,84(r10)
	PPC_STORE_U32(ctx.r10.u32 + 84, r11.u32);
loc_8244FBF4:
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
loc_8244FBF8:
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x8244fbb4
	if (!cr6.eq) goto loc_8244FBB4;
	// addi r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 + 20;
	// b 0x8244fc30
	goto loc_8244FC30;
loc_8244FC0C:
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,84(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x8244fc2c
	if (!cr6.lt) goto loc_8244FC2C;
	// stw r11,84(r10)
	PPC_STORE_U32(ctx.r10.u32 + 84, r11.u32);
loc_8244FC2C:
	// addi r10,r10,20
	ctx.r10.s64 = ctx.r10.s64 + 20;
loc_8244FC30:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x8244fc0c
	if (!cr6.eq) goto loc_8244FC0C;
	// lwz r10,4(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244fb84
	if (cr6.lt) goto loc_8244FB84;
loc_8244FC50:
	// lwz r10,12(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8244fd58
	if (!cr6.gt) goto loc_8244FD58;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8244FC64:
	// lwz r10,16(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,72(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8244fc88
	if (!cr6.lt) goto loc_8244FC88;
	// stw r11,72(r8)
	PPC_STORE_U32(ctx.r8.u32 + 72, r11.u32);
loc_8244FC88:
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x8244fd00
	if (cr6.eq) goto loc_8244FD00;
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,36(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x8244fcb8
	if (!cr6.lt) goto loc_8244FCB8;
	// stw r11,36(r10)
	PPC_STORE_U32(ctx.r10.u32 + 36, r11.u32);
loc_8244FCB8:
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// b 0x8244fce4
	goto loc_8244FCE4;
loc_8244FCC0:
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r3
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// lwz r3,40(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// bge cr6,0x8244fce0
	if (!cr6.lt) goto loc_8244FCE0;
	// stw r11,40(r9)
	PPC_STORE_U32(ctx.r9.u32 + 40, r11.u32);
loc_8244FCE0:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
loc_8244FCE4:
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,84(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x8244fd00
	if (!cr6.lt) goto loc_8244FD00;
	// stw r11,84(r10)
	PPC_STORE_U32(ctx.r10.u32 + 84, r11.u32);
loc_8244FD00:
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x8244fcc0
	if (!cr6.eq) goto loc_8244FCC0;
	// addi r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 + 20;
	// b 0x8244fd38
	goto loc_8244FD38;
loc_8244FD14:
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,84(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x8244fd34
	if (!cr6.lt) goto loc_8244FD34;
	// stw r11,84(r10)
	PPC_STORE_U32(ctx.r10.u32 + 84, r11.u32);
loc_8244FD34:
	// addi r10,r10,20
	ctx.r10.s64 = ctx.r10.s64 + 20;
loc_8244FD38:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x8244fd14
	if (!cr6.eq) goto loc_8244FD14;
	// lwz r10,12(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244fc64
	if (cr6.lt) goto loc_8244FC64;
loc_8244FD58:
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x8244fb5c
	if (cr6.lt) goto loc_8244FB5C;
loc_8244FD6C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x824424f0
	sub_824424F0(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8244ffd4
	if (!cr6.gt) goto loc_8244FFD4;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r21,0
	r21.s64 = 0;
	// addi r22,r11,20728
	r22.s64 = r11.s64 + 20728;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r24,r11,20676
	r24.s64 = r11.s64 + 20676;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r26,r11,20620
	r26.s64 = r11.s64 + 20620;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r28,r11,20560
	r28.s64 = r11.s64 + 20560;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r25,r11,20500
	r25.s64 = r11.s64 + 20500;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r23,r11,20424
	r23.s64 = r11.s64 + 20424;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r27,r11,20356
	r27.s64 = r11.s64 + 20356;
loc_8244FDC0:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r31,r21,r11
	r31.u64 = PPC_LOAD_U32(r21.u32 + r11.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x8244fdec
	if (!cr6.lt) goto loc_8244FDEC;
	// stw r10,84(r31)
	PPC_STORE_U32(r31.u32 + 84, ctx.r10.u32);
loc_8244FDEC:
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x8244fe00
	if (!cr6.lt) goto loc_8244FE00;
	// stw r10,72(r31)
	PPC_STORE_U32(r31.u32 + 72, ctx.r10.u32);
loc_8244FE00:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8244fe98
	if (!cr0.eq) goto loc_8244FE98;
	// lwz r8,84(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x8244fe98
	if (cr6.eq) goto loc_8244FE98;
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8244fe98
	if (cr6.gt) goto loc_8244FE98;
	// lwz r31,96(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x8244fe90
	if (cr0.eq) goto loc_8244FE90;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x8244fe90
	if (!cr6.eq) goto loc_8244FE90;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8244fe90
	if (cr0.eq) goto loc_8244FE90;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x8244fe90
	if (!cr6.eq) goto loc_8244FE90;
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8244ffa8
	if (!cr6.eq) goto loc_8244FFA8;
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// li r5,4000
	ctx.r5.s64 = 4000;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwzx r11,r9,r10
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r4,60(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// bl 0x8244f958
	sub_8244F958(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// b 0x8244ffa8
	goto loc_8244FFA8;
loc_8244FE90:
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// b 0x8244ff78
	goto loc_8244FF78;
loc_8244FE98:
	// rlwinm. r9,r11,0,26,26
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8244feb4
	if (cr0.eq) goto loc_8244FEB4;
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x8244feb4
	if (!cr6.eq) goto loc_8244FEB4;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// b 0x8244ff94
	goto loc_8244FF94;
loc_8244FEB4:
	// rlwinm. r9,r11,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8244fed0
	if (!cr0.eq) goto loc_8244FED0;
	// lwz r8,72(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x8244fed0
	if (cr6.eq) goto loc_8244FED0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// b 0x8244ff78
	goto loc_8244FF78;
loc_8244FED0:
	// andi. r9,r11,13
	ctx.r9.u64 = r11.u64 & 13;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne 0x8244fef0
	if (!cr0.eq) goto loc_8244FEF0;
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x8244fef0
	if (cr6.eq) goto loc_8244FEF0;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// b 0x8244ff94
	goto loc_8244FF94;
loc_8244FEF0:
	// lwz r9,216(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 216);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x8244ffac
	if (cr6.eq) goto loc_8244FFAC;
	// lis r12,1
	r12.s64 = 65536;
	// ori r12,r12,800
	r12.u64 = r12.u64 | 800;
	// and. r11,r11,r12
	r11.u64 = r11.u64 & r12.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8244ffac
	if (!cr0.eq) goto loc_8244FFAC;
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8244ffac
	if (!cr6.eq) goto loc_8244FFAC;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8244ff68
	if (!cr6.eq) goto loc_8244FF68;
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8244ffac
	if (cr6.eq) goto loc_8244FFAC;
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8243d0e8
	sub_8243D0E8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8244ffac
	if (!cr0.eq) goto loc_8244FFAC;
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// lis r9,8336
	ctx.r9.s64 = 546308096;
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8244ffac
	if (cr6.eq) goto loc_8244FFAC;
loc_8244FF68:
	// lwz r8,72(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x8244ff90
	if (cr6.eq) goto loc_8244FF90;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
loc_8244FF78:
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8244f958
	sub_8244F958(ctx, base);
	// b 0x8244ffa8
	goto loc_8244FFA8;
loc_8244FF90:
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
loc_8244FF94:
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8244f958
	sub_8244F958(ctx, base);
loc_8244FFA8:
	// li r20,1
	r20.s64 = 1;
loc_8244FFAC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r21,r21,4
	r21.s64 = r21.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8244fdc0
	if (cr6.lt) goto loc_8244FDC0;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// beq cr6,0x8244ffd4
	if (cr6.eq) goto loc_8244FFD4;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8244ffd8
	goto loc_8244FFD8;
loc_8244FFD4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8244FFD8:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_8244FFE0"))) PPC_WEAK_FUNC(sub_8244FFE0);
PPC_FUNC_IMPL(__imp__sub_8244FFE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r10,r11,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82450008
	if (cr0.eq) goto loc_82450008;
loc_82450000:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82450690
	goto loc_82450690;
loc_82450008:
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82450000
	if (!cr0.eq) goto loc_82450000;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244b5b8
	sub_8244B5B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82450690
	if (cr0.lt) goto loc_82450690;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,508
	ctx.r3.s64 = 508;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245003c
	if (cr0.eq) goto loc_8245003C;
	// bl 0x82483878
	sub_82483878(ctx, base);
	// b 0x82450040
	goto loc_82450040;
loc_8245003C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82450040:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,224(r31)
	PPC_STORE_U32(r31.u32 + 224, ctx.r3.u32);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// lis r5,18008
	ctx.r5.s64 = 1180172288;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// ori r5,r5,513
	ctx.r5.u64 = ctx.r5.u64 | 513;
	// ori r6,r11,256
	ctx.r6.u64 = r11.u64 | 256;
	// bl 0x82447b70
	sub_82447B70(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82450690
	if (cr0.lt) goto loc_82450690;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// bl 0x82442f10
	sub_82442F10(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82450690
	if (cr0.lt) goto loc_82450690;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824431e0
	sub_824431E0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82450690
	if (cr0.lt) goto loc_82450690;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r27,-1
	r27.s64 = -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824500d0
	if (!cr6.gt) goto loc_824500D0;
	// li r11,0
	r11.s64 = 0;
loc_824500A4:
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r27,48(r9)
	PPC_STORE_U32(ctx.r9.u32 + 48, r27.u32);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r27,68(r9)
	PPC_STORE_U32(ctx.r9.u32 + 68, r27.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x824500a4
	if (cr6.lt) goto loc_824500A4;
loc_824500D0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r29,r27
	r29.u64 = r27.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// li r19,0
	r19.s64 = 0;
	// addi r11,r11,23464
	r11.s64 = r11.s64 + 23464;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// lfd f31,-31368(r10)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// li r15,0
	r15.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// ble cr6,0x824503cc
	if (!cr6.gt) goto loc_824503CC;
	// li r14,0
	r14.s64 = 0;
loc_82450104:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r25,r11,r14
	r25.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// rlwinm. r10,r11,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824503b8
	if (cr0.eq) goto loc_824503B8;
	// clrlwi r20,r11,12
	r20.u64 = r11.u32 & 0xFFFFF;
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// li r18,0
	r18.s64 = 0;
	// divwu. r17,r11,r20
	r17.u32 = r11.u32 / r20.u32;
	cr0.compare<int32_t>(r17.s32, 0, xer);
	// twllei r20,0
	// beq 0x824503b8
	if (cr0.eq) goto loc_824503B8;
	// li r21,0
	r21.s64 = 0;
	// rlwinm r16,r20,2,0,29
	r16.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
loc_82450138:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x824503a4
	if (cr6.eq) goto loc_824503A4;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// add r8,r11,r21
	ctx.r8.u64 = r11.u64 + r21.u64;
loc_82450158:
	// lwz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82450190
	if (cr0.eq) goto loc_82450190;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243f338
	sub_8243F338(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82450190
	if (!cr0.eq) goto loc_82450190;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_82450190:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82450158
	if (!cr0.eq) goto loc_82450158;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824503a4
	if (cr6.eq) goto loc_824503A4;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// bne cr6,0x824501d4
	if (!cr6.eq) goto loc_824501D4;
	// lis r5,8
	ctx.r5.s64 = 524288;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r7,4
	ctx.r7.s64 = 4;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// ori r5,r5,593
	ctx.r5.u64 = ctx.r5.u64 | 593;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
loc_824501D4:
	// li r11,1
	r11.s64 = 1;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
	// lwz r11,224(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r23,r11,r10
	r23.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// li r28,0
	r28.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r22,0
	r22.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// mr r29,r21
	r29.u64 = r21.u64;
loc_82450228:
	// lwz r7,8(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r30,r7,r29
	r30.u64 = PPC_LOAD_U32(ctx.r7.u32 + r29.u32);
	// rlwinm r24,r30,2,0,29
	r24.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r24,r11
	ctx.r8.u64 = PPC_LOAD_U32(r24.u32 + r11.u32);
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82450364
	if (cr0.eq) goto loc_82450364;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243f338
	sub_8243F338(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82450364
	if (!cr0.eq) goto loc_82450364;
	// lwz r11,72(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82450298
	if (cr6.eq) goto loc_82450298;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,4112
	ctx.r9.s64 = 269484032;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x82450364
	if (cr6.eq) goto loc_82450364;
loc_82450298:
	// lwz r11,48(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824502ac
	if (cr6.eq) goto loc_824502AC;
	// stwx r11,r7,r29
	PPC_STORE_U32(ctx.r7.u32 + r29.u32, r11.u32);
	// b 0x82450364
	goto loc_82450364;
loc_824502AC:
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r4,132(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmpwi cr6,r27,-1
	cr6.compare<int32_t>(r27.s32, -1, xer);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// stwx r27,r11,r26
	PPC_STORE_U32(r11.u32 + r26.u32, r27.u32);
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// stwx r30,r11,r26
	PPC_STORE_U32(r11.u32 + r26.u32, r30.u32);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// stwx r3,r11,r29
	PPC_STORE_U32(r11.u32 + r29.u32, ctx.r3.u32);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
	// lwz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r10,r10,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r29.u32);
	// lwzx r4,r24,r11
	ctx.r4.u64 = PPC_LOAD_U32(r24.u32 + r11.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243de18
	sub_8243DE18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r27,68(r30)
	PPC_STORE_U32(r30.u32 + 68, r27.u32);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r27,-1
	r27.s64 = -1;
	// stw r11,96(r30)
	PPC_STORE_U32(r30.u32 + 96, r11.u32);
	// stw r11,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r11.u32);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// lwzx r10,r24,r10
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + ctx.r10.u32);
	// stw r11,48(r10)
	PPC_STORE_U32(ctx.r10.u32 + 48, r11.u32);
loc_82450364:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r22,r20
	cr6.compare<uint32_t>(r22.u32, r20.u32, xer);
	// blt cr6,0x82450228
	if (cr6.lt) goto loc_82450228;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82450388
	if (cr6.eq) goto loc_82450388;
	// clrlwi r11,r28,12
	r11.u64 = r28.u32 & 0xFFFFF;
	// oris r11,r11,4096
	r11.u64 = r11.u64 | 268435456;
	// b 0x8245038c
	goto loc_8245038C;
loc_82450388:
	// li r11,0
	r11.s64 = 0;
loc_8245038C:
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
	// stw r28,12(r23)
	PPC_STORE_U32(r23.u32 + 12, r28.u32);
	// stw r28,4(r23)
	PPC_STORE_U32(r23.u32 + 4, r28.u32);
	// beq cr6,0x824503a4
	if (cr6.eq) goto loc_824503A4;
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
loc_824503A4:
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r21,r16,r21
	r21.u64 = r16.u64 + r21.u64;
	// cmplw cr6,r18,r17
	cr6.compare<uint32_t>(r18.u32, r17.u32, xer);
	// blt cr6,0x82450138
	if (cr6.lt) goto loc_82450138;
loc_824503B8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r15,r15,1
	r15.s64 = r15.s64 + 1;
	// addi r14,r14,4
	r14.s64 = r14.s64 + 4;
	// cmplw cr6,r15,r11
	cr6.compare<uint32_t>(r15.u32, r11.u32, xer);
	// blt cr6,0x82450104
	if (cr6.lt) goto loc_82450104;
loc_824503CC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245056c
	if (!cr6.gt) goto loc_8245056C;
	// lwz r24,80(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r26,0
	r26.s64 = 0;
	// li r23,0
	r23.s64 = 0;
loc_824503E8:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r27,r11,r26
	r27.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r4,8(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// beq cr6,0x82450550
	if (cr6.eq) goto loc_82450550;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r28,r10,r11
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82450550
	if (cr0.eq) goto loc_82450550;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243f338
	sub_8243F338(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82450550
	if (!cr0.eq) goto loc_82450550;
	// lwz r11,48(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82450548
	if (!cr6.eq) goto loc_82450548;
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// bne cr6,0x82450470
	if (!cr6.eq) goto loc_82450470;
	// lis r5,8
	ctx.r5.s64 = 524288;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r7,4
	ctx.r7.s64 = 4;
	// li r6,-1
	ctx.r6.s64 = -1;
	// ori r5,r5,593
	ctx.r5.u64 = ctx.r5.u64 | 593;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e308
	sub_8243E308(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r24.u32);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
loc_82450470:
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
	// lwz r11,224(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,72(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 72);
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwzx r4,r9,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwzx r30,r11,r10
	r30.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// lwz r4,132(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 132);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,48(r28)
	PPC_STORE_U32(r28.u32 + 48, ctx.r3.u32);
	// beq cr6,0x8245069c
	if (cr6.eq) goto loc_8245069C;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243de18
	sub_8243DE18(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r23,96(r29)
	PPC_STORE_U32(r29.u32 + 96, r23.u32);
	// stw r23,100(r29)
	PPC_STORE_U32(r29.u32 + 100, r23.u32);
	// stw r11,68(r29)
	PPC_STORE_U32(r29.u32 + 68, r11.u32);
loc_82450548:
	// lwz r11,48(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
loc_82450550:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x824503e8
	if (cr6.lt) goto loc_824503E8;
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r27,-1
	r27.s64 = -1;
loc_8245056C:
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// bl 0x82448278
	sub_82448278(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82450584
	if (cr0.eq) goto loc_82450584;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82450690
	if (cr6.lt) goto loc_82450690;
loc_82450584:
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245059c
	if (cr0.eq) goto loc_8245059C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82450690
	if (cr6.lt) goto loc_82450690;
loc_8245059C:
	// lwz r3,224(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 224);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82448278
	sub_82448278(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824505bc
	if (cr0.eq) goto loc_824505BC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82450690
	if (cr6.lt) goto loc_82450690;
loc_824505BC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824505d4
	if (cr0.eq) goto loc_824505D4;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82450690
	if (cr6.lt) goto loc_82450690;
loc_824505D4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244b3d0
	sub_8244B3D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824505ec
	if (cr0.eq) goto loc_824505EC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82450690
	if (cr6.lt) goto loc_82450690;
loc_824505EC:
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x8245068c
	if (cr6.eq) goto loc_8245068C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245068c
	if (!cr6.gt) goto loc_8245068C;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
loc_8245060C:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r29
	cr6.compare<uint32_t>(ctx.r8.u32, r29.u32, xer);
	// bne cr6,0x8245062c
	if (!cr6.eq) goto loc_8245062C;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// ble cr6,0x8245062c
	if (!cr6.gt) goto loc_8245062C;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
loc_8245062C:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x8245060c
	if (!cr0.eq) goto loc_8245060C;
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// beq cr6,0x8245068c
	if (cr6.eq) goto loc_8245068C;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r11,0
	r11.s64 = 0;
loc_82450648:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r6,r29
	cr6.compare<uint32_t>(ctx.r6.u32, r29.u32, xer);
	// bne cr6,0x82450678
	if (!cr6.eq) goto loc_82450678;
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x82450678
	if (cr6.eq) goto loc_82450678;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// subf r9,r7,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r7.s64;
	// stw r9,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r9.u32);
loc_82450678:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// blt cr6,0x82450648
	if (cr6.lt) goto loc_82450648;
loc_8245068C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82450690:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
loc_8245069C:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82450690
	goto loc_82450690;
}

__attribute__((alias("__imp__sub_824506A8"))) PPC_WEAK_FUNC(sub_824506A8);
PPC_FUNC_IMPL(__imp__sub_824506A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,224(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 224);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824506bc
	if (!cr6.eq) goto loc_824506BC;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_824506BC:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245072c
	if (!cr6.gt) goto loc_8245072C;
	// li r9,0
	ctx.r9.s64 = 0;
loc_824506D0:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r8,68(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82450718
	if (cr6.eq) goto loc_82450718;
	// lwz r8,224(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 224);
	// lwz r7,68(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,20(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// lwzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// stw r6,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, ctx.r6.u32);
	// lwz r8,224(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 224);
	// lwz r11,68(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,20(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// stw r10,68(r11)
	PPC_STORE_U32(r11.u32 + 68, ctx.r10.u32);
loc_82450718:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x824506d0
	if (cr6.lt) goto loc_824506D0;
loc_8245072C:
	// lwz r3,224(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 224);
	// b 0x82447c98
	sub_82447C98(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82450734"))) PPC_WEAK_FUNC(sub_82450734);
PPC_FUNC_IMPL(__imp__sub_82450734) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82450738"))) PPC_WEAK_FUNC(sub_82450738);
PPC_FUNC_IMPL(__imp__sub_82450738) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8239d5e8
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	r27.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r25,-1
	r25.s64 = -1;
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// stw r30,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, r30.u32);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r27.u32);
	// stw r25,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r25.u32);
	// stw r25,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r25.u32);
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r27.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r11,r27
	r11.u64 = r27.u64;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x824507ac
	if (!cr6.gt) goto loc_824507AC;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
loc_8245078C:
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r25,64(r9)
	PPC_STORE_U32(ctx.r9.u32 + 64, r25.u32);
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8245078c
	if (cr6.lt) goto loc_8245078C;
loc_824507AC:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r14,r27
	r14.u64 = r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f30,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// ble cr6,0x82450d38
	if (!cr6.gt) goto loc_82450D38;
	// mr r15,r27
	r15.u64 = r27.u64;
loc_824507C8:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwzx r21,r15,r11
	r21.u64 = PPC_LOAD_U32(r15.u32 + r11.u32);
	// lwz r11,0(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82450d04
	if (cr0.eq) goto loc_82450D04;
	// lwz r10,12(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82450808
	if (cr0.eq) goto loc_82450808;
	// lwz r9,16(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm. r9,r9,0,25,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x82450d04
	if (!cr0.eq) goto loc_82450D04;
loc_82450808:
	// lis r9,8256
	ctx.r9.s64 = 541065216;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x82450820
	if (cr6.eq) goto loc_82450820;
	// lis r9,8272
	ctx.r9.s64 = 542113792;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x82450d04
	if (!cr6.eq) goto loc_82450D04;
loc_82450820:
	// mr r16,r27
	r16.u64 = r27.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82450d04
	if (cr6.eq) goto loc_82450D04;
	// mr r20,r27
	r20.u64 = r27.u64;
loc_82450830:
	// add r10,r10,r16
	ctx.r10.u64 = ctx.r10.u64 + r16.u64;
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// mr r19,r27
	r19.u64 = r27.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r18,r20,r11
	r18.u64 = r20.u64 + r11.u64;
	// add r17,r10,r11
	r17.u64 = ctx.r10.u64 + r11.u64;
	// mr r22,r27
	r22.u64 = r27.u64;
	// stw r18,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r18.u32);
	// stw r17,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r17.u32);
loc_82450854:
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// subfic r24,r19,1
	xer.ca = r19.u32 <= 1;
	r24.s64 = 1 - r19.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r17)
	ctx.r9.u64 = PPC_LOAD_U32(r17.u32 + 0);
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// lwzx r11,r9,r10
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// lwzx r11,r22,r7
	r11.u64 = PPC_LOAD_U32(r22.u32 + ctx.r7.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82450ce0
	if (cr0.eq) goto loc_82450CE0;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82450ce0
	if (!cr6.eq) goto loc_82450CE0;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r9,24(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,0(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// rlwinm. r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x82450ce0
	if (!cr0.eq) goto loc_82450CE0;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8245090c
	if (cr0.eq) goto loc_8245090C;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r5,r22,r5
	ctx.r5.u64 = PPC_LOAD_U32(r22.u32 + ctx.r5.u32);
	// lwz r5,0(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
loc_824508F0:
	// lwz r4,0(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x8245090c
	if (cr6.eq) goto loc_8245090C;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x824508f0
	if (cr6.lt) goto loc_824508F0;
loc_8245090C:
	// add r8,r8,r9
	ctx.r8.u64 = ctx.r8.u64 + ctx.r9.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r25,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r25.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// add r11,r8,r11
	r11.u64 = ctx.r8.u64 + r11.u64;
	// mr r23,r27
	r23.u64 = r27.u64;
	// stw r9,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r9.u32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r11,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// stw r8,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r8.u32);
	// stw r10,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r10.u32);
	// lwzx r31,r22,r7
	r31.u64 = PPC_LOAD_U32(r22.u32 + ctx.r7.u32);
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x824509c0
	if (!cr6.eq) goto loc_824509C0;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x824509c0
	if (cr6.eq) goto loc_824509C0;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r11,r24,2,0,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x8243f670
	sub_8243F670(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r25,88(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwzx r11,r22,r11
	r11.u64 = PPC_LOAD_U32(r22.u32 + r11.u32);
	// stw r25,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r25.u32);
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x8243f670
	sub_8243F670(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r23,r11,1
	r23.u64 = r11.u64 ^ 1;
loc_824509C0:
	// li r29,2
	r29.s64 = 2;
loc_824509C4:
	// addi r11,r1,152
	r11.s64 = ctx.r1.s64 + 152;
	// lwz r30,372(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// subfic r28,r29,5
	xer.ca = r29.u32 <= 5;
	r28.s64 = 5 - r29.s64;
	// lwzx r8,r27,r11
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r7,r11,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82450a2c
	if (cr0.eq) goto loc_82450A2C;
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82450a2c
	if (!cr6.eq) goto loc_82450A2C;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// rlwinm r11,r24,2,0,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82450a2c
	if (cr0.eq) goto loc_82450A2C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82450b18
	if (cr6.eq) goto loc_82450B18;
loc_82450A2C:
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82450b04
	if (!cr6.eq) goto loc_82450B04;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// rlwinm r26,r24,2,0,29
	r26.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r26,r11
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + r11.u32);
	// lwz r11,72(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82450a5c
	if (cr6.eq) goto loc_82450A5C;
	// lwz r6,72(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bge cr6,0x82450b04
	if (!cr6.lt) goto loc_82450B04;
loc_82450A5C:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82450b04
	if (!cr6.eq) goto loc_82450B04;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82450a94
	if (cr6.eq) goto loc_82450A94;
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82450a94
	if (!cr6.eq) goto loc_82450A94;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82450bf0
	if (cr0.eq) goto loc_82450BF0;
loc_82450A94:
	// addi r11,r1,136
	r11.s64 = ctx.r1.s64 + 136;
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// lwzx r30,r27,r11
	r30.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// lwzx r11,r10,r9
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// beq cr6,0x82450b04
	if (cr6.eq) goto loc_82450B04;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x82450aec
	if (!cr6.eq) goto loc_82450AEC;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lwz r3,372(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// stw r25,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r25.u32);
	// bl 0x8243f670
	sub_8243F670(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82450c60
	if (!cr0.eq) goto loc_82450C60;
loc_82450AEC:
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwzx r11,r26,r11
	r11.u64 = PPC_LOAD_U32(r26.u32 + r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82450c60
	if (cr6.eq) goto loc_82450C60;
loc_82450B04:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// blt cr6,0x824509c4
	if (cr6.lt) goto loc_824509C4;
	// b 0x82450cd4
	goto loc_82450CD4;
loc_82450B18:
	// lwz r11,0(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// lis r10,8256
	ctx.r10.s64 = 541065216;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82450b64
	if (cr6.eq) goto loc_82450B64;
	// lis r10,8272
	ctx.r10.s64 = 542113792;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82450b88
	if (!cr6.eq) goto loc_82450B88;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r24,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lfd f0,32(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// lfd f13,32(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fmul f1,f0,f13
	ctx.f1.f64 = f0.f64 * ctx.f13.f64;
	// b 0x82450b88
	goto loc_82450B88;
loc_82450B64:
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// rlwinm r11,r29,2,0,29
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r24,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// lfd f13,32(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fadd f1,f0,f13
	ctx.f1.f64 = f0.f64 + ctx.f13.f64;
loc_82450B88:
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r11,r28,2,0,29
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r22,r9
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + ctx.r9.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r4,120(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r11,r24,2,0,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// li r25,-1
	r25.s64 = -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r11,r11,r20
	r11.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r25,64(r11)
	PPC_STORE_U32(r11.u32 + 64, r25.u32);
	// b 0x82450cdc
	goto loc_82450CDC;
loc_82450BF0:
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lwz r30,372(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// rlwinm r11,r24,2,0,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r29,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// li r27,0
	r27.s64 = 0;
	// li r25,-1
	r25.s64 = -1;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r27,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r27.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r27,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r27.u32);
	// rlwinm r11,r11,0,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF0;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r25,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r25.u32);
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwzx r11,r11,r20
	r11.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r25,64(r11)
	PPC_STORE_U32(r11.u32 + 64, r25.u32);
	// b 0x82450ce0
	goto loc_82450CE0;
loc_82450C60:
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r11,r24,2,0,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r28,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// lwzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r11,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// rlwinm r11,r10,0,0,27
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// lwz r10,372(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r7,64(r31)
	PPC_STORE_U32(r31.u32 + 64, ctx.r7.u32);
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwzx r11,r11,r20
	r11.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r6,64(r11)
	PPC_STORE_U32(r11.u32 + 64, ctx.r6.u32);
loc_82450CD4:
	// lwz r30,372(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// li r25,-1
	r25.s64 = -1;
loc_82450CDC:
	// li r27,0
	r27.s64 = 0;
loc_82450CE0:
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// cmplwi cr6,r22,8
	cr6.compare<uint32_t>(r22.u32, 8, xer);
	// blt cr6,0x82450854
	if (cr6.lt) goto loc_82450854;
	// lwz r10,12(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// addi r16,r16,1
	r16.s64 = r16.s64 + 1;
	// addi r20,r20,4
	r20.s64 = r20.s64 + 4;
	// cmplw cr6,r16,r10
	cr6.compare<uint32_t>(r16.u32, ctx.r10.u32, xer);
	// blt cr6,0x82450830
	if (cr6.lt) goto loc_82450830;
loc_82450D04:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r14,r14,1
	r14.s64 = r14.s64 + 1;
	// addi r15,r15,4
	r15.s64 = r15.s64 + 4;
	// cmplw cr6,r14,r11
	cr6.compare<uint32_t>(r14.u32, r11.u32, xer);
	// blt cr6,0x824507c8
	if (cr6.lt) goto loc_824507C8;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82450d38
	if (cr6.eq) goto loc_82450D38;
	// li r11,1
	r11.s64 = 1;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
loc_82450D38:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// mr r26,r27
	r26.u64 = r27.u64;
	// lis r17,12288
	r17.s64 = 805306368;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82450f94
	if (!cr6.gt) goto loc_82450F94;
	// lwz r25,372(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// li r27,0
	r27.s64 = 0;
loc_82450D54:
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lwzx r30,r27,r11
	r30.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82450f80
	if (cr0.eq) goto loc_82450F80;
	// lwz r29,12(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x82450d94
	if (cr0.eq) goto loc_82450D94;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82450f80
	if (!cr0.eq) goto loc_82450F80;
loc_82450D94:
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// beq cr6,0x82450da8
	if (cr6.eq) goto loc_82450DA8;
	// lis r10,4352
	ctx.r10.s64 = 285212672;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82450f80
	if (!cr6.eq) goto loc_82450F80;
loc_82450DA8:
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82450f80
	if (cr6.eq) goto loc_82450F80;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82450DB8:
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r6,20(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r5,16(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwzx r31,r3,r4
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r4.u32);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r6
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// b 0x82450f4c
	goto loc_82450F4C;
loc_82450DE4:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82450f58
	if (!cr6.eq) goto loc_82450F58;
	// lwz r8,4(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r11,r29
	r11.u64 = r29.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x82450e2c
	if (!cr6.lt) goto loc_82450E2C;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
loc_82450E08:
	// lwz r24,0(r9)
	r24.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r7,r24
	cr6.compare<uint32_t>(ctx.r7.u32, r24.u32, xer);
	// beq cr6,0x82450e24
	if (cr6.eq) goto loc_82450E24;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82450e08
	if (cr6.lt) goto loc_82450E08;
loc_82450E24:
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82450f58
	if (cr6.lt) goto loc_82450F58;
loc_82450E2C:
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// li r11,0
	r11.s64 = 0;
	// lwz r9,24(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82450e6c
	if (cr0.eq) goto loc_82450E6C;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82450E50:
	// lwz r24,0(r8)
	r24.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r24,r7
	cr6.compare<uint32_t>(r24.u32, ctx.r7.u32, xer);
	// beq cr6,0x82450e6c
	if (cr6.eq) goto loc_82450E6C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82450e50
	if (cr6.lt) goto loc_82450E50;
loc_82450E6C:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lis r24,8256
	r24.s64 = 541065216;
	// rlwinm r8,r8,0,0,11
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r8,r24
	cr6.compare<uint32_t>(ctx.r8.u32, r24.u32, xer);
	// bne cr6,0x82450ea8
	if (!cr6.eq) goto loc_82450EA8;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r8,r10
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82450f58
	if (!cr6.eq) goto loc_82450F58;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// b 0x82450f30
	goto loc_82450F30;
loc_82450EA8:
	// lis r24,8272
	r24.s64 = 542113792;
	// cmplw cr6,r8,r24
	cr6.compare<uint32_t>(ctx.r8.u32, r24.u32, xer);
	// bne cr6,0x82450f58
	if (!cr6.eq) goto loc_82450F58;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r8,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r5
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r5.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,23,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82450f00
	if (cr0.eq) goto loc_82450F00;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x82450f00
	if (!cr6.gt) goto loc_82450F00;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// b 0x82450f30
	goto loc_82450F30;
loc_82450F00:
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82450f58
	if (cr0.eq) goto loc_82450F58;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x82450f58
	if (!cr6.gt) goto loc_82450F58;
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
loc_82450F30:
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_82450F4C:
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82450de4
	if (!cr0.eq) goto loc_82450DE4;
loc_82450F58:
	// cmplw cr6,r31,r7
	cr6.compare<uint32_t>(r31.u32, ctx.r7.u32, xer);
	// beq cr6,0x82450f6c
	if (cr6.eq) goto loc_82450F6C;
	// li r11,1
	r11.s64 = 1;
	// stwx r7,r3,r4
	PPC_STORE_U32(ctx.r3.u32 + ctx.r4.u32, ctx.r7.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_82450F6C:
	// lwz r29,12(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// cmplw cr6,r28,r29
	cr6.compare<uint32_t>(r28.u32, r29.u32, xer);
	// blt cr6,0x82450db8
	if (cr6.lt) goto loc_82450DB8;
loc_82450F80:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x82450d54
	if (cr6.lt) goto loc_82450D54;
loc_82450F94:
	// lwz r15,80(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r18,372(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x82450fbc
	if (cr6.eq) goto loc_82450FBC;
	// li r15,0
	r15.s64 = 0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// li r16,1
	r16.s64 = 1;
	// stw r15,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r15.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// b 0x82450fc0
	goto loc_82450FC0;
loc_82450FBC:
	// lwz r16,84(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82450FC0:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// li r19,0
	r19.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824513e0
	if (!cr6.gt) goto loc_824513E0;
	// li r20,0
	r20.s64 = 0;
loc_82450FD4:
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// lwzx r5,r20,r11
	ctx.r5.u64 = PPC_LOAD_U32(r20.u32 + r11.u32);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824513c8
	if (cr0.eq) goto loc_824513C8;
	// lwz r22,12(r5)
	r22.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmplwi r22,0
	cr0.compare<uint32_t>(r22.u32, 0, xer);
	// beq 0x82451014
	if (cr0.eq) goto loc_82451014;
	// lwz r10,16(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// lwz r9,20(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824513c8
	if (!cr0.eq) goto loc_824513C8;
loc_82451014:
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// bne cr6,0x824513c8
	if (!cr6.eq) goto loc_824513C8;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x824513c8
	if (cr6.eq) goto loc_824513C8;
	// li r21,0
	r21.s64 = 0;
loc_8245102C:
	// lwz r25,8(r5)
	r25.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r4,20(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r27,16(r18)
	r27.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// lwzx r7,r21,r25
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + r25.u32);
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824513b4
	if (cr0.eq) goto loc_824513B4;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x824513b4
	if (!cr6.eq) goto loc_824513B4;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r23,24(r18)
	r23.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r23
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824510a8
	if (cr0.eq) goto loc_824510A8;
	// lwz r8,16(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_8245108C:
	// lwz r6,0(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// beq cr6,0x824510a8
	if (cr6.eq) goto loc_824510A8;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x8245108c
	if (cr6.lt) goto loc_8245108C;
loc_824510A8:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lis r7,4112
	ctx.r7.s64 = 269484032;
	// rlwinm r24,r8,0,0,11
	r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r24,r7
	cr6.compare<uint32_t>(r24.u32, ctx.r7.u32, xer);
	// bne cr6,0x824510c4
	if (!cr6.eq) goto loc_824510C4;
	// li r26,1
	r26.s64 = 1;
	// b 0x824510d4
	goto loc_824510D4;
loc_824510C4:
	// lis r8,8272
	ctx.r8.s64 = 542113792;
	// cmplw cr6,r24,r8
	cr6.compare<uint32_t>(r24.u32, ctx.r8.u32, xer);
	// bne cr6,0x824513b4
	if (!cr6.eq) goto loc_824513B4;
	// li r26,2
	r26.s64 = 2;
loc_824510D4:
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x824513b4
	if (cr6.eq) goto loc_824513B4;
	// add r7,r11,r9
	ctx.r7.u64 = r11.u64 + ctx.r9.u64;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r29,r11,-4
	r29.s64 = r11.s64 * -4;
	// add r6,r8,r10
	ctx.r6.u64 = ctx.r8.u64 + ctx.r10.u64;
	// add r3,r9,r10
	ctx.r3.u64 = ctx.r9.u64 + ctx.r10.u64;
loc_82451100:
	// lis r11,8272
	r11.s64 = 542113792;
	// lwz r7,0(r6)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r4
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// bne cr6,0x82451154
	if (!cr6.eq) goto loc_82451154;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824512d8
	if (cr0.eq) goto loc_824512D8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x824512d8
	if (!cr6.eq) goto loc_824512D8;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// bge cr6,0x824512d8
	if (!cr6.lt) goto loc_824512D8;
loc_82451154:
	// rlwinm r11,r22,1,0,30
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bne cr6,0x824511b0
	if (!cr6.eq) goto loc_824511B0;
	// add r11,r22,r31
	r11.u64 = r22.u64 + r31.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r25
	r11.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r27
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r27.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,23,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x824511b0
	if (cr0.eq) goto loc_824511B0;
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// bne cr6,0x824511b0
	if (!cr6.eq) goto loc_824511B0;
	// lfd f0,32(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// beq cr6,0x824512f0
	if (cr6.eq) goto loc_824512F0;
loc_824511B0:
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824512d8
	if (cr0.eq) goto loc_824512D8;
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824512d8
	if (!cr6.eq) goto loc_824512D8;
	// lwz r11,72(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r23
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// bne cr6,0x824512d8
	if (!cr6.eq) goto loc_824512D8;
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82451220
	if (cr0.eq) goto loc_82451220;
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
loc_82451204:
	// lwz r14,0(r11)
	r14.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r14,r7
	cr6.compare<uint32_t>(r14.u32, ctx.r7.u32, xer);
	// beq cr6,0x82451220
	if (cr6.eq) goto loc_82451220;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x82451204
	if (cr6.lt) goto loc_82451204;
loc_82451220:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// add r7,r11,r9
	ctx.r7.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r7,r4
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	// lwzx r10,r10,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r7,r7,0,28,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82451268
	if (cr0.eq) goto loc_82451268;
	// li r7,0
	ctx.r7.s64 = 0;
	// b 0x8245129c
	goto loc_8245129C;
loc_82451268:
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r27
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r27.u32);
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm. r7,r7,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x824512d8
	if (cr0.eq) goto loc_824512D8;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x824512d8
	if (!cr6.eq) goto loc_824512D8;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x824512d8
	if (!cr6.gt) goto loc_824512D8;
	// li r7,1
	ctx.r7.s64 = 1;
loc_8245129C:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82451328
	if (!cr0.eq) goto loc_82451328;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824512d8
	if (cr0.eq) goto loc_824512D8;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824512d8
	if (!cr6.eq) goto loc_824512D8;
	// lfd f0,32(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// bgt cr6,0x82451330
	if (cr6.gt) goto loc_82451330;
loc_824512D8:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// add r6,r30,r6
	ctx.r6.u64 = r30.u64 + ctx.r6.u64;
	// add r3,r29,r3
	ctx.r3.u64 = r29.u64 + ctx.r3.u64;
	// cmplw cr6,r28,r26
	cr6.compare<uint32_t>(r28.u32, r26.u32, xer);
	// blt cr6,0x82451100
	if (cr6.lt) goto loc_82451100;
	// b 0x824513b4
	goto loc_824513B4;
loc_824512F0:
	// lwz r10,8(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// stwx r7,r21,r10
	PPC_STORE_U32(r21.u32 + ctx.r10.u32, ctx.r7.u32);
	// lwz r10,12(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// lwz r9,8(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r7,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r7.u32);
	// lwz r10,12(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// lwz r9,8(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r11,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r11.u32);
	// b 0x824513b0
	goto loc_824513B0;
loc_82451328:
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82451334
	goto loc_82451334;
loc_82451330:
	// li r6,1
	ctx.r6.s64 = 1;
loc_82451334:
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,12(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// add r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 + r31.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r7,r21,r11
	PPC_STORE_U32(r21.u32 + r11.u32, ctx.r7.u32);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// bne cr6,0x82451378
	if (!cr6.eq) goto loc_82451378;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_82451378:
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// lwz r7,8(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r9.u32);
	// beq cr6,0x82451398
	if (cr6.eq) goto loc_82451398;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_82451398:
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// lwz r9,8(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
loc_824513B0:
	// li r15,1
	r15.s64 = 1;
loc_824513B4:
	// lwz r22,12(r5)
	r22.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r21,r21,4
	r21.s64 = r21.s64 + 4;
	// cmplw cr6,r31,r22
	cr6.compare<uint32_t>(r31.u32, r22.u32, xer);
	// blt cr6,0x8245102c
	if (cr6.lt) goto loc_8245102C;
loc_824513C8:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// addi r20,r20,4
	r20.s64 = r20.s64 + 4;
	// cmplw cr6,r19,r11
	cr6.compare<uint32_t>(r19.u32, r11.u32, xer);
	// blt cr6,0x82450fd4
	if (cr6.lt) goto loc_82450FD4;
	// stw r15,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r15.u32);
loc_824513E0:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x824513fc
	if (cr6.eq) goto loc_824513FC;
	// li r15,0
	r15.s64 = 0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// li r16,1
	r16.s64 = 1;
	// stw r15,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r15.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
loc_824513FC:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824518b8
	if (!cr6.gt) goto loc_824518B8;
	// li r25,0
	r25.s64 = 0;
	// li r23,-1
	r23.s64 = -1;
loc_82451414:
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// lwzx r28,r11,r25
	r28.u64 = PPC_LOAD_U32(r11.u32 + r25.u32);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824518a4
	if (cr0.eq) goto loc_824518A4;
	// lwz r10,12(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82451454
	if (cr6.eq) goto loc_82451454;
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r9,20(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824518a4
	if (!cr0.eq) goto loc_824518A4;
loc_82451454:
	// lis r10,4176
	ctx.r10.s64 = 273678336;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824518a4
	if (!cr6.eq) goto loc_824518A4;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// mr r27,r23
	r27.u64 = r23.u64;
	// mr r26,r23
	r26.u64 = r23.u64;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824518a4
	if (!cr6.gt) goto loc_824518A4;
	// li r31,0
	r31.s64 = 0;
loc_8245147C:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,20(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r8,16(r18)
	ctx.r8.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// lwzx r9,r31,r11
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82451694
	if (cr0.eq) goto loc_82451694;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82451694
	if (!cr6.eq) goto loc_82451694;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lis r7,8272
	ctx.r7.s64 = 542113792;
	// lwz r10,24(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// bne cr6,0x82451694
	if (!cr6.eq) goto loc_82451694;
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8245150c
	if (cr0.eq) goto loc_8245150C;
	// lwz r11,16(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
loc_824514F0:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// beq cr6,0x8245150c
	if (cr6.eq) goto loc_8245150C;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// blt cr6,0x824514f0
	if (cr6.lt) goto loc_824514F0;
loc_8245150C:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
loc_82451514:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// mullw r11,r4,r11
	r11.s64 = int64_t(ctx.r4.s32) * int64_t(r11.s32);
	// lwz r10,20(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// lwz r7,16(r18)
	ctx.r7.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r11,r9
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82451684
	if (cr0.eq) goto loc_82451684;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82451684
	if (!cr6.eq) goto loc_82451684;
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lis r29,4192
	r29.s64 = 274726912;
	// lwz r7,24(r18)
	ctx.r7.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r9,r29
	cr6.compare<uint32_t>(ctx.r9.u32, r29.u32, xer);
	// bne cr6,0x82451684
	if (!cr6.eq) goto loc_82451684;
	// lwz r9,92(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x824515f8
	if (!cr6.eq) goto loc_824515F8;
	// lwz r29,16(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwzx r29,r29,r31
	r29.u64 = PPC_LOAD_U32(r29.u32 + r31.u32);
	// rlwinm r29,r29,2,0,29
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r29,r10
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + ctx.r10.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// rlwinm r10,r10,0,4,6
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	// rlwinm. r29,r10,0,4,4
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x824515c0
	if (cr0.eq) goto loc_824515C0;
	// lis r10,2048
	ctx.r10.s64 = 134217728;
	// b 0x824515dc
	goto loc_824515DC;
loc_824515C0:
	// rlwinm. r29,r10,0,5,5
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x824515d0
	if (cr0.eq) goto loc_824515D0;
	// lis r10,1024
	ctx.r10.s64 = 67108864;
	// b 0x824515dc
	goto loc_824515DC;
loc_824515D0:
	// rlwinm. r29,r10,0,6,6
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x824515dc
	if (cr0.eq) goto loc_824515DC;
	// lis r10,512
	ctx.r10.s64 = 33554432;
loc_824515DC:
	// rlwinm r29,r9,0,4,6
	r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r29,r10
	cr6.compare<uint32_t>(r29.u32, ctx.r10.u32, xer);
	// beq cr6,0x824515f8
	if (cr6.eq) goto loc_824515F8;
	// rlwinm r9,r9,0,7,3
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// li r15,1
	r15.s64 = 1;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_824515F8:
	// lwz r11,108(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 108);
	// rlwinm. r11,r11,0,7,7
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82451684
	if (cr0.eq) goto loc_82451684;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82451684
	if (!cr6.eq) goto loc_82451684;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r10,20(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82451684
	if (cr0.eq) goto loc_82451684;
	// lwz r9,12(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82451660
	if (cr0.eq) goto loc_82451660;
	// lwz r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
loc_82451644:
	// lwz r29,0(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r29,r6
	cr6.compare<uint32_t>(r29.u32, ctx.r6.u32, xer);
	// beq cr6,0x82451660
	if (cr6.eq) goto loc_82451660;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82451644
	if (cr6.lt) goto loc_82451644;
loc_82451660:
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// mullw r11,r3,r10
	r11.s64 = int64_t(ctx.r3.s32) * int64_t(ctx.r10.s32);
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwzx r27,r9,r7
	r27.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r26,r11,r10
	r26.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
loc_82451684:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r3,r3,-1
	ctx.r3.s64 = ctx.r3.s64 + -1;
	// cmplwi cr6,r4,2
	cr6.compare<uint32_t>(ctx.r4.u32, 2, xer);
	// blt cr6,0x82451514
	if (cr6.lt) goto loc_82451514;
loc_82451694:
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x8245147c
	if (cr6.lt) goto loc_8245147C;
	// stw r15,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r15.u32);
	// cmpwi cr6,r27,-1
	cr6.compare<int32_t>(r27.s32, -1, xer);
	// beq cr6,0x824518a4
	if (cr6.eq) goto loc_824518A4;
	// lis r4,20496
	ctx.r4.s64 = 1343225856;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// ori r4,r4,4
	ctx.r4.u64 = ctx.r4.u64 | 4;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// beq cr6,0x82451a3c
	if (cr6.eq) goto loc_82451A3C;
	// lis r4,4096
	ctx.r4.s64 = 268435456;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82451a3c
	if (cr6.eq) goto loc_82451A3C;
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r29,r9,r11
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r30,0
	r30.s64 = 0;
	// stw r27,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r27.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r27,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r27.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r26,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r26.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r26,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r26.u32);
loc_82451748:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,136(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stwx r3,r30,r11
	PPC_STORE_U32(r30.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82451a3c
	if (cr6.eq) goto loc_82451A3C;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r11,20(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// stw r11,20(r10)
	PPC_STORE_U32(ctx.r10.u32 + 20, r11.u32);
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwzx r9,r30,r9
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r11,20(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r30,16
	cr6.compare<uint32_t>(r30.u32, 16, xer);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,4,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// blt cr6,0x82451748
	if (cr6.lt) goto loc_82451748;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r11,-1
	ctx.r10.s64 = r11.s64 + -1;
	// cmplw cr6,r10,r24
	cr6.compare<uint32_t>(ctx.r10.u32, r24.u32, xer);
	// stw r11,12(r18)
	PPC_STORE_U32(r18.u32 + 12, r11.u32);
	// ble cr6,0x82451880
	if (!cr6.gt) goto loc_82451880;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r24,r10
	r11.s64 = ctx.r10.s64 - r24.s64;
loc_82451864:
	// lwz r10,24(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// lwz r8,-4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// bne 0x82451864
	if (!cr0.eq) goto loc_82451864;
loc_82451880:
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// stwx r31,r11,r25
	PPC_STORE_U32(r11.u32 + r25.u32, r31.u32);
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// add r11,r11,r25
	r11.u64 = r11.u64 + r25.u64;
	// stw r29,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r29.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// li r15,1
	r15.s64 = 1;
	// stw r15,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r15.u32);
loc_824518A4:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x82451414
	if (cr6.lt) goto loc_82451414;
loc_824518B8:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x824518d4
	if (cr6.eq) goto loc_824518D4;
	// li r15,0
	r15.s64 = 0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// li r16,1
	r16.s64 = 1;
	// stw r15,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r15.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
loc_824518D4:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82451a90
	if (!cr6.gt) goto loc_82451A90;
	// li r27,0
	r27.s64 = 0;
loc_824518E8:
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// lwzx r29,r11,r27
	r29.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82451a78
	if (cr0.eq) goto loc_82451A78;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82451928
	if (cr6.eq) goto loc_82451928;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r9,20(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82451a78
	if (!cr0.eq) goto loc_82451A78;
loc_82451928:
	// lis r10,4160
	ctx.r10.s64 = 272629760;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82451a78
	if (!cr6.eq) goto loc_82451A78;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82451a78
	if (!cr6.gt) goto loc_82451A78;
	// li r4,0
	ctx.r4.s64 = 0;
loc_82451948:
	// lwz r3,8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r31,20(r18)
	r31.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r30,16(r18)
	r30.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// lwzx r8,r3,r4
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r4.u32);
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82451a64
	if (cr0.eq) goto loc_82451A64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82451a64
	if (!cr6.eq) goto loc_82451A64;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lis r9,8256
	ctx.r9.s64 = 541065216;
	// lwz r10,24(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x82451a64
	if (!cr6.eq) goto loc_82451A64;
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x824519d8
	if (cr0.eq) goto loc_824519D8;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_824519BC:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r6,r8
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, xer);
	// beq cr6,0x824519d8
	if (cr6.eq) goto loc_824519D8;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// blt cr6,0x824519bc
	if (cr6.lt) goto loc_824519BC;
loc_824519D8:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,0
	r11.s64 = 0;
	// rlwinm r5,r7,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
loc_824519EC:
	// lwz r6,0(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r31
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r31.u32);
	// lwz r25,4(r6)
	r25.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm r25,r25,2,0,29
	r25.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r25,r25,r30
	r25.u64 = PPC_LOAD_U32(r25.u32 + r30.u32);
	// lwz r25,4(r25)
	r25.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// rlwinm. r25,r25,0,23,23
	r25.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// beq 0x82451a28
	if (cr0.eq) goto loc_82451A28;
	// lwz r25,0(r6)
	r25.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm. r25,r25,0,30,30
	r25.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// beq 0x82451a28
	if (cr0.eq) goto loc_82451A28;
	// lwz r6,8(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// beq cr6,0x82451a48
	if (cr6.eq) goto loc_82451A48;
loc_82451A28:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// add r8,r5,r8
	ctx.r8.u64 = ctx.r5.u64 + ctx.r8.u64;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// blt cr6,0x824519ec
	if (cr6.lt) goto loc_824519EC;
	// b 0x82451a64
	goto loc_82451A64;
loc_82451A3C:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8245260c
	goto loc_8245260C;
loc_82451A48:
	// subfic r11,r11,1
	xer.ca = r11.u32 <= 1;
	r11.s64 = 1 - r11.s64;
	// li r15,1
	r15.s64 = 1;
	// mullw r11,r11,r7
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r7.s32);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stwx r11,r3,r4
	PPC_STORE_U32(ctx.r3.u32 + ctx.r4.u32, r11.u32);
loc_82451A64:
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82451948
	if (cr6.lt) goto loc_82451948;
loc_82451A78:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x824518e8
	if (cr6.lt) goto loc_824518E8;
	// stw r15,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r15.u32);
loc_82451A90:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bne cr6,0x824525e4
	if (!cr6.eq) goto loc_824525E4;
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// bne cr6,0x824525e4
	if (!cr6.eq) goto loc_824525E4;
	// lwz r17,12(r18)
	r17.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// li r14,0
	r14.s64 = 0;
	// lwz r20,96(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r21,92(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmplwi r17,0
	cr0.compare<uint32_t>(r17.u32, 0, xer);
	// beq 0x82452598
	if (cr0.eq) goto loc_82452598;
	// lis r9,-32251
	ctx.r9.s64 = -2113601536;
	// lwz r15,100(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r16,104(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r26,-1
	r26.s64 = -1;
	// lfd f28,264(r9)
	ctx.fpscr.disableFlushMode();
	f28.u64 = PPC_LOAD_U64(ctx.r9.u32 + 264);
	// lfd f29,-30984(r10)
	f29.u64 = PPC_LOAD_U64(ctx.r10.u32 + -30984);
	// lfd f31,-31360(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_82451ADC:
	// addi r17,r17,-1
	r17.s64 = r17.s64 + -1;
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// rlwinm r19,r17,2,0,29
	r19.u64 = __builtin_rotateleft64(r17.u32 | (r17.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r23,r11,r19
	r23.u64 = PPC_LOAD_U32(r11.u32 + r19.u32);
	// lwz r31,12(r23)
	r31.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x82451b18
	if (cr0.eq) goto loc_82451B18;
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// lwz r10,20(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82452584
	if (!cr0.eq) goto loc_82452584;
loc_82451B18:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// lis r10,8256
	ctx.r10.s64 = 541065216;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82451b38
	if (cr6.eq) goto loc_82451B38;
	// lis r10,8272
	ctx.r10.s64 = 542113792;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82451f78
	if (!cr6.eq) goto loc_82451F78;
loc_82451B38:
	// cmplw cr6,r31,r14
	cr6.compare<uint32_t>(r31.u32, r14.u32, xer);
	// ble cr6,0x82451b90
	if (!cr6.gt) goto loc_82451B90;
	// cmplwi cr6,r31,16
	cr6.compare<uint32_t>(r31.u32, 16, xer);
	// mr r14,r31
	r14.u64 = r31.u64;
	// bgt cr6,0x82451b50
	if (cr6.gt) goto loc_82451B50;
	// li r14,16
	r14.s64 = 16;
loc_82451B50:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r14,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r20,r3
	r20.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r20.s32, 0, xer);
	// beq 0x824525d8
	if (cr0.eq) goto loc_824525D8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r14,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// beq 0x824525d8
	if (cr0.eq) goto loc_824525D8;
loc_82451B90:
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82451bfc
	if (cr6.eq) goto loc_82451BFC;
	// li r28,0
	r28.s64 = 0;
	// mr r30,r20
	r30.u64 = r20.u64;
	// mr r29,r21
	r29.u64 = r21.u64;
loc_82451BA8:
	// stw r26,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r26.u32);
	// stfd f31,0(r29)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r29.u32 + 0, f31.u64);
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// lwzx r4,r11,r28
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// bl 0x8243f670
	sub_8243F670(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82451bfc
	if (cr0.lt) goto loc_82451BFC;
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82451bfc
	if (cr6.eq) goto loc_82451BFC;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r27,r31
	cr6.compare<uint32_t>(r27.u32, r31.u32, xer);
	// blt cr6,0x82451ba8
	if (cr6.lt) goto loc_82451BA8;
loc_82451BFC:
	// cmplw cr6,r27,r31
	cr6.compare<uint32_t>(r27.u32, r31.u32, xer);
	// bne cr6,0x82451f78
	if (!cr6.eq) goto loc_82451F78;
	// li r25,1
	r25.s64 = 1;
	// li r11,0
	r11.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82451c6c
	if (cr6.eq) goto loc_82451C6C;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_82451C20:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82451c3c
	if (cr6.eq) goto loc_82451C3C;
	// lfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// lfd f13,-8(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -8);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x82451c3c
	if (cr6.eq) goto loc_82451C3C;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82451C3C:
	// lfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// blt cr6,0x82451c50
	if (cr6.lt) goto loc_82451C50;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x82451c54
	if (!cr6.gt) goto loc_82451C54;
loc_82451C50:
	// li r8,0
	ctx.r8.s64 = 0;
loc_82451C54:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// blt cr6,0x82451c20
	if (cr6.lt) goto loc_82451C20;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82451e30
	if (cr6.eq) goto loc_82451E30;
loc_82451C6C:
	// lfd f0,0(r21)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r21.u32 + 0);
	// fcmpu cr6,f0,f28
	cr6.compare(f0.f64, f28.f64);
	// bne cr6,0x82451d24
	if (!cr6.eq) goto loc_82451D24;
	// clrlwi r11,r31,12
	r11.u64 = r31.u32 & 0xFFFFF;
	// lwz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// oris r11,r11,8256
	r11.u64 = r11.u64 | 541065216;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82451cc8
	if (cr6.eq) goto loc_82451CC8;
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
	// rlwinm r30,r31,1,0,30
	r30.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bge cr6,0x82451cc8
	if (!cr6.lt) goto loc_82451CC8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d6d0
	sub_8243D6D0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r23)
	PPC_STORE_U32(r23.u32 + 8, ctx.r3.u32);
	// beq 0x824525d8
	if (cr0.eq) goto loc_824525D8;
	// rlwinm r5,r30,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r30,4(r23)
	PPC_STORE_U32(r23.u32 + 4, r30.u32);
	// li r4,255
	ctx.r4.s64 = 255;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
loc_82451CC8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82451f78
	if (cr6.eq) goto loc_82451F78;
	// li r11,0
	r11.s64 = 0;
	// rlwinm r8,r31,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
loc_82451CD8:
	// lwz r9,8(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwzx r10,r11,r20
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// lwzx r7,r11,r9
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// beq cr6,0x82451cf4
	if (cr6.eq) goto loc_82451CF4;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
loc_82451CF4:
	// lwz r9,8(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwzx r10,r11,r20
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// lwzx r7,r8,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// beq cr6,0x82451d10
	if (cr6.eq) goto loc_82451D10;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// stwx r10,r8,r9
	PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, ctx.r10.u32);
loc_82451D10:
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82451cd8
	if (!cr0.eq) goto loc_82451CD8;
	// b 0x82451f78
	goto loc_82451F78;
loc_82451D24:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x82451d64
	if (!cr6.eq) goto loc_82451D64;
	// mr r11,r31
	r11.u64 = r31.u64;
	// stw r31,4(r23)
	PPC_STORE_U32(r23.u32 + 4, r31.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// rlwimi r11,r25,28,0,11
	r11.u64 = (__builtin_rotateleft32(r25.u32, 28) & 0xFFF00000) | (r11.u64 & 0xFFFFFFFF000FFFFF);
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
	// beq cr6,0x82451dc8
	if (cr6.eq) goto loc_82451DC8;
	// li r11,0
	r11.s64 = 0;
loc_82451D48:
	// lwzx r10,r11,r20
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// lwz r9,8(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82451d48
	if (!cr0.eq) goto loc_82451D48;
	// b 0x82451dc8
	goto loc_82451DC8;
loc_82451D64:
	// fcmpu cr6,f0,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f30.f64);
	// bne cr6,0x82451dd0
	if (!cr6.eq) goto loc_82451DD0;
	// mr r11,r31
	r11.u64 = r31.u64;
	// stw r31,4(r23)
	PPC_STORE_U32(r23.u32 + 4, r31.u32);
	// cmpwi cr6,r16,-1
	cr6.compare<int32_t>(r16.s32, -1, xer);
	// rlwimi r11,r25,28,0,11
	r11.u64 = (__builtin_rotateleft32(r25.u32, 28) & 0xFFF00000) | (r11.u64 & 0xFFFFFFFF000FFFFF);
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
	// bne cr6,0x82451da8
	if (!cr6.eq) goto loc_82451DA8;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// cmpwi cr6,r16,-1
	cr6.compare<int32_t>(r16.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
loc_82451DA8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82451dc8
	if (cr6.eq) goto loc_82451DC8;
	// li r11,0
	r11.s64 = 0;
loc_82451DB4:
	// lwz r10,8(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// stwx r16,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r16.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82451db4
	if (!cr0.eq) goto loc_82451DB4;
loc_82451DC8:
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// b 0x82451f78
	goto loc_82451F78;
loc_82451DD0:
	// fcmpu cr6,f0,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f29.f64);
	// bne cr6,0x82451e30
	if (!cr6.eq) goto loc_82451E30;
	// clrlwi r11,r31,12
	r11.u64 = r31.u32 & 0xFFFFF;
	// lwz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// oris r11,r11,4112
	r11.u64 = r11.u64 | 269484032;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82451df8
	if (cr6.eq) goto loc_82451DF8;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
	// stw r31,4(r23)
	PPC_STORE_U32(r23.u32 + 4, r31.u32);
loc_82451DF8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82451f78
	if (cr6.eq) goto loc_82451F78;
	// li r11,0
	r11.s64 = 0;
loc_82451E04:
	// lwz r9,8(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwzx r10,r11,r20
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// lwzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// beq cr6,0x82451e20
	if (cr6.eq) goto loc_82451E20;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
loc_82451E20:
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82451e04
	if (!cr0.eq) goto loc_82451E04;
	// b 0x82451f78
	goto loc_82451F78;
loc_82451E30:
	// lwz r11,108(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 108);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82451e44
	if (cr0.eq) goto loc_82451E44;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82451f78
	if (cr6.eq) goto loc_82451F78;
loc_82451E44:
	// clrlwi r11,r31,12
	r11.u64 = r31.u32 & 0xFFFFF;
	// lwz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// oris r11,r11,8272
	r11.u64 = r11.u64 | 542113792;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82451e94
	if (cr6.eq) goto loc_82451E94;
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
	// rlwinm r30,r31,1,0,30
	r30.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bge cr6,0x82451e94
	if (!cr6.lt) goto loc_82451E94;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d6d0
	sub_8243D6D0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r23)
	PPC_STORE_U32(r23.u32 + 8, ctx.r3.u32);
	// beq 0x824525d8
	if (cr0.eq) goto loc_824525D8;
	// rlwinm r5,r30,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r30,4(r23)
	PPC_STORE_U32(r23.u32 + 4, r30.u32);
	// li r4,255
	ctx.r4.s64 = 255;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
loc_82451E94:
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82451f78
	if (cr6.eq) goto loc_82451F78;
	// li r30,0
	r30.s64 = 0;
	// rlwinm r29,r31,2,0,29
	r29.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_82451EAC:
	// lwz r10,8(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwzx r11,r30,r20
	r11.u64 = PPC_LOAD_U32(r30.u32 + r20.u32);
	// lwzx r9,r30,r10
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x82451ec8
	if (cr6.eq) goto loc_82451EC8;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// stwx r11,r30,r10
	PPC_STORE_U32(r30.u32 + ctx.r10.u32, r11.u32);
loc_82451EC8:
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82451ee8
	if (cr6.eq) goto loc_82451EE8;
	// lwz r10,20(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x82451eec
	goto loc_82451EEC;
loc_82451EE8:
	// li r11,0
	r11.s64 = 0;
loc_82451EEC:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82451f2c
	if (cr6.eq) goto loc_82451F2C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,16(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82451f2c
	if (cr0.eq) goto loc_82451F2C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82451f2c
	if (!cr6.eq) goto loc_82451F2C;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// lfd f13,0(r28)
	ctx.f13.u64 = PPC_LOAD_U64(r28.u32 + 0);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x82451f60
	if (cr6.eq) goto loc_82451F60;
loc_82451F2C:
	// li r6,0
	ctx.r6.s64 = 0;
	// lfd f1,0(r28)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r28.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,120(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 120);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// stwx r3,r29,r11
	PPC_STORE_U32(r29.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
loc_82451F60:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r28,r28,8
	r28.s64 = r28.s64 + 8;
	// cmplw cr6,r27,r31
	cr6.compare<uint32_t>(r27.u32, r31.u32, xer);
	// blt cr6,0x82451eac
	if (cr6.lt) goto loc_82451EAC;
loc_82451F78:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// lis r10,8272
	ctx.r10.s64 = 542113792;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82452584
	if (!cr6.eq) goto loc_82452584;
	// lwz r25,12(r23)
	r25.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// li r22,0
	r22.s64 = 0;
	// li r24,0
	r24.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// cmplwi r25,0
	cr0.compare<uint32_t>(r25.u32, 0, xer);
	// beq 0x82452160
	if (cr0.eq) goto loc_82452160;
loc_82451FA4:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r26.u32);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// add r5,r11,r20
	ctx.r5.u64 = r11.u64 + r20.u64;
	// stw r26,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r26.u32);
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r1,92
	ctx.r6.s64 = ctx.r1.s64 + 92;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// stw r26,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r26.u32);
	// lwz r10,16(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x8243f9f0
	sub_8243F9F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82452160
	if (cr0.lt) goto loc_82452160;
	// lwz r7,92(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// beq cr6,0x82452038
	if (cr6.eq) goto loc_82452038;
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82452038
	if (cr6.eq) goto loc_82452038;
	// lwz r11,20(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lfd f0,32(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// lfd f13,32(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x82452030
	if (cr6.lt) goto loc_82452030;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// b 0x82452038
	goto loc_82452038;
loc_82452030:
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// stw r7,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r7.u32);
loc_82452038:
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x82452090
	if (cr6.eq) goto loc_82452090;
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82452088
	if (cr6.eq) goto loc_82452088;
	// lwz r11,20(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// rlwinm r6,r9,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwzx r11,r5,r11
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// lfd f0,32(r6)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r6.u32 + 32);
	// lfd f13,32(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x82452080
	if (cr6.gt) goto loc_82452080;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// b 0x82452088
	goto loc_82452088;
loc_82452080:
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
loc_82452088:
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x824520e4
	if (!cr6.eq) goto loc_824520E4;
loc_82452090:
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x824520b4
	if (!cr6.eq) goto loc_824520B4;
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// beq cr6,0x824520b4
	if (cr6.eq) goto loc_824520B4;
	// lwz r9,20(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// rlwinm r8,r7,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// b 0x82452120
	goto loc_82452120;
loc_824520B4:
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x824520e4
	if (!cr6.eq) goto loc_824520E4;
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x824520e4
	if (!cr6.eq) goto loc_824520E4;
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x824520e4
	if (cr6.eq) goto loc_824520E4;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,0
	ctx.r10.s64 = 0;
loc_824520D4:
	// lwz r9,20(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// lis r11,8240
	r11.s64 = 540016640;
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// b 0x82452124
	goto loc_82452124;
loc_824520E4:
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x82452160
	if (!cr6.eq) goto loc_82452160;
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// bne cr6,0x82452160
	if (!cr6.eq) goto loc_82452160;
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82452108
	if (cr6.eq) goto loc_82452108;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x824520d4
	goto loc_824520D4;
loc_82452108:
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// beq cr6,0x82452160
	if (cr6.eq) goto loc_82452160;
	// lwz r8,20(r18)
	ctx.r8.u64 = PPC_LOAD_U32(r18.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
loc_82452120:
	// lis r11,8224
	r11.s64 = 538968064;
loc_82452124:
	// rlwinm r7,r31,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 3) & 0xFFFFFFF8;
	// lfd f0,32(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stfdx f0,r7,r21
	PPC_STORE_U64(ctx.r7.u32 + r21.u32, f0.u64);
	// bne cr6,0x82452144
	if (!cr6.eq) goto loc_82452144;
	// mr r22,r11
	r22.u64 = r11.u64;
	// mr r24,r10
	r24.u64 = ctx.r10.u64;
	// b 0x82452154
	goto loc_82452154;
loc_82452144:
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bne cr6,0x82452160
	if (!cr6.eq) goto loc_82452160;
	// cmpw cr6,r10,r24
	cr6.compare<int32_t>(ctx.r10.s32, r24.s32, xer);
	// bne cr6,0x82452160
	if (!cr6.eq) goto loc_82452160;
loc_82452154:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r25
	cr6.compare<uint32_t>(r31.u32, r25.u32, xer);
	// blt cr6,0x82451fa4
	if (cr6.lt) goto loc_82451FA4;
loc_82452160:
	// cmplw cr6,r31,r25
	cr6.compare<uint32_t>(r31.u32, r25.u32, xer);
	// bne cr6,0x82452584
	if (!cr6.eq) goto loc_82452584;
	// lwz r11,108(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 108);
	// rlwinm. r11,r11,0,8,8
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8245221c
	if (!cr0.eq) goto loc_8245221C;
	// rlwimi r22,r25,0,12,31
	r22.u64 = (__builtin_rotateleft32(r25.u32, 0) & 0xFFFFF) | (r22.u64 & 0xFFFFFFFFFFF00000);
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// stw r22,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r22.u32);
	// bne cr6,0x82452190
	if (!cr6.eq) goto loc_82452190;
	// li r10,0
	ctx.r10.s64 = 0;
	// beq cr6,0x82452198
	if (cr6.eq) goto loc_82452198;
loc_82452190:
	// li r11,0
	r11.s64 = 0;
	// b 0x8245219c
	goto loc_8245219C;
loc_82452198:
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8245219C:
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82452210
	if (cr6.eq) goto loc_82452210;
	// rlwinm r31,r11,2,0,29
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// mr r28,r21
	r28.u64 = r21.u64;
	// rlwinm r29,r10,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r30,r20
	r30.u64 = r20.u64;
loc_824521BC:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// stwx r10,r29,r11
	PPC_STORE_U32(r29.u32 + r11.u32, ctx.r10.u32);
	// lfd f1,0(r28)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r28.u32 + 0);
	// lwz r4,120(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// lwzx r10,r31,r11
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r28,r28,8
	r28.s64 = r28.s64 + 8;
	// cmplw cr6,r27,r25
	cr6.compare<uint32_t>(r27.u32, r25.u32, xer);
	// blt cr6,0x824521bc
	if (cr6.lt) goto loc_824521BC;
loc_82452210:
	// li r11,1
	r11.s64 = 1;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// b 0x82452584
	goto loc_82452584;
loc_8245221C:
	// clrlwi r31,r25,12
	r31.u64 = r25.u32 & 0xFFFFF;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// oris r4,r31,4112
	ctx.r4.u64 = r31.u64 | 269484032;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// rlwinm r5,r25,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 1) & 0xFFFFFFFE;
	// oris r4,r31,8256
	ctx.r4.u64 = r31.u64 | 541065216;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mulli r5,r25,3
	ctx.r5.s64 = r25.s64 * 3;
	// oris r4,r31,12288
	ctx.r4.u64 = r31.u64 | 805306368;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r3,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r29,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// lwzx r26,r10,r11
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r27,r8,r11
	r27.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r28,r9,r11
	r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// li r29,0
	r29.s64 = 0;
	// bne cr6,0x8245232c
	if (!cr6.eq) goto loc_8245232C;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245238c
	if (cr6.eq) goto loc_8245238C;
	// li r31,0
	r31.s64 = 0;
	// mr r30,r21
	r30.u64 = r21.u64;
loc_824522D8:
	// li r6,0
	ctx.r6.s64 = 0;
	// lfd f1,0(r30)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,120(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 120);
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwzx r10,r31,r20
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + r20.u32);
	// stwx r10,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r10.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// blt cr6,0x824522d8
	if (cr6.lt) goto loc_824522D8;
	// b 0x8245238c
	goto loc_8245238C;
loc_8245232C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245238c
	if (cr6.eq) goto loc_8245238C;
	// li r31,0
	r31.s64 = 0;
	// mr r30,r21
	r30.u64 = r21.u64;
loc_8245233C:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwzx r10,r31,r20
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + r20.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// stwx r10,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r10.u32);
	// lfd f1,0(r30)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// lwz r4,120(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 120);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// blt cr6,0x8245233c
	if (cr6.lt) goto loc_8245233C;
loc_8245238C:
	// cmpwi cr6,r15,-1
	cr6.compare<int32_t>(r15.s32, -1, xer);
	// bne cr6,0x824523b8
	if (!cr6.eq) goto loc_824523B8;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r15,r3
	r15.u64 = ctx.r3.u64;
	// cmpwi cr6,r15,-1
	cr6.compare<int32_t>(r15.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
loc_824523B8:
	// cmpwi cr6,r16,-1
	cr6.compare<int32_t>(r16.s32, -1, xer);
	// bne cr6,0x824523e4
	if (!cr6.eq) goto loc_824523E4;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// cmpwi cr6,r16,-1
	cr6.compare<int32_t>(r16.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
loc_824523E4:
	// lis r11,8240
	r11.s64 = 540016640;
	// cmplw cr6,r22,r11
	cr6.compare<uint32_t>(r22.u32, r11.u32, xer);
	// bne cr6,0x82452428
	if (!cr6.eq) goto loc_82452428;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245245c
	if (cr6.eq) goto loc_8245245C;
	// rlwinm r9,r25,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_82452404:
	// lwz r8,8(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stwx r15,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, r15.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,8(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stwx r16,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, r16.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82452404
	if (!cr0.eq) goto loc_82452404;
	// b 0x8245245c
	goto loc_8245245C;
loc_82452428:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245245c
	if (cr6.eq) goto loc_8245245C;
	// rlwinm r9,r25,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8245243C:
	// lwz r8,8(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stwx r16,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, r16.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,8(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stwx r15,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, r15.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x8245243c
	if (!cr0.eq) goto loc_8245243C;
loc_8245245C:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82452510
	if (cr6.eq) goto loc_82452510;
	// li r31,0
	r31.s64 = 0;
	// rlwinm r30,r25,2,0,29
	r30.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
loc_82452470:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,136(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 136);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// stwx r10,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r10.u32);
	// lwz r4,136(r18)
	ctx.r4.u64 = PPC_LOAD_U32(r18.u32 + 136);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// stwx r3,r31,r11
	PPC_STORE_U32(r31.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,16(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// stwx r11,r31,r10
	PPC_STORE_U32(r31.u32 + ctx.r10.u32, r11.u32);
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824525d8
	if (cr6.eq) goto loc_824525D8;
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// stwx r11,r10,r30
	PPC_STORE_U32(ctx.r10.u32 + r30.u32, r11.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// stwx r11,r10,r31
	PPC_STORE_U32(ctx.r10.u32 + r31.u32, r11.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// blt cr6,0x82452470
	if (cr6.lt) goto loc_82452470;
loc_82452510:
	// lwz r11,12(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 12);
	// addi r10,r11,-3
	ctx.r10.s64 = r11.s64 + -3;
	// cmplw cr6,r10,r17
	cr6.compare<uint32_t>(ctx.r10.u32, r17.u32, xer);
	// ble cr6,0x82452544
	if (!cr6.gt) goto loc_82452544;
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r17,r10
	ctx.r10.s64 = ctx.r10.s64 - r17.s64;
loc_82452528:
	// lwz r9,24(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// stw r8,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, ctx.r8.u32);
	// bne 0x82452528
	if (!cr0.eq) goto loc_82452528;
loc_82452544:
	// lwz r11,24(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// addi r9,r17,3
	ctx.r9.s64 = r17.s64 + 3;
	// addi r10,r17,2
	ctx.r10.s64 = r17.s64 + 2;
	// add r11,r11,r19
	r11.u64 = r11.u64 + r19.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r26,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r26.u32);
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,24(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// li r26,-1
	r26.s64 = -1;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// stwx r28,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r28.u32);
	// lwz r10,24(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 24);
	// stwx r27,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r27.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
loc_82452584:
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// bne cr6,0x82451adc
	if (!cr6.eq) goto loc_82451ADC;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x824525c8
	if (!cr6.eq) goto loc_824525C8;
loc_82452598:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82448278
	sub_82448278(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x824525f0
	if (cr0.lt) goto loc_824525F0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x824525f0
	if (cr0.lt) goto loc_824525F0;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x8244b3d0
	sub_8244B3D0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x824525f0
	if (cr0.lt) goto loc_824525F0;
loc_824525C8:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r31,r11,27,31,31
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x824525f0
	goto loc_824525F0;
loc_824525D8:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x824525f0
	goto loc_824525F0;
loc_824525E4:
	// lwz r20,96(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r31,0
	r31.s64 = 0;
	// lwz r21,92(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_824525F0:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8245260C:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8239d634
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_8245261C"))) PPC_WEAK_FUNC(sub_8245261C);
PPC_FUNC_IMPL(__imp__sub_8245261C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82452620"))) PPC_WEAK_FUNC(sub_82452620);
PPC_FUNC_IMPL(__imp__sub_82452620) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stfd f30,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, f30.u64);
	// stfd f31,-88(r1)
	PPC_STORE_U64(ctx.r1.u32 + -88, f31.u64);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r27,0
	r27.s64 = 0;
	// li r24,0
	r24.s64 = 0;
	// li r23,0
	r23.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82452aac
	if (!cr6.gt) goto loc_82452AAC;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r25,0
	r25.s64 = 0;
	// lfd f30,-28592(r10)
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -28592);
	// lfd f31,-31368(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82452668:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,116(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// lwzx r30,r25,r11
	r30.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82452a90
	if (cr6.eq) goto loc_82452A90;
	// addi r29,r30,8
	r29.s64 = r30.s64 + 8;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82452a90
	if (cr6.eq) goto loc_82452A90;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x824526a4
	if (!cr6.eq) goto loc_824526A4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// li r23,1
	r23.s64 = 1;
loc_824526A4:
	// lwz r28,0(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r11,r28,2,0,29
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82452720
	if (cr6.eq) goto loc_82452720;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x82452720
	if (!cr6.eq) goto loc_82452720;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82452710
	if (cr0.eq) goto loc_82452710;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_824526F4:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r7,r28
	cr6.compare<uint32_t>(ctx.r7.u32, r28.u32, xer);
	// beq cr6,0x82452710
	if (cr6.eq) goto loc_82452710;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x824526f4
	if (cr6.lt) goto loc_824526F4;
loc_82452710:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// b 0x82452724
	goto loc_82452724;
loc_82452720:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_82452724:
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r4,0(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// beq 0x82452744
	if (cr0.eq) goto loc_82452744;
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64;
	// b 0x82452748
	goto loc_82452748;
loc_82452744:
	// fmr f0,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = f30.f64;
loc_82452748:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r9,r10,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824528b0
	if (cr0.eq) goto loc_824528B0;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x824528b0
	if (!cr6.eq) goto loc_824528B0;
	// lfd f13,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// fadd f0,f13,f0
	f0.f64 = ctx.f13.f64 + f0.f64;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// add r7,r11,r10
	ctx.r7.u64 = r11.u64 + ctx.r10.u64;
	// beq 0x82452858
	if (cr0.eq) goto loc_82452858;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
loc_824527A4:
	// cmplw cr6,r8,r26
	cr6.compare<uint32_t>(ctx.r8.u32, r26.u32, xer);
	// beq cr6,0x82452808
	if (cr6.eq) goto loc_82452808;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r6,4(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// bne cr6,0x82452808
	if (!cr6.eq) goto loc_82452808;
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// bne cr6,0x82452808
	if (!cr6.eq) goto loc_82452808;
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// bne cr6,0x82452808
	if (!cr6.eq) goto loc_82452808;
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r5,16(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x82452808
	if (!cr6.eq) goto loc_82452808;
	// lwz r6,20(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r5,20(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplw cr6,r6,r5
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, xer);
	// bne cr6,0x82452808
	if (!cr6.eq) goto loc_82452808;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r6,24(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmpw cr6,r11,r6
	cr6.compare<int32_t>(r11.s32, ctx.r6.s32, xer);
	// beq cr6,0x8245281c
	if (cr6.eq) goto loc_8245281C;
loc_82452808:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x824527a4
	if (cr6.lt) goto loc_824527A4;
	// b 0x82452858
	goto loc_82452858;
loc_8245281C:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x82452854
	if (!cr6.eq) goto loc_82452854;
	// li r11,0
	r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
loc_8245282C:
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r6,r10,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r6)
	PPC_STORE_U32(ctx.r6.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8245282c
	if (cr6.lt) goto loc_8245282C;
	// li r24,1
	r24.s64 = 1;
loc_82452854:
	// stw r8,48(r30)
	PPC_STORE_U32(r30.u32 + 48, ctx.r8.u32);
loc_82452858:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// bne cr6,0x82452a8c
	if (!cr6.eq) goto loc_82452A8C;
	// li r11,-1
	r11.s64 = -1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r7,12(r30)
	PPC_STORE_U32(r30.u32 + 12, ctx.r7.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x82452a8c
	if (cr6.lt) goto loc_82452A8C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r4,96(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 96);
	// li r5,4007
	ctx.r5.s64 = 4007;
	// addi r6,r11,32272
	ctx.r6.s64 = r11.s64 + 32272;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244f958
	sub_8244F958(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82452ac8
	goto loc_82452AC8;
loc_824528B0:
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82452a90
	if (cr0.eq) goto loc_82452A90;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82452a90
	if (cr6.eq) goto loc_82452A90;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,8256
	ctx.r9.s64 = 541065216;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x82452a90
	if (!cr6.eq) goto loc_82452A90;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82452914
	if (cr0.eq) goto loc_82452914;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_824528F8:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r7,r4
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r4.u32, xer);
	// beq cr6,0x82452914
	if (cr6.eq) goto loc_82452914;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x824528f8
	if (cr6.lt) goto loc_824528F8;
loc_82452914:
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r7,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm. r7,r7,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8245298c
	if (cr0.eq) goto loc_8245298C;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x8245298c
	if (!cr6.eq) goto loc_8245298C;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r5,r7,0,29,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8245298c
	if (cr0.eq) goto loc_8245298C;
	// rlwinm. r7,r7,0,30,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82452984
	if (!cr0.eq) goto loc_82452984;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r7,r7,0,30,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8245298c
	if (cr0.eq) goto loc_8245298C;
loc_82452984:
	// lfd f13,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// b 0x824529d8
	goto loc_824529D8;
loc_8245298C:
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82452a90
	if (cr0.eq) goto loc_82452A90;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82452a90
	if (!cr6.eq) goto loc_82452A90;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r7,r9,0,29,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82452a90
	if (cr0.eq) goto loc_82452A90;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824529d0
	if (!cr0.eq) goto loc_824529D0;
	// rlwinm. r11,r9,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82452a90
	if (cr0.eq) goto loc_82452A90;
loc_824529D0:
	// lfd f13,32(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_824529D8:
	// fadd f0,f13,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f13.f64 + f0.f64;
	// addi r11,r1,116
	r11.s64 = ctx.r1.s64 + 116;
	// cmplw cr6,r4,r28
	cr6.compare<uint32_t>(ctx.r4.u32, r28.u32, xer);
	// li r6,0
	ctx.r6.s64 = 0;
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bne cr6,0x82452a44
	if (!cr6.eq) goto loc_82452A44;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82452a8c
	if (!cr6.gt) goto loc_82452A8C;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82452A04:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// bne cr6,0x82452a2c
	if (!cr6.eq) goto loc_82452A2C;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r8,116(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
loc_82452A2C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x82452a04
	if (cr6.lt) goto loc_82452A04;
	// b 0x82452a8c
	goto loc_82452A8C;
loc_82452A44:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82452a88
	if (!cr6.gt) goto loc_82452A88;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82452A50:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// bne cr6,0x82452a74
	if (!cr6.eq) goto loc_82452A74;
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r8,116(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// add r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 + ctx.r8.u64;
	// stw r8,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r8.u32);
loc_82452A74:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x82452a50
	if (cr6.lt) goto loc_82452A50;
loc_82452A88:
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
loc_82452A8C:
	// li r27,1
	r27.s64 = 1;
loc_82452A90:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x82452668
	if (cr6.lt) goto loc_82452668;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82452ab4
	if (!cr6.eq) goto loc_82452AB4;
loc_82452AAC:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82452ac8
	goto loc_82452AC8;
loc_82452AB4:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x82452ac4
	if (cr6.eq) goto loc_82452AC4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
loc_82452AC4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82452AC8:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f30,-96(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_82452AD8"))) PPC_WEAK_FUNC(sub_82452AD8);
PPC_FUNC_IMPL(__imp__sub_82452AD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bccc
	// stfd f31,-136(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -136, f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lwz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwz r7,16(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// lwzx r18,r10,r11
	r18.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r19,48(r10)
	r19.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// lwz r10,4(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 4);
	// rlwinm r8,r19,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r24,r8,r11
	r24.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82452e4c
	if (cr0.eq) goto loc_82452E4C;
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82452e4c
	if (!cr0.eq) goto loc_82452E4C;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm r28,r9,0,0,11
	r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// lwz r10,0(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// lis r8,4096
	ctx.r8.s64 = 268435456;
	// clrlwi r9,r11,27
	ctx.r9.u64 = r11.u32 & 0x1F;
	// rlwinm r5,r10,0,25,25
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// bne cr6,0x82452b64
	if (!cr6.eq) goto loc_82452B64;
	// or r11,r10,r9
	r11.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r19,48(r18)
	PPC_STORE_U32(r18.u32 + 48, r19.u32);
	// stw r11,0(r18)
	PPC_STORE_U32(r18.u32 + 0, r11.u32);
	// b 0x82452e4c
	goto loc_82452E4C;
loc_82452B64:
	// lwz r10,0(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// rlwinm r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// lis r8,4112
	ctx.r8.s64 = 269484032;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// lis r3,4144
	ctx.r3.s64 = 271581184;
	// lis r7,4304
	ctx.r7.s64 = 282066944;
	// lis r6,4320
	ctx.r6.s64 = 283115520;
	// stw r11,0(r18)
	PPC_STORE_U32(r18.u32 + 0, r11.u32);
	// rlwinm. r10,r11,0,4,6
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lis r10,4160
	ctx.r10.s64 = 272629760;
	// bne 0x82452bcc
	if (!cr0.eq) goto loc_82452BCC;
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// beq cr6,0x82452bb8
	if (cr6.eq) goto loc_82452BB8;
	// cmplw cr6,r28,r3
	cr6.compare<uint32_t>(r28.u32, ctx.r3.u32, xer);
	// beq cr6,0x82452bb8
	if (cr6.eq) goto loc_82452BB8;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// beq cr6,0x82452bb8
	if (cr6.eq) goto loc_82452BB8;
	// cmplw cr6,r28,r7
	cr6.compare<uint32_t>(r28.u32, ctx.r7.u32, xer);
	// beq cr6,0x82452bb8
	if (cr6.eq) goto loc_82452BB8;
	// cmplw cr6,r28,r6
	cr6.compare<uint32_t>(r28.u32, ctx.r6.u32, xer);
	// bne cr6,0x82452bcc
	if (!cr6.eq) goto loc_82452BCC;
loc_82452BB8:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r31,0(r18)
	r31.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// rlwinm r11,r11,0,4,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// or r11,r11,r31
	r11.u64 = r11.u64 | r31.u64;
	// stw r11,0(r18)
	PPC_STORE_U32(r18.u32 + 0, r11.u32);
loc_82452BCC:
	// lis r23,4176
	r23.s64 = 273678336;
	// lis r22,4208
	r22.s64 = 275775488;
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// beq cr6,0x82452c28
	if (cr6.eq) goto loc_82452C28;
	// cmplw cr6,r28,r3
	cr6.compare<uint32_t>(r28.u32, ctx.r3.u32, xer);
	// beq cr6,0x82452c08
	if (cr6.eq) goto loc_82452C08;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// beq cr6,0x82452bfc
	if (cr6.eq) goto loc_82452BFC;
	// cmplw cr6,r28,r23
	cr6.compare<uint32_t>(r28.u32, r23.u32, xer);
	// beq cr6,0x82452bfc
	if (cr6.eq) goto loc_82452BFC;
	// cmplw cr6,r28,r22
	cr6.compare<uint32_t>(r28.u32, r22.u32, xer);
	// bne cr6,0x82452c48
	if (!cr6.eq) goto loc_82452C48;
loc_82452BFC:
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// b 0x82452c44
	goto loc_82452C44;
loc_82452C08:
	// rlwinm. r11,r9,0,29,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82452c18
	if (cr0.eq) goto loc_82452C18;
	// rlwinm. r11,r9,0,28,28
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82452bfc
	if (!cr0.eq) goto loc_82452BFC;
loc_82452C18:
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// rlwinm r31,r9,0,28,29
	r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xC;
	// or r11,r31,r11
	r11.u64 = r31.u64 | r11.u64;
	// b 0x82452c44
	goto loc_82452C44;
loc_82452C28:
	// rlwinm r11,r9,31,29,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x4;
	// lwz r31,0(r18)
	r31.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// rlwinm r30,r9,1,28,28
	r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x8;
	// rlwinm r29,r9,0,30,27
	r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF3;
	// or r11,r11,r30
	r11.u64 = r11.u64 | r30.u64;
	// or r11,r11,r29
	r11.u64 = r11.u64 | r29.u64;
	// or r11,r11,r31
	r11.u64 = r11.u64 | r31.u64;
loc_82452C44:
	// stw r11,0(r18)
	PPC_STORE_U32(r18.u32 + 0, r11.u32);
loc_82452C48:
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// lwz r20,16(r25)
	r20.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r20
	r11.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r31,r11,0,23,23
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x82452f04
	if (cr0.eq) goto loc_82452F04;
	// lwz r31,8(r24)
	r31.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// bne cr6,0x82452f04
	if (!cr6.eq) goto loc_82452F04;
	// lis r11,4224
	r11.s64 = 276824064;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// bgt cr6,0x82452de8
	if (cr6.gt) goto loc_82452DE8;
	// beq cr6,0x82452ddc
	if (cr6.eq) goto loc_82452DDC;
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// beq cr6,0x82452dd0
	if (cr6.eq) goto loc_82452DD0;
	// cmplw cr6,r28,r3
	cr6.compare<uint32_t>(r28.u32, ctx.r3.u32, xer);
	// beq cr6,0x82452da0
	if (cr6.eq) goto loc_82452DA0;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// beq cr6,0x82452d7c
	if (cr6.eq) goto loc_82452D7C;
	// cmplw cr6,r28,r23
	cr6.compare<uint32_t>(r28.u32, r23.u32, xer);
	// beq cr6,0x82452d68
	if (cr6.eq) goto loc_82452D68;
	// lis r11,4192
	r11.s64 = 274726912;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x82452d14
	if (cr6.eq) goto loc_82452D14;
	// cmplw cr6,r28,r22
	cr6.compare<uint32_t>(r28.u32, r22.u32, xer);
	// bne cr6,0x82452e4c
	if (!cr6.eq) goto loc_82452E4C;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82452d08
	if (!cr6.eq) goto loc_82452D08;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// lfd f31,-31368(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x82452ce0
	if (!cr6.lt) goto loc_82452CE0;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,4003
	ctx.r5.s64 = 4003;
	// addi r6,r11,20864
	ctx.r6.s64 = r11.s64 + 20864;
	// b 0x82452cf4
	goto loc_82452CF4;
loc_82452CE0:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x82452d08
	if (!cr6.eq) goto loc_82452D08;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,4001
	ctx.r5.s64 = 4001;
	// addi r6,r11,20844
	ctx.r6.s64 = r11.s64 + 20844;
loc_82452CF4:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r4,60(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 60);
	// bl 0x8244f958
	sub_8244F958(ctx, base);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// b 0x82452e30
	goto loc_82452E30;
loc_82452D08:
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// fsqrt f13,f0
	ctx.f13.f64 = sqrt(f0.f64);
	// b 0x82452dc0
	goto loc_82452DC0;
loc_82452D14:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// bne cr6,0x82452d30
	if (!cr6.eq) goto loc_82452D30;
	// lfd f0,32(r24)
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x82452e4c
	if (cr6.eq) goto loc_82452E4C;
loc_82452D30:
	// lfd f1,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// bge cr6,0x82452d4c
	if (!cr6.lt) goto loc_82452D4C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,4002
	ctx.r5.s64 = 4002;
	// addi r6,r11,20820
	ctx.r6.s64 = r11.s64 + 20820;
	// b 0x82452cf4
	goto loc_82452CF4;
loc_82452D4C:
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// lfd f1,264(r11)
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 264);
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// fdiv f1,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64 / ctx.f1.f64;
	// b 0x82452e30
	goto loc_82452E30;
loc_82452D68:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lfd f2,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// lfd f1,264(r11)
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 264);
	// bl 0x8239e6a0
	sub_8239E6A0(ctx, base);
	// b 0x82452e30
	goto loc_82452E30;
loc_82452D7C:
	// lfd f1,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// bl 0x823ae098
	sub_823AE098(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82452e28
	if (cr0.eq) goto loc_82452E28;
	// lfd f1,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// bl 0x8239da30
	sub_8239DA30(ctx, base);
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// fsub f1,f0,f1
	ctx.f1.f64 = f0.f64 - ctx.f1.f64;
	// b 0x82452e30
	goto loc_82452E30;
loc_82452DA0:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82452dbc
	if (!cr6.eq) goto loc_82452DBC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// lfd f1,-31368(r11)
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// beq cr6,0x82452e30
	if (cr6.eq) goto loc_82452E30;
loc_82452DBC:
	// lfd f13,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r24.u32 + 32);
loc_82452DC0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fdiv f1,f0,f13
	ctx.f1.f64 = f0.f64 / ctx.f13.f64;
	// b 0x82452e30
	goto loc_82452E30;
loc_82452DD0:
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// b 0x82452e30
	goto loc_82452E30;
loc_82452DDC:
	// lfd f1,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// bl 0x8239ddc0
	sub_8239DDC0(ctx, base);
	// b 0x82452e30
	goto loc_82452E30;
loc_82452DE8:
	// lis r11,4240
	r11.s64 = 277872640;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x82452ef8
	if (cr6.eq) goto loc_82452EF8;
	// lis r11,4256
	r11.s64 = 278921216;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x82452eb0
	if (cr6.eq) goto loc_82452EB0;
	// lis r11,4272
	r11.s64 = 279969792;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x82452e68
	if (cr6.eq) goto loc_82452E68;
	// lis r11,4288
	r11.s64 = 281018368;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x82452e5c
	if (cr6.eq) goto loc_82452E5C;
	// cmplw cr6,r28,r7
	cr6.compare<uint32_t>(r28.u32, ctx.r7.u32, xer);
	// beq cr6,0x82452e28
	if (cr6.eq) goto loc_82452E28;
	// cmplw cr6,r28,r6
	cr6.compare<uint32_t>(r28.u32, ctx.r6.u32, xer);
	// bne cr6,0x82452e4c
	if (!cr6.eq) goto loc_82452E4C;
loc_82452E28:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f1,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82452E30:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82452E48:
	// stw r11,48(r18)
	PPC_STORE_U32(r18.u32 + 48, r11.u32);
loc_82452E4C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f31,-136(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// b 0x8239bd1c
	return;
loc_82452E5C:
	// lfd f1,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// bl 0x8239df68
	sub_8239DF68(ctx, base);
	// b 0x82452e30
	goto loc_82452E30;
loc_82452E68:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82452ea4
	if (!cr6.eq) goto loc_82452EA4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// lfd f13,-30984(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -30984);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x82452e94
	if (cr6.lt) goto loc_82452E94;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,-31360(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x82452ea4
	if (!cr6.gt) goto loc_82452EA4;
loc_82452E94:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,4006
	ctx.r5.s64 = 4006;
	// addi r6,r11,20796
	ctx.r6.s64 = r11.s64 + 20796;
	// b 0x82452f54
	goto loc_82452F54;
loc_82452EA4:
	// lfd f1,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// bl 0x8239ddb8
	sub_8239DDB8(ctx, base);
	// b 0x82452e30
	goto loc_82452E30;
loc_82452EB0:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82452eec
	if (!cr6.eq) goto loc_82452EEC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,32(r24)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// lfd f13,-30984(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -30984);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x82452edc
	if (cr6.lt) goto loc_82452EDC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,-31360(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x82452eec
	if (!cr6.gt) goto loc_82452EEC;
loc_82452EDC:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,4005
	ctx.r5.s64 = 4005;
	// addi r6,r11,20776
	ctx.r6.s64 = r11.s64 + 20776;
	// b 0x82452f54
	goto loc_82452F54;
loc_82452EEC:
	// lfd f1,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// bl 0x8239dcf0
	sub_8239DCF0(ctx, base);
	// b 0x82452e30
	goto loc_82452E30;
loc_82452EF8:
	// lfd f1,32(r24)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r24.u32 + 32);
	// bl 0x8239de90
	sub_8239DE90(ctx, base);
	// b 0x82452e30
	goto loc_82452E30;
loc_82452F04:
	// clrlwi. r31,r9,31
	r31.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x82452f14
	if (cr0.eq) goto loc_82452F14;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// beq cr6,0x82452e28
	if (cr6.eq) goto loc_82452E28;
loc_82452F14:
	// rlwinm. r31,r9,0,30,30
	r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x82452f24
	if (cr0.eq) goto loc_82452F24;
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// beq cr6,0x82452e28
	if (cr6.eq) goto loc_82452E28;
loc_82452F24:
	// rlwinm. r10,r9,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lis r21,4192
	r21.s64 = 274726912;
	// beq 0x82452f90
	if (cr0.eq) goto loc_82452F90;
	// cmplw cr6,r28,r21
	cr6.compare<uint32_t>(r28.u32, r21.u32, xer);
	// beq cr6,0x82452f64
	if (cr6.eq) goto loc_82452F64;
	// cmplw cr6,r28,r22
	cr6.compare<uint32_t>(r28.u32, r22.u32, xer);
	// bne cr6,0x82452f90
	if (!cr6.eq) goto loc_82452F90;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82452e4c
	if (!cr6.eq) goto loc_82452E4C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,4003
	ctx.r5.s64 = 4003;
	// addi r6,r11,20864
	ctx.r6.s64 = r11.s64 + 20864;
loc_82452F54:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r4,60(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 60);
	// bl 0x8244f958
	sub_8244F958(ctx, base);
	// b 0x82452e28
	goto loc_82452E28;
loc_82452F64:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82452e4c
	if (!cr6.eq) goto loc_82452E4C;
	// rlwinm. r11,r9,0,29,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82452e4c
	if (!cr0.eq) goto loc_82452E4C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r4,60(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 60);
	// li r5,4002
	ctx.r5.s64 = 4002;
	// addi r6,r11,20820
	ctx.r6.s64 = r11.s64 + 20820;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8244f958
	sub_8244F958(ctx, base);
	// b 0x82452e4c
	goto loc_82452E4C;
loc_82452F90:
	// rlwinm. r10,r11,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82452fa8
	if (cr0.eq) goto loc_82452FA8;
	// cmplw cr6,r28,r7
	cr6.compare<uint32_t>(r28.u32, ctx.r7.u32, xer);
	// beq cr6,0x82452e28
	if (cr6.eq) goto loc_82452E28;
	// cmplw cr6,r28,r6
	cr6.compare<uint32_t>(r28.u32, ctx.r6.u32, xer);
	// beq cr6,0x82452e28
	if (cr6.eq) goto loc_82452E28;
loc_82452FA8:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82452e4c
	if (!cr6.eq) goto loc_82452E4C;
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82452e4c
	if (cr0.eq) goto loc_82452E4C;
	// cmplw cr6,r28,r8
	cr6.compare<uint32_t>(r28.u32, ctx.r8.u32, xer);
	// bne cr6,0x82452fe0
	if (!cr6.eq) goto loc_82452FE0;
	// lwz r11,72(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 72);
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// beq cr6,0x82453058
	if (cr6.eq) goto loc_82453058;
loc_82452FE0:
	// cmplw cr6,r28,r3
	cr6.compare<uint32_t>(r28.u32, ctx.r3.u32, xer);
	// bne cr6,0x82453008
	if (!cr6.eq) goto loc_82453008;
	// lwz r11,72(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 72);
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r3
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r3.u32, xer);
	// beq cr6,0x82453058
	if (cr6.eq) goto loc_82453058;
loc_82453008:
	// cmplw cr6,r28,r23
	cr6.compare<uint32_t>(r28.u32, r23.u32, xer);
	// bne cr6,0x82453030
	if (!cr6.eq) goto loc_82453030;
	// lwz r11,72(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 72);
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r21
	cr6.compare<uint32_t>(ctx.r10.u32, r21.u32, xer);
	// beq cr6,0x82453058
	if (cr6.eq) goto loc_82453058;
loc_82453030:
	// cmplw cr6,r28,r21
	cr6.compare<uint32_t>(r28.u32, r21.u32, xer);
	// bne cr6,0x824530b0
	if (!cr6.eq) goto loc_824530B0;
	// lwz r11,72(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 72);
	// lwz r10,24(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r23
	cr6.compare<uint32_t>(ctx.r10.u32, r23.u32, xer);
	// bne cr6,0x824530b0
	if (!cr6.eq) goto loc_824530B0;
loc_82453058:
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82453088
	if (cr0.eq) goto loc_82453088;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_8245306C:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r7,r19
	cr6.compare<uint32_t>(ctx.r7.u32, r19.u32, xer);
	// beq cr6,0x82453088
	if (cr6.eq) goto loc_82453088;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x8245306c
	if (cr6.lt) goto loc_8245306C;
loc_82453088:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bge cr6,0x824530b0
	if (!cr6.lt) goto loc_824530B0;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,20(r25)
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_824530A8:
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82452e48
	goto loc_82452E48;
loc_824530B0:
	// lis r26,8272
	r26.s64 = 542113792;
	// cmplw cr6,r28,r3
	cr6.compare<uint32_t>(r28.u32, ctx.r3.u32, xer);
	// bne cr6,0x824531d4
	if (!cr6.eq) goto loc_824531D4;
	// lwz r11,72(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 72);
	// lwz r27,24(r25)
	r27.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r27
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bne cr6,0x824531d4
	if (!cr6.eq) goto loc_824531D4;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8245310c
	if (cr0.eq) goto loc_8245310C;
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_824530F0:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r7,r19
	cr6.compare<uint32_t>(ctx.r7.u32, r19.u32, xer);
	// beq cr6,0x8245310c
	if (cr6.eq) goto loc_8245310C;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x824530f0
	if (cr6.lt) goto loc_824530F0;
loc_8245310C:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// li r5,0
	ctx.r5.s64 = 0;
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// lwz r31,20(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// add r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r29,r11,-4
	r29.s64 = r11.s64 * -4;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
loc_82453138:
	// lwz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r20
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r20.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824531c0
	if (cr0.eq) goto loc_824531C0;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r27
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bne cr6,0x824531c0
	if (!cr6.eq) goto loc_824531C0;
	// lwz r6,12(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x824531ac
	if (cr0.eq) goto loc_824531AC;
	// lwz r7,16(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_82453190:
	// lwz r17,0(r7)
	r17.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplw cr6,r17,r4
	cr6.compare<uint32_t>(r17.u32, ctx.r4.u32, xer);
	// beq cr6,0x824531ac
	if (cr6.eq) goto loc_824531AC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// blt cr6,0x82453190
	if (cr6.lt) goto loc_82453190;
loc_824531AC:
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x824532f0
	if (cr6.eq) goto loc_824532F0;
loc_824531C0:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// add r8,r30,r8
	ctx.r8.u64 = r30.u64 + ctx.r8.u64;
	// add r10,r29,r10
	ctx.r10.u64 = r29.u64 + ctx.r10.u64;
	// cmplwi cr6,r5,2
	cr6.compare<uint32_t>(ctx.r5.u32, 2, xer);
	// blt cr6,0x82453138
	if (cr6.lt) goto loc_82453138;
loc_824531D4:
	// cmplw cr6,r28,r23
	cr6.compare<uint32_t>(r28.u32, r23.u32, xer);
	// bne cr6,0x82452e4c
	if (!cr6.eq) goto loc_82452E4C;
	// lwz r11,72(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 72);
	// lwz r31,24(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r10,r26
	cr6.compare<uint32_t>(ctx.r10.u32, r26.u32, xer);
	// bne cr6,0x82452e4c
	if (!cr6.eq) goto loc_82452E4C;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8245322c
	if (cr0.eq) goto loc_8245322C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
loc_82453210:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r7,r19
	cr6.compare<uint32_t>(ctx.r7.u32, r19.u32, xer);
	// beq cr6,0x8245322c
	if (cr6.eq) goto loc_8245322C;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x82453210
	if (cr6.lt) goto loc_82453210;
loc_8245322C:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,20(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// li r4,0
	ctx.r4.s64 = 0;
	// rlwinm r3,r8,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r11,r10
	ctx.r7.u64 = r11.u64 + ctx.r10.u64;
loc_82453244:
	// lwz r5,0(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r20
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r20.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824532dc
	if (cr0.eq) goto loc_824532DC;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r31
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// bne cr6,0x824532dc
	if (!cr6.eq) goto loc_824532DC;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x824532b4
	if (cr0.eq) goto loc_824532B4;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
loc_82453298:
	// lwz r30,0(r9)
	r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r30,r5
	cr6.compare<uint32_t>(r30.u32, ctx.r5.u32, xer);
	// beq cr6,0x824532b4
	if (cr6.eq) goto loc_824532B4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82453298
	if (cr6.lt) goto loc_82453298;
loc_824532B4:
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824532dc
	if (cr0.eq) goto loc_824532DC;
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82452e28
	if (!cr0.eq) goto loc_82452E28;
loc_824532DC:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// add r7,r3,r7
	ctx.r7.u64 = ctx.r3.u64 + ctx.r7.u64;
	// cmplwi cr6,r4,2
	cr6.compare<uint32_t>(ctx.r4.u32, 2, xer);
	// blt cr6,0x82453244
	if (cr6.lt) goto loc_82453244;
	// b 0x82452e4c
	goto loc_82452E4C;
loc_824532F0:
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// b 0x824530a8
	goto loc_824530A8;
}

__attribute__((alias("__imp__sub_824532FC"))) PPC_WEAK_FUNC(sub_824532FC);
PPC_FUNC_IMPL(__imp__sub_824532FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82453300"))) PPC_WEAK_FUNC(sub_82453300);
PPC_FUNC_IMPL(__imp__sub_82453300) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -176, f29.u64);
	// stfd f30,-168(r1)
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-496(r1)
	ea = -496 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r17,r5
	r17.u64 = ctx.r5.u64;
	// stw r7,548(r1)
	PPC_STORE_U32(ctx.r1.u32 + 548, ctx.r7.u32);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r16,r4
	r16.u64 = ctx.r4.u64;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// mr r18,r8
	r18.u64 = ctx.r8.u64;
	// mr r24,r9
	r24.u64 = ctx.r9.u64;
	// stw r17,532(r1)
	PPC_STORE_U32(ctx.r1.u32 + 532, r17.u32);
	// mr r23,r10
	r23.u64 = ctx.r10.u64;
	// stw r19,516(r1)
	PPC_STORE_U32(ctx.r1.u32 + 516, r19.u32);
	// stw r16,524(r1)
	PPC_STORE_U32(ctx.r1.u32 + 524, r16.u32);
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// stw r31,540(r1)
	PPC_STORE_U32(ctx.r1.u32 + 540, r31.u32);
	// stw r18,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, r18.u32);
	// stw r24,564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 564, r24.u32);
	// stw r23,572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 572, r23.u32);
	// beq cr6,0x824548a4
	if (cr6.eq) goto loc_824548A4;
	// cmplwi cr6,r17,4
	cr6.compare<uint32_t>(r17.u32, 4, xer);
	// ble cr6,0x8245336c
	if (!cr6.gt) goto loc_8245336C;
loc_82453364:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x824548a8
	goto loc_824548A8;
loc_8245336C:
	// li r6,1
	ctx.r6.s64 = 1;
	// cmplwi cr6,r17,1
	cr6.compare<uint32_t>(r17.u32, 1, xer);
	// ble cr6,0x824533a4
	if (!cr6.gt) goto loc_824533A4;
	// lwz r4,0(r16)
	ctx.r4.u64 = PPC_LOAD_U32(r16.u32 + 0);
	// addi r7,r16,4
	ctx.r7.s64 = r16.s64 + 4;
loc_82453380:
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r5,0(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// bl 0x82441c28
	sub_82441C28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824533a4
	if (cr0.eq) goto loc_824533A4;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r17
	cr6.compare<uint32_t>(ctx.r6.u32, r17.u32, xer);
	// blt cr6,0x82453380
	if (cr6.lt) goto loc_82453380;
loc_824533A4:
	// cmplw cr6,r6,r17
	cr6.compare<uint32_t>(ctx.r6.u32, r17.u32, xer);
	// beq cr6,0x824548a4
	if (cr6.eq) goto loc_824548A4;
	// rlwinm r14,r17,2,0,29
	r14.u64 = __builtin_rotateleft64(r17.u32 | (r17.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// stw r14,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r14.u32);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r15,0
	r15.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x824533fc
	if (cr6.eq) goto loc_824533FC;
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// lis r10,4384
	ctx.r10.s64 = 287309824;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824533fc
	if (cr6.eq) goto loc_824533FC;
	// stw r15,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r15.u32);
	// b 0x82453404
	goto loc_82453404;
loc_824533FC:
	// li r11,1
	r11.s64 = 1;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
loc_82453404:
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r25,r15
	r25.u64 = r15.u64;
	// mr r26,r15
	r26.u64 = r15.u64;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// lfd f31,-31368(r10)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// lfd f29,-31360(r11)
	f29.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// beq cr6,0x824535b0
	if (cr6.eq) goto loc_824535B0;
	// addi r28,r1,160
	r28.s64 = ctx.r1.s64 + 160;
	// mr r27,r15
	r27.u64 = r15.u64;
loc_8245342C:
	// lwz r29,0(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 0);
loc_82453430:
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x82441b88
	sub_82441B88(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82453578
	if (cr0.eq) goto loc_82453578;
	// stfd f29,184(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + 184, f29.u64);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stfd f31,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, f31.u64);
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x82453578
	if (cr6.eq) goto loc_82453578;
	// lwz r30,16(r19)
	r30.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// lwz r31,20(r19)
	r31.u64 = PPC_LOAD_U32(r19.u32 + 20);
loc_8245346C:
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82453498
	if (cr0.eq) goto loc_82453498;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824534b8
	if (cr6.eq) goto loc_824534B8;
loc_82453498:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r6,r1,176
	ctx.r6.s64 = ctx.r1.s64 + 176;
	// addi r5,r1,184
	ctx.r5.s64 = ctx.r1.s64 + 184;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x82441c90
	sub_82441C90(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x8245346c
	if (!cr6.eq) goto loc_8245346C;
	// b 0x82453578
	goto loc_82453578;
loc_824534B8:
	// lfd f13,184(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// lfd f0,176(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcmpu cr6,f13,f29
	cr6.compare(ctx.f13.f64, f29.f64);
	// bne cr6,0x824534d0
	if (!cr6.eq) goto loc_824534D0;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x82453558
	if (cr6.eq) goto loc_82453558;
loc_824534D0:
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,8(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// lfd f12,32(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fmadd f1,f12,f13,f0
	ctx.f1.f64 = ctx.f12.f64 * ctx.f13.f64 + f0.f64;
	// beq 0x82453534
	if (cr0.eq) goto loc_82453534;
loc_824534F0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r30
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82453524
	if (cr0.eq) goto loc_82453524;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82453524
	if (!cr6.eq) goto loc_82453524;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// beq cr6,0x82453534
	if (cr6.eq) goto loc_82453534;
loc_82453524:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// blt cr6,0x824534f0
	if (cr6.lt) goto loc_824534F0;
loc_82453534:
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// bne cr6,0x82453558
	if (!cr6.eq) goto loc_82453558;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
loc_82453558:
	// addi r11,r1,272
	r11.s64 = ctx.r1.s64 + 272;
	// stw r3,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r3.u32);
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stfdx f29,r27,r11
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r27.u32 + r11.u32, f29.u64);
	// stfdx f31,r27,r10
	PPC_STORE_U64(r27.u32 + ctx.r10.u32, f31.u64);
	// bne cr6,0x8245359c
	if (!cr6.eq) goto loc_8245359C;
loc_82453578:
	// lwz r11,20(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,52(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x8245359c
	if (cr6.eq) goto loc_8245359C;
	// mr r29,r11
	r29.u64 = r11.u64;
	// b 0x82453430
	goto loc_82453430;
loc_8245359C:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// cmplw cr6,r26,r17
	cr6.compare<uint32_t>(r26.u32, r17.u32, xer);
	// blt cr6,0x8245342c
	if (cr6.lt) goto loc_8245342C;
loc_824535B0:
	// cmplw cr6,r25,r17
	cr6.compare<uint32_t>(r25.u32, r17.u32, xer);
	// bne cr6,0x824535cc
	if (!cr6.eq) goto loc_824535CC;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// b 0x824548a4
	goto loc_824548A4;
loc_824535CC:
	// li r22,-1
	r22.s64 = -1;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x82453988
	if (cr6.eq) goto loc_82453988;
	// mr r17,r15
	r17.u64 = r15.u64;
	// mr r16,r15
	r16.u64 = r15.u64;
loc_824535E0:
	// addi r19,r1,208
	r19.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r17,r19
	r11.u64 = PPC_LOAD_U32(r17.u32 + r19.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82453958
	if (!cr6.eq) goto loc_82453958;
	// addi r20,r1,160
	r20.s64 = ctx.r1.s64 + 160;
	// lwz r11,516(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// lwzx r22,r17,r20
	r22.u64 = PPC_LOAD_U32(r17.u32 + r20.u32);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r9,r22,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82453630
	if (cr0.eq) goto loc_82453630;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82453958
	if (cr6.eq) goto loc_82453958;
loc_82453630:
	// li r18,-1
	r18.s64 = -1;
	// fmr f11,f31
	ctx.fpscr.disableFlushMode();
	ctx.f11.f64 = f31.f64;
	// fmr f10,f31
	ctx.f10.f64 = f31.f64;
	// li r23,0
	r23.s64 = 0;
	// li r21,0
	r21.s64 = 0;
	// mr r24,r22
	r24.u64 = r22.u64;
loc_82453648:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// lwz r7,572(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	// lwz r6,564(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	// lwz r5,556(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// lwz r3,516(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// bl 0x82441b88
	sub_82441B88(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82453804
	if (cr0.eq) goto loc_82453804;
	// stfd f29,176(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + 176, f29.u64);
	// mr r26,r24
	r26.u64 = r24.u64;
	// stfd f31,184(r1)
	PPC_STORE_U64(ctx.r1.u32 + 184, f31.u64);
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// beq cr6,0x82453804
	if (cr6.eq) goto loc_82453804;
	// lwz r14,516(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
loc_82453680:
	// lwz r11,20(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// li r28,0
	r28.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824536a4
	if (!cr6.eq) goto loc_824536A4;
	// li r30,-1
	r30.s64 = -1;
loc_824536A4:
	// lwz r25,532(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// li r27,0
	r27.s64 = 0;
loc_824536AC:
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x824537a4
	if (!cr6.eq) goto loc_824537A4;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// lwzx r29,r27,r11
	r29.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// mr r31,r29
	r31.u64 = r29.u64;
loc_824536C8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r7,572(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// lwz r6,564(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	// lwz r5,556(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// bl 0x82441b88
	sub_82441B88(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82453784
	if (cr0.eq) goto loc_82453784;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// beq cr6,0x82453784
	if (cr6.eq) goto loc_82453784;
loc_824536F4:
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x82441c28
	sub_82441C28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8245373c
	if (!cr0.eq) goto loc_8245373C;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82453778
	if (!cr6.eq) goto loc_82453778;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x82441c90
	sub_82441C90(ctx, base);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x824536f4
	if (!cr6.eq) goto loc_824536F4;
	// b 0x82453784
	goto loc_82453784;
loc_8245373C:
	// lwz r10,20(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8245377c
	if (cr6.eq) goto loc_8245377C;
	// lwz r10,20(r14)
	ctx.r10.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,564(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// mullw r11,r11,r11
	r11.s64 = int64_t(r11.s32) * int64_t(r11.s32);
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// b 0x8245377c
	goto loc_8245377C;
loc_82453778:
	// li r7,-1
	ctx.r7.s64 = -1;
loc_8245377C:
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x824537a4
	if (!cr6.eq) goto loc_824537A4;
loc_82453784:
	// lwz r11,20(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,52(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// beq cr6,0x824537a4
	if (cr6.eq) goto loc_824537A4;
	// mr r31,r11
	r31.u64 = r11.u64;
	// b 0x824536c8
	goto loc_824536C8;
loc_824537A4:
	// addic. r25,r25,-1
	xer.ca = r25.u32 > 0;
	r25.s64 = r25.s64 + -1;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// bne 0x824536ac
	if (!cr0.eq) goto loc_824536AC;
	// cmplw cr6,r23,r28
	cr6.compare<uint32_t>(r23.u32, r28.u32, xer);
	// blt cr6,0x824537c4
	if (cr6.lt) goto loc_824537C4;
	// bne cr6,0x824537d8
	if (!cr6.eq) goto loc_824537D8;
	// cmplw cr6,r21,r30
	cr6.compare<uint32_t>(r21.u32, r30.u32, xer);
	// bge cr6,0x824537d8
	if (!cr6.lt) goto loc_824537D8;
loc_824537C4:
	// lfd f11,176(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// mr r18,r26
	r18.u64 = r26.u64;
	// lfd f10,184(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// mr r23,r28
	r23.u64 = r28.u64;
	// mr r21,r30
	r21.u64 = r30.u64;
loc_824537D8:
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82453804
	if (!cr6.eq) goto loc_82453804;
	// addi r6,r1,184
	ctx.r6.s64 = ctx.r1.s64 + 184;
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x82441c90
	sub_82441C90(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmpwi cr6,r26,-1
	cr6.compare<int32_t>(r26.s32, -1, xer);
	// bne cr6,0x82453680
	if (!cr6.eq) goto loc_82453680;
loc_82453804:
	// lwz r14,516(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// rlwinm r10,r24,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,52(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplw cr6,r22,r11
	cr6.compare<uint32_t>(r22.u32, r11.u32, xer);
	// beq cr6,0x82453828
	if (cr6.eq) goto loc_82453828;
	// mr r24,r11
	r24.u64 = r11.u64;
	// b 0x82453648
	goto loc_82453648;
loc_82453828:
	// cmpwi cr6,r18,-1
	cr6.compare<int32_t>(r18.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// addi r11,r1,272
	r11.s64 = ctx.r1.s64 + 272;
	// lwz r26,20(r14)
	r26.u64 = PPC_LOAD_U32(r14.u32 + 20);
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// lwz r27,532(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// li r24,1
	r24.s64 = 1;
	// stwx r18,r17,r20
	PPC_STORE_U32(r17.u32 + r20.u32, r18.u32);
	// li r31,0
	r31.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// stfdx f11,r16,r11
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r16.u32 + r11.u32, ctx.f11.u64);
	// stfdx f10,r16,r10
	PPC_STORE_U64(r16.u32 + ctx.r10.u32, ctx.f10.u64);
	// stwx r24,r17,r19
	PPC_STORE_U32(r17.u32 + r19.u32, r24.u32);
loc_8245385C:
	// addi r25,r1,208
	r25.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r31,r25
	r11.u64 = PPC_LOAD_U32(r31.u32 + r25.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82453948
	if (!cr6.eq) goto loc_82453948;
	// addi r28,r1,160
	r28.s64 = ctx.r1.s64 + 160;
	// lwzx r30,r31,r28
	r30.u64 = PPC_LOAD_U32(r31.u32 + r28.u32);
	// b 0x82453940
	goto loc_82453940;
loc_82453878:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r7,572(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// lwz r6,564(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	// lwz r5,556(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// bl 0x82441b88
	sub_82441B88(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82453924
	if (cr0.eq) goto loc_82453924;
	// stfd f29,184(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + 184, f29.u64);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// stfd f31,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, f31.u64);
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x82453924
	if (cr6.eq) goto loc_82453924;
loc_824538AC:
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x82441c28
	sub_82441C28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824538f4
	if (!cr0.eq) goto loc_824538F4;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82453918
	if (!cr6.eq) goto loc_82453918;
	// addi r6,r1,176
	ctx.r6.s64 = ctx.r1.s64 + 176;
	// addi r5,r1,184
	ctx.r5.s64 = ctx.r1.s64 + 184;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x82441c90
	sub_82441C90(ctx, base);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x824538ac
	if (!cr6.eq) goto loc_824538AC;
	// b 0x82453924
	goto loc_82453924;
loc_824538F4:
	// addi r11,r1,272
	r11.s64 = ctx.r1.s64 + 272;
	// lfd f0,184(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// lfd f13,176(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// stwx r7,r31,r28
	PPC_STORE_U32(r31.u32 + r28.u32, ctx.r7.u32);
	// stwx r24,r31,r25
	PPC_STORE_U32(r31.u32 + r25.u32, r24.u32);
	// stfdx f0,r29,r11
	PPC_STORE_U64(r29.u32 + r11.u32, f0.u64);
	// stfdx f13,r29,r10
	PPC_STORE_U64(r29.u32 + ctx.r10.u32, ctx.f13.u64);
	// b 0x8245391c
	goto loc_8245391C;
loc_82453918:
	// li r7,-1
	ctx.r7.s64 = -1;
loc_8245391C:
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x82453948
	if (!cr6.eq) goto loc_82453948;
loc_82453924:
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r31,r28
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + r28.u32);
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r11,52(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82453948
	if (cr6.eq) goto loc_82453948;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_82453940:
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// bne cr6,0x82453878
	if (!cr6.eq) goto loc_82453878;
loc_82453948:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// bne 0x8245385c
	if (!cr0.eq) goto loc_8245385C;
loc_82453958:
	// lwz r11,532(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// addi r15,r15,1
	r15.s64 = r15.s64 + 1;
	// addi r16,r16,8
	r16.s64 = r16.s64 + 8;
	// addi r17,r17,4
	r17.s64 = r17.s64 + 4;
	// cmplw cr6,r15,r11
	cr6.compare<uint32_t>(r15.u32, r11.u32, xer);
	// blt cr6,0x824535e0
	if (cr6.lt) goto loc_824535E0;
	// lwz r16,524(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	// rotlwi r17,r11,0
	r17.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r19,516(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// li r22,-1
	r22.s64 = -1;
	// lwz r18,556(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// lwz r14,192(r1)
	r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
loc_82453988:
	// lwz r15,540(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// li r29,0
	r29.s64 = 0;
	// li r23,0
	r23.s64 = 0;
	// li r21,0
	r21.s64 = 0;
	// li r20,0
	r20.s64 = 0;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x82453a54
	if (cr6.eq) goto loc_82453A54;
	// lwz r26,20(r19)
	r26.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// lwz r24,16(r19)
	r24.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// li r31,0
	r31.s64 = 0;
	// mr r30,r17
	r30.u64 = r17.u64;
loc_824539B8:
	// lwz r4,0(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r5,160(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r11,r26
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// bl 0x82441c28
	sub_82441C28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824539dc
	if (!cr0.eq) goto loc_824539DC;
	// li r29,1
	r29.s64 = 1;
loc_824539DC:
	// addi r11,r1,272
	r11.s64 = ctx.r1.s64 + 272;
	// lfdx f0,r31,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + r11.u32);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// beq cr6,0x824539f0
	if (cr6.eq) goto loc_824539F0;
	// li r23,1
	r23.s64 = 1;
loc_824539F0:
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// lfdx f0,r31,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + r11.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x82453a04
	if (cr6.eq) goto loc_82453A04;
	// li r21,1
	r21.s64 = 1;
loc_82453A04:
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r24
	r11.u64 = PPC_LOAD_U32(r11.u32 + r24.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82453a2c
	if (cr0.eq) goto loc_82453A2C;
	// lwz r11,8(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82453a2c
	if (!cr6.eq) goto loc_82453A2C;
	// li r20,1
	r20.s64 = 1;
loc_82453A2C:
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// bne 0x824539b8
	if (!cr0.eq) goto loc_824539B8;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x82453a70
	if (!cr6.eq) goto loc_82453A70;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// bne cr6,0x82453a70
	if (!cr6.eq) goto loc_82453A70;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x82453a70
	if (!cr6.eq) goto loc_82453A70;
loc_82453A54:
	// li r31,1
	r31.s64 = 1;
loc_82453A58:
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x824548a8
	goto loc_824548A8;
loc_82453A70:
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x824548a8
	if (!cr6.eq) goto loc_824548A8;
	// lwz r25,108(r19)
	r25.u64 = PPC_LOAD_U32(r19.u32 + 108);
	// li r29,0
	r29.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwinm r11,r25,3,0,28
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 3) & 0xFFFFFFF8;
	// li r4,0
	ctx.r4.s64 = 0;
	// srawi r28,r11,31
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7FFFFFFF) != 0);
	r28.s64 = r11.s32 >> 31;
loc_82453A98:
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// lwzx r11,r4,r11
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r11,r26
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// bne cr6,0x82453bd8
	if (!cr6.eq) goto loc_82453BD8;
	// rlwinm. r11,r25,0,2,2
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82453bd8
	if (!cr0.eq) goto loc_82453BD8;
	// lwz r5,4(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r24
	r11.u64 = PPC_LOAD_U32(r11.u32 + r24.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82453b34
	if (cr0.eq) goto loc_82453B34;
	// lwz r11,8(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82453b34
	if (!cr6.eq) goto loc_82453B34;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82453bdc
	if (cr6.eq) goto loc_82453BDC;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
loc_82453AEC:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r5,r8
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r8.u32, xer);
	// bne cr6,0x82453b20
	if (!cr6.eq) goto loc_82453B20;
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// bne cr6,0x82453b20
	if (!cr6.eq) goto loc_82453B20;
	// lfd f0,32(r6)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r6.u32 + 32);
	// lfd f13,32(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x82453bdc
	if (cr6.eq) goto loc_82453BDC;
loc_82453B20:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// blt cr6,0x82453aec
	if (cr6.lt) goto loc_82453AEC;
	// b 0x82453bdc
	goto loc_82453BDC;
loc_82453B34:
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82453bdc
	if (cr6.eq) goto loc_82453BDC;
	// addi r10,r1,272
	ctx.r10.s64 = ctx.r1.s64 + 272;
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// li r11,0
	r11.s64 = 0;
	// lfdx f0,r3,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + ctx.r10.u32);
loc_82453B50:
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addi r31,r1,272
	r31.s64 = ctx.r1.s64 + 272;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lfdx f13,r11,r31
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + r31.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lwzx r10,r10,r26
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r26.u32);
	// bne cr6,0x82453bc0
	if (!cr6.eq) goto loc_82453BC0;
	// addi r31,r1,240
	r31.s64 = ctx.r1.s64 + 240;
	// addi r30,r1,240
	r30.s64 = ctx.r1.s64 + 240;
	// lfdx f13,r3,r31
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + r31.u32);
	// lfdx f12,r11,r30
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + r30.u32);
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bne cr6,0x82453bc0
	if (!cr6.eq) goto loc_82453BC0;
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r5,r31
	cr6.compare<uint32_t>(ctx.r5.u32, r31.u32, xer);
	// bne cr6,0x82453bc0
	if (!cr6.eq) goto loc_82453BC0;
	// lwz r31,8(r6)
	r31.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// lwz r30,8(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// bne cr6,0x82453bc0
	if (!cr6.eq) goto loc_82453BC0;
	// lwz r31,12(r6)
	r31.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// lwz r30,12(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// bne cr6,0x82453bc0
	if (!cr6.eq) goto loc_82453BC0;
	// lwz r31,16(r6)
	r31.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplw cr6,r31,r10
	cr6.compare<uint32_t>(r31.u32, ctx.r10.u32, xer);
	// beq cr6,0x82453bdc
	if (cr6.eq) goto loc_82453BDC;
loc_82453BC0:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// blt cr6,0x82453b50
	if (cr6.lt) goto loc_82453B50;
	// b 0x82453bdc
	goto loc_82453BDC;
loc_82453BD8:
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82453BDC:
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// stwx r9,r4,r11
	PPC_STORE_U32(ctx.r4.u32 + r11.u32, ctx.r9.u32);
	// bne cr6,0x82453bf0
	if (!cr6.eq) goto loc_82453BF0;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
loc_82453BF0:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r3,r3,8
	ctx.r3.s64 = ctx.r3.s64 + 8;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r7,r17
	cr6.compare<uint32_t>(ctx.r7.u32, r17.u32, xer);
	// blt cr6,0x82453a98
	if (cr6.lt) goto loc_82453A98;
	// li r27,1
	r27.s64 = 1;
	// mr r31,r22
	r31.u64 = r22.u64;
	// li r30,0
	r30.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82453C18:
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// bne cr6,0x82453cfc
	if (!cr6.eq) goto loc_82453CFC;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// lwz r6,136(r19)
	ctx.r6.u64 = PPC_LOAD_U32(r19.u32 + 136);
	// lwzx r11,r3,r11
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r11,r26
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// bne cr6,0x82453cfc
	if (!cr6.eq) goto loc_82453CFC;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
loc_82453C58:
	// addi r9,r1,304
	ctx.r9.s64 = ctx.r1.s64 + 304;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x82453cbc
	if (!cr6.eq) goto loc_82453CBC;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r26
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r26.u32);
	// lwz r15,4(r9)
	r15.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r6,r15
	cr6.compare<uint32_t>(ctx.r6.u32, r15.u32, xer);
	// bne cr6,0x82453cb8
	if (!cr6.eq) goto loc_82453CB8;
	// lwz r15,12(r5)
	r15.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r15,r9
	cr6.compare<uint32_t>(r15.u32, ctx.r9.u32, xer);
	// bne cr6,0x82453cb8
	if (!cr6.eq) goto loc_82453CB8;
	// addi r9,r1,272
	ctx.r9.s64 = ctx.r1.s64 + 272;
	// lfdx f0,r8,r9
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// bne cr6,0x82453cb8
	if (!cr6.eq) goto loc_82453CB8;
	// addi r9,r1,240
	ctx.r9.s64 = ctx.r1.s64 + 240;
	// lfdx f0,r8,r9
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r9.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x82453cb8
	if (!cr6.eq) goto loc_82453CB8;
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
loc_82453CB8:
	// lwz r15,540(r1)
	r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
loc_82453CBC:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r8,r8,8
	ctx.r8.s64 = ctx.r8.s64 + 8;
	// cmplw cr6,r10,r17
	cr6.compare<uint32_t>(ctx.r10.u32, r17.u32, xer);
	// blt cr6,0x82453c58
	if (cr6.lt) goto loc_82453C58;
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r15
	r11.u64 = PPC_LOAD_U32(r11.u32 + r15.u32);
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bgt cr6,0x82453cfc
	if (cr6.gt) goto loc_82453CFC;
	// cmplw cr6,r7,r31
	cr6.compare<uint32_t>(ctx.r7.u32, r31.u32, xer);
	// bge cr6,0x82453cfc
	if (!cr6.lt) goto loc_82453CFC;
	// li r27,0
	r27.s64 = 0;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
loc_82453CFC:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// cmplw cr6,r4,r17
	cr6.compare<uint32_t>(ctx.r4.u32, r17.u32, xer);
	// blt cr6,0x82453c18
	if (cr6.lt) goto loc_82453C18;
	// lis r3,4096
	ctx.r3.s64 = 268435456;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x82453d20
	if (!cr6.eq) goto loc_82453D20;
	// rlwinm. r11,r25,0,2,2
	r11.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82453e10
	if (cr0.eq) goto loc_82453E10;
loc_82453D20:
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// blt cr6,0x82453e10
	if (cr6.lt) goto loc_82453E10;
	// lis r10,16384
	ctx.r10.s64 = 1073741824;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x82453e10
	if (cr6.gt) goto loc_82453E10;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
loc_82453D44:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82453e10
	if (!cr6.eq) goto loc_82453E10;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r26
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r5,4(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r24
	r11.u64 = PPC_LOAD_U32(r11.u32 + r24.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82453d80
	if (cr0.eq) goto loc_82453D80;
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82453e00
	if (!cr6.eq) goto loc_82453E00;
loc_82453D80:
	// lwz r11,16(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// lwz r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x82453e00
	if (cr6.eq) goto loc_82453E00;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
loc_82453DAC:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r31,4(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r31,r5
	cr6.compare<uint32_t>(r31.u32, ctx.r5.u32, xer);
	// bne cr6,0x82453de8
	if (!cr6.eq) goto loc_82453DE8;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r29,12(r9)
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bne cr6,0x82453de8
	if (!cr6.eq) goto loc_82453DE8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r31,8(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x82453de8
	if (!cr6.eq) goto loc_82453DE8;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
loc_82453DE8:
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82453dac
	if (!cr0.eq) goto loc_82453DAC;
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// ble cr6,0x82453e00
	if (!cr6.gt) goto loc_82453E00;
	// li r27,1
	r27.s64 = 1;
loc_82453E00:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r4,r17
	cr6.compare<uint32_t>(ctx.r4.u32, r17.u32, xer);
	// blt cr6,0x82453d44
	if (cr6.lt) goto loc_82453D44;
loc_82453E10:
	// lwz r11,0(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// bne cr6,0x82453e50
	if (!cr6.eq) goto loc_82453E50;
	// rlwinm. r10,r25,0,4,4
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82453e50
	if (!cr0.eq) goto loc_82453E50;
	// lwz r10,16(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r26
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r26.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r24
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r24.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82453e84
	if (!cr0.eq) goto loc_82453E84;
loc_82453E50:
	// lis r10,4384
	ctx.r10.s64 = 287309824;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82453e84
	if (cr6.eq) goto loc_82453E84;
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// bne cr6,0x82453e84
	if (!cr6.eq) goto loc_82453E84;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x82453e84
	if (!cr6.eq) goto loc_82453E84;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// bne cr6,0x82453e84
	if (!cr6.eq) goto loc_82453E84;
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// bne cr6,0x82453e84
	if (!cr6.eq) goto loc_82453E84;
	// li r31,0
	r31.s64 = 0;
	// b 0x82453a58
	goto loc_82453A58;
loc_82453E84:
	// stw r22,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r22.u32);
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82453ea8
	if (cr6.eq) goto loc_82453EA8;
	// lwz r10,548(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// mr r23,r11
	r23.u64 = r11.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// b 0x82453ec0
	goto loc_82453EC0;
loc_82453EA8:
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// lwz r23,12(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_82453EC0:
	// lwz r11,16(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 16);
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// lwz r10,20(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// stw r23,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, r23.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r10,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r10.u32);
	// stw r11,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r11.u32);
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// li r21,0
	r21.s64 = 0;
	// li r22,1
	r22.s64 = 1;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// mr r11,r21
	r11.u64 = r21.u64;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
loc_82453F0C:
	// addi r8,r1,304
	ctx.r8.s64 = ctx.r1.s64 + 304;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82453f6c
	if (!cr6.eq) goto loc_82453F6C;
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// lwz r7,20(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r6,136(r19)
	ctx.r6.u64 = PPC_LOAD_U32(r19.u32 + 136);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r7,4(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// bne cr6,0x82453f74
	if (!cr6.eq) goto loc_82453F74;
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplw cr6,r23,r8
	cr6.compare<uint32_t>(r23.u32, ctx.r8.u32, xer);
	// bne cr6,0x82453f74
	if (!cr6.eq) goto loc_82453F74;
	// addi r8,r1,272
	ctx.r8.s64 = ctx.r1.s64 + 272;
	// lfdx f0,r9,r8
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + ctx.r8.u32);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// bne cr6,0x82453f74
	if (!cr6.eq) goto loc_82453F74;
	// addi r8,r1,240
	ctx.r8.s64 = ctx.r1.s64 + 240;
	// lfdx f0,r9,r8
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + ctx.r8.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x82453f74
	if (!cr6.eq) goto loc_82453F74;
loc_82453F6C:
	// addi r8,r1,208
	ctx.r8.s64 = ctx.r1.s64 + 208;
	// stwx r22,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, r22.u32);
loc_82453F74:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r17
	cr6.compare<uint32_t>(ctx.r10.u32, r17.u32, xer);
	// blt cr6,0x82453f0c
	if (cr6.lt) goto loc_82453F0C;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82454148
	if (!cr6.eq) goto loc_82454148;
	// mr r25,r21
	r25.u64 = r21.u64;
	// mr r24,r17
	r24.u64 = r17.u64;
loc_82453F98:
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8245413c
	if (!cr6.eq) goto loc_8245413C;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// lwz r27,20(r19)
	r27.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r26,136(r19)
	r26.u64 = PPC_LOAD_U32(r19.u32 + 136);
	// lwzx r4,r25,r11
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r11,r27
	r28.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// bne cr6,0x8245413c
	if (!cr6.eq) goto loc_8245413C;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// mr r29,r21
	r29.u64 = r21.u64;
	// mr r31,r21
	r31.u64 = r21.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r30,r21
	r30.u64 = r21.u64;
loc_82453FE0:
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82454030
	if (!cr6.eq) goto loc_82454030;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// lwzx r5,r7,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// bl 0x82441c28
	sub_82441C28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82454030
	if (cr0.eq) goto loc_82454030;
	// addi r11,r1,272
	r11.s64 = ctx.r1.s64 + 272;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lfdx f0,r30,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r30.u32 + r11.u32);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// bne cr6,0x82454044
	if (!cr6.eq) goto loc_82454044;
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// lfdx f0,r30,r11
	f0.u64 = PPC_LOAD_U64(r30.u32 + r11.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x82454044
	if (!cr6.eq) goto loc_82454044;
loc_82454030:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// cmplw cr6,r31,r17
	cr6.compare<uint32_t>(r31.u32, r17.u32, xer);
	// blt cr6,0x82453fe0
	if (cr6.lt) goto loc_82453FE0;
loc_82454044:
	// cmplw cr6,r31,r17
	cr6.compare<uint32_t>(r31.u32, r17.u32, xer);
	// blt cr6,0x8245413c
	if (cr6.lt) goto loc_8245413C;
	// lwz r5,12(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// rlwinm r8,r23,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r8,r15
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r15.u32);
	// lwzx r11,r11,r15
	r11.u64 = PPC_LOAD_U32(r11.u32 + r15.u32);
	// subf r11,r29,r11
	r11.s64 = r11.s64 - r29.s64;
	// add r11,r11,r6
	r11.u64 = r11.u64 + ctx.r6.u64;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bgt cr6,0x8245413c
	if (cr6.gt) goto loc_8245413C;
	// mr r11,r21
	r11.u64 = r21.u64;
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
loc_8245407C:
	// addi r9,r1,208
	ctx.r9.s64 = ctx.r1.s64 + 208;
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x824540b8
	if (!cr6.eq) goto loc_824540B8;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r26,r6
	cr6.compare<uint32_t>(r26.u32, ctx.r6.u32, xer);
	// bne cr6,0x824540b8
	if (!cr6.eq) goto loc_824540B8;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// bne cr6,0x824540b8
	if (!cr6.eq) goto loc_824540B8;
	// stwx r22,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, r22.u32);
loc_824540B8:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8245407c
	if (!cr0.eq) goto loc_8245407C;
	// lwz r11,8(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82454124
	if (!cr6.gt) goto loc_82454124;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
loc_824540D8:
	// lwz r11,20(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r10,136(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 136);
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x82454110
	if (!cr6.eq) goto loc_82454110;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// bne cr6,0x82454110
	if (!cr6.eq) goto loc_82454110;
	// stw r23,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r23.u32);
	// lwzx r9,r8,r15
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r15.u32);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
loc_82454110:
	// lwz r11,8(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x824540d8
	if (cr6.lt) goto loc_824540D8;
loc_82454124:
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r8,r15
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r15.u32);
	// lwzx r10,r11,r15
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + r15.u32);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stwx r10,r8,r15
	PPC_STORE_U32(ctx.r8.u32 + r15.u32, ctx.r10.u32);
	// stwx r21,r11,r15
	PPC_STORE_U32(r11.u32 + r15.u32, r21.u32);
loc_8245413C:
	// addic. r24,r24,-1
	xer.ca = r24.u32 > 0;
	r24.s64 = r24.s64 + -1;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// bne 0x82453f98
	if (!cr0.eq) goto loc_82453F98;
loc_82454148:
	// lwz r11,108(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 108);
	// rlwinm. r10,r11,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82454298
	if (!cr0.eq) goto loc_82454298;
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82454298
	if (!cr0.eq) goto loc_82454298;
	// mr r30,r21
	r30.u64 = r21.u64;
	// mr r26,r17
	r26.u64 = r17.u64;
loc_82454164:
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8245428c
	if (!cr6.eq) goto loc_8245428C;
	// addi r29,r1,160
	r29.s64 = ctx.r1.s64 + 160;
	// lwz r28,20(r19)
	r28.u64 = PPC_LOAD_U32(r19.u32 + 20);
	// lwz r27,16(r19)
	r27.u64 = PPC_LOAD_U32(r19.u32 + 16);
	// lwzx r4,r30,r29
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r28
	r11.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824541b0
	if (cr0.eq) goto loc_824541B0;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8245428c
	if (cr6.eq) goto loc_8245428C;
loc_824541B0:
	// mr r31,r21
	r31.u64 = r21.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
loc_824541BC:
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x824541e8
	if (!cr6.eq) goto loc_824541E8;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwzx r5,r7,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// bl 0x82441c28
	sub_82441C28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824541e8
	if (cr0.eq) goto loc_824541E8;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_824541E8:
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x824541bc
	if (!cr0.eq) goto loc_824541BC;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82454200:
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// bge cr6,0x8245428c
	if (!cr6.lt) goto loc_8245428C;
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82454278
	if (!cr6.eq) goto loc_82454278;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// lwzx r10,r8,r6
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r6.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r10,r28
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r28.u32);
	// lwz r10,4(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82454278
	if (cr0.eq) goto loc_82454278;
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82454278
	if (!cr6.eq) goto loc_82454278;
	// addi r9,r1,272
	ctx.r9.s64 = ctx.r1.s64 + 272;
	// lwzx r4,r30,r29
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// lfd f0,32(r7)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + 32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lfdx f13,r11,r9
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// stwx r4,r8,r6
	PPC_STORE_U32(ctx.r8.u32 + ctx.r6.u32, ctx.r4.u32);
	// lfdx f12,r11,r10
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + ctx.r10.u32);
	// fmadd f0,f0,f13,f12
	f0.f64 = f0.f64 * ctx.f13.f64 + ctx.f12.f64;
	// stfdx f31,r11,r9
	PPC_STORE_U64(r11.u32 + ctx.r9.u32, f31.u64);
	// stfdx f0,r11,r10
	PPC_STORE_U64(r11.u32 + ctx.r10.u32, f0.u64);
loc_82454278:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// cmplw cr6,r5,r17
	cr6.compare<uint32_t>(ctx.r5.u32, r17.u32, xer);
	// blt cr6,0x82454200
	if (cr6.lt) goto loc_82454200;
loc_8245428C:
	// addic. r26,r26,-1
	xer.ca = r26.u32 > 0;
	r26.s64 = r26.s64 + -1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x82454164
	if (!cr0.eq) goto loc_82454164;
loc_82454298:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// stw r21,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r21.u32);
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r11,r11,20888
	r11.s64 = r11.s64 + 20888;
	// stw r9,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r9.u32);
	// lfd f30,-30984(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -30984);
	// stw r11,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, r11.u32);
loc_824542B8:
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8245482c
	if (!cr6.eq) goto loc_8245482C;
	// lwz r10,196(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// li r30,1
	r30.s64 = 1;
	// lwz r31,532(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// lwz r28,516(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// li r29,0
	r29.s64 = 0;
	// li r14,0
	r14.s64 = 0;
	// li r15,0
	r15.s64 = 0;
	// lwzx r27,r10,r11
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// li r16,1
	r16.s64 = 1;
	// stw r30,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, r30.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r27,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r27.u32);
loc_82454300:
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82454370
	if (!cr6.eq) goto loc_82454370;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwzx r5,r7,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// bl 0x82441c28
	sub_82441C28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82454370
	if (cr0.eq) goto loc_82454370;
	// addi r11,r1,272
	r11.s64 = ctx.r1.s64 + 272;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lfdx f0,r6,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r6.u32 + r11.u32);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// beq cr6,0x82454344
	if (cr6.eq) goto loc_82454344;
	// li r14,1
	r14.s64 = 1;
loc_82454344:
	// fcmpu cr6,f0,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f30.f64);
	// beq cr6,0x82454350
	if (cr6.eq) goto loc_82454350;
	// li r30,0
	r30.s64 = 0;
loc_82454350:
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// lfdx f13,r6,r11
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r6.u32 + r11.u32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// beq cr6,0x82454364
	if (cr6.eq) goto loc_82454364;
	// li r15,1
	r15.s64 = 1;
loc_82454364:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f31.f64);
	// beq cr6,0x82454370
	if (cr6.eq) goto loc_82454370;
	// li r16,0
	r16.s64 = 0;
loc_82454370:
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r6,r6,8
	ctx.r6.s64 = ctx.r6.s64 + 8;
	// bne 0x82454300
	if (!cr0.eq) goto loc_82454300;
	// stw r30,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, r30.u32);
	// li r17,0
	r17.s64 = 0;
	// li r22,0
	r22.s64 = 0;
	// li r21,0
	r21.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// beq cr6,0x824543a4
	if (cr6.eq) goto loc_824543A4;
	// li r14,0
	r14.s64 = 0;
	// li r15,0
	r15.s64 = 0;
loc_824543A4:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// li r31,-1
	r31.s64 = -1;
	// beq cr6,0x82454414
	if (cr6.eq) goto loc_82454414;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r11,257
	r11.s64 = 257;
	// bne cr6,0x824543d0
	if (!cr6.eq) goto loc_824543D0;
	// li r11,517
	r11.s64 = 517;
loc_824543D0:
	// rlwimi r4,r11,20,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 20) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r17,r3
	r17.u64 = ctx.r3.u64;
	// cmpwi cr6,r17,-1
	cr6.compare<int32_t>(r17.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm r10,r17,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r17.u32 | (r17.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,556(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwzx r21,r10,r11
	r21.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bne cr6,0x82454420
	if (!cr6.eq) goto loc_82454420;
	// mr r22,r17
	r22.u64 = r17.u64;
	// mr r26,r21
	r26.u64 = r21.u64;
	// b 0x82454418
	goto loc_82454418;
loc_82454414:
	// lwz r30,556(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
loc_82454418:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x82454470
	if (cr6.eq) goto loc_82454470;
loc_82454420:
	// li r11,129
	r11.s64 = 129;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// rlwimi r4,r11,22,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 22) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// cmpwi cr6,r22,-1
	cr6.compare<int32_t>(r22.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm r10,r22,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwzx r26,r10,r11
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bne cr6,0x824544c8
	if (!cr6.eq) goto loc_824544C8;
	// mr r17,r22
	r17.u64 = r22.u64;
	// mr r21,r26
	r21.u64 = r26.u64;
loc_82454470:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bne cr6,0x824544c8
	if (!cr6.eq) goto loc_824544C8;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bne cr6,0x824544c8
	if (!cr6.eq) goto loc_824544C8;
	// li r11,1
	r11.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r17,r22
	r17.u64 = r22.u64;
	// cmpwi cr6,r22,-1
	cr6.compare<int32_t>(r22.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm r10,r22,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwzx r26,r10,r11
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// mr r21,r26
	r21.u64 = r26.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
loc_824544C8:
	// lwz r10,524(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// li r18,0
	r18.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// rlwinm r25,r29,2,0,29
	r25.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// li r20,0
	r20.s64 = 0;
	// subf r24,r11,r10
	r24.s64 = ctx.r10.s64 - r11.s64;
	// li r23,0
	r23.s64 = 0;
	// b 0x824544f4
	goto loc_824544F4;
loc_824544EC:
	// lwz r27,184(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r28,516(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
loc_824544F4:
	// addi r19,r1,208
	r19.s64 = ctx.r1.s64 + 208;
	// lwzx r11,r23,r19
	r11.u64 = PPC_LOAD_U32(r23.u32 + r19.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82454814
	if (!cr6.eq) goto loc_82454814;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// add r27,r23,r11
	r27.u64 = r23.u64 + r11.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,0(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// bl 0x82441c28
	sub_82441C28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82454814
	if (cr0.eq) goto loc_82454814;
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// beq cr6,0x8245454c
	if (cr6.eq) goto loc_8245454C;
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// lwz r4,120(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lfdx f1,r20,r11
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r20.u32 + r11.u32);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// b 0x82454550
	goto loc_82454550;
loc_8245454C:
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
loc_82454550:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// lwz r31,516(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r28,r10,r11
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// stwx r3,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, ctx.r3.u32);
	// beq cr6,0x8245457c
	if (cr6.eq) goto loc_8245457C;
	// stw r3,52(r28)
	PPC_STORE_U32(r28.u32 + 52, ctx.r3.u32);
loc_8245457C:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// beq cr6,0x82454688
	if (cr6.eq) goto loc_82454688;
	// lwz r11,236(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x824545c4
	if (!cr6.eq) goto loc_824545C4;
	// addi r11,r1,272
	r11.s64 = ctx.r1.s64 + 272;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfdx f1,r20,r11
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r20.u32 + r11.u32);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// stwx r3,r25,r11
	PPC_STORE_U32(r25.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
loc_824545C4:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x8245472c
	if (cr6.eq) goto loc_8245472C;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824545ec
	if (!cr6.eq) goto loc_824545EC;
	// lwz r10,548(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
loc_824545EC:
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r11,540(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// rlwinm r29,r5,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,516(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// lwzx r6,r29,r11
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// addi r10,r6,1
	ctx.r10.s64 = ctx.r6.s64 + 1;
	// stwx r10,r29,r11
	PPC_STORE_U32(r29.u32 + r11.u32, ctx.r10.u32);
	// lwz r4,136(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 136);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// lwz r11,540(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// ble cr6,0x82454644
	if (!cr6.gt) goto loc_82454644;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,232(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,516(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// bl 0x8244f958
	sub_8244F958(ctx, base);
loc_82454644:
	// lwz r11,516(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,228(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// stw r17,72(r11)
	PPC_STORE_U32(r11.u32 + 72, r17.u32);
	// rlwinm r10,r10,0,4,6
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// stwx r31,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, r31.u32);
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// stwx r31,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, r31.u32);
	// lwz r31,516(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
loc_82454688:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x8245472c
	if (cr6.eq) goto loc_8245472C;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x824546e8
	if (cr0.eq) goto loc_824546E8;
	// lwz r8,120(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_824546A8:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// bne cr6,0x824546d8
	if (!cr6.eq) goto loc_824546D8;
	// lwz r7,8(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r7,-1
	cr6.compare<int32_t>(ctx.r7.s32, -1, xer);
	// bne cr6,0x824546d8
	if (!cr6.eq) goto loc_824546D8;
	// addi r7,r1,240
	ctx.r7.s64 = ctx.r1.s64 + 240;
	// lfd f0,32(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// lfdx f13,r20,r7
	ctx.f13.u64 = PPC_LOAD_U64(r20.u32 + ctx.r7.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x824546e8
	if (cr6.eq) goto loc_824546E8;
loc_824546D8:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r3,r9
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, xer);
	// blt cr6,0x824546a8
	if (cr6.lt) goto loc_824546A8;
loc_824546E8:
	// cmplw cr6,r3,r9
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, xer);
	// bne cr6,0x82454724
	if (!cr6.eq) goto loc_82454724;
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfdx f1,r20,r11
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r20.u32 + r11.u32);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r3,52(r11)
	PPC_STORE_U32(r11.u32 + 52, ctx.r3.u32);
loc_82454724:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// stwx r3,r11,r25
	PPC_STORE_U32(r11.u32 + r25.u32, ctx.r3.u32);
loc_8245472C:
	// lwz r5,224(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// lwz r11,540(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// rlwinm r29,r5,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r28,516(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwzx r6,r29,r11
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// addi r10,r6,1
	ctx.r10.s64 = ctx.r6.s64 + 1;
	// stwx r10,r29,r11
	PPC_STORE_U32(r29.u32 + r11.u32, ctx.r10.u32);
	// lwz r4,136(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 136);
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// lwz r11,540(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// ble cr6,0x82454788
	if (!cr6.gt) goto loc_82454788;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,232(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8244f958
	sub_8244F958(ctx, base);
loc_82454788:
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// stwx r9,r23,r19
	PPC_STORE_U32(r23.u32 + r19.u32, ctx.r9.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r9,228(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
	// lwz r9,176(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r9,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r9.u32);
	// lwzx r9,r24,r27
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + r27.u32);
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r22,72(r11)
	PPC_STORE_U32(r11.u32 + 72, r22.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// stwx r31,r30,r11
	PPC_STORE_U32(r30.u32 + r11.u32, r31.u32);
	// lwzx r9,r24,r27
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + r27.u32);
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,52(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 52);
	// stw r10,52(r11)
	PPC_STORE_U32(r11.u32 + 52, ctx.r10.u32);
	// lwzx r11,r24,r27
	r11.u64 = PPC_LOAD_U32(r24.u32 + r27.u32);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r31,52(r11)
	PPC_STORE_U32(r11.u32 + 52, r31.u32);
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
loc_82454814:
	// lwz r11,532(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// addi r20,r20,8
	r20.s64 = r20.s64 + 8;
	// addi r23,r23,4
	r23.s64 = r23.s64 + 4;
	// cmplw cr6,r18,r11
	cr6.compare<uint32_t>(r18.u32, r11.u32, xer);
	// blt cr6,0x824544ec
	if (cr6.lt) goto loc_824544EC;
loc_8245482C:
	// lwz r11,192(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r10,196(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwz r8,532(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// stw r11,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r11.u32);
	// stw r9,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r9.u32);
	// blt cr6,0x824542b8
	if (cr6.lt) goto loc_824542B8;
	// lwz r11,524(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	// addi r10,r1,304
	ctx.r10.s64 = ctx.r1.s64 + 304;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - r11.s64;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_82454860:
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82454860
	if (!cr0.eq) goto loc_82454860;
	// li r11,0
	r11.s64 = 0;
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
loc_82454888:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82453364
	if (cr6.eq) goto loc_82453364;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82454888
	if (cr6.lt) goto loc_82454888;
loc_824548A4:
	// li r3,1
	ctx.r3.s64 = 1;
loc_824548A8:
	// addi r1,r1,496
	ctx.r1.s64 = ctx.r1.s64 + 496;
	// lfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -176);
	// lfd f30,-168(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_824548BC"))) PPC_WEAK_FUNC(sub_824548BC);
PPC_FUNC_IMPL(__imp__sub_824548BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824548C0"))) PPC_WEAK_FUNC(sub_824548C0);
PPC_FUNC_IMPL(__imp__sub_824548C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// rlwinm r10,r27,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r22,r6
	r22.u64 = ctx.r6.u64;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824548fc
	if (cr6.eq) goto loc_824548FC;
	// mr r27,r10
	r27.u64 = ctx.r10.u64;
loc_824548FC:
	// rlwinm r10,r27,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r20,-1
	r20.s64 = -1;
	// lwzx r21,r10,r11
	r21.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x82454c74
	if (!cr6.eq) goto loc_82454C74;
	// lwz r11,12(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82454c74
	if (!cr6.eq) goto loc_82454C74;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bge cr6,0x82454954
	if (!cr6.lt) goto loc_82454954;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x82454c74
	if (cr6.lt) goto loc_82454C74;
loc_82454954:
	// mr r25,r20
	r25.u64 = r20.u64;
	// mr r29,r20
	r29.u64 = r20.u64;
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// bne cr6,0x82454ac0
	if (!cr6.eq) goto loc_82454AC0;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82454af8
	if (!cr6.gt) goto loc_82454AF8;
	// li r28,0
	r28.s64 = 0;
loc_82454978:
	// lwz r11,12(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r7,32(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,64(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// lwzx r30,r28,r7
	r30.u64 = PPC_LOAD_U32(r28.u32 + ctx.r7.u32);
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// beq 0x824549e0
	if (cr0.eq) goto loc_824549E0;
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_824549B4:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r5
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// cmplw cr6,r30,r4
	cr6.compare<uint32_t>(r30.u32, ctx.r4.u32, xer);
	// beq cr6,0x824549d8
	if (cr6.eq) goto loc_824549D8;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// blt cr6,0x824549b4
	if (cr6.lt) goto loc_824549B4;
loc_824549D8:
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// blt cr6,0x82454aa8
	if (cr6.lt) goto loc_82454AA8;
loc_824549E0:
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// beq cr6,0x82454a48
	if (cr6.eq) goto loc_82454A48;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// rlwinm r6,r24,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// beq 0x82454a48
	if (cr0.eq) goto loc_82454A48;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_82454A1C:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// cmplw cr6,r30,r8
	cr6.compare<uint32_t>(r30.u32, ctx.r8.u32, xer);
	// beq cr6,0x82454a40
	if (cr6.eq) goto loc_82454A40;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x82454a1c
	if (cr6.lt) goto loc_82454A1C;
loc_82454A40:
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x82454aa8
	if (cr6.lt) goto loc_82454AA8;
loc_82454A48:
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x824466f8
	sub_824466F8(ctx, base);
	// cmplw cr6,r3,r29
	cr6.compare<uint32_t>(ctx.r3.u32, r29.u32, xer);
	// bge cr6,0x82454aa8
	if (!cr6.lt) goto loc_82454AA8;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// mr r25,r30
	r25.u64 = r30.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// beq cr6,0x82454af0
	if (cr6.eq) goto loc_82454AF0;
loc_82454AA8:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x82454978
	if (cr6.lt) goto loc_82454978;
	// b 0x82454af0
	goto loc_82454AF0;
loc_82454AC0:
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r20
	ctx.r9.u64 = r20.u64;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// lwzx r6,r11,r10
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// bl 0x824466f8
	sub_824466F8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_82454AF0:
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// bne cr6,0x82454b2c
	if (!cr6.eq) goto loc_82454B2C;
loc_82454AF8:
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82454b20
	if (cr0.eq) goto loc_82454B20;
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,4004
	ctx.r5.s64 = 4004;
	// addi r6,r11,20928
	ctx.r6.s64 = r11.s64 + 20928;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwz r4,60(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// bl 0x8244f958
	sub_8244F958(ctx, base);
loc_82454B20:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82454ca4
	goto loc_82454CA4;
loc_82454B2C:
	// lwz r11,12(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r25,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r25.u32);
	// lwz r11,204(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82454bb8
	if (cr0.eq) goto loc_82454BB8;
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplw cr6,r25,r9
	cr6.compare<uint32_t>(r25.u32, ctx.r9.u32, xer);
	// bge cr6,0x82454bb8
	if (!cr6.lt) goto loc_82454BB8;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r11,0
	r11.s64 = 0;
	// b 0x82454b64
	goto loc_82454B64;
loc_82454B60:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_82454B64:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r8,r25
	cr6.compare<uint32_t>(ctx.r8.u32, r25.u32, xer);
	// bne cr6,0x82454b60
	if (!cr6.eq) goto loc_82454B60;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x82454ba4
	if (!cr6.lt) goto loc_82454BA4;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82454B80:
	// lwz r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,-4(r9)
	PPC_STORE_U32(ctx.r9.u32 + -4, ctx.r8.u32);
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82454b80
	if (cr6.lt) goto loc_82454B80;
loc_82454BA4:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r25,-4(r11)
	PPC_STORE_U32(r11.u32 + -4, r25.u32);
loc_82454BB8:
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
loc_82454BC0:
	// lwz r11,12(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmpwi cr6,r8,-1
	cr6.compare<int32_t>(ctx.r8.s32, -1, xer);
	// beq cr6,0x82454c64
	if (cr6.eq) goto loc_82454C64;
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r9,r25,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r11,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, r11.u32);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82454c4c
	if (cr6.eq) goto loc_82454C4C;
	// lwz r9,20(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r7,88(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
loc_82454C1C:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r9,r10
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r4,88(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// cmplw cr6,r4,r7
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r7.u32, xer);
	// ble cr6,0x82454c4c
	if (!cr6.gt) goto loc_82454C4C;
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r11,r11,48
	r11.s64 = r11.s64 + 48;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82454c1c
	if (!cr6.eq) goto loc_82454C1C;
loc_82454C4C:
	// lwz r10,20(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stw r7,48(r10)
	PPC_STORE_U32(ctx.r10.u32 + 48, ctx.r7.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
loc_82454C64:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplwi cr6,r5,4
	cr6.compare<uint32_t>(ctx.r5.u32, 4, xer);
	// blt cr6,0x82454bc0
	if (cr6.lt) goto loc_82454BC0;
loc_82454C74:
	// lwz r5,8(r21)
	ctx.r5.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x82454ca0
	if (cr6.eq) goto loc_82454CA0;
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x824548c0
	sub_824548C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82454ca4
	if (cr0.lt) goto loc_82454CA4;
loc_82454CA0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82454CA4:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_82454CAC"))) PPC_WEAK_FUNC(sub_82454CAC);
PPC_FUNC_IMPL(__imp__sub_82454CAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82454CB0"))) PPC_WEAK_FUNC(sub_82454CB0);
PPC_FUNC_IMPL(__imp__sub_82454CB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x82454cec
	if (cr6.eq) goto loc_82454CEC;
	// li r8,-1
	ctx.r8.s64 = -1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// bl 0x824548c0
	sub_824548C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82454cf0
	if (cr0.lt) goto loc_82454CF0;
loc_82454CEC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82454CF0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82454D00"))) PPC_WEAK_FUNC(sub_82454D00);
PPC_FUNC_IMPL(__imp__sub_82454D00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcdc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// stw r31,188(r26)
	PPC_STORE_U32(r26.u32 + 188, r31.u32);
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// rlwimi r11,r5,30,1,1
	r11.u64 = (__builtin_rotateleft32(ctx.r5.u32, 30) & 0x40000000) | (r11.u64 & 0xFFFFFFFFBFFFFFFF);
	// stw r11,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r11.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82454d8c
	if (!cr6.gt) goto loc_82454D8C;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82454D3C:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// bne cr6,0x82454d78
	if (!cr6.eq) goto loc_82454D78;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82454d78
	if (!cr6.eq) goto loc_82454D78;
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r7,88(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// bgt cr6,0x82454d78
	if (cr6.gt) goto loc_82454D78;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r9.u32);
loc_82454D78:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x82454d3c
	if (cr6.lt) goto loc_82454D3C;
loc_82454D8C:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r4,255
	ctx.r4.s64 = 255;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r4,255
	ctx.r4.s64 = 255;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r5,r11,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r4,255
	ctx.r4.s64 = 255;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r5,r11,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r21,-1
	r21.s64 = -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82454e38
	if (!cr6.gt) goto loc_82454E38;
	// li r8,0
	ctx.r8.s64 = 0;
loc_82454DE0:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// stw r21,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r21.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// bne cr6,0x82454e24
	if (!cr6.eq) goto loc_82454E24;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x82454e24
	if (!cr6.eq) goto loc_82454E24;
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r10.u32);
loc_82454E24:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82454de0
	if (cr6.lt) goto loc_82454DE0;
loc_82454E38:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82454eb0
	if (!cr6.gt) goto loc_82454EB0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r11,0
	r11.s64 = 0;
loc_82454E64:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r9,4
	ctx.r9.s64 = 4;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
loc_82454E74:
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x82454e84
	if (cr6.eq) goto loc_82454E84;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_82454E84:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82454e74
	if (!cr0.eq) goto loc_82454E74;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// stwx r8,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, ctx.r8.u32);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// blt cr6,0x82454e64
	if (cr6.lt) goto loc_82454E64;
loc_82454EB0:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82455038
	if (!cr6.gt) goto loc_82455038;
	// li r29,0
	r29.s64 = 0;
loc_82454ED8:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// lwzx r30,r29,r11
	r30.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d1c8
	sub_8243D1C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82455024
	if (cr0.eq) goto loc_82455024;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r11,r9
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82455024
	if (!cr6.eq) goto loc_82455024;
	// li r5,2
	ctx.r5.s64 = 2;
loc_82454F18:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245501c
	if (!cr6.gt) goto loc_8245501C;
loc_82454F28:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82454f58
	if (cr6.eq) goto loc_82454F58;
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82454f58
	if (cr6.eq) goto loc_82454F58;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82454F58:
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,16(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,14,14
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82454fa0
	if (cr0.eq) goto loc_82454FA0;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r9,24(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
loc_82454FA0:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x82455008
	if (!cr6.eq) goto loc_82455008;
	// lwz r4,12(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r4,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r10.u32);
	// lwzx r4,r9,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bge cr6,0x82454fdc
	if (!cr6.lt) goto loc_82454FDC;
	// stwx r10,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r10.u32);
loc_82454FDC:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,12(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// bge cr6,0x82455008
	if (!cr6.lt) goto loc_82455008;
	// stwx r11,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r11.u32);
loc_82455008:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// add r6,r6,r11
	ctx.r6.u64 = ctx.r6.u64 + r11.u64;
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// blt cr6,0x82454f28
	if (cr6.lt) goto loc_82454F28;
loc_8245501C:
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bne 0x82454f18
	if (!cr0.eq) goto loc_82454F18;
loc_82455024:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82454ed8
	if (cr6.lt) goto loc_82454ED8;
loc_82455038:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82455170
	if (!cr6.gt) goto loc_82455170;
	// li r25,0
	r25.s64 = 0;
loc_82455060:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// lwzx r30,r25,r11
	r30.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245515c
	if (cr0.eq) goto loc_8245515C;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824550cc
	if (!cr6.gt) goto loc_824550CC;
	// li r29,0
	r29.s64 = 0;
loc_82455088:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r5,20(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x824550b8
	if (cr6.eq) goto loc_824550B8;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82446a90
	sub_82446A90(ctx, base);
loc_824550B8:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82455088
	if (cr6.lt) goto loc_82455088;
loc_824550CC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245510c
	if (!cr6.gt) goto loc_8245510C;
	// li r29,0
	r29.s64 = 0;
loc_824550E0:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r5,r29,r11
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// bl 0x82446a90
	sub_82446A90(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x824550e0
	if (cr6.lt) goto loc_824550E0;
loc_8245510C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d0e8
	sub_8243D0E8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245515c
	if (cr0.eq) goto loc_8245515C;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245515c
	if (!cr6.gt) goto loc_8245515C;
	// li r29,0
	r29.s64 = 0;
loc_82455130:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r5,r29,r11
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// bl 0x82446a90
	sub_82446A90(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82455130
	if (cr6.lt) goto loc_82455130;
loc_8245515C:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r25,r25,4
	r25.s64 = r25.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x82455060
	if (cr6.lt) goto loc_82455060;
loc_82455170:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// li r27,0
	r27.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245526c
	if (!cr6.gt) goto loc_8245526C;
	// li r28,0
	r28.s64 = 0;
loc_82455184:
	// lwz r11,76(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// lwz r9,80(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// lwz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// lwzx r30,r28,r11
	r30.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// lwzx r11,r28,r9
	r11.u64 = PPC_LOAD_U32(r28.u32 + ctx.r9.u32);
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r10
	r29.u64 = r11.u64 + ctx.r10.u64;
	// ble cr6,0x82455258
	if (!cr6.gt) goto loc_82455258;
	// lis r11,-32188
	r11.s64 = -2109472768;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r11,-4256
	ctx.r3.s64 = r11.s64 + -4256;
	// bl 0x8243f018
	sub_8243F018(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// ble cr6,0x8245523c
	if (!cr6.gt) goto loc_8245523C;
	// addi r11,r29,4
	r11.s64 = r29.s64 + 4;
	// addi r3,r30,-1
	ctx.r3.s64 = r30.s64 + -1;
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
loc_824551DC:
	// lwz r11,188(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 188);
	// lwz r10,-4(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + -4);
	// lwz r7,0(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mulli r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 * 12;
	// mulli r9,r7,12
	ctx.r9.s64 = ctx.r7.s64 * 12;
	// lwz r11,88(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// blt cr6,0x82455224
	if (cr6.lt) goto loc_82455224;
	// bgt cr6,0x82455224
	if (cr6.gt) goto loc_82455224;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// blt cr6,0x82455224
	if (cr6.lt) goto loc_82455224;
	// ble cr6,0x82455230
	if (!cr6.gt) goto loc_82455230;
loc_82455224:
	// stw r7,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r7.u32);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
loc_82455230:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x824551dc
	if (!cr0.eq) goto loc_824551DC;
loc_8245523C:
	// lwz r10,76(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 76);
	// lis r11,-32188
	r11.s64 = -2109472768;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r11,-4312
	ctx.r3.s64 = r11.s64 + -4312;
	// stwx r5,r28,r10
	PPC_STORE_U32(r28.u32 + ctx.r10.u32, ctx.r5.u32);
	// bl 0x8243f018
	sub_8243F018(ctx, base);
loc_82455258:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x82455184
	if (cr6.lt) goto loc_82455184;
loc_8245526C:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r4,255
	ctx.r4.s64 = 255;
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// rlwinm r5,r11,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x824552b4
	if (!cr6.gt) goto loc_824552B4;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82455294:
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r9,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r9,44(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82455294
	if (cr6.lt) goto loc_82455294;
loc_824552B4:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm r11,r11,31,1,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// lwz r24,12(r26)
	r24.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmplwi r24,0
	cr0.compare<uint32_t>(r24.u32, 0, xer);
	// beq 0x82455440
	if (cr0.eq) goto loc_82455440;
	// rlwinm r23,r24,2,0,29
	r23.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
loc_824552D8:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// addi r23,r23,-4
	r23.s64 = r23.s64 + -4;
	// lis r10,8336
	ctx.r10.s64 = 546308096;
	// addi r24,r24,-1
	r24.s64 = r24.s64 + -1;
	// lwzx r29,r11,r23
	r29.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82455438
	if (!cr6.eq) goto loc_82455438;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82455438
	if (!cr6.gt) goto loc_82455438;
	// li r27,0
	r27.s64 = 0;
loc_82455310:
	// stw r29,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r29.u32);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82455340
	if (cr6.eq) goto loc_82455340;
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82455340
	if (cr6.eq) goto loc_82455340;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82455340:
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x824548c0
	sub_824548C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245567c
	if (cr0.lt) goto loc_8245567C;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// add r10,r10,r25
	ctx.r10.u64 = ctx.r10.u64 + r25.u64;
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r7,24(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r10,r7
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x824553c4
	if (cr0.eq) goto loc_824553C4;
	// lwz r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 16);
loc_824553A8:
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r7,r9
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, xer);
	// beq cr6,0x824553c4
	if (cr6.eq) goto loc_824553C4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x824553a8
	if (cr6.lt) goto loc_824553A8;
loc_824553C4:
	// stw r30,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r30.u32);
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r7,r11,r28
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r28.u32);
	// lwzx r5,r10,r27
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + r27.u32);
	// bl 0x824548c0
	sub_824548C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245567c
	if (cr0.lt) goto loc_8245567C;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r7,r11,r27
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// lwzx r5,r10,r28
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + r28.u32);
	// bl 0x824548c0
	sub_824548C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245567c
	if (cr0.lt) goto loc_8245567C;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x82455310
	if (cr6.lt) goto loc_82455310;
loc_82455438:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x824552d8
	if (!cr6.eq) goto loc_824552D8;
loc_82455440:
	// li r22,4
	r22.s64 = 4;
loc_82455444:
	// stw r22,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r22.u32);
	// lwz r24,12(r26)
	r24.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmplwi r24,0
	cr0.compare<uint32_t>(r24.u32, 0, xer);
	// beq 0x824555e4
	if (cr0.eq) goto loc_824555E4;
	// rlwinm r23,r24,2,0,29
	r23.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
loc_82455458:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// addi r23,r23,-4
	r23.s64 = r23.s64 + -4;
	// addi r24,r24,-1
	r24.s64 = r24.s64 + -1;
	// lwzx r29,r11,r23
	r29.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// stw r29,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r29.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824555dc
	if (cr0.eq) goto loc_824555DC;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824554bc
	if (!cr6.gt) goto loc_824554BC;
	// li r30,0
	r30.s64 = 0;
loc_8245548C:
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// bl 0x82454cb0
	sub_82454CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245567c
	if (cr0.lt) goto loc_8245567C;
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x8245548c
	if (cr6.lt) goto loc_8245548C;
loc_824554BC:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r25,0
	r25.s64 = 0;
	// clrlwi r30,r11,12
	r30.u64 = r11.u32 & 0xFFFFF;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// divwu r28,r11,r30
	r28.u32 = r11.u32 / r30.u32;
	// twllei r30,0
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824555dc
	if (cr0.eq) goto loc_824555DC;
	// li r27,0
	r27.s64 = 0;
loc_824554E0:
	// lwz r11,112(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 112);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245557c
	if (cr0.eq) goto loc_8245557C;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8245557c
	if (cr6.eq) goto loc_8245557C;
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r4,r30,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 8);
loc_8245550C:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82455530
	if (cr6.eq) goto loc_82455530;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x82455530
	if (cr6.eq) goto loc_82455530;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82455530:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// bne cr6,0x82455570
	if (!cr6.eq) goto loc_82455570;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82455570
	if (cr6.eq) goto loc_82455570;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245556c
	if (cr0.eq) goto loc_8245556C;
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// b 0x82455570
	goto loc_82455570;
loc_8245556C:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
loc_82455570:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// add r8,r4,r8
	ctx.r8.u64 = ctx.r4.u64 + ctx.r8.u64;
	// bne 0x8245550c
	if (!cr0.eq) goto loc_8245550C;
loc_8245557C:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r11,r11,r27
	r11.u64 = PPC_LOAD_U32(r11.u32 + r27.u32);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x824555a8
	if (cr6.eq) goto loc_824555A8;
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x824555a8
	if (cr6.eq) goto loc_824555A8;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_824555A8:
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x824548c0
	sub_824548C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245567c
	if (cr0.lt) goto loc_8245567C;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x824554e0
	if (cr6.lt) goto loc_824554E0;
loc_824555DC:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x82455458
	if (!cr6.eq) goto loc_82455458;
loc_824555E4:
	// addic. r22,r22,-1
	xer.ca = r22.u32 > 0;
	r22.s64 = r22.s64 + -1;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// bne 0x82455444
	if (!cr0.eq) goto loc_82455444;
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82455664
	if (cr0.eq) goto loc_82455664;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82455664
	if (!cr6.gt) goto loc_82455664;
	// li r9,0
	ctx.r9.s64 = 0;
loc_8245560C:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x82455650
	if (!cr6.eq) goto loc_82455650;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// add r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r6
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r6.u32);
	// stw r8,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r8.u32);
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
loc_82455650:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x8245560c
	if (cr6.lt) goto loc_8245560C;
loc_82455664:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r10,16(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r21,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r21.u32);
loc_8245567C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd2c
	return;
}

__attribute__((alias("__imp__sub_82455684"))) PPC_WEAK_FUNC(sub_82455684);
PPC_FUNC_IMPL(__imp__sub_82455684) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82455688"))) PPC_WEAK_FUNC(sub_82455688);
PPC_FUNC_IMPL(__imp__sub_82455688) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r22,0
	r22.s64 = 0;
	// mr r23,r22
	r23.u64 = r22.u64;
	// mr r11,r22
	r11.u64 = r22.u64;
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x824556e0
	if (!cr6.gt) goto loc_824556E0;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_824556BC:
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x824556bc
	if (cr6.lt) goto loc_824556BC;
loc_824556E0:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// li r20,-1
	r20.s64 = -1;
	// mr r18,r22
	r18.u64 = r22.u64;
	// mr r14,r20
	r14.u64 = r20.u64;
	// mr r19,r20
	r19.u64 = r20.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82456880
	if (!cr6.gt) goto loc_82456880;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r21,1
	r21.s64 = 1;
	// lis r15,4096
	r15.s64 = 268435456;
	// lis r16,8192
	r16.s64 = 536870912;
	// lfd f30,-31360(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// lis r17,12288
	r17.s64 = 805306368;
	// lfd f31,-31368(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82455724:
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// rlwinm r10,r18,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r10,r9,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82456868
	if (cr0.eq) goto loc_82456868;
	// lis r11,4352
	r11.s64 = 285212672;
	// lwz r24,8(r26)
	r24.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x824557a8
	if (!cr6.eq) goto loc_824557A8;
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x8245579c
	if (cr0.eq) goto loc_8245579C;
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
loc_82455764:
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,48(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r7,r7,0,29,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8245579c
	if (cr0.eq) goto loc_8245579C;
	// lwz r7,4(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// blt cr6,0x82455764
	if (cr6.lt) goto loc_82455764;
loc_8245579C:
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bne cr6,0x8245675c
	if (!cr6.eq) goto loc_8245675C;
	// b 0x8245674c
	goto loc_8245674C;
loc_824557A8:
	// rlwinm r11,r9,0,0,3
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// bne cr6,0x82455a28
	if (!cr6.eq) goto loc_82455A28;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r27,r22
	r27.u64 = r22.u64;
	// mr r28,r22
	r28.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245592c
	if (!cr6.gt) goto loc_8245592C;
	// mr r29,r22
	r29.u64 = r22.u64;
loc_824557CC:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// lwzx r9,r9,r29
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// cmplw cr6,r10,r15
	cr6.compare<uint32_t>(ctx.r10.u32, r15.u32, xer);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r8,r29
	r30.u64 = PPC_LOAD_U32(ctx.r8.u32 + r29.u32);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r6,48(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// beq cr6,0x82455808
	if (cr6.eq) goto loc_82455808;
	// lis r9,4112
	ctx.r9.s64 = 269484032;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x824558b8
	if (!cr6.eq) goto loc_824558B8;
loc_82455808:
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// rlwinm r11,r11,0,4,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// rlwinm. r7,r11,0,6,6
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82455838
	if (cr0.eq) goto loc_82455838;
	// lis r11,512
	r11.s64 = 33554432;
	// b 0x82455854
	goto loc_82455854;
loc_82455838:
	// rlwinm. r7,r11,0,5,5
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82455848
	if (cr0.eq) goto loc_82455848;
	// lis r11,1024
	r11.s64 = 67108864;
	// b 0x82455854
	goto loc_82455854;
loc_82455848:
	// rlwinm. r7,r11,0,4,4
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82455854
	if (cr0.eq) goto loc_82455854;
	// lis r11,2048
	r11.s64 = 134217728;
loc_82455854:
	// rlwinm r7,r10,0,4,6
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// beq cr6,0x82455870
	if (cr6.eq) goto loc_82455870;
	// rlwinm r10,r10,0,7,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// mr r23,r21
	r23.u64 = r21.u64;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
loc_82455870:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r8,r10,0,4,6
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x824558b8
	if (cr6.eq) goto loc_824558B8;
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r7,16(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm. r8,r8,0,30,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x824558b8
	if (cr0.eq) goto loc_824558B8;
	// lwz r8,92(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 92);
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// bne cr6,0x824558b8
	if (!cr6.eq) goto loc_824558B8;
	// rlwinm r10,r10,0,7,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// mr r23,r21
	r23.u64 = r21.u64;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
loc_824558B8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82452ad8
	sub_82452AD8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824568a8
	if (cr0.lt) goto loc_824568A8;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x824558f0
	if (!cr6.eq) goto loc_824558F0;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// b 0x82455918
	goto loc_82455918;
loc_824558F0:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82455918
	if (!cr6.eq) goto loc_82455918;
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
loc_82455918:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x824557cc
	if (cr6.lt) goto loc_824557CC;
loc_8245592C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// beq cr6,0x8245675c
	if (cr6.eq) goto loc_8245675C;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82455a14
	if (cr6.eq) goto loc_82455A14;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
loc_82455950:
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r8,r9
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r10
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r10.u32);
	// lwz r4,48(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// bne cr6,0x8245598c
	if (!cr6.eq) goto loc_8245598C;
	// stwx r11,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, r11.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stwx r10,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r10.u32);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// b 0x824559ec
	goto loc_824559EC;
loc_8245598C:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,16(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,48(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824559ec
	if (cr0.eq) goto loc_824559EC;
	// lwz r10,96(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x824559ec
	if (!cr6.eq) goto loc_824559EC;
	// lwz r10,96(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 96);
	// stw r10,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r10.u32);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,100(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 100);
	// stw r10,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r10.u32);
loc_824559EC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x82455950
	if (cr6.lt) goto loc_82455950;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x82455a14
	if (cr6.eq) goto loc_82455A14;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwimi r11,r6,0,12,31
	r11.u64 = (__builtin_rotateleft32(ctx.r6.u32, 0) & 0xFFFFF) | (r11.u64 & 0xFFFFFFFFFFF00000);
	// b 0x82455a18
	goto loc_82455A18;
loc_82455A14:
	// mr r11,r22
	r11.u64 = r22.u64;
loc_82455A18:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r6,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r6.u32);
	// stw r6,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r6.u32);
	// b 0x82456758
	goto loc_82456758;
loc_82455A28:
	// cmplw cr6,r11,r16
	cr6.compare<uint32_t>(r11.u32, r16.u32, xer);
	// bne cr6,0x82455fb4
	if (!cr6.eq) goto loc_82455FB4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r25,r22
	r25.u64 = r22.u64;
	// mr r28,r22
	r28.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82455c2c
	if (!cr6.gt) goto loc_82455C2C;
	// mr r29,r22
	r29.u64 = r22.u64;
loc_82455A48:
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// add r8,r28,r8
	ctx.r8.u64 = r28.u64 + ctx.r8.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwzx r30,r7,r29
	r30.u64 = PPC_LOAD_U32(ctx.r7.u32 + r29.u32);
	// rlwinm r9,r9,0,0,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFF00000;
	// lwzx r7,r10,r29
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r29.u32);
	// cmplw cr6,r9,r16
	cr6.compare<uint32_t>(ctx.r9.u32, r16.u32, xer);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// rlwinm r8,r7,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r6,48(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// lwz r7,48(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// beq cr6,0x82455aa0
	if (cr6.eq) goto loc_82455AA0;
	// lis r10,8208
	ctx.r10.s64 = 537919488;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x82455bb8
	if (!cr6.eq) goto loc_82455BB8;
loc_82455AA0:
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r9,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r9,r8,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// rlwinm r11,r11,0,4,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// rlwinm. r4,r11,0,4,4
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x82455ad8
	if (cr0.eq) goto loc_82455AD8;
	// lis r11,2048
	r11.s64 = 134217728;
	// b 0x82455af4
	goto loc_82455AF4;
loc_82455AD8:
	// rlwinm. r4,r11,0,5,5
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x82455ae8
	if (cr0.eq) goto loc_82455AE8;
	// lis r11,1024
	r11.s64 = 67108864;
	// b 0x82455af4
	goto loc_82455AF4;
loc_82455AE8:
	// rlwinm. r4,r11,0,6,6
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x82455af4
	if (cr0.eq) goto loc_82455AF4;
	// lis r11,512
	r11.s64 = 33554432;
loc_82455AF4:
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,0,4,6
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// rlwinm. r9,r11,0,6,6
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82455b10
	if (cr0.eq) goto loc_82455B10;
	// lis r11,512
	r11.s64 = 33554432;
	// b 0x82455b2c
	goto loc_82455B2C;
loc_82455B10:
	// rlwinm. r9,r11,0,5,5
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82455b20
	if (cr0.eq) goto loc_82455B20;
	// lis r11,1024
	r11.s64 = 67108864;
	// b 0x82455b2c
	goto loc_82455B2C;
loc_82455B20:
	// rlwinm. r9,r11,0,4,4
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82455b2c
	if (cr0.eq) goto loc_82455B2C;
	// lis r11,2048
	r11.s64 = 134217728;
loc_82455B2C:
	// rlwinm r9,r8,0,4,6
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x82455b70
	if (cr6.eq) goto loc_82455B70;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r4,16(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r4
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82455b70
	if (cr0.eq) goto loc_82455B70;
	// lwz r9,92(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 92);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x82455b70
	if (!cr6.eq) goto loc_82455B70;
	// rlwinm r9,r8,0,7,3
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// mr r23,r21
	r23.u64 = r21.u64;
	// or r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 | r11.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
loc_82455B70:
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r9,r10,0,4,6
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x82455bb8
	if (cr6.eq) goto loc_82455BB8;
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// lwz r8,16(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82455bb8
	if (cr0.eq) goto loc_82455BB8;
	// lwz r9,92(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 92);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x82455bb8
	if (!cr6.eq) goto loc_82455BB8;
	// rlwinm r10,r10,0,7,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// mr r23,r21
	r23.u64 = r21.u64;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
loc_82455BB8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x824437c0
	sub_824437C0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824568a8
	if (cr0.lt) goto loc_824568A8;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x82455bf0
	if (!cr6.eq) goto loc_82455BF0;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// b 0x82455c18
	goto loc_82455C18;
loc_82455BF0:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82455c18
	if (!cr6.eq) goto loc_82455C18;
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
loc_82455C18:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82455a48
	if (cr6.lt) goto loc_82455A48;
loc_82455C2C:
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r25,r7
	cr6.compare<uint32_t>(r25.u32, ctx.r7.u32, xer);
	// beq cr6,0x8245675c
	if (cr6.eq) goto loc_8245675C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r27,r22
	r27.u64 = r22.u64;
	// clrlwi. r29,r11,12
	r29.u64 = r11.u32 & 0xFFFFF;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x82455dbc
	if (cr0.eq) goto loc_82455DBC;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
loc_82455C58:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r6,72(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 72);
	// cmplw cr6,r6,r18
	cr6.compare<uint32_t>(ctx.r6.u32, r18.u32, xer);
	// beq cr6,0x82455c80
	if (cr6.eq) goto loc_82455C80;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_82455C80:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82455c58
	if (!cr0.eq) goto loc_82455C58;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82455dbc
	if (cr6.eq) goto loc_82455DBC;
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// beq cr6,0x82455dbc
	if (cr6.eq) goto loc_82455DBC;
	// subf r11,r8,r7
	r11.s64 = ctx.r7.s64 - ctx.r8.s64;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// bne cr6,0x82455dbc
	if (!cr6.eq) goto loc_82455DBC;
	// li r3,116
	ctx.r3.s64 = 116;
	// subf r28,r8,r29
	r28.s64 = r29.s64 - ctx.r8.s64;
	// bl 0x8243d710
	sub_8243D710(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82455cc8
	if (cr0.eq) goto loc_82455CC8;
	// bl 0x8243d018
	sub_8243D018(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82455ccc
	goto loc_82455CCC;
loc_82455CC8:
	// mr r30,r22
	r30.u64 = r22.u64;
loc_82455CCC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82456888
	if (cr6.eq) goto loc_82456888;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// rlwimi r4,r28,0,12,31
	ctx.r4.u64 = (__builtin_rotateleft32(r28.u32, 0) & 0xFFFFF) | (ctx.r4.u64 & 0xFFFFFFFFFFF00000);
	// rlwinm r5,r28,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d7a8
	sub_8243D7A8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// mr r11,r22
	r11.u64 = r22.u64;
	// rlwinm r8,r28,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r29,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
loc_82455D0C:
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r9
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	// lwz r5,48(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r5,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
	// lwz r9,72(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 72);
	// cmplw cr6,r9,r18
	cr6.compare<uint32_t>(ctx.r9.u32, r18.u32, xer);
	// beq cr6,0x82455d40
	if (cr6.eq) goto loc_82455D40;
	// stw r20,72(r6)
	PPC_STORE_U32(ctx.r6.u32 + 72, r20.u32);
	// b 0x82455d78
	goto loc_82455D78;
loc_82455D40:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r6,8(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stwx r9,r10,r6
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, ctx.r9.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r6,8(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r9,r7,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// stwx r9,r8,r6
	PPC_STORE_U32(ctx.r8.u32 + ctx.r6.u32, ctx.r9.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r6,16(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r9,r6,r10
	PPC_STORE_U32(ctx.r6.u32 + ctx.r10.u32, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_82455D78:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x82455d0c
	if (!cr0.eq) goto loc_82455D0C;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243dac8
	sub_8243DAC8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// blt cr6,0x82456894
	if (cr6.lt) goto loc_82456894;
	// cmplw cr6,r25,r28
	cr6.compare<uint32_t>(r25.u32, r28.u32, xer);
	// bne cr6,0x82455dbc
	if (!cr6.eq) goto loc_82455DBC;
	// mr r27,r21
	r27.u64 = r21.u64;
loc_82455DBC:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x82455e3c
	if (!cr6.eq) goto loc_82455E3C;
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// ble cr6,0x82455e3c
	if (!cr6.gt) goto loc_82455E3C;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,48(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
loc_82455DFC:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// bne cr6,0x82455e38
	if (!cr6.eq) goto loc_82455E38;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// blt cr6,0x82455dfc
	if (cr6.lt) goto loc_82455DFC;
	// b 0x82455e3c
	goto loc_82455E3C;
loc_82455E38:
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
loc_82455E3C:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82456758
	if (!cr6.eq) goto loc_82456758;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82455f20
	if (cr6.eq) goto loc_82455F20;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82455ed0
	if (!cr6.gt) goto loc_82455ED0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
loc_82455E60:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r7,r10,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r11,r10
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r9,48(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// beq cr6,0x82455ebc
	if (cr6.eq) goto loc_82455EBC;
	// rotlwi r9,r6,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r6.u32, 0);
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r9,48(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,7,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x82455eb0
	if (cr6.eq) goto loc_82455EB0;
	// mr r23,r21
	r23.u64 = r21.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82455EB0:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r7,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r7.u32);
loc_82455EBC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x82455e60
	if (cr6.lt) goto loc_82455E60;
loc_82455ED0:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r28,r24
	r28.u64 = r24.u64;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// bge cr6,0x82455f18
	if (!cr6.lt) goto loc_82455F18;
	// rlwinm r30,r24,2,0,29
	r30.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
loc_82455EE4:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r29,r30,r11
	r29.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x82455f04
	if (cr0.eq) goto loc_82455F04;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243def8
	sub_8243DEF8(ctx, base);
loc_82455F04:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82455ee4
	if (cr6.lt) goto loc_82455EE4;
loc_82455F18:
	// stw r24,8(r26)
	PPC_STORE_U32(r26.u32 + 8, r24.u32);
	// b 0x8245675c
	goto loc_8245675C;
loc_82455F20:
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245674c
	if (!cr6.gt) goto loc_8245674C;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_82455F30:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r7,16(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r6,48(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r6,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r7.u32);
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm. r7,r7,0,30,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82455f9c
	if (cr0.eq) goto loc_82455F9C;
	// lwz r7,96(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82455f9c
	if (!cr6.eq) goto loc_82455F9C;
	// lwz r9,96(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 96);
	// stw r9,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r9.u32);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r7,20(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,100(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 100);
	// stw r9,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r9.u32);
loc_82455F9C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x82455f30
	if (cr6.lt) goto loc_82455F30;
	// b 0x8245674c
	goto loc_8245674C;
loc_82455FB4:
	// cmplw cr6,r11,r17
	cr6.compare<uint32_t>(r11.u32, r17.u32, xer);
	// bne cr6,0x824563b0
	if (!cr6.eq) goto loc_824563B0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r27,r22
	r27.u64 = r22.u64;
	// mr r29,r22
	r29.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824561c8
	if (!cr6.gt) goto loc_824561C8;
	// mr r28,r22
	r28.u64 = r22.u64;
loc_82455FD4:
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r7,r7,0,0,11
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFF00000;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r30,r8,r28
	r30.u64 = PPC_LOAD_U32(ctx.r8.u32 + r28.u32);
	// rlwinm r8,r9,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + r29.u64;
	// add r8,r8,r29
	ctx.r8.u64 = ctx.r8.u64 + r29.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r7,r17
	cr6.compare<uint32_t>(ctx.r7.u32, r17.u32, xer);
	// lwzx r7,r10,r28
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r28.u32);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r7,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r6,48(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// lwz r7,48(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// lwz r8,48(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// bne cr6,0x82456154
	if (!cr6.eq) goto loc_82456154;
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r30,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r9,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r9,r5,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + r11.u32);
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// or r11,r5,r11
	r11.u64 = ctx.r5.u64 | r11.u64;
	// rlwinm r11,r11,0,4,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE000000;
	// rlwinm. r3,r11,0,4,4
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82456074
	if (cr0.eq) goto loc_82456074;
	// lis r11,2048
	r11.s64 = 134217728;
	// b 0x82456090
	goto loc_82456090;
loc_82456074:
	// rlwinm. r3,r11,0,5,5
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82456084
	if (cr0.eq) goto loc_82456084;
	// lis r11,1024
	r11.s64 = 67108864;
	// b 0x82456090
	goto loc_82456090;
loc_82456084:
	// rlwinm. r3,r11,0,6,6
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82456090
	if (cr0.eq) goto loc_82456090;
	// lis r11,512
	r11.s64 = 33554432;
loc_82456090:
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r9,r9,0,4,6
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE000000;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// rlwinm. r9,r11,0,6,6
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824560ac
	if (cr0.eq) goto loc_824560AC;
	// lis r11,512
	r11.s64 = 33554432;
	// b 0x824560c8
	goto loc_824560C8;
loc_824560AC:
	// rlwinm. r9,r11,0,5,5
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824560bc
	if (cr0.eq) goto loc_824560BC;
	// lis r11,1024
	r11.s64 = 67108864;
	// b 0x824560c8
	goto loc_824560C8;
loc_824560BC:
	// rlwinm. r9,r11,0,4,4
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824560c8
	if (cr0.eq) goto loc_824560C8;
	// lis r11,2048
	r11.s64 = 134217728;
loc_824560C8:
	// rlwinm r9,r5,0,4,6
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8245610c
	if (cr6.eq) goto loc_8245610C;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r3,16(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r3
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8245610c
	if (cr0.eq) goto loc_8245610C;
	// lwz r9,92(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 92);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x8245610c
	if (!cr6.eq) goto loc_8245610C;
	// rlwinm r9,r5,0,7,3
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// mr r23,r21
	r23.u64 = r21.u64;
	// or r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 | r11.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
loc_8245610C:
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r9,r10,0,4,6
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE000000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x82456154
	if (cr6.eq) goto loc_82456154;
	// lwz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r5,16(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82456154
	if (cr0.eq) goto loc_82456154;
	// lwz r9,92(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 92);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x82456154
	if (!cr6.eq) goto loc_82456154;
	// rlwinm r10,r10,0,7,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// mr r23,r21
	r23.u64 = r21.u64;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
loc_82456154:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82444ba0
	sub_82444BA0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824568a8
	if (cr0.lt) goto loc_824568A8;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// bne cr6,0x8245618c
	if (!cr6.eq) goto loc_8245618C;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// b 0x824561b4
	goto loc_824561B4;
loc_8245618C:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x824561b4
	if (!cr6.eq) goto loc_824561B4;
	// lwzx r10,r9,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
loc_824561B4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82455fd4
	if (cr6.lt) goto loc_82455FD4;
loc_824561C8:
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r27,r7
	cr6.compare<uint32_t>(r27.u32, ctx.r7.u32, xer);
	// beq cr6,0x8245675c
	if (cr6.eq) goto loc_8245675C;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x824562e4
	if (!cr6.eq) goto loc_824562E4;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// ble cr6,0x82456248
	if (!cr6.gt) goto loc_82456248;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,48(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
loc_82456210:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r6,48(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// bne cr6,0x824562dc
	if (!cr6.eq) goto loc_824562DC;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// blt cr6,0x82456210
	if (cr6.lt) goto loc_82456210;
loc_82456248:
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x8245674c
	if (cr6.eq) goto loc_8245674C;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_82456258:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r7,16(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r6,48(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r6,r11
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r11.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r6,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r7.u32);
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm. r7,r7,0,30,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x824562c4
	if (cr0.eq) goto loc_824562C4;
	// lwz r7,96(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x824562c4
	if (!cr6.eq) goto loc_824562C4;
	// lwz r9,96(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 96);
	// stw r9,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r9.u32);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r7,20(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwz r9,100(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 100);
	// stw r9,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r9.u32);
loc_824562C4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x82456258
	if (cr6.lt) goto loc_82456258;
	// b 0x8245674c
	goto loc_8245674C;
loc_824562DC:
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x82456248
	if (cr0.eq) goto loc_82456248;
loc_824562E4:
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82456364
	if (cr6.eq) goto loc_82456364;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
loc_824562F4:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r7,r5,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r11,r10
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r9,48(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// beq cr6,0x82456350
	if (cr6.eq) goto loc_82456350;
	// rotlwi r9,r6,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r6.u32, 0);
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r9,48(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,7,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFF1FFFFFF;
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// beq cr6,0x82456344
	if (cr6.eq) goto loc_82456344;
	// mr r23,r21
	r23.u64 = r21.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82456344:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r7,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r7.u32);
loc_82456350:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// blt cr6,0x824562f4
	if (cr6.lt) goto loc_824562F4;
loc_82456364:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r28,r24
	r28.u64 = r24.u64;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// bge cr6,0x82455f18
	if (!cr6.lt) goto loc_82455F18;
	// rlwinm r30,r24,2,0,29
	r30.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
loc_82456378:
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r29,r30,r11
	r29.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x82456398
	if (cr0.eq) goto loc_82456398;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8243def8
	sub_8243DEF8(ctx, base);
loc_82456398:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82456378
	if (cr6.lt) goto loc_82456378;
	// b 0x82455f18
	goto loc_82455F18;
loc_824563B0:
	// lis r11,20480
	r11.s64 = 1342177280;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82456474
	if (!cr6.eq) goto loc_82456474;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82445330
	sub_82445330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824568a8
	if (cr0.lt) goto loc_824568A8;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x824563e0
	if (cr6.eq) goto loc_824563E0;
	// mr r23,r21
	r23.u64 = r21.u64;
loc_824563E0:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r8,48(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x8245675c
	if (cr6.eq) goto loc_8245675C;
	// rotlwi r10,r9,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// lwz r9,16(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r8,48(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82456464
	if (cr0.eq) goto loc_82456464;
	// lwz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82456464
	if (!cr6.eq) goto loc_82456464;
	// lwz r10,96(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 96);
	// stw r10,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r10.u32);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,100(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 100);
	// stw r10,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r10.u32);
loc_82456464:
	// stw r22,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r22.u32);
	// stw r22,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r22.u32);
	// stw r22,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r22.u32);
	// b 0x8245675c
	goto loc_8245675C;
loc_82456474:
	// lis r11,20496
	r11.s64 = 1343225856;
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x8245675c
	if (!cr6.eq) goto loc_8245675C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// lwz r9,16(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// stw r21,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r21.u32);
	// stw r21,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r21.u32);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r5,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r5.u32);
	// rlwinm r4,r11,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// lwzx r11,r8,r10
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r8,r7,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwzx r7,r4,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r10.u32);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r4,r4,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r4,r9
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r9.u32);
	// lwz r4,4(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// rlwinm. r4,r4,0,23,23
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x8245658c
	if (cr0.eq) goto loc_8245658C;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmpwi cr6,r4,-1
	cr6.compare<int32_t>(ctx.r4.s32, -1, xer);
	// bne cr6,0x8245658c
	if (!cr6.eq) goto loc_8245658C;
	// lfd f0,32(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x82456580
	if (!cr6.gt) goto loc_82456580;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// li r6,2
	ctx.r6.s64 = 2;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824565b0
	if (cr0.eq) goto loc_824565B0;
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824565b0
	if (!cr6.eq) goto loc_824565B0;
	// lfd f0,32(r8)
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x82456584
	if (!cr6.gt) goto loc_82456584;
	// lwz r11,4(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824565b0
	if (cr0.eq) goto loc_824565B0;
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824565b0
	if (!cr6.eq) goto loc_824565B0;
	// lfd f0,32(r7)
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + 32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x8245656c
	if (!cr6.eq) goto loc_8245656C;
	// stw r21,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r21.u32);
	// b 0x824565e4
	goto loc_824565E4;
loc_8245656C:
	// fcmpu cr6,f0,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f30.f64);
	// bne cr6,0x824565b0
	if (!cr6.eq) goto loc_824565B0;
	// li r11,3
	r11.s64 = 3;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// b 0x824565e4
	goto loc_824565E4;
loc_82456580:
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r22.u32);
loc_82456584:
	// stw r22,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r22.u32);
	// b 0x824565e4
	goto loc_824565E4;
loc_8245658C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,92(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824565b0
	if (!cr6.eq) goto loc_824565B0;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
loc_824565B0:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r11,92(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 92);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824565d4
	if (!cr6.eq) goto loc_824565D4;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// stw r5,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r5.u32);
loc_824565D4:
	// cmpwi cr6,r6,-1
	cr6.compare<int32_t>(ctx.r6.s32, -1, xer);
	// beq cr6,0x8245675c
	if (cr6.eq) goto loc_8245675C;
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x8245675c
	if (cr6.eq) goto loc_8245675C;
loc_824565E4:
	// mr r30,r22
	r30.u64 = r22.u64;
loc_824565E8:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x82456688
	if (cr6.lt) goto loc_82456688;
	// beq cr6,0x82456638
	if (cr6.eq) goto loc_82456638;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x82456614
	if (cr6.lt) goto loc_82456614;
	// bne cr6,0x824566d4
	if (!cr6.eq) goto loc_824566D4;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// b 0x8245661c
	goto loc_8245661C;
loc_82456614:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
loc_8245661C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// b 0x824566d4
	goto loc_824566D4;
loc_82456638:
	// cmpwi cr6,r14,-1
	cr6.compare<int32_t>(r14.s32, -1, xer);
	// bne cr6,0x8245666c
	if (!cr6.eq) goto loc_8245666C;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r10,r14,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r14,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r14.u32);
loc_8245666C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r14,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r14.u32);
	// b 0x824566d4
	goto loc_824566D4;
loc_82456688:
	// cmpwi cr6,r19,-1
	cr6.compare<int32_t>(r19.s32, -1, xer);
	// bne cr6,0x824566bc
	if (!cr6.eq) goto loc_824566BC;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r10,r19,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r19,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r19.u32);
loc_824566BC:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r19,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r19.u32);
loc_824566D4:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r9,16(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r8,48(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r8,r11
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm. r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82456740
	if (cr0.eq) goto loc_82456740;
	// lwz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82456740
	if (!cr6.eq) goto loc_82456740;
	// lwz r10,96(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 96);
	// stw r10,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r10.u32);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r10,r30,r10
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r10,100(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 100);
	// stw r10,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r10.u32);
loc_82456740:
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r30,16
	cr6.compare<uint32_t>(r30.u32, 16, xer);
	// blt cr6,0x824565e8
	if (cr6.lt) goto loc_824565E8;
loc_8245674C:
	// stw r22,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r22.u32);
	// stw r22,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r22.u32);
	// stw r22,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r22.u32);
loc_82456758:
	// mr r23,r21
	r23.u64 = r21.u64;
loc_8245675C:
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x82456868
	if (cr0.eq) goto loc_82456868;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x824567dc
	if (cr6.eq) goto loc_824567DC;
	// lwz r7,20(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
loc_8245677C:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm. r5,r9,0,25,25
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bne 0x824567dc
	if (!cr0.eq) goto loc_824567DC;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lis r12,1
	r12.s64 = 65536;
	// lwz r5,16(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// ori r12,r12,4136
	r12.u64 = r12.u64 | 4136;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// and. r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 & r12.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824567dc
	if (!cr0.eq) goto loc_824567DC;
	// rlwinm. r10,r9,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824567dc
	if (cr0.eq) goto loc_824567DC;
	// rlwinm. r10,r9,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824567dc
	if (cr0.eq) goto loc_824567DC;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// blt cr6,0x8245677c
	if (cr6.lt) goto loc_8245677C;
loc_824567DC:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// bne cr6,0x82456868
	if (!cr6.eq) goto loc_82456868;
	// cmpwi cr6,r19,-1
	cr6.compare<int32_t>(r19.s32, -1, xer);
	// bne cr6,0x82456818
	if (!cr6.eq) goto loc_82456818;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// rlwinm r10,r19,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r19,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r19.u32);
loc_82456818:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82456858
	if (!cr6.gt) goto loc_82456858;
	// mr r11,r22
	r11.u64 = r22.u64;
loc_8245682C:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stw r19,48(r9)
	PPC_STORE_U32(ctx.r9.u32 + 48, r19.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8245682c
	if (cr6.lt) goto loc_8245682C;
loc_82456858:
	// mr r23,r21
	r23.u64 = r21.u64;
	// stw r22,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r22.u32);
	// stw r22,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r22.u32);
	// stw r22,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r22.u32);
loc_82456868:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// cmplw cr6,r18,r11
	cr6.compare<uint32_t>(r18.u32, r11.u32, xer);
	// blt cr6,0x82455724
	if (cr6.lt) goto loc_82455724;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x8245689c
	if (!cr6.eq) goto loc_8245689C;
loc_82456880:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x824568a8
	goto loc_824568A8;
loc_82456888:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x824568a8
	goto loc_824568A8;
loc_82456894:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x824568a8
	goto loc_824568A8;
loc_8245689C:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_824568A8:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_824568B8"))) PPC_WEAK_FUNC(sub_824568B8);
PPC_FUNC_IMPL(__imp__sub_824568B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r14,-1
	r14.s64 = -1;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r14,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r14.u32);
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// li r22,0
	r22.s64 = 0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// beq 0x8245692c
	if (cr0.eq) goto loc_8245692C;
	// lwz r7,136(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
loc_824568FC:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r6,4(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// bne cr6,0x8245691c
	if (!cr6.eq) goto loc_8245691C;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8245691c
	if (cr6.gt) goto loc_8245691C;
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
loc_8245691C:
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x824568fc
	if (!cr0.eq) goto loc_824568FC;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
loc_8245692C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r28,r3
	r28.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r28.u32);
	// bne 0x82456960
	if (!cr0.eq) goto loc_82456960;
loc_82456954:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x824570b0
	goto loc_824570B0;
loc_82456960:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824569d0
	if (!cr6.gt) goto loc_824569D0;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
loc_82456984:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,136(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x824569bc
	if (!cr6.eq) goto loc_824569BC;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r10,r28
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r28.u32);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bgt cr6,0x824569bc
	if (cr6.gt) goto loc_824569BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stwx r11,r10,r28
	PPC_STORE_U32(ctx.r10.u32 + r28.u32, r11.u32);
loc_824569BC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x82456984
	if (cr6.lt) goto loc_82456984;
loc_824569D0:
	// lwz r15,12(r31)
	r15.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// stw r22,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r22.u32);
	// cmplwi r15,0
	cr0.compare<uint32_t>(r15.u32, 0, xer);
	// beq 0x82457020
	if (cr0.eq) goto loc_82457020;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// lfd f30,-31360(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// lfd f31,-31368(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_824569F8:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r27,r9,r11
	r27.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82456ffc
	if (cr0.eq) goto loc_82456FFC;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// li r29,1
	r29.s64 = 1;
	// mr r30,r22
	r30.u64 = r22.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824570c0
	if (cr0.eq) goto loc_824570C0;
loc_82456A2C:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// mr r9,r15
	ctx.r9.u64 = r15.u64;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82456a5c
	if (!cr0.eq) goto loc_82456A5C;
	// mr r29,r22
	r29.u64 = r22.u64;
loc_82456A5C:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x82456a2c
	if (!cr0.eq) goto loc_82456A2C;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x824570c0
	if (!cr6.eq) goto loc_824570C0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8243d0e8
	sub_8243D0E8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824570c0
	if (!cr0.eq) goto loc_824570C0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r18,r22
	r18.u64 = r22.u64;
	// bl 0x8243d090
	sub_8243D090(ctx, base);
	// mr. r24,r3
	r24.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// beq 0x82456abc
	if (cr0.eq) goto loc_82456ABC;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// twllei r24,0
	// divwu r20,r11,r24
	r20.u32 = r11.u32 / r24.u32;
	// b 0x82456ac0
	goto loc_82456AC0;
loc_82456ABC:
	// mr r20,r22
	r20.u64 = r22.u64;
loc_82456AC0:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// mr r21,r22
	r21.u64 = r22.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// std r22,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r22.u64);
	// std r22,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r22.u64);
	// beq cr6,0x82456ffc
	if (cr6.eq) goto loc_82456FFC;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lwz r16,80(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r19,r1,128
	r19.s64 = ctx.r1.s64 + 128;
	// subfic r17,r11,4
	xer.ca = r11.u32 <= 4;
	r17.s64 = 4 - r11.s64;
loc_82456AE8:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// add r10,r22,r11
	ctx.r10.u64 = r22.u64 + r11.u64;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82456e54
	if (!cr6.eq) goto loc_82456E54;
	// addi r11,r21,1
	r11.s64 = r21.s64 + 1;
	// li r23,1
	r23.s64 = 1;
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bge cr6,0x82456bd0
	if (!cr6.lt) goto loc_82456BD0;
	// subf r9,r22,r17
	ctx.r9.s64 = r17.s64 - r22.s64;
	// addi r30,r10,4
	r30.s64 = ctx.r10.s64 + 4;
	// add r4,r9,r10
	ctx.r4.u64 = ctx.r9.u64 + ctx.r10.u64;
	// subf r3,r11,r24
	ctx.r3.s64 = r24.s64 - r11.s64;
loc_82456B1C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82456bc0
	if (!cr6.eq) goto loc_82456BC0;
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82456bb4
	if (cr6.eq) goto loc_82456BB4;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r6,r24,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// add r11,r11,r22
	r11.u64 = r11.u64 + r22.u64;
loc_82456B44:
	// lwzx r10,r4,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + r11.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r7,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwzx r29,r7,r9
	r29.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r29,4(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmplw cr6,r29,r8
	cr6.compare<uint32_t>(r29.u32, ctx.r8.u32, xer);
	// bne cr6,0x82456bb4
	if (!cr6.eq) goto loc_82456BB4;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r29,r8,r10
	r29.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// lwz r29,8(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmplw cr6,r8,r29
	cr6.compare<uint32_t>(ctx.r8.u32, r29.u32, xer);
	// bne cr6,0x82456bb4
	if (!cr6.eq) goto loc_82456BB4;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x82456bb4
	if (!cr6.eq) goto loc_82456BB4;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// add r11,r6,r11
	r11.u64 = ctx.r6.u64 + r11.u64;
	// cmplw cr6,r5,r20
	cr6.compare<uint32_t>(ctx.r5.u32, r20.u32, xer);
	// blt cr6,0x82456b44
	if (cr6.lt) goto loc_82456B44;
loc_82456BB4:
	// cmplw cr6,r5,r20
	cr6.compare<uint32_t>(ctx.r5.u32, r20.u32, xer);
	// bne cr6,0x82456bc0
	if (!cr6.eq) goto loc_82456BC0;
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
loc_82456BC0:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x82456b1c
	if (!cr0.eq) goto loc_82456B1C;
loc_82456BD0:
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// rlwimi r4,r23,0,12,31
	ctx.r4.u64 = (__builtin_rotateleft32(r23.u32, 0) & 0xFFFFF) | (ctx.r4.u64 & 0xFFFFFFFFFFF00000);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmpwi cr6,r26,-1
	cr6.compare<int32_t>(r26.s32, -1, xer);
	// beq cr6,0x82457164
	if (cr6.eq) goto loc_82457164;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// addi r11,r23,-1
	r11.s64 = r23.s64 + -1;
	// cmplw cr6,r24,r21
	cr6.compare<uint32_t>(r24.u32, r21.u32, xer);
	// ble cr6,0x82456d60
	if (!cr6.gt) goto loc_82456D60;
	// rlwinm r4,r24,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r25,r21,r24
	r25.s64 = r24.s64 - r21.s64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// subf r29,r22,r4
	r29.s64 = ctx.r4.s64 - r22.s64;
loc_82456C2C:
	// addi r5,r5,-4
	ctx.r5.s64 = ctx.r5.s64 + -4;
	// addi r28,r1,112
	r28.s64 = ctx.r1.s64 + 112;
	// addi r29,r29,-4
	r29.s64 = r29.s64 + -4;
	// lwzx r11,r5,r28
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + r28.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82456d58
	if (!cr6.eq) goto loc_82456D58;
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82456d10
	if (cr6.eq) goto loc_82456D10;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// add r9,r11,r22
	ctx.r9.u64 = r11.u64 + r22.u64;
loc_82456C5C:
	// lwzx r11,r9,r29
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r29.u32);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r7
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwzx r14,r10,r7
	r14.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r14,4(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 4);
	// cmplw cr6,r14,r8
	cr6.compare<uint32_t>(r14.u32, ctx.r8.u32, xer);
	// bne cr6,0x82456ccc
	if (!cr6.eq) goto loc_82456CCC;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r14,r10,r8
	r14.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r14,8(r14)
	r14.u64 = PPC_LOAD_U32(r14.u32 + 8);
	// lwz r8,8(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmplw cr6,r14,r8
	cr6.compare<uint32_t>(r14.u32, ctx.r8.u32, xer);
	// bne cr6,0x82456ccc
	if (!cr6.eq) goto loc_82456CCC;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82456ccc
	if (!cr6.eq) goto loc_82456CCC;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// cmplw cr6,r6,r20
	cr6.compare<uint32_t>(ctx.r6.u32, r20.u32, xer);
	// blt cr6,0x82456c5c
	if (cr6.lt) goto loc_82456C5C;
loc_82456CCC:
	// cmplw cr6,r6,r20
	cr6.compare<uint32_t>(ctx.r6.u32, r20.u32, xer);
	// blt cr6,0x82456d54
	if (cr6.lt) goto loc_82456D54;
	// rlwinm r8,r23,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// mr r11,r20
	r11.u64 = r20.u64;
loc_82456CE4:
	// lwz r7,8(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r6,8(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// stwx r7,r9,r6
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, ctx.r7.u32);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// bne 0x82456ce4
	if (!cr0.eq) goto loc_82456CE4;
	// li r11,1
	r11.s64 = 1;
	// li r14,-1
	r14.s64 = -1;
	// stwx r11,r5,r28
	PPC_STORE_U32(ctx.r5.u32 + r28.u32, r11.u32);
loc_82456D10:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82456d4c
	if (cr6.eq) goto loc_82456D4C;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// stwx r11,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r26,72(r11)
	PPC_STORE_U32(r11.u32 + 72, r26.u32);
loc_82456D4C:
	// addi r3,r3,-4
	ctx.r3.s64 = ctx.r3.s64 + -4;
	// b 0x82456d58
	goto loc_82456D58;
loc_82456D54:
	// li r14,-1
	r14.s64 = -1;
loc_82456D58:
	// addic. r25,r25,-1
	xer.ca = r25.u32 > 0;
	r25.s64 = r25.s64 + -1;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// bne 0x82456c2c
	if (!cr0.eq) goto loc_82456C2C;
loc_82456D60:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lis r10,20480
	ctx.r10.s64 = 1342177280;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82456e54
	if (!cr6.eq) goto loc_82456E54;
	// cmplw cr6,r23,r24
	cr6.compare<uint32_t>(r23.u32, r24.u32, xer);
	// bne cr6,0x82456d90
	if (!cr6.eq) goto loc_82456D90;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// b 0x82456e3c
	goto loc_82456E3C;
loc_82456D90:
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// mr r5,r16
	ctx.r5.u64 = r16.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stw r3,0(r19)
	PPC_STORE_U32(r19.u32 + 0, ctx.r3.u32);
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82457164
	if (cr6.eq) goto loc_82457164;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r9,16(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r10,20(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// bl 0x82445330
	sub_82445330(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824570b0
	if (cr0.lt) goto loc_824570B0;
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// addi r19,r19,4
	r19.s64 = r19.s64 + 4;
loc_82456E3C:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r26,72(r11)
	PPC_STORE_U32(r11.u32 + 72, r26.u32);
loc_82456E54:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmplw cr6,r21,r24
	cr6.compare<uint32_t>(r21.u32, r24.u32, xer);
	// blt cr6,0x82456ae8
	if (cr6.lt) goto loc_82456AE8;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82456ff8
	if (cr6.eq) goto loc_82456FF8;
	// cmplwi cr6,r18,2
	cr6.compare<uint32_t>(r18.u32, 2, xer);
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
	// mr r5,r14
	ctx.r5.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x82456f20
	if (!cr6.eq) goto loc_82456F20;
	// lis r4,8256
	ctx.r4.s64 = 541065216;
	// ori r4,r4,1
	ctx.r4.u64 = ctx.r4.u64 | 1;
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// li r9,2
	ctx.r9.s64 = 2;
loc_82456E98:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lis r8,4096
	ctx.r8.s64 = 268435456;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r7,72(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 72);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r6
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// lwz r7,0(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r7,r7,0,0,11
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// bne cr6,0x82456f10
	if (!cr6.eq) goto loc_82456F10;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rotlwi r7,r6,0
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r6.u32, 0);
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r8,72(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r10,72(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_82456F10:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82456e98
	if (!cr0.eq) goto loc_82456E98;
	// b 0x82456f34
	goto loc_82456F34;
loc_82456F20:
	// li r11,5
	r11.s64 = 5;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_82456F34:
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x82456954
	if (cr6.eq) goto loc_82456954;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r28,r18,2,0,29
	r28.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r29,72(r11)
	PPC_STORE_U32(r11.u32 + 72, r29.u32);
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// cmplwi cr6,r18,2
	cr6.compare<uint32_t>(r18.u32, 2, xer);
	// beq cr6,0x82456ff0
	if (cr6.eq) goto loc_82456FF0;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82456fc8
	if (!cr6.eq) goto loc_82456FC8;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,120(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243e3a8
	sub_8243E3A8(ctx, base);
	// stw r3,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82457164
	if (cr6.eq) goto loc_82457164;
loc_82456FC8:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82456ff0
	if (cr6.eq) goto loc_82456FF0;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// mr r11,r18
	r11.u64 = r18.u64;
loc_82456FD8:
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stwx r8,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82456fd8
	if (!cr0.eq) goto loc_82456FD8;
loc_82456FF0:
	// addi r11,r16,1
	r11.s64 = r16.s64 + 1;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_82456FF8:
	// lwz r28,88(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82456FFC:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r22,0
	r22.s64 = 0;
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r15
	cr6.compare<uint32_t>(r11.u32, r15.u32, xer);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// blt cr6,0x824569f8
	if (cr6.lt) goto loc_824569F8;
loc_82457020:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x82457048
	if (cr6.eq) goto loc_82457048;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// mr r11,r15
	r11.u64 = r15.u64;
loc_82457030:
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r22,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r22.u32);
	// bne 0x82457030
	if (!cr0.eq) goto loc_82457030;
loc_82457048:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82448278
	sub_82448278(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82457064
	if (cr0.eq) goto loc_82457064;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x824570a0
	if (cr6.lt) goto loc_824570A0;
loc_82457064:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82457080
	if (cr0.eq) goto loc_82457080;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x824570a0
	if (cr6.lt) goto loc_824570A0;
loc_82457080:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82448968
	sub_82448968(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245709c
	if (cr0.eq) goto loc_8245709C;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x824570a0
	if (cr6.lt) goto loc_824570A0;
loc_8245709C:
	// mr r30,r22
	r30.u64 = r22.u64;
loc_824570A0:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_824570B0:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8239bd10
	return;
loc_824570C0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r6,12(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// lwz r5,4(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x8243e448
	sub_8243E448(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x82457164
	if (cr6.eq) goto loc_82457164;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwzx r30,r10,r11
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// lwz r4,8(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// lwz r4,16(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r11,r22
	r11.u64 = r22.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82456ffc
	if (!cr6.gt) goto loc_82456FFC;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_82457134:
	// lwz r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stw r29,72(r9)
	PPC_STORE_U32(ctx.r9.u32 + 72, r29.u32);
	// lwz r9,12(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82457134
	if (cr6.lt) goto loc_82457134;
	// b 0x82456ffc
	goto loc_82456FFC;
loc_82457164:
	// lis r30,-32761
	r30.s64 = -2147024896;
	// lwz r28,88(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x824570a0
	goto loc_824570A0;
}

__attribute__((alias("__imp__sub_82457174"))) PPC_WEAK_FUNC(sub_82457174);
PPC_FUNC_IMPL(__imp__sub_82457174) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82457178"))) PPC_WEAK_FUNC(sub_82457178);
PPC_FUNC_IMPL(__imp__sub_82457178) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r11,204(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245719c
	if (cr0.eq) goto loc_8245719C;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x824582a4
	goto loc_824582A4;
loc_8245719C:
	// li r17,0
	r17.s64 = 0;
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// mr r11,r17
	r11.u64 = r17.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stw r17,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r17.u32);
	// ble cr6,0x824571d8
	if (!cr6.gt) goto loc_824571D8;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
loc_824571B8:
	// lwz r9,16(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r17,16(r9)
	PPC_STORE_U32(ctx.r9.u32 + 16, r17.u32);
	// lwz r9,4(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x824571b8
	if (cr6.lt) goto loc_824571B8;
loc_824571D8:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82457250
	if (!cr6.gt) goto loc_82457250;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
loc_824571EC:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r10,116(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 116);
	// lwzx r9,r8,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x8245723c
	if (cr6.eq) goto loc_8245723C;
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r6,r10,0,30,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x8245723c
	if (cr0.eq) goto loc_8245723C;
	// rlwinm. r10,r10,0,21,21
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8245723c
	if (!cr0.eq) goto loc_8245723C;
	// lwz r10,12(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bge cr6,0x8245723c
	if (!cr6.lt) goto loc_8245723C;
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
loc_8245723C:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x824571ec
	if (cr6.lt) goto loc_824571EC;
loc_82457250:
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82457280
	if (!cr6.gt) goto loc_82457280;
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
loc_82457268:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// bne 0x82457268
	if (!cr0.eq) goto loc_82457268;
loc_82457280:
	// rlwinm r31,r9,2,0,29
	r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r30,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r30.u32);
	// beq 0x824582ac
	if (cr0.eq) goto loc_824582AC;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82457310
	if (!cr6.gt) goto loc_82457310;
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// mr r11,r17
	r11.u64 = r17.u64;
loc_824572C8:
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x824572e4
	if (cr6.eq) goto loc_824572E4;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + r30.u64;
	// b 0x824572e8
	goto loc_824572E8;
loc_824572E4:
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
loc_824572E8:
	// stw r10,28(r7)
	PPC_STORE_U32(ctx.r7.u32 + 28, ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r7,4(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r7,16(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// add r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 + ctx.r8.u64;
	// blt cr6,0x824572c8
	if (cr6.lt) goto loc_824572C8;
loc_82457310:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82457388
	if (!cr6.gt) goto loc_82457388;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
loc_82457324:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r9,116(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 116);
	// lwzx r10,r11,r8
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x82457374
	if (cr6.eq) goto loc_82457374;
	// lwz r9,16(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82457374
	if (cr0.eq) goto loc_82457374;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r6,r9,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmplw cr6,r6,r10
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, xer);
	// bge cr6,0x82457374
	if (!cr6.lt) goto loc_82457374;
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r10.u32);
loc_82457374:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x82457324
	if (cr6.lt) goto loc_82457324;
loc_82457388:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82457444
	if (!cr6.gt) goto loc_82457444;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
loc_8245739C:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lis r9,24576
	ctx.r9.s64 = 1610612736;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r8,r10,0,0,3
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// beq cr6,0x824573c8
	if (cr6.eq) goto loc_824573C8;
	// rlwinm r10,r10,0,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFF00000;
	// lis r9,4352
	ctx.r9.s64 = 285212672;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bne cr6,0x82457430
	if (!cr6.eq) goto loc_82457430;
loc_824573C8:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82457430
	if (!cr6.gt) goto loc_82457430;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
loc_824573DC:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,20(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r4,16(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwzx r10,r8,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r4
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	// lwz r9,28(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8245741c
	if (cr0.eq) goto loc_8245741C;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// li r4,4
	ctx.r4.s64 = 4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r4,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r4.u32);
loc_8245741C:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x824573dc
	if (cr6.lt) goto loc_824573DC;
loc_82457430:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// blt cr6,0x8245739c
	if (cr6.lt) goto loc_8245739C;
loc_82457444:
	// lwz r11,108(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// rlwinm. r10,r11,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8245780c
	if (!cr0.eq) goto loc_8245780C;
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8245780c
	if (!cr0.eq) goto loc_8245780C;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r20,r17
	r20.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245780c
	if (!cr6.gt) goto loc_8245780C;
	// lis r11,8272
	r11.s64 = 542113792;
	// mr r21,r17
	r21.u64 = r17.u64;
	// ori r19,r11,1
	r19.u64 = r11.u64 | 1;
	// lis r18,20480
	r18.s64 = 1342177280;
	// li r22,-1
	r22.s64 = -1;
loc_82457484:
	// lwz r8,24(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lis r11,8256
	r11.s64 = 541065216;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// lwzx r25,r21,r8
	r25.u64 = PPC_LOAD_U32(r21.u32 + ctx.r8.u32);
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x824577f8
	if (!cr6.eq) goto loc_824577F8;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// lwz r7,20(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r11,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r7
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwzx r9,r6,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r7.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r6,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r6,4(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm. r6,r6,0,30,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x824577f8
	if (cr0.eq) goto loc_824577F8;
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r6,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824577f8
	if (cr0.eq) goto loc_824577F8;
	// lwz r11,72(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r10,72(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 72);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r24,r11,r8
	r24.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwzx r23,r10,r8
	r23.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x82457524
	if (cr6.eq) goto loc_82457524;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// bne cr6,0x824577f8
	if (!cr6.eq) goto loc_824577F8;
loc_82457524:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// beq cr6,0x8245753c
	if (cr6.eq) goto loc_8245753C;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r18
	cr6.compare<uint32_t>(r11.u32, r18.u32, xer);
	// bne cr6,0x824577f8
	if (!cr6.eq) goto loc_824577F8;
loc_8245753C:
	// lwz r9,4(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// li r10,2
	ctx.r10.s64 = 2;
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// lwz r8,108(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// rlwinm r30,r9,31,1,31
	r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r11,r11,31,1,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// not r9,r8
	ctx.r9.u64 = ~ctx.r8.u64;
	// add r26,r30,r11
	r26.u64 = r30.u64 + r11.u64;
	// rlwimi r10,r9,7,31,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 7) & 0x1) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFFE);
	// cmplw cr6,r26,r10
	cr6.compare<uint32_t>(r26.u32, ctx.r10.u32, xer);
	// blt cr6,0x824577f8
	if (cr6.lt) goto loc_824577F8;
	// cmplwi cr6,r26,4
	cr6.compare<uint32_t>(r26.u32, 4, xer);
	// bgt cr6,0x824577f8
	if (cr6.gt) goto loc_824577F8;
	// lwz r10,16(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 16);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r9,84(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r20,r9
	cr6.compare<uint32_t>(r20.u32, ctx.r9.u32, xer);
	// bne cr6,0x824577f8
	if (!cr6.eq) goto loc_824577F8;
	// lwz r10,88(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	// cmplw cr6,r20,r10
	cr6.compare<uint32_t>(r20.u32, ctx.r10.u32, xer);
	// bne cr6,0x824577f8
	if (!cr6.eq) goto loc_824577F8;
	// lwz r10,16(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 16);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r9,84(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r20,r9
	cr6.compare<uint32_t>(r20.u32, ctx.r9.u32, xer);
	// bne cr6,0x824577f8
	if (!cr6.eq) goto loc_824577F8;
	// lwz r10,88(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 88);
	// cmplw cr6,r20,r10
	cr6.compare<uint32_t>(r20.u32, ctx.r10.u32, xer);
	// bne cr6,0x824577f8
	if (!cr6.eq) goto loc_824577F8;
	// lwz r29,8(r24)
	r29.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// rlwinm r31,r11,2,0,29
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r28,8(r23)
	r28.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// rlwinm r30,r30,2,0,29
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// add r4,r29,r31
	ctx.r4.u64 = r29.u64 + r31.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// add r4,r28,r30
	ctx.r4.u64 = r28.u64 + r30.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82457678
	if (cr0.eq) goto loc_82457678;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82457678
	if (cr0.eq) goto loc_82457678;
	// mr r28,r17
	r28.u64 = r17.u64;
	// b 0x82457724
	goto loc_82457724;
loc_82457678:
	// lwz r29,8(r24)
	r29.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r28,8(r23)
	r28.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// add r4,r28,r30
	ctx.r4.u64 = r28.u64 + r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// add r4,r29,r31
	ctx.r4.u64 = r29.u64 + r31.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824577f8
	if (cr0.eq) goto loc_824577F8;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824577f8
	if (cr0.eq) goto loc_824577F8;
	// li r28,1
	r28.s64 = 1;
loc_82457724:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x8243d710
	sub_8243D710(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82457740
	if (cr0.eq) goto loc_82457740;
	// bl 0x8243d018
	sub_8243D018(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82457744
	goto loc_82457744;
loc_82457740:
	// mr r31,r17
	r31.u64 = r17.u64;
loc_82457744:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x824582ac
	if (cr6.eq) goto loc_824582AC;
	// li r11,5
	r11.s64 = 5;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwimi r4,r11,28,0,11
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 28) & 0xFFF00000) | (ctx.r4.u64 & 0xFFFFFFFF000FFFFF);
	// li r6,1
	ctx.r6.s64 = 1;
	// rlwinm r5,r26,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d7a8
	sub_8243D7A8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x824582b8
	if (cr0.lt) goto loc_824582B8;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x824582b8
	if (cr0.lt) goto loc_824582B8;
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// beq cr6,0x824577a8
	if (cr6.eq) goto loc_824577A8;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
loc_824577A8:
	// rlwinm r30,r26,2,0,29
	r30.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// beq cr6,0x824577c8
	if (cr6.eq) goto loc_824577C8;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
loc_824577C8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// stwx r31,r11,r21
	PPC_STORE_U32(r11.u32 + r21.u32, r31.u32);
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// stw r17,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r17.u32);
	// stw r17,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r17.u32);
loc_824577F8:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// addi r20,r20,1
	r20.s64 = r20.s64 + 1;
	// addi r21,r21,4
	r21.s64 = r21.s64 + 4;
	// cmplw cr6,r20,r11
	cr6.compare<uint32_t>(r20.u32, r11.u32, xer);
	// blt cr6,0x82457484
	if (cr6.lt) goto loc_82457484;
loc_8245780C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r14,r17
	r14.u64 = r17.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82458288
	if (!cr6.gt) goto loc_82458288;
loc_82457824:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// rlwinm r10,r14,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r14.u32 | (r14.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// rlwinm r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82458278
	if (cr6.lt) goto loc_82458278;
	// lis r8,16384
	ctx.r8.s64 = 1073741824;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// bgt cr6,0x82458278
	if (cr6.gt) goto loc_82458278;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x82457874
	if (cr6.eq) goto loc_82457874;
	// lwz r11,108(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// rlwinm. r10,r11,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82458278
	if (!cr0.eq) goto loc_82458278;
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82458278
	if (!cr0.eq) goto loc_82458278;
loc_82457874:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d420
	sub_8243D420(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458278
	if (!cr0.eq) goto loc_82458278;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r6,20(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r5,16(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r11,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, r11.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r5
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r5.u32);
	// lwz r16,28(r11)
	r16.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi r16,0
	cr0.compare<uint32_t>(r16.u32, 0, xer);
	// beq 0x82458278
	if (cr0.eq) goto loc_82458278;
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r15,r11
	r15.u64 = r11.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// ble cr6,0x82457938
	if (!cr6.gt) goto loc_82457938;
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rotlwi r7,r10,0
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
loc_824578E0:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// b 0x82457920
	goto loc_82457920;
loc_824578E8:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8245791c
	if (cr0.eq) goto loc_8245791C;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bge cr6,0x8245791c
	if (!cr6.lt) goto loc_8245791C;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
loc_8245791C:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_82457920:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x824578e8
	if (!cr6.eq) goto loc_824578E8;
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x824578e0
	if (!cr0.eq) goto loc_824578E0;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
loc_82457938:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824579bc
	if (!cr6.gt) goto loc_824579BC;
	// rotlwi r8,r11,0
	ctx.r8.u64 = __builtin_rotateleft32(r11.u32, 0);
loc_82457948:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r6
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r11,84(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	// cmplw cr6,r15,r11
	cr6.compare<uint32_t>(r15.u32, r11.u32, xer);
	// ble cr6,0x82457964
	if (!cr6.gt) goto loc_82457964;
	// mr r15,r11
	r15.u64 = r11.u64;
loc_82457964:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// b 0x824579a4
	goto loc_824579A4;
loc_8245796C:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r6
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824579a0
	if (cr0.eq) goto loc_824579A0;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bge cr6,0x824579a0
	if (!cr6.lt) goto loc_824579A0;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
loc_824579A0:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_824579A4:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8245796c
	if (!cr6.eq) goto loc_8245796C;
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82457948
	if (!cr0.eq) goto loc_82457948;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
loc_824579BC:
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// cmplw cr6,r4,r15
	cr6.compare<uint32_t>(ctx.r4.u32, r15.u32, xer);
	// bge cr6,0x82458278
	if (!cr6.lt) goto loc_82458278;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rotlwi r29,r4,0
	r29.u64 = __builtin_rotateleft32(ctx.r4.u32, 0);
	// rlwinm r17,r11,2,0,29
	r17.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_824579D4:
	// cmplw cr6,r14,r29
	cr6.compare<uint32_t>(r14.u32, r29.u32, xer);
	// beq cr6,0x82457f04
	if (cr6.eq) goto loc_82457F04;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmplw cr6,r14,r29
	cr6.compare<uint32_t>(r14.u32, r29.u32, xer);
	// lwzx r30,r11,r17
	r30.u64 = PPC_LOAD_U32(r11.u32 + r17.u32);
	// mr r21,r30
	r21.u64 = r30.u64;
	// stw r30,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r30.u32);
	// blt cr6,0x824579fc
	if (cr6.lt) goto loc_824579FC;
	// lwz r21,116(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// bge cr6,0x82457a00
	if (!cr6.lt) goto loc_82457A00;
loc_824579FC:
	// lwz r30,116(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
loc_82457A00:
	// lwz r4,0(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r5,r4,0,0,11
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFF00000;
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// bne cr6,0x82457f04
	if (!cr6.eq) goto loc_82457F04;
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r7,20(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r6,r9
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r9.u32, xer);
	// bne cr6,0x82457f04
	if (!cr6.eq) goto loc_82457F04;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x82457f04
	if (!cr6.eq) goto loc_82457F04;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r8,20(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x82457f04
	if (!cr6.eq) goto loc_82457F04;
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r8,24(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// cmpw cr6,r9,r8
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, xer);
	// bne cr6,0x82457f04
	if (!cr6.eq) goto loc_82457F04;
	// lwz r23,12(r30)
	r23.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r22,12(r21)
	r22.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r8,4(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// add r24,r22,r23
	r24.u64 = r22.u64 + r23.u64;
	// add r18,r9,r8
	r18.u64 = ctx.r9.u64 + ctx.r8.u64;
	// cmplwi cr6,r24,4
	cr6.compare<uint32_t>(r24.u32, 4, xer);
	// bgt cr6,0x82457f04
	if (cr6.gt) goto loc_82457F04;
	// lwz r19,12(r11)
	r19.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r20,12(r10)
	r20.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r19,r20
	cr6.compare<uint32_t>(r19.u32, r20.u32, xer);
	// beq cr6,0x82457af4
	if (cr6.eq) goto loc_82457AF4;
	// lwz r11,108(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// rlwinm. r10,r11,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82457f04
	if (!cr0.eq) goto loc_82457F04;
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82457f04
	if (!cr0.eq) goto loc_82457F04;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82457f04
	if (!cr0.eq) goto loc_82457F04;
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r19,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r16
	r11.u64 = PPC_LOAD_U32(r11.u32 + r16.u32);
	// lwzx r10,r10,r16
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r16.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bgt cr6,0x82457f04
	if (cr6.gt) goto loc_82457F04;
loc_82457AF4:
	// cmplw cr6,r14,r29
	cr6.compare<uint32_t>(r14.u32, r29.u32, xer);
	// bge cr6,0x82457b00
	if (!cr6.lt) goto loc_82457B00;
	// mr r29,r14
	r29.u64 = r14.u64;
loc_82457B00:
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x82457e20
	if (cr6.eq) goto loc_82457E20;
	// lis r11,4112
	r11.s64 = 269484032;
	// cmplw cr6,r5,r11
	cr6.compare<uint32_t>(ctx.r5.u32, r11.u32, xer);
	// beq cr6,0x82457e20
	if (cr6.eq) goto loc_82457E20;
	// rlwinm r11,r4,0,0,3
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82457b7c
	if (!cr6.eq) goto loc_82457B7C;
	// rlwinm r31,r23,2,0,29
	r31.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// rlwinm r5,r22,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,8(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82457ebc
	if (cr0.eq) goto loc_82457EBC;
	// b 0x82457e94
	goto loc_82457E94;
loc_82457B7C:
	// lis r10,8192
	ctx.r10.s64 = 536870912;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82457d00
	if (!cr6.eq) goto loc_82457D00;
	// lwz r26,8(r30)
	r26.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r31,r23,2,0,29
	r31.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r25,8(r21)
	r25.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// rlwinm r28,r22,2,0,29
	r28.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// add r4,r26,r31
	ctx.r4.u64 = r26.u64 + r31.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// add r4,r25,r28
	ctx.r4.u64 = r25.u64 + r28.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x82457c3c
	if (cr6.eq) goto loc_82457C3C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82457e94
	if (!cr6.eq) goto loc_82457E94;
loc_82457C3C:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8243d178
	sub_8243D178(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82457ebc
	if (cr0.eq) goto loc_82457EBC;
	// lwz r26,8(r30)
	r26.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r25,8(r21)
	r25.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// add r4,r25,r28
	ctx.r4.u64 = r25.u64 + r28.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// add r4,r26,r31
	ctx.r4.u64 = r26.u64 + r31.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r11,r1,192
	r11.s64 = ctx.r1.s64 + 192;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x82457ebc
	if (cr6.eq) goto loc_82457EBC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82457ebc
	if (cr6.eq) goto loc_82457EBC;
	// li r28,1
	r28.s64 = 1;
	// b 0x82457e98
	goto loc_82457E98;
loc_82457D00:
	// lis r10,12288
	ctx.r10.s64 = 805306368;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82457ebc
	if (!cr6.eq) goto loc_82457EBC;
	// lwz r26,8(r30)
	r26.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r31,r23,2,0,29
	r31.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r25,8(r21)
	r25.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// rlwinm r28,r22,2,0,29
	r28.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// add r4,r26,r31
	ctx.r4.u64 = r26.u64 + r31.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// add r4,r25,r28
	ctx.r4.u64 = r25.u64 + r28.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// rlwinm r11,r23,3,0,28
	r11.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// add r4,r11,r26
	ctx.r4.u64 = r11.u64 + r26.u64;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// rlwinm r10,r22,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r1,224
	r11.s64 = ctx.r1.s64 + 224;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// add r4,r10,r25
	ctx.r4.u64 = ctx.r10.u64 + r25.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82453300
	sub_82453300(ctx, base);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x82457ebc
	if (cr6.eq) goto loc_82457EBC;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x82457ebc
	if (cr6.eq) goto loc_82457EBC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82457ebc
	if (cr6.eq) goto loc_82457EBC;
	// b 0x82457e94
	goto loc_82457E94;
loc_82457E20:
	// lwz r29,8(r21)
	r29.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x82457ebc
	if (!cr6.eq) goto loc_82457EBC;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// bne cr6,0x82457ebc
	if (!cr6.eq) goto loc_82457EBC;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82457ebc
	if (!cr6.eq) goto loc_82457EBC;
	// rlwinm r31,r23,2,0,29
	r31.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// rlwinm r5,r22,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_82457E94:
	// li r28,0
	r28.s64 = 0;
loc_82457E98:
	// cmplw cr6,r19,r20
	cr6.compare<uint32_t>(r19.u32, r20.u32, xer);
	// beq cr6,0x82457f1c
	if (cr6.eq) goto loc_82457F1C;
	// rlwinm r11,r20,2,0,29
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r19,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r16
	r11.u64 = PPC_LOAD_U32(r11.u32 + r16.u32);
	// lwzx r10,r10,r16
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r16.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// ble cr6,0x82457f1c
	if (!cr6.gt) goto loc_82457F1C;
loc_82457EBC:
	// lwz r30,112(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82457EC0:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// ble cr6,0x82457f00
	if (!cr6.gt) goto loc_82457F00;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r10,24(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,12(r27)
	PPC_STORE_U32(r27.u32 + 12, r11.u32);
	// lwzx r31,r9,r10
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x82457ec0
	if (cr0.eq) goto loc_82457EC0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// b 0x82457ec0
	goto loc_82457EC0;
loc_82457F00:
	// lwz r29,80(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82457F04:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r17,r17,4
	r17.s64 = r17.s64 + 4;
	// cmplw cr6,r29,r15
	cr6.compare<uint32_t>(r29.u32, r15.u32, xer);
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// blt cr6,0x824579d4
	if (cr6.lt) goto loc_824579D4;
	// b 0x82458274
	goto loc_82458274;
loc_82457F1C:
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x8243d710
	sub_8243D710(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82457f38
	if (cr0.eq) goto loc_82457F38;
	// bl 0x8243d018
	sub_8243D018(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82457f3c
	goto loc_82457F3C;
loc_82457F38:
	// li r31,0
	r31.s64 = 0;
loc_82457F3C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x824582ac
	if (cr6.eq) goto loc_824582AC;
	// lwz r4,0(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// rlwimi r4,r24,0,12,31
	ctx.r4.u64 = (__builtin_rotateleft32(r24.u32, 0) & 0xFFFFF) | (ctx.r4.u64 & 0xFFFFFFFFFFF00000);
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d7a8
	sub_8243D7A8(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x824582b8
	if (cr0.lt) goto loc_824582B8;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d068
	sub_8243D068(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x824582b8
	if (cr0.lt) goto loc_824582B8;
	// cmplw cr6,r19,r20
	cr6.compare<uint32_t>(r19.u32, r20.u32, xer);
	// li r26,0
	r26.s64 = 0;
	// beq cr6,0x82458008
	if (cr6.eq) goto loc_82458008;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82457fec
	if (!cr6.gt) goto loc_82457FEC;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
loc_82457F9C:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r9,208(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x82457fd8
	if (!cr6.eq) goto loc_82457FD8;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r19,r10
	cr6.compare<uint32_t>(r19.u32, ctx.r10.u32, xer);
	// bne cr6,0x82457fd8
	if (!cr6.eq) goto loc_82457FD8;
	// rlwinm r10,r20,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r20,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r20.u32);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwzx r10,r10,r16
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r16.u32);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
loc_82457FD8:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// blt cr6,0x82457f9c
	if (cr6.lt) goto loc_82457F9C;
loc_82457FEC:
	// rlwinm r10,r20,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r19,2,0,29
	r11.u64 = __builtin_rotateleft64(r19.u32 | (r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r16
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r16.u32);
	// lwzx r9,r11,r16
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + r16.u32);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stwx r9,r10,r16
	PPC_STORE_U32(ctx.r10.u32 + r16.u32, ctx.r9.u32);
	// stwx r26,r11,r16
	PPC_STORE_U32(r11.u32 + r16.u32, r26.u32);
loc_82458008:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r9,12(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,16(r21)
	ctx.r4.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,0(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82458060
	if (!cr6.eq) goto loc_82458060;
	// rlwinm r5,r24,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_82458060:
	// lwz r11,0(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// lis r10,8192
	ctx.r10.s64 = 536870912;
	// rlwinm r11,r11,0,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824580b0
	if (!cr6.eq) goto loc_824580B0;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// beq cr6,0x82458084
	if (cr6.eq) goto loc_82458084;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
loc_82458084:
	// rlwinm r30,r24,2,0,29
	r30.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// beq cr6,0x824580a4
	if (cr6.eq) goto loc_824580A4;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
loc_824580A4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r3,r30,r11
	ctx.r3.u64 = r30.u64 + r11.u64;
	// b 0x824580f4
	goto loc_824580F4;
loc_824580B0:
	// lis r10,12288
	ctx.r10.s64 = 805306368;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824580fc
	if (!cr6.eq) goto loc_824580FC;
	// rlwinm r30,r24,2,0,29
	r30.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// add r3,r30,r11
	ctx.r3.u64 = r30.u64 + r11.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r24,3,0,28
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
loc_824580F4:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_824580FC:
	// lwz r28,116(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r5,r1,240
	ctx.r5.s64 = ctx.r1.s64 + 240;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// clrlwi r11,r11,12
	r11.u64 = r11.u32 & 0xFFFFF;
	// divwu r29,r10,r11
	r29.u32 = ctx.r10.u32 / r11.u32;
	// twllei r11,0
	// bl 0x82442290
	sub_82442290(ctx, base);
	// mr r30,r26
	r30.u64 = r26.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82458198
	if (cr6.eq) goto loc_82458198;
loc_82458138:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mullw r11,r30,r11
	r11.s64 = int64_t(r30.s32) * int64_t(r11.s32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// beq cr6,0x8245818c
	if (cr6.eq) goto loc_8245818C;
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
loc_8245815C:
	// addi r9,r1,240
	ctx.r9.s64 = ctx.r1.s64 + 240;
	// addi r8,r1,256
	ctx.r8.s64 = ctx.r1.s64 + 256;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r3
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// stwx r9,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8245815c
	if (!cr0.eq) goto loc_8245815C;
	// addi r4,r1,256
	ctx.r4.s64 = ctx.r1.s64 + 256;
	// rlwinm r5,r24,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239d2a8
	sub_8239D2A8(ctx, base);
loc_8245818C:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r29
	cr6.compare<uint32_t>(r30.u32, r29.u32, xer);
	// blt cr6,0x82458138
	if (cr6.lt) goto loc_82458138;
loc_82458198:
	// lwz r30,176(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824581b4
	if (cr6.eq) goto loc_824581B4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
loc_824581B4:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// stwx r31,r11,r30
	PPC_STORE_U32(r11.u32 + r30.u32, r31.u32);
	// stw r26,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r26.u32);
	// stw r26,4(r28)
	PPC_STORE_U32(r28.u32 + 4, r26.u32);
	// stw r26,12(r28)
	PPC_STORE_U32(r28.u32 + 12, r26.u32);
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8245825c
	if (!cr6.gt) goto loc_8245825C;
	// subf r28,r10,r11
	r28.s64 = r11.s64 - ctx.r10.s64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r29,r28,2,0,29
	r29.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x824582ac
	if (cr0.eq) goto loc_824582AC;
	// lwz r26,112(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r10,24(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// add r9,r28,r10
	ctx.r9.u64 = r28.u64 + ctx.r10.u64;
	// subf r8,r10,r26
	ctx.r8.s64 = r26.s64 - ctx.r10.s64;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r8,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r30,r11
	ctx.r4.u64 = r30.u64 + r11.u64;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x8239d800
	sub_8239D800(ctx, base);
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
loc_8245825C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82446d98
	sub_82446D98(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r14,r11,-1
	r14.s64 = r11.s64 + -1;
loc_82458274:
	// li r17,0
	r17.s64 = 0;
loc_82458278:
	// lwz r11,12(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// addi r14,r14,1
	r14.s64 = r14.s64 + 1;
	// cmplw cr6,r14,r11
	cr6.compare<uint32_t>(r14.u32, r11.u32, xer);
	// blt cr6,0x82457824
	if (cr6.lt) goto loc_82457824;
loc_82458288:
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r29,r11,27,31,31
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
loc_82458294:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_824582A4:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// b 0x8239bd10
	return;
loc_824582AC:
	// lis r29,-32761
	r29.s64 = -2147024896;
	// ori r29,r29,14
	r29.u64 = r29.u64 | 14;
	// b 0x82458294
	goto loc_82458294;
loc_824582B8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x822f5468
	sub_822F5468(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8243d768
	sub_8243D768(ctx, base);
	// b 0x82458294
	goto loc_82458294;
}

__attribute__((alias("__imp__sub_824582CC"))) PPC_WEAK_FUNC(sub_824582CC);
PPC_FUNC_IMPL(__imp__sub_824582CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824582D0"))) PPC_WEAK_FUNC(sub_824582D0);
PPC_FUNC_IMPL(__imp__sub_824582D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce8
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r24,0
	r24.s64 = 0;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82458300
	if (!cr0.eq) goto loc_82458300;
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82458300
	if (!cr0.eq) goto loc_82458300;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82458588
	goto loc_82458588;
loc_82458300:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82458588
	if (cr0.lt) goto loc_82458588;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,136(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// addi r6,r11,-1
	ctx.r6.s64 = r11.s64 + -1;
	// bl 0x8244ef18
	sub_8244EF18(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82458348
	if (cr0.lt) goto loc_82458348;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82454d00
	sub_82454D00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82458388
	if (!cr0.lt) goto loc_82458388;
loc_82458348:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446c90
	sub_82446C90(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r6,44(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lwz r5,136(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// bl 0x8244ef18
	sub_8244EF18(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245856c
	if (cr0.lt) goto loc_8245856C;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82454d00
	sub_82454D00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245856c
	if (cr0.lt) goto loc_8245856C;
loc_82458388:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r24,r3
	r24.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// beq 0x8245856c
	if (cr0.eq) goto loc_8245856C;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82440c28
	sub_82440C28(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x824584ac
	if (!cr6.gt) goto loc_824584AC;
	// li r29,0
	r29.s64 = 0;
loc_824583D4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwzx r11,r29,r11
	r11.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82458498
	if (cr0.eq) goto loc_82458498;
	// mr r27,r25
	r27.u64 = r25.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82458488
	if (cr6.eq) goto loc_82458488;
	// mr r28,r29
	r28.u64 = r29.u64;
loc_824583F8:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82440d38
	sub_82440D38(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458488
	if (cr0.eq) goto loc_82458488;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82440c28
	sub_82440C28(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// bgt cr6,0x8245847c
	if (cr6.gt) goto loc_8245847C;
	// bne cr6,0x82458450
	if (!cr6.eq) goto loc_82458450;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8245847c
	if (!cr0.eq) goto loc_8245847C;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lwz r10,-4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,44(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 44);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8245847c
	if (!cr6.eq) goto loc_8245847C;
loc_82458450:
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82454d00
	sub_82454D00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245847c
	if (cr0.lt) goto loc_8245847C;
	// addi r5,r29,4
	ctx.r5.s64 = r29.s64 + 4;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// mr r26,r30
	r26.u64 = r30.u64;
loc_8245847C:
	// addic. r27,r27,-1
	xer.ca = r27.u32 > 0;
	r27.s64 = r27.s64 + -1;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// addi r28,r28,-4
	r28.s64 = r28.s64 + -4;
	// bne 0x824583f8
	if (!cr0.eq) goto loc_824583F8;
loc_82458488:
	// addi r5,r29,4
	ctx.r5.s64 = r29.s64 + 4;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
loc_82458498:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// blt cr6,0x824583d4
	if (cr6.lt) goto loc_824583D4;
loc_824584AC:
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x8245856c
	if (cr0.eq) goto loc_8245856C;
loc_824584BC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245855c
	if (cr0.eq) goto loc_8245855C;
	// addi r6,r8,1
	ctx.r6.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// bge cr6,0x82458514
	if (!cr6.lt) goto loc_82458514;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r11,r9
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,44(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
loc_824584F4:
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r5,44(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// bne cr6,0x82458514
	if (!cr6.eq) goto loc_82458514;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplw cr6,r6,r7
	cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, xer);
	// blt cr6,0x824584f4
	if (cr6.lt) goto loc_824584F4;
loc_82458514:
	// subf r11,r8,r6
	r11.s64 = ctx.r6.s64 - ctx.r8.s64;
	// rlwinm. r10,r11,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82458558
	if (cr0.eq) goto loc_82458558;
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
loc_82458524:
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// add r7,r9,r8
	ctx.r7.u64 = ctx.r9.u64 + ctx.r8.u64;
	// add r8,r11,r8
	ctx.r8.u64 = r11.u64 + ctx.r8.u64;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r5,-4(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4);
	// lwz r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// add r7,r11,r7
	ctx.r7.u64 = r11.u64 + ctx.r7.u64;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// stw r8,-4(r7)
	PPC_STORE_U32(ctx.r7.u32 + -4, ctx.r8.u32);
	// bne 0x82458524
	if (!cr0.eq) goto loc_82458524;
loc_82458558:
	// addi r8,r6,-1
	ctx.r8.s64 = ctx.r6.s64 + -1;
loc_8245855C:
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// blt cr6,0x824584bc
	if (cr6.lt) goto loc_824584BC;
loc_8245856C:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446c90
	sub_82446C90(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82458588:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x8239bd38
	return;
}

__attribute__((alias("__imp__sub_82458590"))) PPC_WEAK_FUNC(sub_82458590);
PPC_FUNC_IMPL(__imp__sub_82458590) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r6,2
	ctx.r6.s64 = 131072;
	// li r5,3
	ctx.r5.s64 = 3;
	// ori r6,r6,1024
	ctx.r6.u64 = ctx.r6.u64 | 1024;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// li r6,1025
	ctx.r6.s64 = 1025;
	// lwz r4,140(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 140);
	// li r5,6
	ctx.r5.s64 = 6;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// li r6,17409
	ctx.r6.s64 = 17409;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// li r5,10
	ctx.r5.s64 = 10;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// lwz r11,200(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// lis r10,18008
	ctx.r10.s64 = 1180172288;
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82458614
	if (cr6.eq) goto loc_82458614;
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82458634
	if (!cr6.eq) goto loc_82458634;
loc_82458614:
	// lis r6,3
	ctx.r6.s64 = 196608;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// li r5,2
	ctx.r5.s64 = 2;
	// ori r6,r6,4136
	ctx.r6.u64 = ctx.r6.u64 | 4136;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
loc_82458634:
	// lwz r11,200(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82458664
	if (cr6.eq) goto loc_82458664;
	// li r6,512
	ctx.r6.s64 = 512;
	// lwz r4,128(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// li r5,16
	ctx.r5.s64 = 16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
loc_82458664:
	// lis r6,4
	ctx.r6.s64 = 262144;
	// lwz r4,132(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// li r5,32
	ctx.r5.s64 = 32;
	// ori r6,r6,8192
	ctx.r6.u64 = ctx.r6.u64 | 8192;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// lis r6,4
	ctx.r6.s64 = 262144;
	// lwz r4,180(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 180);
	// li r5,8224
	ctx.r5.s64 = 8224;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// lis r5,4
	ctx.r5.s64 = 262144;
	// lwz r4,184(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 184);
	// li r6,8192
	ctx.r6.s64 = 8192;
	// ori r5,r5,32
	ctx.r5.u64 = ctx.r5.u64 | 32;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// lwz r11,200(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824586f0
	if (cr6.eq) goto loc_824586F0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,148(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 148);
	// li r5,128
	ctx.r5.s64 = 128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
loc_824586F0:
	// lwz r6,48(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmplwi r6,0
	cr0.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq 0x82458784
	if (cr0.eq) goto loc_82458784;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r5,140(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 140);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244ef18
	sub_8244EF18(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82454d00
	sub_82454D00(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bge 0x82458764
	if (!cr0.lt) goto loc_82458764;
	// lis r6,3
	ctx.r6.s64 = 196608;
	// lwz r4,136(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// li r5,2
	ctx.r5.s64 = 2;
	// ori r6,r6,40
	ctx.r6.u64 = ctx.r6.u64 | 40;
	// bl 0x82441e78
	sub_82441E78(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bge 0x82458770
	if (!cr0.lt) goto loc_82458770;
loc_8245874C:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446c90
	sub_82446C90(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8245875C:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x8239bd3c
	return;
loc_82458764:
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82454d00
	sub_82454D00(ctx, base);
loc_82458770:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446c90
	sub_82446C90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
loc_82458784:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r6,44(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,136(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// bl 0x8244ef18
	sub_8244EF18(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8245874c
	if (cr0.lt) goto loc_8245874C;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82454d00
	sub_82454D00(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8245874c
	if (cr0.lt) goto loc_8245874C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446c90
	sub_82446C90(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8245874c
	if (cr0.lt) goto loc_8245874C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r6,52(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,144(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// bl 0x8244ef18
	sub_8244EF18(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8245874c
	if (cr0.lt) goto loc_8245874C;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82454d00
	sub_82454D00(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8245874c
	if (cr0.lt) goto loc_8245874C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446c90
	sub_82446C90(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// blt 0x8245874c
	if (cr0.lt) goto loc_8245874C;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82458a18
	if (!cr0.eq) goto loc_82458A18;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r27,0
	r27.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x8245885c
	if (!cr6.gt) goto loc_8245885C;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82458838:
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,48(r8)
	PPC_STORE_U32(ctx.r8.u32 + 48, ctx.r9.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x82458838
	if (cr6.lt) goto loc_82458838;
loc_8245885C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82458a18
	if (!cr6.gt) goto loc_82458A18;
	// li r29,0
	r29.s64 = 0;
loc_82458870:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lis r10,4096
	ctx.r10.s64 = 268435456;
	// lwzx r9,r29,r11
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,0,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824589cc
	if (!cr6.eq) goto loc_824589CC;
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// li r3,0
	ctx.r3.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82458998
	if (!cr6.gt) goto loc_82458998;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
loc_824588A8:
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r7,16(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwzx r5,r8,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// lwzx r6,r8,r7
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r6,2,0,29
	r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwzx r10,r26,r10
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + ctx.r10.u32);
	// lwz r26,4(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r25,4(r10)
	r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r25,r26
	cr6.compare<uint32_t>(r25.u32, r26.u32, xer);
	// bne cr6,0x8245896c
	if (!cr6.eq) goto loc_8245896C;
	// lwz r26,8(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r25,8(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// bne cr6,0x8245896c
	if (!cr6.eq) goto loc_8245896C;
	// lwz r26,12(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r25,12(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// bne cr6,0x8245896c
	if (!cr6.eq) goto loc_8245896C;
	// lwz r26,16(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r25,16(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// bne cr6,0x8245896c
	if (!cr6.eq) goto loc_8245896C;
	// lwz r26,20(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r25,20(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplw cr6,r26,r25
	cr6.compare<uint32_t>(r26.u32, r25.u32, xer);
	// bne cr6,0x8245896c
	if (!cr6.eq) goto loc_8245896C;
	// lwz r26,24(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r25,24(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpw cr6,r26,r25
	cr6.compare<int32_t>(r26.s32, r25.s32, xer);
	// bne cr6,0x8245896c
	if (!cr6.eq) goto loc_8245896C;
	// lwz r26,60(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x8245896c
	if (!cr6.eq) goto loc_8245896C;
	// lwz r11,60(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8245896c
	if (!cr6.eq) goto loc_8245896C;
	// cmpwi cr6,r5,-1
	cr6.compare<int32_t>(ctx.r5.s32, -1, xer);
	// beq cr6,0x82458960
	if (cr6.eq) goto loc_82458960;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// rlwinm r7,r5,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r7,r11
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + r11.u32);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// b 0x82458964
	goto loc_82458964;
loc_82458960:
	// li r11,-1
	r11.s64 = -1;
loc_82458964:
	// stw r11,48(r10)
	PPC_STORE_U32(ctx.r10.u32 + 48, r11.u32);
	// b 0x82458984
	goto loc_82458984;
loc_8245896C:
	// stwx r6,r4,r7
	PPC_STORE_U32(ctx.r4.u32 + ctx.r7.u32, ctx.r6.u32);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// stwx r10,r4,r11
	PPC_STORE_U32(ctx.r4.u32 + r11.u32, ctx.r10.u32);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
loc_82458984:
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x824588a8
	if (cr6.lt) goto loc_824588A8;
loc_82458998:
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x824589cc
	if (cr6.eq) goto loc_824589CC;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824589b8
	if (cr6.eq) goto loc_824589B8;
	// clrlwi r11,r3,12
	r11.u64 = ctx.r3.u32 & 0xFFFFF;
	// oris r11,r11,4096
	r11.u64 = r11.u64 | 268435456;
	// b 0x824589bc
	goto loc_824589BC;
loc_824589B8:
	// li r11,0
	r11.s64 = 0;
loc_824589BC:
	// li r27,1
	r27.s64 = 1;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stw r3,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r3.u32);
	// stw r3,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, ctx.r3.u32);
loc_824589CC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// blt cr6,0x82458870
	if (cr6.lt) goto loc_82458870;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82458a18
	if (cr6.eq) goto loc_82458A18;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447630
	sub_82447630(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244b3d0
	sub_8244B3D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245875c
	if (cr0.lt) goto loc_8245875C;
loc_82458A18:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245875c
	goto loc_8245875C;
}

__attribute__((alias("__imp__sub_82458A20"))) PPC_WEAK_FUNC(sub_82458A20);
PPC_FUNC_IMPL(__imp__sub_82458A20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8244fac0
	sub_8244FAC0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82458e40
	if (cr0.lt) goto loc_82458E40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82448278
	sub_82448278(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458a54
	if (cr0.eq) goto loc_82458A54;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458A54:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82448968
	sub_82448968(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458a6c
	if (cr0.eq) goto loc_82458A6C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458A6C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458a84
	if (cr0.eq) goto loc_82458A84;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458A84:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244b3d0
	sub_8244B3D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458a9c
	if (cr0.eq) goto loc_82458A9C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458A9C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r30,0
	r30.s64 = 0;
	// li r27,1
	r27.s64 = 1;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82458af4
	if (!cr6.gt) goto loc_82458AF4;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
loc_82458AB8:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lis r8,4128
	ctx.r8.s64 = 270532608;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,0,0,11
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFF00000;
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// bne cr6,0x82458ae0
	if (!cr6.eq) goto loc_82458AE0;
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwimi r8,r27,28,0,11
	ctx.r8.u64 = (__builtin_rotateleft32(r27.u32, 28) & 0xFFF00000) | (ctx.r8.u64 & 0xFFFFFFFF000FFFFF);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
loc_82458AE0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// blt cr6,0x82458ab8
	if (cr6.lt) goto loc_82458AB8;
loc_82458AF4:
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82458b20
	if (cr0.eq) goto loc_82458B20;
	// stw r27,216(r31)
	PPC_STORE_U32(r31.u32 + 216, r27.u32);
	// bl 0x82448968
	sub_82448968(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458e3c
	if (cr0.eq) goto loc_82458E3C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
	// b 0x82458e3c
	goto loc_82458E3C;
loc_82458B20:
	// bl 0x8244b9a8
	sub_8244B9A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458b34
	if (cr0.eq) goto loc_82458B34;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458B34:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82447ef8
	sub_82447EF8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458b4c
	if (cr0.eq) goto loc_82458B4C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458B4C:
	// mr r28,r30
	r28.u64 = r30.u64;
loc_82458B50:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82455688
	sub_82455688(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458b68
	if (!cr0.eq) goto loc_82458B68;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458b74
	goto loc_82458B74;
loc_82458B68:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458B74:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r29,r11,27,31,31
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x82448278
	sub_82448278(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458b98
	if (!cr0.eq) goto loc_82458B98;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458ba4
	goto loc_82458BA4;
loc_82458B98:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458BA4:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
	// bl 0x82448c18
	sub_82448C18(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458bcc
	if (!cr0.eq) goto loc_82458BCC;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458bd8
	goto loc_82458BD8;
loc_82458BCC:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458BD8:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// li r4,0
	ctx.r4.s64 = 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
	// bl 0x82449288
	sub_82449288(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458c04
	if (!cr0.eq) goto loc_82458C04;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458c10
	goto loc_82458C10;
loc_82458C04:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458C10:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
	// bl 0x824497b8
	sub_824497B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458c38
	if (!cr0.eq) goto loc_82458C38;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458c44
	goto loc_82458C44;
loc_82458C38:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458C44:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
	// bl 0x82450738
	sub_82450738(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458c6c
	if (!cr0.eq) goto loc_82458C6C;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458c78
	goto loc_82458C78;
loc_82458C6C:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458C78:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
	// bl 0x82452620
	sub_82452620(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458ca0
	if (!cr0.eq) goto loc_82458CA0;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458cac
	goto loc_82458CAC;
loc_82458CA0:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458CAC:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
	// bl 0x82449db8
	sub_82449DB8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458cd4
	if (!cr0.eq) goto loc_82458CD4;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458ce0
	goto loc_82458CE0;
loc_82458CD4:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458CE0:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or r29,r11,r29
	r29.u64 = r11.u64 | r29.u64;
	// bl 0x8244a708
	sub_8244A708(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82458d08
	if (!cr0.eq) goto loc_82458D08;
	// mr r11,r30
	r11.u64 = r30.u64;
	// b 0x82458d14
	goto loc_82458D14;
loc_82458D08:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458D14:
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// or. r11,r11,r29
	r11.u64 = r11.u64 | r29.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82458d34
	if (cr0.eq) goto loc_82458D34;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplwi cr6,r28,256
	cr6.compare<uint32_t>(r28.u32, 256, xer);
	// blt cr6,0x82458b50
	if (cr6.lt) goto loc_82458B50;
loc_82458D34:
	// cmplwi cr6,r28,256
	cr6.compare<uint32_t>(r28.u32, 256, xer);
	// bne cr6,0x82458d54
	if (!cr6.eq) goto loc_82458D54;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,20996
	ctx.r6.s64 = r11.s64 + 20996;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244fa10
	sub_8244FA10(ctx, base);
loc_82458D54:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82458dc0
	if (!cr6.gt) goto loc_82458DC0;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82458D68:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwzx r11,r30,r11
	r11.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm. r7,r10,0,23,23
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82458dac
	if (cr0.eq) goto loc_82458DAC;
	// rlwinm. r7,r10,0,21,21
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82458dac
	if (!cr0.eq) goto loc_82458DAC;
	// rlwinm. r10,r10,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82458dac
	if (!cr0.eq) goto loc_82458DAC;
	// lwz r10,120(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// stw r9,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r9.u32);
	// stw r9,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r9.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
loc_82458DAC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// blt cr6,0x82458d68
	if (cr6.lt) goto loc_82458D68;
loc_82458DC0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244ffe0
	sub_8244FFE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458dd8
	if (cr0.eq) goto loc_82458DD8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458DD8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244afd8
	sub_8244AFD8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458df0
	if (cr0.eq) goto loc_82458DF0;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458DF0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82448968
	sub_82448968(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458e08
	if (cr0.eq) goto loc_82458E08;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458E08:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458e20
	if (cr0.eq) goto loc_82458E20;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458E20:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244b3d0
	sub_8244B3D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458e38
	if (cr0.eq) goto loc_82458E38;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82458e40
	if (cr6.lt) goto loc_82458E40;
loc_82458E38:
	// stw r27,216(r31)
	PPC_STORE_U32(r31.u32 + 216, r27.u32);
loc_82458E3C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82458E40:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_82458E48"))) PPC_WEAK_FUNC(sub_82458E48);
PPC_FUNC_IMPL(__imp__sub_82458E48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8244b9a8
	sub_8244B9A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458e74
	if (cr0.eq) goto loc_82458E74;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458E74:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824568b8
	sub_824568B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458e8c
	if (cr0.eq) goto loc_82458E8C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458E8C:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244dbc0
	sub_8244DBC0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458ea8
	if (cr0.eq) goto loc_82458EA8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458EA8:
	// li r30,0
	r30.s64 = 0;
loc_82458EAC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82449288
	sub_82449288(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458ed0
	if (cr0.eq) goto loc_82458ED0;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x82458edc
	if (cr6.eq) goto loc_82458EDC;
loc_82458ED0:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r30,256
	cr6.compare<uint32_t>(r30.u32, 256, xer);
	// blt cr6,0x82458eac
	if (cr6.lt) goto loc_82458EAC;
loc_82458EDC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244bd28
	sub_8244BD28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458ef4
	if (cr0.eq) goto loc_82458EF4;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458EF4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82457178
	sub_82457178(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458f0c
	if (cr0.eq) goto loc_82458F0C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458F0C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458f30
	if (cr0.eq) goto loc_82458F30;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458F30:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244dbc0
	sub_8244DBC0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458f4c
	if (cr0.eq) goto loc_82458F4C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458F4C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244df10
	sub_8244DF10(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458f64
	if (cr0.eq) goto loc_82458F64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458F64:
	// li r11,1
	r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r11.u32);
	// bl 0x8244e760
	sub_8244E760(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458f84
	if (cr0.eq) goto loc_82458F84;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458F84:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824582d0
	sub_824582D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458f9c
	if (cr0.eq) goto loc_82458F9C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458F9C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82446490
	sub_82446490(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458fb4
	if (cr0.eq) goto loc_82458FB4;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458FB4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458fd8
	if (cr0.eq) goto loc_82458FD8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458FD8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82458ffc
	if (cr0.eq) goto loc_82458FFC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82458FFC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82442e58
	sub_82442E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82459014
	if (cr0.eq) goto loc_82459014;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82459014:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244b3d0
	sub_8244B3D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245902c
	if (cr0.eq) goto loc_8245902C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_8245902C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82458590
	sub_82458590(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82459044
	if (cr0.eq) goto loc_82459044;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_82459044:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8244ec38
	sub_8244EC38(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245905c
	if (cr0.eq) goto loc_8245905C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82459060
	if (cr6.lt) goto loc_82459060;
loc_8245905C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82459060:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82459078"))) PPC_WEAK_FUNC(sub_82459078);
PPC_FUNC_IMPL(__imp__sub_82459078) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// stw r11,216(r31)
	PPC_STORE_U32(r31.u32 + 216, r11.u32);
	// stw r11,220(r31)
	PPC_STORE_U32(r31.u32 + 220, r11.u32);
	// beq cr6,0x824590a4
	if (cr6.eq) goto loc_824590A4;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
loc_824590A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82458a20
	sub_82458A20(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824590bc
	if (cr0.eq) goto loc_824590BC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x824590d8
	if (cr6.lt) goto loc_824590D8;
loc_824590BC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82458e48
	sub_82458E48(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824590d4
	if (cr0.eq) goto loc_824590D4;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x824590d8
	if (cr6.lt) goto loc_824590D8;
loc_824590D4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824590D8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824590EC"))) PPC_WEAK_FUNC(sub_824590EC);
PPC_FUNC_IMPL(__imp__sub_824590EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824590F0"))) PPC_WEAK_FUNC(sub_824590F0);
PPC_FUNC_IMPL(__imp__sub_824590F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245910C"))) PPC_WEAK_FUNC(sub_8245910C);
PPC_FUNC_IMPL(__imp__sub_8245910C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82459110"))) PPC_WEAK_FUNC(sub_82459110);
PPC_FUNC_IMPL(__imp__sub_82459110) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r4,28
	r31.s64 = ctx.r4.s64 + 28;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r30,20(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245919c
	if (cr6.eq) goto loc_8245919C;
	// lwz r6,24(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 24);
loc_82459138:
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// lwz r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
loc_82459144:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82459168
	if (cr0.eq) goto loc_82459168;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82459144
	if (cr6.eq) goto loc_82459144;
loc_82459168:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bge 0x82459178
	if (!cr0.lt) goto loc_82459178;
	// addi r31,r7,8
	r31.s64 = ctx.r7.s64 + 8;
	// b 0x82459184
	goto loc_82459184;
loc_82459178:
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// ble cr6,0x82459190
	if (!cr6.gt) goto loc_82459190;
	// addi r31,r7,12
	r31.s64 = ctx.r7.s64 + 12;
loc_82459184:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82459138
	if (!cr6.eq) goto loc_82459138;
loc_82459190:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824591e0
	if (!cr6.eq) goto loc_824591E0;
loc_8245919C:
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824591c4
	if (cr0.eq) goto loc_824591C4;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x82409790
	sub_82409790(ctx, base);
	// b 0x824591c8
	goto loc_824591C8;
loc_824591C4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824591C8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// bne cr6,0x824591e0
	if (!cr6.eq) goto loc_824591E0;
loc_824591D4:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x824592e0
	goto loc_824592E0;
loc_824591E0:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245920c
	if (cr0.eq) goto loc_8245920C;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r6,r11,-24228
	ctx.r6.s64 = r11.s64 + -24228;
	// lwz r5,20(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82459210
	goto loc_82459210;
loc_8245920C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82459210:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r3.u32);
	// beq cr6,0x824591d4
	if (cr6.eq) goto loc_824591D4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824592dc
	if (!cr6.eq) goto loc_824592DC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// b 0x8245927c
	goto loc_8245927C;
loc_82459244:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82459270
	if (cr0.eq) goto loc_82459270;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82459270
	if (cr0.eq) goto loc_82459270;
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, r11.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r8.u32);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// b 0x82459244
	goto loc_82459244;
loc_82459270:
	// addi r9,r11,12
	ctx.r9.s64 = r11.s64 + 12;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
loc_8245927C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82459244
	if (!cr6.eq) goto loc_82459244;
	// rlwinm. r6,r7,31,1,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x824592dc
	if (cr0.eq) goto loc_824592DC;
loc_8245928C:
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// beq cr6,0x824592d4
	if (cr6.eq) goto loc_824592D4;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
loc_8245929C:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x824592c4
	if (cr0.eq) goto loc_824592C4;
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824592c4
	if (cr0.eq) goto loc_824592C4;
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// stw r8,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r8.u32);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
loc_824592C4:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r9,r11,12
	ctx.r9.s64 = r11.s64 + 12;
	// bne 0x8245929c
	if (!cr0.eq) goto loc_8245929C;
loc_824592D4:
	// rlwinm. r6,r6,31,1,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x8245928c
	if (!cr0.eq) goto loc_8245928C;
loc_824592DC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824592E0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_824592E8"))) PPC_WEAK_FUNC(sub_824592E8);
PPC_FUNC_IMPL(__imp__sub_824592E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r3,24
	cr6.compare<int32_t>(ctx.r3.s32, 24, xer);
	// bne cr6,0x82459330
	if (!cr6.eq) goto loc_82459330;
	// cmpwi cr6,r4,24
	cr6.compare<int32_t>(ctx.r4.s32, 24, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,25
	cr6.compare<int32_t>(ctx.r4.s32, 25, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,27
	cr6.compare<int32_t>(ctx.r4.s32, 27, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,29
	cr6.compare<int32_t>(ctx.r4.s32, 29, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,30
	cr6.compare<int32_t>(ctx.r4.s32, 30, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,26
	cr6.compare<int32_t>(ctx.r4.s32, 26, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,28
	cr6.compare<int32_t>(ctx.r4.s32, 28, xer);
loc_82459324:
	// bne cr6,0x82459360
	if (!cr6.eq) goto loc_82459360;
loc_82459328:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82459330:
	// cmpwi cr6,r3,33
	cr6.compare<int32_t>(ctx.r3.s32, 33, xer);
	// bne cr6,0x82459360
	if (!cr6.eq) goto loc_82459360;
	// cmpwi cr6,r4,33
	cr6.compare<int32_t>(ctx.r4.s32, 33, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,34
	cr6.compare<int32_t>(ctx.r4.s32, 34, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,35
	cr6.compare<int32_t>(ctx.r4.s32, 35, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,36
	cr6.compare<int32_t>(ctx.r4.s32, 36, xer);
	// beq cr6,0x82459328
	if (cr6.eq) goto loc_82459328;
	// cmpwi cr6,r4,37
	cr6.compare<int32_t>(ctx.r4.s32, 37, xer);
	// b 0x82459324
	goto loc_82459324;
loc_82459360:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82459368"))) PPC_WEAK_FUNC(sub_82459368);
PPC_FUNC_IMPL(__imp__sub_82459368) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r7,28(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 28);
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq 0x824593c8
	if (cr0.eq) goto loc_824593C8;
	// lwz r6,8(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
loc_82459378:
	// lwz r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_82459380:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824593a4
	if (cr0.eq) goto loc_824593A4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82459380
	if (cr6.eq) goto loc_82459380;
loc_824593A4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x824593d0
	if (cr0.eq) goto loc_824593D0;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bge cr6,0x824593bc
	if (!cr6.lt) goto loc_824593BC;
	// lwz r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// b 0x824593c0
	goto loc_824593C0;
loc_824593BC:
	// lwz r7,12(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
loc_824593C0:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82459378
	if (!cr6.eq) goto loc_82459378;
loc_824593C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_824593D0:
	// lwz r3,20(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824593D8"))) PPC_WEAK_FUNC(sub_824593D8);
PPC_FUNC_IMPL(__imp__sub_824593D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	// cmpw cr6,r4,r5
	cr6.compare<int32_t>(ctx.r4.s32, ctx.r5.s32, xer);
	// bne cr6,0x824593e8
	if (!cr6.eq) goto loc_824593E8;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_824593E8:
	// addi r11,r4,-1
	r11.s64 = ctx.r4.s64 + -1;
	// cmplwi cr6,r11,12
	cr6.compare<uint32_t>(r11.u32, 12, xer);
	// bgt cr6,0x8245942c
	if (cr6.gt) {
		// ERROR 8245942C
		return;
	}
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-26560
	r12.s64 = r12.s64 + -26560;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,-27620
	r12.s64 = r12.s64 + -27620;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		// ERROR: 0x8245941C
		return;
	case 1:
		// ERROR: 0x8245941C
		return;
	case 2:
		// ERROR: 0x82459434
		return;
	case 3:
		// ERROR: 0x82459454
		return;
	case 4:
		// ERROR: 0x82459480
		return;
	case 5:
		// ERROR: 0x8245941C
		return;
	case 6:
		// ERROR: 0x82459434
		return;
	case 7:
		// ERROR: 0x82459454
		return;
	case 8:
		// ERROR: 0x82459480
		return;
	case 9:
		// ERROR: 0x824594A8
		return;
	case 10:
		// ERROR: 0x824594B8
		return;
	case 11:
		// ERROR: 0x824594C8
		return;
	case 12:
		// ERROR: 0x824594D8
		return;
	default:
		__builtin_unreachable();
	}
}

__attribute__((alias("__imp__sub_8245941C"))) PPC_WEAK_FUNC(sub_8245941C);
PPC_FUNC_IMPL(__imp__sub_8245941C) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// ble cr6,0x8245942c
	if (!cr6.gt) goto loc_8245942C;
	// cmpwi cr6,r5,9
	cr6.compare<int32_t>(ctx.r5.s32, 9, xer);
	// ble cr6,0x824593e0
	if (!cr6.gt) {
		// ERROR 824593E0
		return;
	}
loc_8245942C:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82459434"))) PPC_WEAK_FUNC(sub_82459434);
PPC_FUNC_IMPL(__imp__sub_82459434) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// ble cr6,0x8245942c
	if (!cr6.gt) {
		// ERROR 8245942C
		return;
	}
	// cmpwi cr6,r5,3
	cr6.compare<int32_t>(ctx.r5.s32, 3, xer);
	// ble cr6,0x824593e0
	if (!cr6.gt) {
		// ERROR 824593E0
		return;
	}
	// cmpwi cr6,r5,5
	cr6.compare<int32_t>(ctx.r5.s32, 5, xer);
	// ble cr6,0x8245942c
	if (!cr6.gt) {
		// ERROR 8245942C
		return;
	}
	// cmpwi cr6,r5,7
	cr6.compare<int32_t>(ctx.r5.s32, 7, xer);
	// b 0x82459428
	// ERROR 82459428
	return;
}

__attribute__((alias("__imp__sub_82459454"))) PPC_WEAK_FUNC(sub_82459454);
PPC_FUNC_IMPL(__imp__sub_82459454) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// ble cr6,0x8245942c
	if (!cr6.gt) {
		// ERROR 8245942C
		return;
	}
	// cmpwi cr6,r5,2
	cr6.compare<int32_t>(ctx.r5.s32, 2, xer);
	// ble cr6,0x824593e0
	if (!cr6.gt) {
		// ERROR 824593E0
		return;
	}
	// cmpwi cr6,r5,4
	cr6.compare<int32_t>(ctx.r5.s32, 4, xer);
	// beq cr6,0x824593e0
	if (cr6.eq) {
		// ERROR 824593E0
		return;
	}
	// cmpwi cr6,r5,6
	cr6.compare<int32_t>(ctx.r5.s32, 6, xer);
	// beq cr6,0x824593e0
	if (cr6.eq) {
		// ERROR 824593E0
		return;
	}
	// cmpwi cr6,r5,8
	cr6.compare<int32_t>(ctx.r5.s32, 8, xer);
	// bne cr6,0x8245942c
	if (!cr6.eq) {
		// ERROR 8245942C
		return;
	}
	// b 0x824593e0
	// ERROR 824593E0
	return;
}

__attribute__((alias("__imp__sub_82459480"))) PPC_WEAK_FUNC(sub_82459480);
PPC_FUNC_IMPL(__imp__sub_82459480) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// ble cr6,0x8245942c
	if (!cr6.gt) {
		// ERROR 8245942C
		return;
	}
	// cmpwi cr6,r5,2
	cr6.compare<int32_t>(ctx.r5.s32, 2, xer);
	// ble cr6,0x824593e0
	if (!cr6.gt) {
		// ERROR 824593E0
		return;
	}
	// cmpwi cr6,r5,4
	cr6.compare<int32_t>(ctx.r5.s32, 4, xer);
	// ble cr6,0x8245942c
	if (!cr6.gt) {
		// ERROR 8245942C
		return;
	}
	// cmpwi cr6,r5,6
	cr6.compare<int32_t>(ctx.r5.s32, 6, xer);
	// ble cr6,0x824593e0
	if (!cr6.gt) {
		// ERROR 824593E0
		return;
	}
	// cmpwi cr6,r5,9
	cr6.compare<int32_t>(ctx.r5.s32, 9, xer);
	// b 0x82459478
	// ERROR 82459478
	return;
}

__attribute__((alias("__imp__sub_824594A8"))) PPC_WEAK_FUNC(sub_824594A8);
PPC_FUNC_IMPL(__imp__sub_824594A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r5,10
	cr6.compare<int32_t>(ctx.r5.s32, 10, xer);
	// blt cr6,0x8245942c
	if (cr6.lt) {
		// ERROR 8245942C
		return;
	}
	// cmpwi cr6,r5,13
	cr6.compare<int32_t>(ctx.r5.s32, 13, xer);
	// b 0x82459428
	// ERROR 82459428
	return;
}

__attribute__((alias("__imp__sub_824594B8"))) PPC_WEAK_FUNC(sub_824594B8);
PPC_FUNC_IMPL(__imp__sub_824594B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r5,10
	cr6.compare<int32_t>(ctx.r5.s32, 10, xer);
	// blt cr6,0x8245942c
	if (cr6.lt) {
		// ERROR 8245942C
		return;
	}
	// cmpwi cr6,r5,11
	cr6.compare<int32_t>(ctx.r5.s32, 11, xer);
	// b 0x82459428
	// ERROR 82459428
	return;
}

__attribute__((alias("__imp__sub_824594C8"))) PPC_WEAK_FUNC(sub_824594C8);
PPC_FUNC_IMPL(__imp__sub_824594C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r5,10
	cr6.compare<int32_t>(ctx.r5.s32, 10, xer);
	// beq cr6,0x824593e0
	if (cr6.eq) {
		// ERROR 824593E0
		return;
	}
	// cmpwi cr6,r5,12
	cr6.compare<int32_t>(ctx.r5.s32, 12, xer);
	// b 0x82459478
	// ERROR 82459478
	return;
}

__attribute__((alias("__imp__sub_824594D8"))) PPC_WEAK_FUNC(sub_824594D8);
PPC_FUNC_IMPL(__imp__sub_824594D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// cmpwi cr6,r5,10
	cr6.compare<int32_t>(ctx.r5.s32, 10, xer);
	// beq cr6,0x824593e0
	if (cr6.eq) {
		// ERROR 824593E0
		return;
	}
	// cmpwi cr6,r5,13
	cr6.compare<int32_t>(ctx.r5.s32, 13, xer);
	// b 0x82459478
	// ERROR 82459478
	return;
}

__attribute__((alias("__imp__sub_824594E8"))) PPC_WEAK_FUNC(sub_824594E8);
PPC_FUNC_IMPL(__imp__sub_824594E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r3,40
	ctx.r3.s64 = 40;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82459520
	if (cr0.eq) goto loc_82459520;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8240a3a0
	sub_8240A3A0(ctx, base);
	// b 0x82459524
	goto loc_82459524;
loc_82459520:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82459524:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82459540
	if (cr6.eq) goto loc_82459540;
	// lwz r11,104(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 104);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// lwz r11,104(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 104);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,104(r29)
	PPC_STORE_U32(r29.u32 + 104, r11.u32);
loc_82459540:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_82459548"))) PPC_WEAK_FUNC(sub_82459548);
PPC_FUNC_IMPL(__imp__sub_82459548) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
loc_82459560:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82459614
	if (cr6.eq) goto loc_82459614;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x824595ac
	if (!cr6.eq) goto loc_824595AC;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82459680
	if (cr6.eq) goto loc_82459680;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x824595ac
	if (!cr6.eq) goto loc_824595AC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82459680
	if (cr0.eq) goto loc_82459680;
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// b 0x82459560
	goto loc_82459560;
loc_824595AC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82459680
	if (cr6.eq) goto loc_82459680;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82459680
	if (!cr6.eq) goto loc_82459680;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x82459608
	if (cr6.eq) goto loc_82459608;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x824595ec
	if (cr6.eq) goto loc_824595EC;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x82459624
	if (cr6.eq) goto loc_82459624;
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x82459680
	if (!cr6.eq) goto loc_82459680;
	// lwz r31,48(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r30,48(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// b 0x82459560
	goto loc_82459560;
loc_824595EC:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82459680
	if (!cr6.eq) goto loc_82459680;
	// lwz r31,16(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r30,16(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// b 0x82459560
	goto loc_82459560;
loc_82459608:
	// lwz r31,24(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r30,24(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// b 0x82459560
	goto loc_82459560;
loc_82459614:
	// addi r11,r31,0
	r11.s64 = r31.s64 + 0;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x82459684
	goto loc_82459684;
loc_82459624:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82459680
	if (!cr6.eq) goto loc_82459680;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82459680
	if (!cr6.eq) goto loc_82459680;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82459680
	if (cr0.eq) goto loc_82459680;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x82459680
	if (!cr6.eq) goto loc_82459680;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82459684
	if (cr6.eq) goto loc_82459684;
loc_82459680:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82459684:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245968C"))) PPC_WEAK_FUNC(sub_8245968C);
PPC_FUNC_IMPL(__imp__sub_8245968C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82459690"))) PPC_WEAK_FUNC(sub_82459690);
PPC_FUNC_IMPL(__imp__sub_82459690) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x824598d8
	if (cr6.eq) goto loc_824598D8;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x824598d8
	if (!cr6.eq) goto loc_824598D8;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x824598d8
	if (cr6.eq) goto loc_824598D8;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x824598d8
	if (!cr6.eq) goto loc_824598D8;
	// lwz r4,20(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// lwz r5,20(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 20);
	// cmpw cr6,r4,r5
	cr6.compare<int32_t>(ctx.r4.s32, ctx.r5.s32, xer);
	// bne cr6,0x824596d4
	if (!cr6.eq) goto loc_824596D4;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// blr 
	return;
loc_824596D4:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// rlwinm r10,r5,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r11,-24216
	r11.s64 = r11.s64 + -24216;
	// rlwinm r9,r4,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// ble cr6,0x824596f8
	if (!cr6.gt) goto loc_824596F8;
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
loc_824596F8:
	// addi r7,r11,4
	ctx.r7.s64 = r11.s64 + 4;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// and r11,r9,r10
	r11.u64 = ctx.r9.u64 & ctx.r10.u64;
	// clrlwi. r7,r11,31
	ctx.r7.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82459724
	if (cr0.eq) goto loc_82459724;
	// li r11,0
	r11.s64 = 0;
loc_82459718:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
loc_82459724:
	// rlwinm. r7,r11,0,26,26
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82459734
	if (cr0.eq) goto loc_82459734;
	// li r11,1
	r11.s64 = 1;
	// b 0x82459718
	goto loc_82459718;
loc_82459734:
	// rlwinm. r7,r11,0,29,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82459780
	if (!cr0.eq) goto loc_82459780;
	// rlwinm. r7,r11,0,30,30
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82459818
	if (cr0.eq) goto loc_82459818;
	// addi r11,r5,-1
	r11.s64 = ctx.r5.s64 + -1;
	// cmpwi cr6,r4,1
	cr6.compare<int32_t>(ctx.r4.s32, 1, xer);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bne cr6,0x82459768
	if (!cr6.eq) goto loc_82459768;
	// rlwinm. r7,r10,0,29,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x82459768
	if (cr0.eq) goto loc_82459768;
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82459780
	if (cr0.eq) goto loc_82459780;
loc_82459768:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x824597d0
	if (cr6.eq) goto loc_824597D0;
	// rlwinm. r11,r9,0,29,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824597d0
	if (cr0.eq) goto loc_824597D0;
	// clrlwi. r11,r9,31
	r11.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824597d0
	if (!cr0.eq) goto loc_824597D0;
loc_82459780:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82459798
	if (!cr6.eq) goto loc_82459798;
	// li r11,6
	r11.s64 = 6;
loc_8245978C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
loc_82459790:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82459798:
	// cmplwi cr6,r8,8
	cr6.compare<uint32_t>(ctx.r8.u32, 8, xer);
	// beq cr6,0x824597c8
	if (cr6.eq) goto loc_824597C8;
	// cmplwi cr6,r8,16
	cr6.compare<uint32_t>(ctx.r8.u32, 16, xer);
	// beq cr6,0x824597c0
	if (cr6.eq) goto loc_824597C0;
	// cmplwi cr6,r8,32
	cr6.compare<uint32_t>(ctx.r8.u32, 32, xer);
	// beq cr6,0x824597b8
	if (cr6.eq) goto loc_824597B8;
	// cmplwi cr6,r8,64
	cr6.compare<uint32_t>(ctx.r8.u32, 64, xer);
	// bne cr6,0x82459790
	if (!cr6.eq) goto loc_82459790;
loc_824597B8:
	// li r11,9
	r11.s64 = 9;
	// b 0x8245978c
	goto loc_8245978C;
loc_824597C0:
	// li r11,8
	r11.s64 = 8;
	// b 0x8245978c
	goto loc_8245978C;
loc_824597C8:
	// li r11,7
	r11.s64 = 7;
	// b 0x8245978c
	goto loc_8245978C;
loc_824597D0:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82459810
	if (cr6.eq) goto loc_82459810;
	// cmplwi cr6,r8,8
	cr6.compare<uint32_t>(ctx.r8.u32, 8, xer);
	// beq cr6,0x82459808
	if (cr6.eq) goto loc_82459808;
	// cmplwi cr6,r8,16
	cr6.compare<uint32_t>(ctx.r8.u32, 16, xer);
	// beq cr6,0x82459800
	if (cr6.eq) goto loc_82459800;
	// cmplwi cr6,r8,32
	cr6.compare<uint32_t>(ctx.r8.u32, 32, xer);
	// beq cr6,0x824597f8
	if (cr6.eq) goto loc_824597F8;
	// cmplwi cr6,r8,64
	cr6.compare<uint32_t>(ctx.r8.u32, 64, xer);
	// bne cr6,0x82459790
	if (!cr6.eq) goto loc_82459790;
loc_824597F8:
	// li r11,5
	r11.s64 = 5;
	// b 0x8245978c
	goto loc_8245978C;
loc_82459800:
	// li r11,4
	r11.s64 = 4;
	// b 0x8245978c
	goto loc_8245978C;
loc_82459808:
	// li r11,3
	r11.s64 = 3;
	// b 0x8245978c
	goto loc_8245978C;
loc_82459810:
	// li r11,2
	r11.s64 = 2;
	// b 0x8245978c
	goto loc_8245978C;
loc_82459818:
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82459868
	if (cr0.eq) goto loc_82459868;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82459860
	if (cr6.eq) goto loc_82459860;
	// cmplwi cr6,r8,8
	cr6.compare<uint32_t>(ctx.r8.u32, 8, xer);
	// beq cr6,0x82459858
	if (cr6.eq) goto loc_82459858;
	// cmplwi cr6,r8,16
	cr6.compare<uint32_t>(ctx.r8.u32, 16, xer);
	// beq cr6,0x82459858
	if (cr6.eq) goto loc_82459858;
	// cmplwi cr6,r8,32
	cr6.compare<uint32_t>(ctx.r8.u32, 32, xer);
	// beq cr6,0x82459850
	if (cr6.eq) goto loc_82459850;
	// cmplwi cr6,r8,64
	cr6.compare<uint32_t>(ctx.r8.u32, 64, xer);
	// bne cr6,0x82459790
	if (!cr6.eq) goto loc_82459790;
	// li r11,13
	r11.s64 = 13;
	// b 0x8245978c
	goto loc_8245978C;
loc_82459850:
	// li r11,12
	r11.s64 = 12;
	// b 0x8245978c
	goto loc_8245978C;
loc_82459858:
	// li r11,11
	r11.s64 = 11;
	// b 0x8245978c
	goto loc_8245978C;
loc_82459860:
	// li r11,10
	r11.s64 = 10;
	// b 0x8245978c
	goto loc_8245978C;
loc_82459868:
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824598d8
	if (cr0.eq) goto loc_824598D8;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82459874:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// bne cr6,0x82459888
	if (!cr6.eq) goto loc_82459888;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// beq cr6,0x82459890
	if (cr6.eq) goto loc_82459890;
loc_82459888:
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// b 0x82459894
	goto loc_82459894;
loc_82459890:
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_82459894:
	// cmpwi cr6,r10,22
	cr6.compare<int32_t>(ctx.r10.s32, 22, xer);
	// beq cr6,0x82459718
	if (cr6.eq) goto loc_82459718;
	// cmpwi cr6,r10,24
	cr6.compare<int32_t>(ctx.r10.s32, 24, xer);
	// bne cr6,0x824598b4
	if (!cr6.eq) goto loc_824598B4;
	// cmpwi cr6,r11,24
	cr6.compare<int32_t>(r11.s32, 24, xer);
	// blt cr6,0x824598cc
	if (cr6.lt) goto loc_824598CC;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// b 0x824598c8
	goto loc_824598C8;
loc_824598B4:
	// cmpwi cr6,r10,33
	cr6.compare<int32_t>(ctx.r10.s32, 33, xer);
	// bne cr6,0x824598cc
	if (!cr6.eq) goto loc_824598CC;
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// blt cr6,0x824598cc
	if (cr6.lt) goto loc_824598CC;
	// cmpwi cr6,r11,37
	cr6.compare<int32_t>(r11.s32, 37, xer);
loc_824598C8:
	// ble cr6,0x82459718
	if (!cr6.gt) goto loc_82459718;
loc_824598CC:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplwi cr6,r9,2
	cr6.compare<uint32_t>(ctx.r9.u32, 2, xer);
	// blt cr6,0x82459874
	if (cr6.lt) goto loc_82459874;
loc_824598D8:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824598E4"))) PPC_WEAK_FUNC(sub_824598E4);
PPC_FUNC_IMPL(__imp__sub_824598E4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824598E8"))) PPC_WEAK_FUNC(sub_824598E8);
PPC_FUNC_IMPL(__imp__sub_824598E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82459914
	if (!cr6.eq) goto loc_82459914;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82459a84
	goto loc_82459A84;
loc_82459914:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x82459a30
	if (cr6.eq) goto loc_82459A30;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x82459a18
	if (cr6.eq) goto loc_82459A18;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x824599dc
	if (cr6.eq) goto loc_824599DC;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x82459948
	if (cr6.eq) goto loc_82459948;
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x82459a80
	if (!cr6.eq) goto loc_82459A80;
	// lwz r4,48(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// b 0x82459a1c
	goto loc_82459A1C;
loc_82459948:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r9,3
	ctx.r9.s64 = 3;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r8,28(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi cr6,r11,50
	cr6.compare<uint32_t>(r11.u32, 50, xer);
	// mullw r30,r10,r8
	r30.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// bgt cr6,0x824599b8
	if (cr6.gt) goto loc_824599B8;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-26544
	r12.s64 = r12.s64 + -26544;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,-26228
	r12.s64 = r12.s64 + -26228;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8245998C;
	case 1:
		goto loc_82459994;
	case 2:
		goto loc_82459994;
	case 3:
		goto loc_82459994;
	case 4:
		goto loc_82459994;
	case 5:
		goto loc_82459994;
	case 6:
		goto loc_8245999C;
	case 7:
		goto loc_8245999C;
	case 8:
		goto loc_8245999C;
	case 9:
		goto loc_8245999C;
	case 10:
		goto loc_824599A4;
	case 11:
		goto loc_824599A4;
	case 12:
		goto loc_824599A4;
	case 13:
		goto loc_824599A4;
	case 14:
		goto loc_824599B8;
	case 15:
		goto loc_824599B8;
	case 16:
		goto loc_824599B8;
	case 17:
		goto loc_824599B8;
	case 18:
		goto loc_824599B8;
	case 19:
		goto loc_824599B8;
	case 20:
		goto loc_824599B8;
	case 21:
		goto loc_824599B8;
	case 22:
		goto loc_824599B4;
	case 23:
		goto loc_824599B4;
	case 24:
		goto loc_824599B4;
	case 25:
		goto loc_824599B4;
	case 26:
		goto loc_824599B4;
	case 27:
		goto loc_824599B4;
	case 28:
		goto loc_824599B4;
	case 29:
		goto loc_824599B4;
	case 30:
		goto loc_824599B4;
	case 31:
		goto loc_824599B8;
	case 32:
		goto loc_824599B8;
	case 33:
		goto loc_824599AC;
	case 34:
		goto loc_824599AC;
	case 35:
		goto loc_824599AC;
	case 36:
		goto loc_824599AC;
	case 37:
		goto loc_824599AC;
	case 38:
		goto loc_824599B8;
	case 39:
		goto loc_824599B4;
	case 40:
		goto loc_824599B8;
	case 41:
		goto loc_824599B8;
	case 42:
		goto loc_824599B4;
	case 43:
		goto loc_824599B4;
	case 44:
		goto loc_824599B4;
	case 45:
		goto loc_824599B4;
	case 46:
		goto loc_824599B4;
	case 47:
		goto loc_824599AC;
	case 48:
		goto loc_824599AC;
	case 49:
		goto loc_824599AC;
	case 50:
		goto loc_824599AC;
	default:
		__builtin_unreachable();
	}
loc_8245998C:
	// li r9,0
	ctx.r9.s64 = 0;
	// b 0x824599b8
	goto loc_824599B8;
loc_82459994:
	// li r9,1
	ctx.r9.s64 = 1;
	// b 0x824599b8
	goto loc_824599B8;
loc_8245999C:
	// li r9,2
	ctx.r9.s64 = 2;
	// b 0x824599b8
	goto loc_824599B8;
loc_824599A4:
	// li r9,3
	ctx.r9.s64 = 3;
	// b 0x824599b8
	goto loc_824599B8;
loc_824599AC:
	// li r9,4
	ctx.r9.s64 = 4;
	// b 0x824599b8
	goto loc_824599B8;
loc_824599B4:
	// li r9,5
	ctx.r9.s64 = 5;
loc_824599B8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82459a80
	if (cr6.eq) goto loc_82459A80;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_824599C8:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x824599c8
	if (!cr0.eq) goto loc_824599C8;
	// b 0x82459a80
	goto loc_82459A80;
loc_824599DC:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82459a80
	if (!cr6.gt) goto loc_82459A80;
loc_824599EC:
	// rlwinm r11,r30,4,0,27
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 4) & 0xFFFFFFF0;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// add r5,r11,r27
	ctx.r5.u64 = r11.u64 + r27.u64;
	// bl 0x824598e8
	sub_824598E8(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// add r30,r3,r30
	r30.u64 = ctx.r3.u64 + r30.u64;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x824599ec
	if (cr6.lt) goto loc_824599EC;
	// b 0x82459a80
	goto loc_82459A80;
loc_82459A18:
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
loc_82459A1C:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// bl 0x824598e8
	sub_824598E8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82459a80
	goto loc_82459A80;
loc_82459A30:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82459a60
	if (!cr6.eq) goto loc_82459A60;
	// rlwinm r11,r30,4,0,27
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 4) & 0xFFFFFFF0;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// add r5,r11,r27
	ctx.r5.u64 = r11.u64 + r27.u64;
	// bl 0x824598e8
	sub_824598E8(ctx, base);
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r30,r3,r30
	r30.u64 = ctx.r3.u64 + r30.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x82459a30
	if (!cr0.eq) goto loc_82459A30;
loc_82459A60:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82459a80
	if (cr6.eq) goto loc_82459A80;
	// rlwinm r11,r30,4,0,27
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// add r5,r11,r27
	ctx.r5.u64 = r11.u64 + r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x824598e8
	sub_824598E8(ctx, base);
	// add r30,r3,r30
	r30.u64 = ctx.r3.u64 + r30.u64;
loc_82459A80:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_82459A84:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_82459A8C"))) PPC_WEAK_FUNC(sub_82459A8C);
PPC_FUNC_IMPL(__imp__sub_82459A8C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82459A90"))) PPC_WEAK_FUNC(sub_82459A90);
PPC_FUNC_IMPL(__imp__sub_82459A90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x82459ae4
	if (cr6.lt) goto loc_82459AE4;
	// beq cr6,0x82459ad4
	if (cr6.eq) goto loc_82459AD4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x82459ac0
	if (cr6.lt) goto loc_82459AC0;
	// beq cr6,0x82459ab8
	if (cr6.eq) goto loc_82459AB8;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_82459AB8:
	// lfd f0,8(r5)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// b 0x82459b04
	goto loc_82459B04;
loc_82459AC0:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r11.u64);
	// lfd f0,-16(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
loc_82459ACC:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// b 0x82459b04
	goto loc_82459B04;
loc_82459AD4:
	// lwa r11,8(r5)
	r11.s64 = int32_t(PPC_LOAD_U32(ctx.r5.u32 + 8));
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r11.u64);
	// lfd f0,-16(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// b 0x82459acc
	goto loc_82459ACC;
loc_82459AE4:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82459afc
	if (cr6.eq) goto loc_82459AFC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// b 0x82459b04
	goto loc_82459B04;
loc_82459AFC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82459B04:
	// stfd f0,0(r4)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r4.u32 + 0, f0.u64);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82459B10"))) PPC_WEAK_FUNC(sub_82459B10);
PPC_FUNC_IMPL(__imp__sub_82459B10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
loc_82459B2C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82459bd4
	if (cr6.eq) goto loc_82459BD4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82459b5c
	if (!cr6.eq) goto loc_82459B5C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x82459b10
	sub_82459B10(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82459bcc
	if (!cr0.eq) goto loc_82459BCC;
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// b 0x82459b2c
	goto loc_82459B2C;
loc_82459B5C:
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// beq cr6,0x82459b98
	if (cr6.eq) goto loc_82459B98;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82459bd4
	if (!cr6.eq) goto loc_82459BD4;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bgt cr6,0x82459bc0
	if (cr6.gt) goto loc_82459BC0;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bge cr6,0x82459b90
	if (!cr6.lt) goto loc_82459B90;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x82459bcc
	if (cr6.lt) goto loc_82459BCC;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bgt cr6,0x82459bb0
	if (cr6.gt) goto loc_82459BB0;
loc_82459B90:
	// lwz r31,32(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// b 0x82459b2c
	goto loc_82459B2C;
loc_82459B98:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r11,r11,-6
	r11.s64 = r11.s64 + -6;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// b 0x82459bd8
	goto loc_82459BD8;
loc_82459BB0:
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// ble cr6,0x82459bcc
	if (!cr6.gt) goto loc_82459BCC;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// b 0x82459bc8
	goto loc_82459BC8;
loc_82459BC0:
	// addi r11,r11,-31
	r11.s64 = r11.s64 + -31;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
loc_82459BC8:
	// ble cr6,0x82459bd4
	if (!cr6.gt) goto loc_82459BD4;
loc_82459BCC:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82459bd8
	goto loc_82459BD8;
loc_82459BD4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82459BD8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82459BF0"))) PPC_WEAK_FUNC(sub_82459BF0);
PPC_FUNC_IMPL(__imp__sub_82459BF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
loc_82459C08:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82459dc0
	if (cr6.eq) goto loc_82459DC0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82459c3c
	if (!cr6.eq) goto loc_82459C3C;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82459bf0
	sub_82459BF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82459cc4
	if (cr0.eq) goto loc_82459CC4;
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// b 0x82459c08
	goto loc_82459C08;
loc_82459C3C:
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// beq cr6,0x82459c98
	if (cr6.eq) goto loc_82459C98;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82459dc0
	if (!cr6.eq) goto loc_82459DC0;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// blt cr6,0x82459da0
	if (cr6.lt) goto loc_82459DA0;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// ble cr6,0x82459cc4
	if (!cr6.gt) goto loc_82459CC4;
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// beq cr6,0x82459ccc
	if (cr6.eq) goto loc_82459CCC;
	// cmpwi cr6,r11,34
	cr6.compare<int32_t>(r11.s32, 34, xer);
	// bne cr6,0x82459da0
	if (!cr6.eq) goto loc_82459DA0;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82459cc4
	if (cr0.eq) goto loc_82459CC4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x82459cc4
	if (!cr6.eq) goto loc_82459CC4;
	// lwz r31,36(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// b 0x82459c08
	goto loc_82459C08;
loc_82459C98:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x82459dc0
	if (!cr6.eq) goto loc_82459DC0;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// bne cr6,0x82459dc0
	if (!cr6.eq) goto loc_82459DC0;
loc_82459CC4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82459dc4
	goto loc_82459DC4;
loc_82459CCC:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmpwi cr6,r11,96
	cr6.compare<int32_t>(r11.s32, 96, xer);
	// bgt cr6,0x82459d28
	if (cr6.gt) goto loc_82459D28;
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,73
	cr6.compare<int32_t>(r11.s32, 73, xer);
	// bgt cr6,0x82459d10
	if (cr6.gt) goto loc_82459D10;
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,42
	cr6.compare<int32_t>(r11.s32, 42, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,66
	cr6.compare<int32_t>(r11.s32, 66, xer);
	// b 0x82459d5c
	goto loc_82459D5C;
loc_82459D10:
	// cmpwi cr6,r11,78
	cr6.compare<int32_t>(r11.s32, 78, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,83
	cr6.compare<int32_t>(r11.s32, 83, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,91
	cr6.compare<int32_t>(r11.s32, 91, xer);
	// b 0x82459d5c
	goto loc_82459D5C;
loc_82459D28:
	// cmpwi cr6,r11,101
	cr6.compare<int32_t>(r11.s32, 101, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,109
	cr6.compare<int32_t>(r11.s32, 109, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,112
	cr6.compare<int32_t>(r11.s32, 112, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,115
	cr6.compare<int32_t>(r11.s32, 115, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,123
	cr6.compare<int32_t>(r11.s32, 123, xer);
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// cmpwi cr6,r11,126
	cr6.compare<int32_t>(r11.s32, 126, xer);
loc_82459D5C:
	// beq cr6,0x82459cc4
	if (cr6.eq) goto loc_82459CC4;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x82459bf0
	sub_82459BF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82459cc4
	if (cr0.eq) goto loc_82459CC4;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_82459D84:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x82459bf0
	sub_82459BF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82459dc4
	if (!cr0.eq) goto loc_82459DC4;
	// b 0x82459cc4
	goto loc_82459CC4;
loc_82459DA0:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82459bf0
	sub_82459BF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82459cc4
	if (cr0.eq) goto loc_82459CC4;
	// lwz r4,36(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// b 0x82459d84
	goto loc_82459D84;
loc_82459DC0:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82459DC4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_82459DCC"))) PPC_WEAK_FUNC(sub_82459DCC);
PPC_FUNC_IMPL(__imp__sub_82459DCC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82459DD0"))) PPC_WEAK_FUNC(sub_82459DD0);
PPC_FUNC_IMPL(__imp__sub_82459DD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// subf r11,r10,r31
	r11.s64 = r31.s64 - ctx.r10.s64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// rlwinm r9,r11,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// subf r10,r10,r11
	ctx.r10.s64 = r11.s64 - ctx.r10.s64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cmpw cr6,r9,r10
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, xer);
	// bne cr6,0x82459f48
	if (!cr6.eq) goto loc_82459F48;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82459e98
	if (cr6.eq) goto loc_82459E98;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82459e60
	if (cr0.lt) goto loc_82459E60;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82459e60
	if (cr0.lt) goto loc_82459E60;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82459e98
	if (cr6.eq) goto loc_82459E98;
	// b 0x82459f48
	goto loc_82459F48;
loc_82459E60:
	// lwz r10,36(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
loc_82459E6C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82459e90
	if (cr0.eq) goto loc_82459E90;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82459e6c
	if (cr6.eq) goto loc_82459E6C;
loc_82459E90:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82459f48
	if (!cr0.eq) goto loc_82459F48;
loc_82459E98:
	// lwz r9,44(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82459f3c
	if (cr0.eq) goto loc_82459F3C;
loc_82459EA8:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82459f34
	if (cr6.eq) goto loc_82459F34;
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r7,44(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// lwz r6,44(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 44);
	// cmplw cr6,r7,r6
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, xer);
	// bne cr6,0x82459f48
	if (!cr6.eq) goto loc_82459F48;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,48(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// lwz r4,48(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82459f48
	if (cr0.eq) goto loc_82459F48;
	// b 0x82459efc
	goto loc_82459EFC;
loc_82459EEC:
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x82459f1c
	if (cr6.eq) goto loc_82459F1C;
loc_82459EFC:
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne 0x82459eec
	if (!cr0.eq) goto loc_82459EEC;
	// b 0x82459f1c
	goto loc_82459F1C;
loc_82459F0C:
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x82459f28
	if (cr6.eq) goto loc_82459F28;
loc_82459F1C:
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne 0x82459f0c
	if (!cr0.eq) goto loc_82459F0C;
loc_82459F28:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82459ea8
	if (!cr6.eq) goto loc_82459EA8;
	// b 0x82459f3c
	goto loc_82459F3C;
loc_82459F34:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82459f48
	if (!cr6.eq) goto loc_82459F48;
loc_82459F3C:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq cr6,0x82459f4c
	if (cr6.eq) goto loc_82459F4C;
loc_82459F48:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82459F4C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_82459F54"))) PPC_WEAK_FUNC(sub_82459F54);
PPC_FUNC_IMPL(__imp__sub_82459F54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82459F58"))) PPC_WEAK_FUNC(sub_82459F58);
PPC_FUNC_IMPL(__imp__sub_82459F58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82459f98
	if (cr0.eq) goto loc_82459F98;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-23840
	ctx.r6.s64 = r11.s64 + -23840;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82459f9c
	goto loc_82459F9C;
loc_82459F98:
	// li r31,0
	r31.s64 = 0;
loc_82459F9C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82459fac
	if (!cr6.eq) goto loc_82459FAC;
loc_82459FA4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82459fe4
	goto loc_82459FE4;
loc_82459FAC:
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82459fd0
	if (cr0.eq) goto loc_82459FD0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8240a638
	sub_8240A638(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x82459fd4
	goto loc_82459FD4;
loc_82459FD0:
	// li r11,0
	r11.s64 = 0;
loc_82459FD4:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82459fa4
	if (cr6.eq) goto loc_82459FA4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_82459FE4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_82459FEC"))) PPC_WEAK_FUNC(sub_82459FEC);
PPC_FUNC_IMPL(__imp__sub_82459FEC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82459FF0"))) PPC_WEAK_FUNC(sub_82459FF0);
PPC_FUNC_IMPL(__imp__sub_82459FF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8245a16c
	if (cr6.lt) goto loc_8245A16C;
	// beq cr6,0x8245a120
	if (cr6.eq) goto loc_8245A120;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245a0cc
	if (cr6.lt) goto loc_8245A0CC;
	// beq cr6,0x8245a060
	if (cr6.eq) goto loc_8245A060;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// blt cr6,0x8245a050
	if (cr6.lt) goto loc_8245A050;
	// bne cr6,0x8245a188
	if (!cr6.eq) goto loc_8245A188;
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x8245a040
	if (cr6.eq) goto loc_8245A040;
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// bne cr6,0x8245a188
	if (!cr6.eq) goto loc_8245A188;
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// lwz r11,12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, r11.u32);
	// b 0x8245a1c8
	goto loc_8245A1C8;
loc_8245A040:
	// li r11,4
	r11.s64 = 4;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
loc_8245A048:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// b 0x8245a1c4
	goto loc_8245A1C4;
loc_8245A050:
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x8245a188
	if (!cr6.eq) goto loc_8245A188;
	// b 0x8245a048
	goto loc_8245A048;
loc_8245A060:
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8245a0ac
	if (cr6.lt) goto loc_8245A0AC;
	// beq cr6,0x8245a09c
	if (cr6.eq) goto loc_8245A09C;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245a088
	if (cr6.lt) goto loc_8245A088;
	// bne cr6,0x8245a188
	if (!cr6.eq) goto loc_8245A188;
	// lfd f0,8(r5)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
loc_8245A080:
	// stfd f0,8(r4)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r4.u32 + 8, f0.u64);
	// b 0x8245a1c8
	goto loc_8245A1C8;
loc_8245A088:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r11.u64);
	// lfd f0,-16(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
loc_8245A094:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// b 0x8245a080
	goto loc_8245A080;
loc_8245A09C:
	// lwa r11,8(r5)
	r11.s64 = int32_t(PPC_LOAD_U32(ctx.r5.u32 + 8));
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r11.u64);
	// lfd f0,-16(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// b 0x8245a094
	goto loc_8245A094;
loc_8245A0AC:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r11.u64);
	// lfd f0,-16(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// b 0x8245a094
	goto loc_8245A094;
loc_8245A0CC:
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8245a1b4
	if (cr6.lt) goto loc_8245A1B4;
	// beq cr6,0x8245a048
	if (cr6.eq) goto loc_8245A048;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245a048
	if (cr6.lt) goto loc_8245A048;
	// bne cr6,0x8245a188
	if (!cr6.eq) goto loc_8245A188;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,8(r5)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// lfd f13,-31368(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfd f13,31184(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 31184);
	// blt cr6,0x8245a10c
	if (cr6.lt) goto loc_8245A10C;
	// fadd f0,f0,f13
	f0.f64 = f0.f64 + ctx.f13.f64;
	// b 0x8245a110
	goto loc_8245A110;
loc_8245A10C:
	// fsub f0,f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = f0.f64 - ctx.f13.f64;
loc_8245A110:
	// fctidz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&f0.f64));
loc_8245A114:
	// addi r11,r4,8
	r11.s64 = ctx.r4.s64 + 8;
	// stfiwx f0,0,r11
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U32(r11.u32, f0.u32);
	// b 0x8245a1c8
	goto loc_8245A1C8;
loc_8245A120:
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8245a1b4
	if (cr6.lt) goto loc_8245A1B4;
	// beq cr6,0x8245a048
	if (cr6.eq) goto loc_8245A048;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245a048
	if (cr6.lt) goto loc_8245A048;
	// bne cr6,0x8245a188
	if (!cr6.eq) goto loc_8245A188;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,8(r5)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// lfd f13,-31368(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfd f13,31184(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 31184);
	// blt cr6,0x8245a160
	if (cr6.lt) goto loc_8245A160;
	// fadd f0,f0,f13
	f0.f64 = f0.f64 + ctx.f13.f64;
	// b 0x8245a164
	goto loc_8245A164;
loc_8245A160:
	// fsub f0,f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = f0.f64 - ctx.f13.f64;
loc_8245A164:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// b 0x8245a114
	goto loc_8245A114;
loc_8245A16C:
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8245a1b4
	if (cr6.lt) goto loc_8245A1B4;
	// beq cr6,0x8245a1b4
	if (cr6.eq) goto loc_8245A1B4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245a1b4
	if (cr6.lt) goto loc_8245A1B4;
	// beq cr6,0x8245a194
	if (cr6.eq) goto loc_8245A194;
loc_8245A188:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_8245A194:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,8(r5)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// lfd f0,-31368(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// li r11,1
	r11.s64 = 1;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x8245a1c4
	if (!cr6.eq) goto loc_8245A1C4;
	// li r11,0
	r11.s64 = 0;
	// b 0x8245a1c4
	goto loc_8245A1C4;
loc_8245A1B4:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
loc_8245A1C4:
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
loc_8245A1C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245A1D0"))) PPC_WEAK_FUNC(sub_8245A1D0);
PPC_FUNC_IMPL(__imp__sub_8245A1D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8245a234
	if (cr6.lt) goto loc_8245A234;
	// beq cr6,0x8245a22c
	if (cr6.eq) goto loc_8245A22C;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245a22c
	if (cr6.lt) goto loc_8245A22C;
	// beq cr6,0x8245a1f8
	if (cr6.eq) goto loc_8245A1F8;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_8245A1F8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,8(r5)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// lfd f13,-31368(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfd f13,31184(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 31184);
	// blt cr6,0x8245a21c
	if (cr6.lt) goto loc_8245A21C;
	// fadd f0,f0,f13
	f0.f64 = f0.f64 + ctx.f13.f64;
	// b 0x8245a220
	goto loc_8245A220;
loc_8245A21C:
	// fsub f0,f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = f0.f64 - ctx.f13.f64;
loc_8245A220:
	// fctidz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r4
	PPC_STORE_U32(ctx.r4.u32, f0.u32);
	// b 0x8245a248
	goto loc_8245A248;
loc_8245A22C:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// b 0x8245a244
	goto loc_8245A244;
loc_8245A234:
	// lwz r11,8(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
loc_8245A244:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
loc_8245A248:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245A250"))) PPC_WEAK_FUNC(sub_8245A250);
PPC_FUNC_IMPL(__imp__sub_8245A250) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8245a2e0
	if (cr6.lt) goto loc_8245A2E0;
	// beq cr6,0x8245a2b4
	if (cr6.eq) goto loc_8245A2B4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245a280
	if (cr6.lt) goto loc_8245A280;
	// beq cr6,0x8245a278
	if (cr6.eq) goto loc_8245A278;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_8245A278:
	// stfd f1,8(r4)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r4.u32 + 8, ctx.f1.u64);
	// b 0x8245a2fc
	goto loc_8245A2FC;
loc_8245A280:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// lfd f0,31184(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 31184);
	// blt cr6,0x8245a2a0
	if (cr6.lt) goto loc_8245A2A0;
	// fadd f0,f1,f0
	f0.f64 = ctx.f1.f64 + f0.f64;
	// b 0x8245a2a4
	goto loc_8245A2A4;
loc_8245A2A0:
	// fsub f0,f1,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64 - f0.f64;
loc_8245A2A4:
	// fctidz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&f0.f64));
loc_8245A2A8:
	// addi r11,r4,8
	r11.s64 = ctx.r4.s64 + 8;
	// stfiwx f0,0,r11
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U32(r11.u32, f0.u32);
	// b 0x8245a2fc
	goto loc_8245A2FC;
loc_8245A2B4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// lfd f0,31184(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 31184);
	// blt cr6,0x8245a2d4
	if (cr6.lt) goto loc_8245A2D4;
	// fadd f0,f1,f0
	f0.f64 = ctx.f1.f64 + f0.f64;
	// b 0x8245a2d8
	goto loc_8245A2D8;
loc_8245A2D4:
	// fsub f0,f1,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64 - f0.f64;
loc_8245A2D8:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// b 0x8245a2a8
	goto loc_8245A2A8;
loc_8245A2E0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// li r11,1
	r11.s64 = 1;
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bne cr6,0x8245a2f8
	if (!cr6.eq) goto loc_8245A2F8;
	// li r11,0
	r11.s64 = 0;
loc_8245A2F8:
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
loc_8245A2FC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245A304"))) PPC_WEAK_FUNC(sub_8245A304);
PPC_FUNC_IMPL(__imp__sub_8245A304) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245A308"))) PPC_WEAK_FUNC(sub_8245A308);
PPC_FUNC_IMPL(__imp__sub_8245A308) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,52
	ctx.r3.s64 = 52;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a338
	if (cr0.eq) goto loc_8245A338;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245a33c
	goto loc_8245A33C;
loc_8245A338:
	// li r31,0
	r31.s64 = 0;
loc_8245A33C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245a3bc
	if (cr6.eq) goto loc_8245A3BC;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
	// beq cr6,0x8245a388
	if (cr6.eq) goto loc_8245A388;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// beq 0x8245a3bc
	if (cr0.eq) goto loc_8245A3BC;
loc_8245A388:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a3b0
	if (cr0.eq) goto loc_8245A3B0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245a3b4
	goto loc_8245A3B4;
loc_8245A3B0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A3B4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8245a3c0
	if (!cr6.eq) goto loc_8245A3C0;
loc_8245A3BC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A3C0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245A3C8"))) PPC_WEAK_FUNC(sub_8245A3C8);
PPC_FUNC_IMPL(__imp__sub_8245A3C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,116(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 116);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245a4b4
	if (cr6.eq) goto loc_8245A4B4;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a414
	if (cr0.eq) goto loc_8245A414;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245a418
	goto loc_8245A418;
loc_8245A414:
	// li r31,0
	r31.s64 = 0;
loc_8245A418:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245a4b4
	if (cr6.eq) goto loc_8245A4B4;
	// li r11,10
	r11.s64 = 10;
	// li r3,80
	ctx.r3.s64 = 80;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a470
	if (cr0.eq) goto loc_8245A470;
	// addi r9,r30,40
	ctx.r9.s64 = r30.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245a474
	goto loc_8245A474;
loc_8245A470:
	// li r11,0
	r11.s64 = 0;
loc_8245A474:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245a4b4
	if (cr6.eq) goto loc_8245A4B4;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a4a8
	if (cr0.eq) goto loc_8245A4A8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245a4ac
	goto loc_8245A4AC;
loc_8245A4A8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A4AC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8245a4b8
	if (!cr6.eq) goto loc_8245A4B8;
loc_8245A4B4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A4B8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245A4D0"))) PPC_WEAK_FUNC(sub_8245A4D0);
PPC_FUNC_IMPL(__imp__sub_8245A4D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,116(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 116);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245a5bc
	if (cr6.eq) goto loc_8245A5BC;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a51c
	if (cr0.eq) goto loc_8245A51C;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245a520
	goto loc_8245A520;
loc_8245A51C:
	// li r31,0
	r31.s64 = 0;
loc_8245A520:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245a5bc
	if (cr6.eq) goto loc_8245A5BC;
	// li r11,11
	r11.s64 = 11;
	// li r3,80
	ctx.r3.s64 = 80;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a578
	if (cr0.eq) goto loc_8245A578;
	// addi r9,r30,40
	ctx.r9.s64 = r30.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245a57c
	goto loc_8245A57C;
loc_8245A578:
	// li r11,0
	r11.s64 = 0;
loc_8245A57C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245a5bc
	if (cr6.eq) goto loc_8245A5BC;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a5b0
	if (cr0.eq) goto loc_8245A5B0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245a5b4
	goto loc_8245A5B4;
loc_8245A5B0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A5B4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8245a5c0
	if (!cr6.eq) goto loc_8245A5C0;
loc_8245A5BC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A5C0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245A5D8"))) PPC_WEAK_FUNC(sub_8245A5D8);
PPC_FUNC_IMPL(__imp__sub_8245A5D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,116(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 116);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245a6c4
	if (cr6.eq) goto loc_8245A6C4;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a624
	if (cr0.eq) goto loc_8245A624;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245a628
	goto loc_8245A628;
loc_8245A624:
	// li r31,0
	r31.s64 = 0;
loc_8245A628:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245a6c4
	if (cr6.eq) goto loc_8245A6C4;
	// li r11,9
	r11.s64 = 9;
	// li r3,80
	ctx.r3.s64 = 80;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a680
	if (cr0.eq) goto loc_8245A680;
	// addi r9,r30,40
	ctx.r9.s64 = r30.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245a684
	goto loc_8245A684;
loc_8245A680:
	// li r11,0
	r11.s64 = 0;
loc_8245A684:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245a6c4
	if (cr6.eq) goto loc_8245A6C4;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a6b8
	if (cr0.eq) goto loc_8245A6B8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245a6bc
	goto loc_8245A6BC;
loc_8245A6B8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A6BC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8245a6c8
	if (!cr6.eq) goto loc_8245A6C8;
loc_8245A6C4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A6C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245A6E0"))) PPC_WEAK_FUNC(sub_8245A6E0);
PPC_FUNC_IMPL(__imp__sub_8245A6E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245a7c0
	if (cr6.eq) goto loc_8245A7C0;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a720
	if (cr0.eq) goto loc_8245A720;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245a724
	goto loc_8245A724;
loc_8245A720:
	// li r31,0
	r31.s64 = 0;
loc_8245A724:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245a7c0
	if (cr6.eq) goto loc_8245A7C0;
	// li r11,6
	r11.s64 = 6;
	// li r3,80
	ctx.r3.s64 = 80;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a77c
	if (cr0.eq) goto loc_8245A77C;
	// addi r9,r30,40
	ctx.r9.s64 = r30.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245a780
	goto loc_8245A780;
loc_8245A77C:
	// li r11,0
	r11.s64 = 0;
loc_8245A780:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245a7c0
	if (cr6.eq) goto loc_8245A7C0;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a7b4
	if (cr0.eq) goto loc_8245A7B4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245a7b8
	goto loc_8245A7B8;
loc_8245A7B4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A7B8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8245a7c4
	if (!cr6.eq) goto loc_8245A7C4;
loc_8245A7C0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A7C4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245A7DC"))) PPC_WEAK_FUNC(sub_8245A7DC);
PPC_FUNC_IMPL(__imp__sub_8245A7DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245A7E0"))) PPC_WEAK_FUNC(sub_8245A7E0);
PPC_FUNC_IMPL(__imp__sub_8245A7E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r3,52
	ctx.r3.s64 = 52;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,116(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 116);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a820
	if (cr0.eq) goto loc_8245A820;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245a824
	goto loc_8245A824;
loc_8245A820:
	// li r31,0
	r31.s64 = 0;
loc_8245A824:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245a8cc
	if (cr6.eq) goto loc_8245A8CC;
	// li r11,13
	r11.s64 = 13;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
	// beq cr6,0x8245a870
	if (cr6.eq) goto loc_8245A870;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// beq 0x8245a8cc
	if (cr0.eq) goto loc_8245A8CC;
loc_8245A870:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8245a898
	if (cr6.eq) goto loc_8245A898;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8245a8cc
	if (cr0.eq) goto loc_8245A8CC;
loc_8245A898:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245a8c0
	if (cr0.eq) goto loc_8245A8C0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-23828
	ctx.r6.s64 = r11.s64 + -23828;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245a8c4
	goto loc_8245A8C4;
loc_8245A8C0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A8C4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8245a8d0
	if (!cr6.eq) goto loc_8245A8D0;
loc_8245A8CC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245A8D0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8245A8D8"))) PPC_WEAK_FUNC(sub_8245A8D8);
PPC_FUNC_IMPL(__imp__sub_8245A8D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r10,r11,12644
	ctx.r10.s64 = r11.s64 + 12644;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_8245A900:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8245a924
	if (cr0.eq) goto loc_8245A924;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8245a900
	if (cr6.eq) goto loc_8245A900;
loc_8245A924:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8245a964
	if (cr0.eq) goto loc_8245A964;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823defe0
	sub_823DEFE0(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// li r11,0
	r11.s64 = 0;
	// addi r6,r10,-24616
	ctx.r6.s64 = ctx.r10.s64 + -24616;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// stb r11,335(r1)
	PPC_STORE_U8(ctx.r1.u32 + 335, r11.u8);
	// b 0x8245aad4
	goto loc_8245AAD4;
loc_8245A964:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8245aad8
	if (!cr6.eq) goto loc_8245AAD8;
	// addi r30,r31,40
	r30.s64 = r31.s64 + 40;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bgt cr6,0x8245aa14
	if (cr6.gt) goto loc_8245AA14;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-26488
	r12.s64 = r12.s64 + -26488;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,-22104
	r12.s64 = r12.s64 + -22104;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8245A9A8;
	case 1:
		goto loc_8245A9B4;
	case 2:
		goto loc_8245A9D0;
	case 3:
		goto loc_8245A9D0;
	case 4:
		goto loc_8245A9D0;
	case 5:
		goto loc_8245A9DC;
	case 6:
		goto loc_8245A9DC;
	case 7:
		goto loc_8245A9DC;
	case 8:
		goto loc_8245A9DC;
	case 9:
		goto loc_8245A9E8;
	case 10:
		goto loc_8245A9F0;
	case 11:
		goto loc_8245AA14;
	case 12:
		goto loc_8245A9FC;
	case 13:
		goto loc_8245AA08;
	default:
		__builtin_unreachable();
	}
loc_8245A9A8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,14040
	ctx.r5.s64 = r11.s64 + 14040;
	// b 0x8245aa1c
	goto loc_8245AA1C;
loc_8245A9B4:
	// addi r6,r31,48
	ctx.r6.s64 = r31.s64 + 48;
loc_8245A9B8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r5,r11,14028
	ctx.r5.s64 = r11.s64 + 14028;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
	// b 0x8245aa28
	goto loc_8245AA28;
loc_8245A9D0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r5,r11,-23612
	ctx.r5.s64 = r11.s64 + -23612;
	// b 0x8245aa1c
	goto loc_8245AA1C;
loc_8245A9DC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r5,r11,-23628
	ctx.r5.s64 = r11.s64 + -23628;
	// b 0x8245aa1c
	goto loc_8245AA1C;
loc_8245A9E8:
	// lwz r6,48(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// b 0x8245a9b8
	goto loc_8245A9B8;
loc_8245A9F0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,13916
	ctx.r5.s64 = r11.s64 + 13916;
	// b 0x8245aa1c
	goto loc_8245AA1C;
loc_8245A9FC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,13904
	ctx.r5.s64 = r11.s64 + 13904;
	// b 0x8245aa1c
	goto loc_8245AA1C;
loc_8245AA08:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,13892
	ctx.r5.s64 = r11.s64 + 13892;
	// b 0x8245aa1c
	goto loc_8245AA1C;
loc_8245AA14:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,13884
	ctx.r5.s64 = r11.s64 + 13884;
loc_8245AA1C:
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
loc_8245AA28:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r11,-23656
	ctx.r6.s64 = r11.s64 + -23656;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r5,3000
	ctx.r5.s64 = 3000;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245aad8
	if (!cr6.eq) goto loc_8245AAD8;
	// lis r11,-32139
	r11.s64 = -2106261504;
	// addi r11,r11,-6292
	r11.s64 = r11.s64 + -6292;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8245aad8
	if (cr6.eq) goto loc_8245AAD8;
	// lwz r6,48(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
loc_8245AA74:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_8245AA7C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8245aaa0
	if (cr0.eq) goto loc_8245AAA0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8245aa7c
	if (cr6.eq) goto loc_8245AA7C;
loc_8245AAA0:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8245aabc
	if (cr0.eq) goto loc_8245AABC;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// lwz r7,0(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi r7,0
	cr0.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne 0x8245aa74
	if (!cr0.eq) goto loc_8245AA74;
	// b 0x8245aad8
	goto loc_8245AAD8;
loc_8245AABC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// li r5,3000
	ctx.r5.s64 = 3000;
	// addi r6,r10,-23816
	ctx.r6.s64 = ctx.r10.s64 + -23816;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
loc_8245AAD4:
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
loc_8245AAD8:
	// li r11,1
	r11.s64 = 1;
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245AAF8"))) PPC_WEAK_FUNC(sub_8245AAF8);
PPC_FUNC_IMPL(__imp__sub_8245AAF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,432
	ctx.r10.s64 = ctx.r1.s64 + 432;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x823defe0
	sub_823DEFE0(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r10,-24616
	ctx.r6.s64 = ctx.r10.s64 + -24616;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245AB70"))) PPC_WEAK_FUNC(sub_8245AB70);
PPC_FUNC_IMPL(__imp__sub_8245AB70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,432
	ctx.r10.s64 = ctx.r1.s64 + 432;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x823defe0
	sub_823DEFE0(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r10,-24616
	ctx.r6.s64 = ctx.r10.s64 + -24616;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823ebe20
	sub_823EBE20(ctx, base);
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245ABE0"))) PPC_WEAK_FUNC(sub_8245ABE0);
PPC_FUNC_IMPL(__imp__sub_8245ABE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,432
	ctx.r10.s64 = ctx.r1.s64 + 432;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x823defe0
	sub_823DEFE0(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r10,-24616
	ctx.r6.s64 = ctx.r10.s64 + -24616;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x823ebc20
	sub_823EBC20(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// stw r11,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r11.u32);
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245AC5C"))) PPC_WEAK_FUNC(sub_8245AC5C);
PPC_FUNC_IMPL(__imp__sub_8245AC5C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245AC60"))) PPC_WEAK_FUNC(sub_8245AC60);
PPC_FUNC_IMPL(__imp__sub_8245AC60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8245acac
	if (!cr6.eq) goto loc_8245ACAC;
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8245aca0
	if (!cr6.eq) goto loc_8245ACA0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-23592
	ctx.r6.s64 = r11.s64 + -23592;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
loc_8245ACA0:
	// li r11,1
	r11.s64 = 1;
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// stw r11,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r11.u32);
loc_8245ACAC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245ACC8"))) PPC_WEAK_FUNC(sub_8245ACC8);
PPC_FUNC_IMPL(__imp__sub_8245ACC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8245ad10
	if (cr6.eq) goto loc_8245AD10;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8245ACF4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8245acf4
	if (!cr6.eq) goto loc_8245ACF4;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r29,r11,0
	r29.u64 = __builtin_rotateleft32(r11.u32, 0);
loc_8245AD10:
	// lwz r9,20(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8245addc
	if (cr0.eq) goto loc_8245ADDC;
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8245addc
	if (cr0.eq) goto loc_8245ADDC;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8245AD2C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x8245ad2c
	if (!cr6.eq) goto loc_8245AD2C;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi. r31,r11,0
	r31.u64 = __builtin_rotateleft32(r11.u32, 0);
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x8245addc
	if (cr0.eq) goto loc_8245ADDC;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8245addc
	if (cr6.eq) goto loc_8245ADDC;
	// add r11,r31,r29
	r11.u64 = r31.u64 + r29.u64;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r4,r11,3
	ctx.r4.s64 = r11.s64 + 3;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x8245ad94
	if (!cr0.eq) goto loc_8245AD94;
loc_8245AD70:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,12944
	ctx.r6.s64 = r11.s64 + 12944;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8245ae34
	goto loc_8245AE34;
loc_8245AD94:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,20(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// add r31,r30,r31
	r31.u64 = r30.u64 + r31.u64;
	// li r11,58
	r11.s64 = 58;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r31,2
	ctx.r3.s64 = r31.s64 + 2;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// stb r11,1(r31)
	PPC_STORE_U8(r31.u32 + 1, r11.u8);
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// add r11,r31,r29
	r11.u64 = r31.u64 + r29.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r28,r30
	r28.u64 = r30.u64;
	// stb r10,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r10.u8);
	// b 0x8245adf0
	goto loc_8245ADF0;
loc_8245ADDC:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8245adf0
	if (cr6.eq) goto loc_8245ADF0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x8245adf0
	if (!cr6.eq) goto loc_8245ADF0;
	// lwz r28,20(r9)
	r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
loc_8245ADF0:
	// li r3,36
	ctx.r3.s64 = 36;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245ae20
	if (cr0.eq) goto loc_8245AE20;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x82409d88
	sub_82409D88(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245ae24
	goto loc_8245AE24;
loc_8245AE20:
	// li r11,0
	r11.s64 = 0;
loc_8245AE24:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245ad70
	if (cr6.eq) goto loc_8245AD70;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,20(r27)
	PPC_STORE_U32(r27.u32 + 20, r11.u32);
loc_8245AE34:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8245AE3C"))) PPC_WEAK_FUNC(sub_8245AE3C);
PPC_FUNC_IMPL(__imp__sub_8245AE3C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245AE40"))) PPC_WEAK_FUNC(sub_8245AE40);
PPC_FUNC_IMPL(__imp__sub_8245AE40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8245ae7c
	if (!cr0.eq) goto loc_8245AE7C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-23556
	ctx.r6.s64 = r11.s64 + -23556;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8245af28
	goto loc_8245AF28;
loc_8245AE7C:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// li r29,0
	r29.s64 = 0;
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// bne cr6,0x8245af14
	if (!cr6.eq) goto loc_8245AF14;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8245af14
	if (cr0.eq) goto loc_8245AF14;
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// beq cr6,0x8245af14
	if (cr6.eq) goto loc_8245AF14;
	// addi r31,r11,24
	r31.s64 = r11.s64 + 24;
	// b 0x8245aee0
	goto loc_8245AEE0;
loc_8245AEAC:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,32(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	// bl 0x82459110
	sub_82459110(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245af28
	if (cr0.lt) goto loc_8245AF28;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r31,r11,12
	r31.s64 = r11.s64 + 12;
loc_8245AEE0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8245aeac
	if (!cr0.eq) goto loc_8245AEAC;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, r11.u32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r29,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r29.u32);
loc_8245AF14:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// stw r10,20(r30)
	PPC_STORE_U32(r30.u32 + 20, ctx.r10.u32);
	// stw r29,32(r11)
	PPC_STORE_U32(r11.u32 + 32, r29.u32);
loc_8245AF28:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245AF30"))) PPC_WEAK_FUNC(sub_8245AF30);
PPC_FUNC_IMPL(__imp__sub_8245AF30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne 0x8245af74
	if (!cr0.eq) goto loc_8245AF74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-23460
	ctx.r6.s64 = r11.s64 + -23460;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
loc_8245AF68:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8245b10c
	goto loc_8245B10C;
loc_8245AF74:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addi r30,r11,16
	r30.s64 = r11.s64 + 16;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82459368
	sub_82459368(ctx, base);
	// mr. r11,r3
	r11.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245afc0
	if (cr0.eq) goto loc_8245AFC0;
loc_8245AF8C:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,48(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x8245afb4
	if (!cr6.eq) goto loc_8245AFB4;
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bne cr6,0x8245b00c
	if (!cr6.eq) goto loc_8245B00C;
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x8245b00c
	if (!cr6.eq) goto loc_8245B00C;
loc_8245AFB4:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8245af8c
	if (!cr0.eq) goto loc_8245AF8C;
loc_8245AFC0:
	// lwz r11,32(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 32);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8245b048
	if (cr0.eq) goto loc_8245B048;
	// lwz r10,16(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x8245b048
	if (!cr6.eq) goto loc_8245B048;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x8245b048
	if (!cr6.eq) goto loc_8245B048;
	// mr r5,r11
	ctx.r5.u64 = r11.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82459368
	sub_82459368(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245b048
	if (cr0.eq) goto loc_8245B048;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3036
	ctx.r5.s64 = 3036;
	// addi r6,r11,-23500
	ctx.r6.s64 = r11.s64 + -23500;
	// b 0x8245b034
	goto loc_8245B034;
loc_8245B00C:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x8245b028
	if (cr6.eq) goto loc_8245B028;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x824094c8
	sub_824094C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8245b108
	if (!cr0.eq) goto loc_8245B108;
loc_8245B028:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3003
	ctx.r5.s64 = 3003;
	// addi r6,r11,-23524
	ctx.r6.s64 = r11.s64 + -23524;
loc_8245B034:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x8245af68
	goto loc_8245AF68;
loc_8245B048:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245b074
	if (cr0.eq) goto loc_8245B074;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-24228
	ctx.r6.s64 = r11.s64 + -24228;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8245b078
	goto loc_8245B078;
loc_8245B074:
	// li r30,0
	r30.s64 = 0;
loc_8245B078:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8245b08c
	if (!cr6.eq) goto loc_8245B08C;
loc_8245B080:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8245b10c
	goto loc_8245B10C;
loc_8245B08C:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// mr. r11,r3
	r11.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// beq 0x8245b080
	if (cr0.eq) goto loc_8245B080;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// stw r10,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r10.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// stw r11,36(r29)
	PPC_STORE_U32(r29.u32 + 36, r11.u32);
	// lwz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// stw r11,40(r29)
	PPC_STORE_U32(r29.u32 + 40, r11.u32);
	// lwz r11,84(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r11.u32);
	// lwz r11,24(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r30,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r30.u32);
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bl 0x82459110
	sub_82459110(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245b10c
	if (cr0.lt) goto loc_8245B10C;
loc_8245B108:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245B10C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8245B114"))) PPC_WEAK_FUNC(sub_8245B114);
PPC_FUNC_IMPL(__imp__sub_8245B114) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245B118"))) PPC_WEAK_FUNC(sub_8245B118);
PPC_FUNC_IMPL(__imp__sub_8245B118) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8245b194
	if (cr6.eq) goto loc_8245B194;
	// lwz r11,16(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// rlwinm. r10,r11,0,29,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8245b184
	if (cr0.eq) goto loc_8245B184;
	// cmpwi cr6,r31,7
	cr6.compare<int32_t>(r31.s32, 7, xer);
	// bne cr6,0x8245b160
	if (!cr6.eq) goto loc_8245B160;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-23376
	ctx.r6.s64 = r11.s64 + -23376;
	// b 0x8245b170
	goto loc_8245B170;
loc_8245B160:
	// cmpwi cr6,r31,8
	cr6.compare<int32_t>(r31.s32, 8, xer);
	// bne cr6,0x8245b220
	if (!cr6.eq) goto loc_8245B220;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-23420
	ctx.r6.s64 = r11.s64 + -23420;
loc_8245B170:
	// li r5,3048
	ctx.r5.s64 = 3048;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x8245b220
	goto loc_8245B220;
loc_8245B184:
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// lwz r3,28(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 28);
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
loc_8245B194:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245b1c0
	if (cr0.eq) goto loc_8245B1C0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-23428
	ctx.r6.s64 = r11.s64 + -23428;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x8245b1c4
	goto loc_8245B1C4;
loc_8245B1C0:
	// li r29,0
	r29.s64 = 0;
loc_8245B1C4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8245b220
	if (cr6.eq) goto loc_8245B220;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245b1fc
	if (cr0.eq) goto loc_8245B1FC;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// lwz r5,20(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245b200
	goto loc_8245B200;
loc_8245B1FC:
	// li r31,0
	r31.s64 = 0;
loc_8245B200:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245b220
	if (cr6.eq) goto loc_8245B220;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245af30
	sub_8245AF30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8245b228
	if (!cr0.lt) goto loc_8245B228;
loc_8245B220:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245b238
	goto loc_8245B238;
loc_8245B228:
	// stw r31,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r31.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// stw r26,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r26.u32);
loc_8245B238:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8245B240"))) PPC_WEAK_FUNC(sub_8245B240);
PPC_FUNC_IMPL(__imp__sub_8245B240) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245b288
	if (cr0.eq) goto loc_8245B288;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-23332
	ctx.r6.s64 = r11.s64 + -23332;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x8245b28c
	goto loc_8245B28C;
loc_8245B288:
	// li r28,0
	r28.s64 = 0;
loc_8245B28C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8245b2e8
	if (cr6.eq) goto loc_8245B2E8;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245b2c4
	if (cr0.eq) goto loc_8245B2C4;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,6
	ctx.r4.s64 = 6;
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x8245b2c8
	goto loc_8245B2C8;
loc_8245B2C4:
	// li r4,0
	ctx.r4.s64 = 0;
loc_8245B2C8:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8245b2e8
	if (cr6.eq) goto loc_8245B2E8;
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r4,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r4.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245af30
	sub_8245AF30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8245b2f0
	if (!cr0.lt) goto loc_8245B2F0;
loc_8245B2E8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245b2f4
	goto loc_8245B2F4;
loc_8245B2F0:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_8245B2F4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd44
	return;
}

__attribute__((alias("__imp__sub_8245B2FC"))) PPC_WEAK_FUNC(sub_8245B2FC);
PPC_FUNC_IMPL(__imp__sub_8245B2FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245B300"))) PPC_WEAK_FUNC(sub_8245B300);
PPC_FUNC_IMPL(__imp__sub_8245B300) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245b348
	if (cr0.eq) goto loc_8245B348;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r6,r11,-23320
	ctx.r6.s64 = r11.s64 + -23320;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245b34c
	goto loc_8245B34C;
loc_8245B348:
	// li r11,0
	r11.s64 = 0;
loc_8245B34C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8245b36c
	if (!cr6.eq) goto loc_8245B36C;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8245b378
	goto loc_8245B378;
loc_8245B36C:
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r30.u32);
loc_8245B378:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245B390"))) PPC_WEAK_FUNC(sub_8245B390);
PPC_FUNC_IMPL(__imp__sub_8245B390) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245b46c
	if (cr6.eq) goto loc_8245B46C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8245b42c
	if (cr6.eq) goto loc_8245B42C;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8245b424
	if (cr6.eq) goto loc_8245B424;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x8245b41c
	if (cr6.eq) goto loc_8245B41C;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x8245b3fc
	if (cr6.eq) goto loc_8245B3FC;
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// beq cr6,0x8245b3f4
	if (cr6.eq) goto loc_8245B3F4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,31668
	ctx.r6.s64 = r11.s64 + 31668;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
	// b 0x8245b46c
	goto loc_8245B46C;
loc_8245B3F4:
	// lwz r4,48(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// b 0x8245b464
	goto loc_8245B464;
loc_8245B3FC:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x8245b410
	if (cr6.eq) goto loc_8245B410;
	// ori r11,r11,512
	r11.u64 = r11.u64 | 512;
	// b 0x8245b414
	goto loc_8245B414;
loc_8245B410:
	// rlwinm r11,r11,0,23,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFDFF;
loc_8245B414:
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x8245b46c
	goto loc_8245B46C;
loc_8245B41C:
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// b 0x8245b460
	goto loc_8245B460;
loc_8245B424:
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// b 0x8245b460
	goto loc_8245B460;
loc_8245B42C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245b454
	if (!cr6.eq) goto loc_8245B454;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x8245b42c
	if (!cr0.eq) goto loc_8245B42C;
loc_8245B454:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245b46c
	if (cr6.eq) goto loc_8245B46C;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_8245B460:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8245B464:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
loc_8245B46C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245B478"))) PPC_WEAK_FUNC(sub_8245B478);
PPC_FUNC_IMPL(__imp__sub_8245B478) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
loc_8245B494:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245b51c
	if (cr6.eq) goto loc_8245B51C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245b4c4
	if (!cr6.eq) goto loc_8245B4C4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8245b4fc
	if (!cr0.eq) goto loc_8245B4FC;
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// b 0x8245b494
	goto loc_8245B494;
loc_8245B4C4:
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8245b4f4
	if (cr6.eq) goto loc_8245B4F4;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x8245b4ec
	if (cr6.eq) goto loc_8245B4EC;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x8245b524
	if (cr6.eq) goto loc_8245B524;
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x8245b504
	if (!cr6.eq) goto loc_8245B504;
	// lwz r31,48(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// b 0x8245b494
	goto loc_8245B494;
loc_8245B4EC:
	// lwz r31,16(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// b 0x8245b494
	goto loc_8245B494;
loc_8245B4F4:
	// lwz r31,24(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// b 0x8245b494
	goto loc_8245B494;
loc_8245B4FC:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8245b52c
	goto loc_8245B52C;
loc_8245B504:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,31668
	ctx.r6.s64 = r11.s64 + 31668;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
loc_8245B51C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245b52c
	goto loc_8245B52C;
loc_8245B524:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm r3,r11,0,22,22
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
loc_8245B52C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245B544"))) PPC_WEAK_FUNC(sub_8245B544);
PPC_FUNC_IMPL(__imp__sub_8245B544) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245B548"))) PPC_WEAK_FUNC(sub_8245B548);
PPC_FUNC_IMPL(__imp__sub_8245B548) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
loc_8245B564:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245b5fc
	if (cr6.eq) goto loc_8245B5FC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245b594
	if (!cr6.eq) goto loc_8245B594;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245b5f4
	if (cr0.eq) goto loc_8245B5F4;
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// b 0x8245b564
	goto loc_8245B564;
loc_8245B594:
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8245b5c4
	if (cr6.eq) goto loc_8245B5C4;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x8245b5bc
	if (cr6.eq) goto loc_8245B5BC;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x8245b5e8
	if (cr6.eq) goto loc_8245B5E8;
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x8245b5cc
	if (!cr6.eq) goto loc_8245B5CC;
	// lwz r31,48(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// b 0x8245b564
	goto loc_8245B564;
loc_8245B5BC:
	// lwz r31,16(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// b 0x8245b564
	goto loc_8245B564;
loc_8245B5C4:
	// lwz r31,24(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// b 0x8245b564
	goto loc_8245B564;
loc_8245B5CC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,31668
	ctx.r6.s64 = r11.s64 + 31668;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
	// b 0x8245b5f4
	goto loc_8245B5F4;
loc_8245B5E8:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245b5fc
	if (cr6.lt) goto loc_8245B5FC;
loc_8245B5F4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245b600
	goto loc_8245B600;
loc_8245B5FC:
	// li r3,1
	ctx.r3.s64 = 1;
loc_8245B600:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245B618"))) PPC_WEAK_FUNC(sub_8245B618);
PPC_FUNC_IMPL(__imp__sub_8245B618) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245b668
	if (cr6.eq) goto loc_8245B668;
loc_8245B638:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245b660
	if (!cr6.eq) goto loc_8245B660;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r30,r3,r30
	r30.u64 = ctx.r3.u64 + r30.u64;
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x8245b638
	if (!cr0.eq) goto loc_8245B638;
loc_8245B660:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8245b670
	if (!cr6.eq) goto loc_8245B670;
loc_8245B668:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x8245b6f8
	goto loc_8245B6F8;
loc_8245B670:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8245b6e8
	if (cr6.eq) goto loc_8245B6E8;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x8245b6d0
	if (cr6.eq) goto loc_8245B6D0;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x8245b6bc
	if (cr6.eq) goto loc_8245B6BC;
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// beq cr6,0x8245b6b4
	if (cr6.eq) goto loc_8245B6B4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,31668
	ctx.r6.s64 = r11.s64 + 31668;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245b6f8
	goto loc_8245B6F8;
loc_8245B6B4:
	// lwz r4,48(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// b 0x8245b6f0
	goto loc_8245B6F0;
loc_8245B6BC:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
loc_8245B6C8:
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
	// b 0x8245b6f8
	goto loc_8245B6F8;
loc_8245B6D0:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mullw r11,r3,r11
	r11.s64 = int64_t(ctx.r3.s32) * int64_t(r11.s32);
	// b 0x8245b6c8
	goto loc_8245B6C8;
loc_8245B6E8:
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_8245B6F0:
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// add r3,r3,r30
	ctx.r3.u64 = ctx.r3.u64 + r30.u64;
loc_8245B6F8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245B700"))) PPC_WEAK_FUNC(sub_8245B700);
PPC_FUNC_IMPL(__imp__sub_8245B700) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// addi r26,r1,80
	r26.s64 = ctx.r1.s64 + 80;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x8245b730
	if (!cr6.eq) goto loc_8245B730;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245bb20
	goto loc_8245BB20;
loc_8245B730:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8245b744
	if (!cr6.eq) goto loc_8245B744;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r26,r11,-28732
	r26.s64 = r11.s64 + -28732;
	// b 0x8245bad0
	goto loc_8245BAD0;
loc_8245B744:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8245ba80
	if (cr6.eq) goto loc_8245BA80;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x8245b9e4
	if (cr6.eq) goto loc_8245B9E4;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x8245b76c
	if (cr6.eq) goto loc_8245B76C;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r26,r11,27144
	r26.s64 = r11.s64 + 27144;
	// b 0x8245bad0
	goto loc_8245BAD0;
loc_8245B76C:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// rlwinm. r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245b784
	if (cr0.eq) goto loc_8245B784;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,-28200
	ctx.r6.s64 = r11.s64 + -28200;
	// b 0x8245b78c
	goto loc_8245B78C;
loc_8245B784:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r6,r11,9120
	ctx.r6.s64 = r11.s64 + 9120;
loc_8245B78C:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,53
	cr6.compare<uint32_t>(r11.u32, 53, xer);
	// bgt cr6,0x8245b988
	if (cr6.gt) goto loc_8245B988;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-26472
	r12.s64 = r12.s64 + -26472;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = __builtin_rotateleft64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,-18496
	r12.s64 = r12.s64 + -18496;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8245B7C0;
	case 1:
		goto loc_8245B7CC;
	case 2:
		goto loc_8245B7CC;
	case 3:
		goto loc_8245B7CC;
	case 4:
		goto loc_8245B7CC;
	case 5:
		goto loc_8245B7CC;
	case 6:
		goto loc_8245B7D8;
	case 7:
		goto loc_8245B7D8;
	case 8:
		goto loc_8245B7D8;
	case 9:
		goto loc_8245B7D8;
	case 10:
		goto loc_8245B7E4;
	case 11:
		goto loc_8245B7F0;
	case 12:
		goto loc_8245B7E4;
	case 13:
		goto loc_8245B7FC;
	case 14:
		goto loc_8245B808;
	case 15:
		goto loc_8245B814;
	case 16:
		goto loc_8245B808;
	case 17:
		goto loc_8245B820;
	case 18:
		goto loc_8245B82C;
	case 19:
		goto loc_8245B838;
	case 20:
		goto loc_8245B82C;
	case 21:
		goto loc_8245B844;
	case 22:
		goto loc_8245B850;
	case 23:
		goto loc_8245B85C;
	case 24:
		goto loc_8245B868;
	case 25:
		goto loc_8245B874;
	case 26:
		goto loc_8245B8A4;
	case 27:
		goto loc_8245B880;
	case 28:
		goto loc_8245B8B0;
	case 29:
		goto loc_8245B88C;
	case 30:
		goto loc_8245B898;
	case 31:
		goto loc_8245B8BC;
	case 32:
		goto loc_8245B8C8;
	case 33:
		goto loc_8245B8E0;
	case 34:
		goto loc_8245B8EC;
	case 35:
		goto loc_8245B8F8;
	case 36:
		goto loc_8245B904;
	case 37:
		goto loc_8245B910;
	case 38:
		goto loc_8245B988;
	case 39:
		goto loc_8245B8D4;
	case 40:
		goto loc_8245B988;
	case 41:
		goto loc_8245B988;
	case 42:
		goto loc_8245B91C;
	case 43:
		goto loc_8245B928;
	case 44:
		goto loc_8245B934;
	case 45:
		goto loc_8245B940;
	case 46:
		goto loc_8245B94C;
	case 47:
		goto loc_8245B958;
	case 48:
		goto loc_8245B988;
	case 49:
		goto loc_8245B988;
	case 50:
		goto loc_8245B988;
	case 51:
		goto loc_8245B964;
	case 52:
		goto loc_8245B970;
	case 53:
		goto loc_8245B97C;
	default:
		__builtin_unreachable();
	}
loc_8245B7C0:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r7,r11,-24640
	ctx.r7.s64 = r11.s64 + -24640;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B7CC:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r7,r11,25892
	ctx.r7.s64 = r11.s64 + 25892;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B7D8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-22936
	ctx.r7.s64 = r11.s64 + -22936;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B7E4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r7,r11,-28056
	ctx.r7.s64 = r11.s64 + -28056;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B7F0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-22944
	ctx.r7.s64 = r11.s64 + -22944;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B7FC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r7,r11,-28064
	ctx.r7.s64 = r11.s64 + -28064;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B808:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-22956
	ctx.r7.s64 = r11.s64 + -22956;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B814:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-22968
	ctx.r7.s64 = r11.s64 + -22968;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B820:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-22984
	ctx.r7.s64 = r11.s64 + -22984;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B82C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-22996
	ctx.r7.s64 = r11.s64 + -22996;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B838:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23008
	ctx.r7.s64 = r11.s64 + -23008;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B844:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23024
	ctx.r7.s64 = r11.s64 + -23024;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B850:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r7,r11,-28652
	ctx.r7.s64 = r11.s64 + -28652;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B85C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r7,r11,-18396
	ctx.r7.s64 = r11.s64 + -18396;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B868:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r7,r11,27080
	ctx.r7.s64 = r11.s64 + 27080;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B874:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23036
	ctx.r7.s64 = r11.s64 + -23036;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B880:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23048
	ctx.r7.s64 = r11.s64 + -23048;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B88C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23060
	ctx.r7.s64 = r11.s64 + -23060;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B898:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23072
	ctx.r7.s64 = r11.s64 + -23072;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B8A4:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23088
	ctx.r7.s64 = r11.s64 + -23088;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B8B0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23104
	ctx.r7.s64 = r11.s64 + -23104;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B8BC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23116
	ctx.r7.s64 = r11.s64 + -23116;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B8C8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23136
	ctx.r7.s64 = r11.s64 + -23136;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B8D4:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23144
	ctx.r7.s64 = r11.s64 + -23144;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B8E0:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r7,r11,-18344
	ctx.r7.s64 = r11.s64 + -18344;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B8EC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23156
	ctx.r7.s64 = r11.s64 + -23156;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B8F8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23168
	ctx.r7.s64 = r11.s64 + -23168;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B904:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23180
	ctx.r7.s64 = r11.s64 + -23180;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B910:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23192
	ctx.r7.s64 = r11.s64 + -23192;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B91C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r7,r11,-18504
	ctx.r7.s64 = r11.s64 + -18504;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B928:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r7,r11,-18520
	ctx.r7.s64 = r11.s64 + -18520;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B934:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23208
	ctx.r7.s64 = r11.s64 + -23208;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B940:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23224
	ctx.r7.s64 = r11.s64 + -23224;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B94C:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r7,r11,-18552
	ctx.r7.s64 = r11.s64 + -18552;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B958:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23236
	ctx.r7.s64 = r11.s64 + -23236;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B964:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23248
	ctx.r7.s64 = r11.s64 + -23248;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B970:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23260
	ctx.r7.s64 = r11.s64 + -23260;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B97C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r7,r11,-23276
	ctx.r7.s64 = r11.s64 + -23276;
	// b 0x8245b990
	goto loc_8245B990;
loc_8245B988:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r7,r11,27144
	ctx.r7.s64 = r11.s64 + 27144;
loc_8245B990:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r4,255
	ctx.r4.s64 = 255;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8245b9d0
	if (cr6.eq) goto loc_8245B9D0;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x8245b9b8
	if (cr6.eq) goto loc_8245B9B8;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r5,r11,26560
	ctx.r5.s64 = r11.s64 + 26560;
	// b 0x8245bacc
	goto loc_8245BACC;
loc_8245B9B8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r8,28(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// addi r5,r11,-23288
	ctx.r5.s64 = r11.s64 + -23288;
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
	// b 0x8245bad0
	goto loc_8245BAD0;
loc_8245B9D0:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r8,32(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// addi r5,r11,20252
	ctx.r5.s64 = r11.s64 + 20252;
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
	// b 0x8245bad0
	goto loc_8245BAD0;
loc_8245B9E4:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// b 0x8245b9f8
	goto loc_8245B9F8;
loc_8245B9F0:
	// lwz r6,16(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// lwz r11,4(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
loc_8245B9F8:
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x8245b9f0
	if (cr6.eq) goto loc_8245B9F0;
	// li r5,255
	ctx.r5.s64 = 255;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245b700
	sub_8245B700(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x8245bad0
	if (!cr6.eq) goto loc_8245BAD0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r28,r11,-23296
	r28.s64 = r11.s64 + -23296;
loc_8245BA28:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r6,20(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// add r29,r31,r11
	r29.u64 = r31.u64 + r11.u64;
	// subfic r4,r31,255
	xer.ca = r31.u32 <= 255;
	ctx.r4.s64 = 255 - r31.s64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8245BA4C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8245ba4c
	if (!cr6.eq) goto loc_8245BA4C;
	// lwz r30,16(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// cmpwi cr6,r10,8
	cr6.compare<int32_t>(ctx.r10.s32, 8, xer);
	// beq cr6,0x8245ba28
	if (cr6.eq) goto loc_8245BA28;
	// b 0x8245bad0
	goto loc_8245BAD0;
loc_8245BA80:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245baa0
	if (cr0.eq) goto loc_8245BAA0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r31,r11,-28200
	r31.s64 = r11.s64 + -28200;
	// b 0x8245baa8
	goto loc_8245BAA8;
loc_8245BAA0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r31,r11,9120
	r31.s64 = r11.s64 + 9120;
loc_8245BAA8:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// addi r5,r11,-23312
	ctx.r5.s64 = r11.s64 + -23312;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,255
	ctx.r4.s64 = 255;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
loc_8245BACC:
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
loc_8245BAD0:
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8245BAD8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8245bad8
	if (!cr6.eq) goto loc_8245BAD8;
	// subf r10,r10,r11
	ctx.r10.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r27,-1
	r11.s64 = r27.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rotlwi r31,r10,0
	r31.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// ble cr6,0x8245bb04
	if (!cr6.gt) goto loc_8245BB04;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_8245BB04:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stbx r11,r31,r25
	PPC_STORE_U8(r31.u32 + r25.u32, r11.u8);
loc_8245BB20:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_8245BB28"))) PPC_WEAK_FUNC(sub_8245BB28);
PPC_FUNC_IMPL(__imp__sub_8245BB28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// b 0x8245bbd4
	goto loc_8245BBD4;
loc_8245BB48:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8245bbb0
	if (cr6.eq) goto loc_8245BBB0;
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x8245bba8
	if (cr6.eq) goto loc_8245BBA8;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x8245bb7c
	if (cr6.eq) goto loc_8245BB7C;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x8245bc0c
	if (cr6.eq) goto loc_8245BC0C;
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x8245bbec
	if (!cr6.eq) goto loc_8245BBEC;
	// lwz r31,48(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// b 0x8245bbd4
	goto loc_8245BBD4;
loc_8245BB7C:
	// lwz r31,16(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245bbdc
	if (cr0.eq) goto loc_8245BBDC;
	// divwu r11,r30,r3
	r11.u32 = r30.u32 / ctx.r3.u32;
	// twllei r3,0
	// mullw r11,r11,r3
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r3.s32);
	// subf r30,r11,r30
	r30.s64 = r30.s64 - r11.s64;
	// b 0x8245bbd4
	goto loc_8245BBD4;
loc_8245BBA8:
	// lwz r31,24(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// b 0x8245bbd4
	goto loc_8245BBD4;
loc_8245BBB0:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// cmplw cr6,r30,r3
	cr6.compare<uint32_t>(r30.u32, ctx.r3.u32, xer);
	// bge cr6,0x8245bbcc
	if (!cr6.lt) goto loc_8245BBCC;
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// b 0x8245bbd4
	goto loc_8245BBD4;
loc_8245BBCC:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// subf r30,r3,r30
	r30.s64 = r30.s64 - ctx.r3.s64;
loc_8245BBD4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8245bb48
	if (!cr6.eq) goto loc_8245BB48;
loc_8245BBDC:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8245BBE4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd48
	return;
loc_8245BBEC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,31668
	ctx.r6.s64 = r11.s64 + 31668;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245bbe4
	goto loc_8245BBE4;
loc_8245BC0C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8245bc30
	if (cr6.lt) goto loc_8245BC30;
	// beq cr6,0x8245bc30
	if (cr6.eq) goto loc_8245BC30;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x8245bc30
	if (cr6.lt) goto loc_8245BC30;
	// bne cr6,0x8245bc38
	if (!cr6.eq) goto loc_8245BC38;
	// li r11,3
	r11.s64 = 3;
	// b 0x8245bc34
	goto loc_8245BC34;
loc_8245BC30:
	// li r11,0
	r11.s64 = 0;
loc_8245BC34:
	// stw r11,16(r28)
	PPC_STORE_U32(r28.u32 + 16, r11.u32);
loc_8245BC38:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r11,1
	r11.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,28(r28)
	PPC_STORE_U32(r28.u32 + 28, r11.u32);
	// stw r11,32(r28)
	PPC_STORE_U32(r28.u32 + 32, r11.u32);
	// stw r10,20(r28)
	PPC_STORE_U32(r28.u32 + 20, ctx.r10.u32);
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// stw r11,36(r28)
	PPC_STORE_U32(r28.u32 + 36, r11.u32);
	// b 0x8245bbe4
	goto loc_8245BBE4;
}

__attribute__((alias("__imp__sub_8245BC60"))) PPC_WEAK_FUNC(sub_8245BC60);
PPC_FUNC_IMPL(__imp__sub_8245BC60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// andis. r11,r11,528
	r11.u64 = r11.u64 & 34603008;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8245bcac
	if (cr0.eq) goto loc_8245BCAC;
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// b 0x8245bca4
	goto loc_8245BCA4;
loc_8245BC84:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x8245bcc0
	if (cr6.eq) goto loc_8245BCC0;
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beq cr6,0x8245bcc0
	if (cr6.eq) goto loc_8245BCC0;
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// beq cr6,0x8245bcc0
	if (cr6.eq) goto loc_8245BCC0;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
loc_8245BCA4:
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8245bc84
	if (!cr0.eq) goto loc_8245BC84;
loc_8245BCAC:
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
loc_8245BCB0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_8245BCC0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3064
	ctx.r5.s64 = 3064;
	// addi r6,r11,-22928
	ctx.r6.s64 = r11.s64 + -22928;
	// addi r4,r3,40
	ctx.r4.s64 = ctx.r3.s64 + 40;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245bcb0
	goto loc_8245BCB0;
}

__attribute__((alias("__imp__sub_8245BCDC"))) PPC_WEAK_FUNC(sub_8245BCDC);
PPC_FUNC_IMPL(__imp__sub_8245BCDC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245BCE0"))) PPC_WEAK_FUNC(sub_8245BCE0);
PPC_FUNC_IMPL(__imp__sub_8245BCE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcdc
	// addi r12,r1,-96
	r12.s64 = ctx.r1.s64 + -96;
	// bl 0x8239d5e0
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x8245bd18
	if (!cr6.eq) goto loc_8245BD18;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x8245d2d0
	if (!cr6.eq) goto loc_8245D2D0;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245d2d8
	goto loc_8245D2D8;
loc_8245BD18:
	// lwz r11,4(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8245d2d0
	if (!cr6.eq) goto loc_8245D2D0;
	// lwz r10,28(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// lwz r11,20(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 20);
	// cmpwi cr6,r10,32
	cr6.compare<int32_t>(ctx.r10.s32, 32, xer);
	// lwz r10,24(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// mullw r25,r11,r10
	r25.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// bne cr6,0x8245d2d0
	if (!cr6.eq) goto loc_8245D2D0;
	// lwz r22,36(r23)
	r22.u64 = PPC_LOAD_U32(r23.u32 + 36);
	// li r24,0
	r24.s64 = 0;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r27,8(r22)
	r27.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// std r24,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r24.u64);
	// std r24,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r24.u64);
	// cmplwi r27,0
	cr0.compare<uint32_t>(r27.u32, 0, xer);
	// std r24,0(r9)
	PPC_STORE_U64(ctx.r9.u32 + 0, r24.u64);
	// std r24,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r24.u64);
	// std r24,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r24.u64);
	// std r24,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, r24.u64);
	// beq 0x8245be3c
	if (cr0.eq) goto loc_8245BE3C;
	// mr r29,r24
	r29.u64 = r24.u64;
loc_8245BD78:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8245be2c
	if (cr0.eq) goto loc_8245BE2C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x8245be2c
	if (!cr6.eq) goto loc_8245BE2C;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// addi r31,r1,96
	r31.s64 = ctx.r1.s64 + 96;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// addi r28,r1,112
	r28.s64 = ctx.r1.s64 + 112;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// stwx r11,r29,r31
	PPC_STORE_U32(r29.u32 + r31.u32, r11.u32);
	// stwx r10,r29,r28
	PPC_STORE_U32(r29.u32 + r28.u32, ctx.r10.u32);
	// rlwinm r3,r10,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stwx r30,r29,r11
	PPC_STORE_U32(r29.u32 + r11.u32, r30.u32);
	// beq 0x8245be78
	if (cr0.eq) goto loc_8245BE78;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwzx r4,r29,r31
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + r31.u32);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8245ffa0
	sub_8245FFA0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x8245d2a8
	if (cr0.lt) goto loc_8245D2A8;
	// lwzx r11,r29,r28
	r11.u64 = PPC_LOAD_U32(r29.u32 + r28.u32);
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245be2c
	if (!cr6.gt) goto loc_8245BE2C;
	// addi r6,r23,48
	ctx.r6.s64 = r23.s64 + 48;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r30,8
	ctx.r4.s64 = r30.s64 + 8;
loc_8245BDFC:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82459a90
	sub_82459A90(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x8245d2a8
	if (cr0.lt) goto loc_8245D2A8;
	// li r11,3
	r11.s64 = 3;
	// lwzx r9,r29,r28
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + r28.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// addi r5,r5,16
	ctx.r5.s64 = ctx.r5.s64 + 16;
	// blt cr6,0x8245bdfc
	if (cr6.lt) goto loc_8245BDFC;
loc_8245BE2C:
	// lwz r27,12(r27)
	r27.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi r27,0
	cr0.compare<uint32_t>(r27.u32, 0, xer);
	// bne 0x8245bd78
	if (!cr0.eq) goto loc_8245BD78;
loc_8245BE3C:
	// lwz r11,32(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,134
	cr6.compare<uint32_t>(r11.u32, 134, xer);
	// bgt cr6,0x8245d2a0
	if (cr6.gt) goto loc_8245D2A0;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-26416
	r12.s64 = r12.s64 + -26416;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,-16776
	r12.s64 = r12.s64 + -16776;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8245BE84;
	case 1:
		goto loc_8245BEB8;
	case 2:
		goto loc_8245BF10;
	case 3:
		goto loc_8245BF58;
	case 4:
		goto loc_8245BFA8;
	case 5:
		goto loc_8245C000;
	case 6:
		goto loc_8245C034;
	case 7:
		goto loc_8245C074;
	case 8:
		goto loc_8245C0A8;
	case 9:
		goto loc_8245D2A0;
	case 10:
		goto loc_8245C108;
	case 11:
		goto loc_8245C13C;
	case 12:
		goto loc_8245C170;
	case 13:
		goto loc_8245C1D0;
	case 14:
		goto loc_8245C1FC;
	case 15:
		goto loc_8245C228;
	case 16:
		goto loc_8245C264;
	case 17:
		goto loc_8245D2A0;
	case 18:
		goto loc_8245C3C0;
	case 19:
		goto loc_8245C408;
	case 20:
		goto loc_8245C454;
	case 21:
		goto loc_8245C488;
	case 22:
		goto loc_8245C4BC;
	case 23:
		goto loc_8245C4FC;
	case 24:
		goto loc_8245C578;
	case 25:
		goto loc_8245C5AC;
	case 26:
		goto loc_8245C5EC;
	case 27:
		goto loc_8245D2A0;
	case 28:
		goto loc_8245C648;
	case 29:
		goto loc_8245C674;
	case 30:
		goto loc_8245C6CC;
	case 31:
		goto loc_8245C724;
	case 32:
		goto loc_8245C77C;
	case 33:
		goto loc_8245C7CC;
	case 34:
		goto loc_8245C800;
	case 35:
		goto loc_8245C854;
	case 36:
		goto loc_8245D2A0;
	case 37:
		goto loc_8245C8AC;
	case 38:
		goto loc_8245C8F4;
	case 39:
		goto loc_8245C954;
	case 40:
		goto loc_8245C9B4;
	case 41:
		goto loc_8245C9FC;
	case 42:
		goto loc_8245D2A0;
	case 43:
		goto loc_8245CA44;
	case 44:
		goto loc_8245CA44;
	case 45:
		goto loc_8245CA44;
	case 46:
		goto loc_8245CA80;
	case 47:
		goto loc_8245CABC;
	case 48:
		goto loc_8245CABC;
	case 49:
		goto loc_8245CA80;
	case 50:
		goto loc_8245CABC;
	case 51:
		goto loc_8245CABC;
	case 52:
		goto loc_8245D2A0;
	case 53:
		goto loc_8245CBA0;
	case 54:
		goto loc_8245CC24;
	case 55:
		goto loc_8245CC7C;
	case 56:
		goto loc_8245D2A0;
	case 57:
		goto loc_8245D2A0;
	case 58:
		goto loc_8245D2A0;
	case 59:
		goto loc_8245CCB8;
	case 60:
		goto loc_8245CD38;
	case 61:
		goto loc_8245CE04;
	case 62:
		goto loc_8245CE44;
	case 63:
		goto loc_8245CEA0;
	case 64:
		goto loc_8245CF00;
	case 65:
		goto loc_8245CF68;
	case 66:
		goto loc_8245D2A0;
	case 67:
		goto loc_8245CF9C;
	case 68:
		goto loc_8245CFD0;
	case 69:
		goto loc_8245D078;
	case 70:
		goto loc_8245D0C0;
	case 71:
		goto loc_8245D120;
	case 72:
		goto loc_8245D154;
	case 73:
		goto loc_8245D2A0;
	case 74:
		goto loc_8245D2A0;
	case 75:
		goto loc_8245D2A0;
	case 76:
		goto loc_8245D2A0;
	case 77:
		goto loc_8245D2A0;
	case 78:
		goto loc_8245D2A0;
	case 79:
		goto loc_8245D2A0;
	case 80:
		goto loc_8245D2A0;
	case 81:
		goto loc_8245D2A0;
	case 82:
		goto loc_8245D2A0;
	case 83:
		goto loc_8245D2A0;
	case 84:
		goto loc_8245D2A0;
	case 85:
		goto loc_8245D2A0;
	case 86:
		goto loc_8245D2A0;
	case 87:
		goto loc_8245D2A0;
	case 88:
		goto loc_8245D2A0;
	case 89:
		goto loc_8245D2A0;
	case 90:
		goto loc_8245D2A0;
	case 91:
		goto loc_8245D2A0;
	case 92:
		goto loc_8245D2A0;
	case 93:
		goto loc_8245D2A0;
	case 94:
		goto loc_8245D2A0;
	case 95:
		goto loc_8245D2A0;
	case 96:
		goto loc_8245D2A0;
	case 97:
		goto loc_8245D2A0;
	case 98:
		goto loc_8245D2A0;
	case 99:
		goto loc_8245D2A0;
	case 100:
		goto loc_8245D2A0;
	case 101:
		goto loc_8245D2A0;
	case 102:
		goto loc_8245D2A0;
	case 103:
		goto loc_8245D2A0;
	case 104:
		goto loc_8245D2A0;
	case 105:
		goto loc_8245D2A0;
	case 106:
		goto loc_8245D2A0;
	case 107:
		goto loc_8245D2A0;
	case 108:
		goto loc_8245D2A0;
	case 109:
		goto loc_8245D2A0;
	case 110:
		goto loc_8245D2A0;
	case 111:
		goto loc_8245D2A0;
	case 112:
		goto loc_8245D2A0;
	case 113:
		goto loc_8245D2A0;
	case 114:
		goto loc_8245D2A0;
	case 115:
		goto loc_8245D2A0;
	case 116:
		goto loc_8245D2A0;
	case 117:
		goto loc_8245D2A0;
	case 118:
		goto loc_8245D2A0;
	case 119:
		goto loc_8245D2A0;
	case 120:
		goto loc_8245D2A0;
	case 121:
		goto loc_8245D2A0;
	case 122:
		goto loc_8245D2A0;
	case 123:
		goto loc_8245D2A0;
	case 124:
		goto loc_8245D2A0;
	case 125:
		goto loc_8245D2A0;
	case 126:
		goto loc_8245D2A0;
	case 127:
		goto loc_8245D2A0;
	case 128:
		goto loc_8245D2A0;
	case 129:
		goto loc_8245D2A0;
	case 130:
		goto loc_8245D2A0;
	case 131:
		goto loc_8245D2A0;
	case 132:
		goto loc_8245D188;
	case 133:
		goto loc_8245D2A0;
	case 134:
		goto loc_8245D204;
	default:
		__builtin_unreachable();
	}
loc_8245BE78:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x8245d2a8
	goto loc_8245D2A8;
loc_8245BE84:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r26,8
	r11.s64 = r26.s64 + 8;
	// subf r9,r26,r10
	ctx.r9.s64 = ctx.r10.s64 - r26.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245BE9C:
	// lfdx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// fabs f0,f0
	f0.u64 = f0.u64 & ~0x8000000000000000;
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245be9c
	if (!cr0.eq) goto loc_8245BE9C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245BEB8:
	// mr r30,r24
	r30.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r26
	r29.s64 = r26.s64 - r11.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f30,-31360(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// lfd f31,-30984(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -30984);
loc_8245BEE0:
	// lfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// blt cr6,0x8245d2a0
	if (cr6.lt) goto loc_8245D2A0;
	// fcmpu cr6,f1,f30
	cr6.compare(ctx.f1.f64, f30.f64);
	// bgt cr6,0x8245d2a0
	if (cr6.gt) goto loc_8245D2A0;
	// bl 0x8239ddb8
	sub_8239DDB8(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stfdx f1,r29,r31
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r29.u32 + r31.u32, ctx.f1.u64);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// blt cr6,0x8245bee0
	if (cr6.lt) goto loc_8245BEE0;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245BF10:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// mr r11,r24
	r11.u64 = r24.u64;
	// stfd f0,8(r26)
	PPC_STORE_U64(r26.u32 + 8, f0.u64);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// lfd f0,-31368(r9)
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + -31368);
loc_8245BF38:
	// lfd f13,0(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// beq cr6,0x8245bfa0
	if (cr6.eq) goto loc_8245BFA0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// blt cr6,0x8245bf38
	if (cr6.lt) goto loc_8245BF38;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245BF58:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lfd f0,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// mr r11,r24
	r11.u64 = r24.u64;
	// stfd f0,8(r26)
	PPC_STORE_U64(r26.u32 + 8, f0.u64);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
loc_8245BF78:
	// lfd f13,0(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x8245bf98
	if (!cr6.eq) goto loc_8245BF98;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// blt cr6,0x8245bf78
	if (cr6.lt) goto loc_8245BF78;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245BF98:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_8245BFA0:
	// stfd f0,8(r26)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r26.u32 + 8, f0.u64);
	// b 0x8245d240
	goto loc_8245D240;
loc_8245BFA8:
	// mr r30,r24
	r30.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r26
	r29.s64 = r26.s64 - r11.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f30,-31360(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// lfd f31,-30984(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -30984);
loc_8245BFD0:
	// lfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// blt cr6,0x8245d2a0
	if (cr6.lt) goto loc_8245D2A0;
	// fcmpu cr6,f1,f30
	cr6.compare(ctx.f1.f64, f30.f64);
	// bgt cr6,0x8245d2a0
	if (cr6.gt) goto loc_8245D2A0;
	// bl 0x8239dcf0
	sub_8239DCF0(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + r29.u32, ctx.f1.u64);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// blt cr6,0x8245bfd0
	if (cr6.lt) goto loc_8245BFD0;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C000:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245C018:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x8239df68
	sub_8239DF68(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c018
	if (!cr0.eq) goto loc_8245C018;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C034:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r30,r25
	r30.u64 = r25.u64;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r10
	r29.s64 = ctx.r10.s64 - r11.s64;
	// subf r28,r11,r26
	r28.s64 = r26.s64 - r11.s64;
loc_8245C054:
	// lfdx f2,r29,r31
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r29.u32 + r31.u32);
	// lfd f1,0(r31)
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// bl 0x8239e050
	sub_8239E050(ctx, base);
	// stfdx f1,r31,r28
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + r28.u32, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c054
	if (!cr0.eq) goto loc_8245C054;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C074:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245C08C:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x8239e180
	sub_8239E180(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c08c
	if (!cr0.eq) goto loc_8245C08C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C0A8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// subf r7,r11,r9
	ctx.r7.s64 = ctx.r9.s64 - r11.s64;
	// subf r11,r11,r26
	r11.s64 = r26.s64 - r11.s64;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
loc_8245C0D0:
	// lfdx f0,r7,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + ctx.r10.u32);
	// lfdx f13,r8,r10
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r10.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x8245c0ec
	if (cr6.lt) goto loc_8245C0EC;
	// lfd f13,0(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x8245c0f4
	if (!cr6.gt) goto loc_8245C0F4;
loc_8245C0EC:
	// stfdx f13,r11,r10
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + ctx.r10.u32, ctx.f13.u64);
	// b 0x8245c0f8
	goto loc_8245C0F8;
loc_8245C0F4:
	// stfdx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + ctx.r10.u32, f0.u64);
loc_8245C0F8:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245c0d0
	if (!cr0.eq) goto loc_8245C0D0;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C108:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245C120:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x8239de90
	sub_8239DE90(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c120
	if (!cr0.eq) goto loc_8245C120;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C13C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245C154:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x826a7818
	sub_826A7818(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c154
	if (!cr0.eq) goto loc_8245C154;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C170:
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfd f0,24(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// lfd f13,40(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 40);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// lfd f12,24(r10)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// lfd f13,40(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// fmsub f0,f12,f13,f0
	f0.f64 = ctx.f12.f64 * ctx.f13.f64 - f0.f64;
	// stfd f0,8(r26)
	PPC_STORE_U64(r26.u32 + 8, f0.u64);
	// lfd f13,40(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// lfd f0,8(r10)
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 8);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// lfd f12,40(r10)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + 40);
	// lfd f13,8(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// fmsub f0,f13,f12,f0
	f0.f64 = ctx.f13.f64 * ctx.f12.f64 - f0.f64;
	// stfd f0,24(r26)
	PPC_STORE_U64(r26.u32 + 24, f0.u64);
	// lfd f13,24(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// lfd f0,8(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// lfd f12,8(r10)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + 8);
	// lfd f13,24(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// fmsub f0,f13,f12,f0
	f0.f64 = ctx.f13.f64 * ctx.f12.f64 - f0.f64;
	// stfd f0,40(r26)
	PPC_STORE_U64(r26.u32 + 40, f0.u64);
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C1D0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r10,r26,8
	ctx.r10.s64 = r26.s64 + 8;
	// mr r11,r25
	r11.u64 = r25.u64;
	// lfd f0,-31368(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + -31368);
loc_8245C1E8:
	// stfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + 0, f0.u64);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245c1e8
	if (!cr0.eq) goto loc_8245C1E8;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C1FC:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r10,r26,8
	ctx.r10.s64 = r26.s64 + 8;
	// mr r11,r25
	r11.u64 = r25.u64;
	// lfd f0,-31368(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + -31368);
loc_8245C214:
	// stfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + 0, f0.u64);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245c214
	if (!cr0.eq) goto loc_8245C214;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C228:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r26,8
	r11.s64 = r26.s64 + 8;
	// subf r9,r26,r10
	ctx.r9.s64 = ctx.r10.s64 - r26.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// lfd f0,32136(r8)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + 32136);
loc_8245C248:
	// lfdx f13,r11,r9
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// fmul f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 * f0.f64;
	// stfd f13,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.f13.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245c248
	if (!cr0.eq) goto loc_8245C248;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C264:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8245c3b4
	if (cr6.eq) goto loc_8245C3B4;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x8245c394
	if (cr6.eq) goto loc_8245C394;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x8245c344
	if (cr6.eq) goto loc_8245C344;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x8245d2a0
	if (!cr6.eq) goto loc_8245D2A0;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfd f11,184(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(r11.u32 + 184);
	// lfd f12,232(r11)
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 232);
	// lfd f9,200(r11)
	ctx.f9.u64 = PPC_LOAD_U64(r11.u32 + 200);
	// fmul f2,f11,f12
	ctx.f2.f64 = ctx.f11.f64 * ctx.f12.f64;
	// fmul f28,f9,f11
	f28.f64 = ctx.f9.f64 * ctx.f11.f64;
	// lfd f13,168(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 168);
	// lfd f7,216(r11)
	ctx.f7.u64 = PPC_LOAD_U64(r11.u32 + 216);
	// fmul f26,f9,f13
	f26.f64 = ctx.f9.f64 * ctx.f13.f64;
	// lfd f8,152(r11)
	ctx.f8.u64 = PPC_LOAD_U64(r11.u32 + 152);
	// fmul f27,f7,f11
	f27.f64 = ctx.f7.f64 * ctx.f11.f64;
	// lfd f0,248(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 248);
	// fmul f9,f9,f8
	ctx.f9.f64 = ctx.f9.f64 * ctx.f8.f64;
	// lfd f10,136(r11)
	ctx.f10.u64 = PPC_LOAD_U64(r11.u32 + 136);
	// lfd f6,104(r11)
	ctx.f6.u64 = PPC_LOAD_U64(r11.u32 + 104);
	// lfd f5,72(r11)
	ctx.f5.u64 = PPC_LOAD_U64(r11.u32 + 72);
	// lfd f4,88(r11)
	ctx.f4.u64 = PPC_LOAD_U64(r11.u32 + 88);
	// lfd f3,120(r11)
	ctx.f3.u64 = PPC_LOAD_U64(r11.u32 + 120);
	// fmsub f11,f13,f0,f2
	ctx.f11.f64 = ctx.f13.f64 * f0.f64 - ctx.f2.f64;
	// lfd f1,24(r11)
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// fmsub f2,f10,f0,f28
	ctx.f2.f64 = ctx.f10.f64 * f0.f64 - f28.f64;
	// lfd f31,8(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// fmul f28,f7,f13
	f28.f64 = ctx.f7.f64 * ctx.f13.f64;
	// lfd f30,40(r11)
	f30.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// fmsub f13,f10,f12,f26
	ctx.f13.f64 = ctx.f10.f64 * ctx.f12.f64 - f26.f64;
	// lfd f29,56(r11)
	f29.u64 = PPC_LOAD_U64(r11.u32 + 56);
	// fmsub f10,f10,f7,f9
	ctx.f10.f64 = ctx.f10.f64 * ctx.f7.f64 - ctx.f9.f64;
	// fmsub f0,f8,f0,f27
	f0.f64 = ctx.f8.f64 * f0.f64 - f27.f64;
	// fmul f9,f2,f6
	ctx.f9.f64 = ctx.f2.f64 * ctx.f6.f64;
	// fmsub f12,f8,f12,f28
	ctx.f12.f64 = ctx.f8.f64 * ctx.f12.f64 - f28.f64;
	// fmul f8,f2,f4
	ctx.f8.f64 = ctx.f2.f64 * ctx.f4.f64;
	// fmul f2,f13,f4
	ctx.f2.f64 = ctx.f13.f64 * ctx.f4.f64;
	// fmul f7,f6,f0
	ctx.f7.f64 = ctx.f6.f64 * f0.f64;
	// fmsub f9,f5,f11,f9
	ctx.f9.f64 = ctx.f5.f64 * ctx.f11.f64 - ctx.f9.f64;
	// fmsub f0,f5,f0,f8
	f0.f64 = ctx.f5.f64 * f0.f64 - ctx.f8.f64;
	// fmsub f11,f4,f11,f7
	ctx.f11.f64 = ctx.f4.f64 * ctx.f11.f64 - ctx.f7.f64;
	// fmadd f13,f13,f3,f9
	ctx.f13.f64 = ctx.f13.f64 * ctx.f3.f64 + ctx.f9.f64;
	// fmsub f9,f5,f12,f2
	ctx.f9.f64 = ctx.f5.f64 * ctx.f12.f64 - ctx.f2.f64;
	// fmadd f0,f10,f3,f0
	f0.f64 = ctx.f10.f64 * ctx.f3.f64 + f0.f64;
	// fmadd f12,f3,f12,f11
	ctx.f12.f64 = ctx.f3.f64 * ctx.f12.f64 + ctx.f11.f64;
	// fmul f13,f13,f1
	ctx.f13.f64 = ctx.f13.f64 * ctx.f1.f64;
	// fmadd f11,f10,f6,f9
	ctx.f11.f64 = ctx.f10.f64 * ctx.f6.f64 + ctx.f9.f64;
	// fmsub f13,f12,f31,f13
	ctx.f13.f64 = ctx.f12.f64 * f31.f64 - ctx.f13.f64;
	// fmadd f0,f0,f30,f13
	f0.f64 = f0.f64 * f30.f64 + ctx.f13.f64;
	// fnmsub f0,f11,f29,f0
	f0.f64 = -(ctx.f11.f64 * f29.f64 - f0.f64);
	// b 0x8245bfa0
	goto loc_8245BFA0;
loc_8245C344:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfd f13,88(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 88);
	// lfd f11,104(r11)
	ctx.f11.u64 = PPC_LOAD_U64(r11.u32 + 104);
	// fmul f5,f11,f13
	ctx.f5.f64 = ctx.f11.f64 * ctx.f13.f64;
	// lfd f9,120(r11)
	ctx.f9.u64 = PPC_LOAD_U64(r11.u32 + 120);
	// lfd f10,72(r11)
	ctx.f10.u64 = PPC_LOAD_U64(r11.u32 + 72);
	// fmul f13,f13,f9
	ctx.f13.f64 = ctx.f13.f64 * ctx.f9.f64;
	// lfd f12,56(r11)
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 56);
	// fmul f11,f11,f10
	ctx.f11.f64 = ctx.f11.f64 * ctx.f10.f64;
	// lfd f0,136(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 136);
	// lfd f8,24(r11)
	ctx.f8.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// lfd f7,8(r11)
	ctx.f7.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// lfd f6,40(r11)
	ctx.f6.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// fmsub f5,f12,f0,f5
	ctx.f5.f64 = ctx.f12.f64 * f0.f64 - ctx.f5.f64;
	// fmsub f0,f10,f0,f13
	f0.f64 = ctx.f10.f64 * f0.f64 - ctx.f13.f64;
	// fmsub f13,f12,f9,f11
	ctx.f13.f64 = ctx.f12.f64 * ctx.f9.f64 - ctx.f11.f64;
	// fmul f12,f5,f8
	ctx.f12.f64 = ctx.f5.f64 * ctx.f8.f64;
	// fmsub f0,f0,f7,f12
	f0.f64 = f0.f64 * ctx.f7.f64 - ctx.f12.f64;
	// fmadd f0,f13,f6,f0
	f0.f64 = ctx.f13.f64 * ctx.f6.f64 + f0.f64;
	// b 0x8245bfa0
	goto loc_8245BFA0;
loc_8245C394:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfd f13,24(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// lfd f0,40(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// lfd f12,8(r11)
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// lfd f13,56(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 56);
	// fmsub f0,f13,f12,f0
	f0.f64 = ctx.f13.f64 * ctx.f12.f64 - f0.f64;
	// b 0x8245bfa0
	goto loc_8245BFA0;
loc_8245C3B4:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfd f0,8(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// b 0x8245bfa0
	goto loc_8245BFA0;
loc_8245C3C0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lfd f13,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// beq cr6,0x8245c400
	if (cr6.eq) goto loc_8245C400;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245C3E4:
	// lfdx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lfd f12,0(r11)
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// fsub f0,f0,f12
	f0.f64 = f0.f64 - ctx.f12.f64;
	// fmadd f13,f0,f0,f13
	ctx.f13.f64 = f0.f64 * f0.f64 + ctx.f13.f64;
	// bne 0x8245c3e4
	if (!cr0.eq) goto loc_8245C3E4;
loc_8245C400:
	// fsqrt f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = sqrt(ctx.f13.f64);
	// b 0x8245bfa0
	goto loc_8245BFA0;
loc_8245C408:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lfd f0,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// stfd f0,8(r26)
	PPC_STORE_U64(r26.u32 + 8, f0.u64);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r9,8
	r11.s64 = ctx.r9.s64 + 8;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_8245C430:
	// lfdx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lfd f13,0(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// lfd f12,8(r26)
	ctx.f12.u64 = PPC_LOAD_U64(r26.u32 + 8);
	// fmadd f0,f0,f13,f12
	f0.f64 = f0.f64 * ctx.f13.f64 + ctx.f12.f64;
	// stfd f0,8(r26)
	PPC_STORE_U64(r26.u32 + 8, f0.u64);
	// bne 0x8245c430
	if (!cr0.eq) goto loc_8245C430;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C454:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfd f0,-31360(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f0,8(r26)
	PPC_STORE_U64(r26.u32 + 8, f0.u64);
	// lfd f13,24(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// lfd f0,24(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// stfd f0,24(r26)
	PPC_STORE_U64(r26.u32 + 24, f0.u64);
	// lfd f0,40(r10)
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 40);
	// stfd f0,40(r26)
	PPC_STORE_U64(r26.u32 + 40, f0.u64);
	// lfd f0,56(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + 56);
	// b 0x8245d23c
	goto loc_8245D23C;
loc_8245C488:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245C4A0:
	// lfdx f1,r29,r31
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r29.u32 + r31.u32);
	// bl 0x823a05b0
	sub_823A05B0(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c4a0
	if (!cr0.eq) goto loc_8245C4A0;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C4BC:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lfd f31,264(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 264);
loc_8245C4DC:
	// lfdx f2,r29,r31
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r29.u32 + r31.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8239e6a0
	sub_8239E6A0(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c4dc
	if (!cr0.eq) goto loc_8245C4DC;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C4FC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lfd f12,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fmr f13,f12
	ctx.f13.f64 = ctx.f12.f64;
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245C524:
	// lfdx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lfd f11,0(r11)
	ctx.f11.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// fmadd f13,f0,f11,f13
	ctx.f13.f64 = f0.f64 * ctx.f11.f64 + ctx.f13.f64;
	// bne 0x8245c524
	if (!cr0.eq) goto loc_8245C524;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// subf r9,r10,r26
	ctx.r9.s64 = r26.s64 - ctx.r10.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245C554:
	// lfd f0,0(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// blt cr6,0x8245c564
	if (cr6.lt) goto loc_8245C564;
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
loc_8245C564:
	// stfdx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r9.u32 + r11.u32, f0.u64);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245c554
	if (!cr0.eq) goto loc_8245C554;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C578:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245C590:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x8239da30
	sub_8239DA30(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c590
	if (!cr0.eq) goto loc_8245C590;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C5AC:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r30,r25
	r30.u64 = r25.u64;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r10
	r29.s64 = ctx.r10.s64 - r11.s64;
	// subf r28,r11,r26
	r28.s64 = r26.s64 - r11.s64;
loc_8245C5CC:
	// lfdx f2,r29,r31
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r29.u32 + r31.u32);
	// lfd f1,0(r31)
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// bl 0x8239da70
	sub_8239DA70(ctx, base);
	// stfdx f1,r31,r28
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + r28.u32, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c5cc
	if (!cr0.eq) goto loc_8245C5CC;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C5EC:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r30,r25
	r30.u64 = r25.u64;
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r26
	r29.s64 = r26.s64 - r11.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_8245C60C:
	// lfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// bl 0x823ae098
	sub_823AE098(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245c634
	if (cr0.eq) goto loc_8245C634;
	// lfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// bl 0x8239da30
	sub_8239DA30(ctx, base);
	// lfd f0,0(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// fsub f0,f0,f1
	f0.f64 = f0.f64 - ctx.f1.f64;
	// stfdx f0,r31,r29
	PPC_STORE_U64(r31.u32 + r29.u32, f0.u64);
	// b 0x8245c638
	goto loc_8245C638;
loc_8245C634:
	// stfdx f31,r31,r29
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + r29.u32, f31.u64);
loc_8245C638:
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c60c
	if (!cr0.eq) goto loc_8245C60C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C648:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r10,r26,8
	ctx.r10.s64 = r26.s64 + 8;
	// mr r11,r25
	r11.u64 = r25.u64;
	// lfd f0,-31368(r9)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + -31368);
loc_8245C660:
	// stfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + 0, f0.u64);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245c660
	if (!cr0.eq) goto loc_8245C660;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C674:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r25
	r30.u64 = r25.u64;
	// lfd f30,-31368(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// lfd f31,-31360(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_8245C69C:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x823ae098
	sub_823AE098(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245c6b4
	if (cr0.eq) goto loc_8245C6B4;
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64;
	// b 0x8245c6b8
	goto loc_8245C6B8;
loc_8245C6B4:
	// fmr f0,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = f30.f64;
loc_8245C6B8:
	// stfd f0,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, f0.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c69c
	if (!cr0.eq) goto loc_8245C69C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C6CC:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r25
	r30.u64 = r25.u64;
	// lfd f30,-31368(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// lfd f31,-31360(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_8245C6F4:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x823ae098
	sub_823AE098(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245c70c
	if (cr0.eq) goto loc_8245C70C;
	// fmr f0,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = f30.f64;
	// b 0x8245c710
	goto loc_8245C710;
loc_8245C70C:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64;
loc_8245C710:
	// stfd f0,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, f0.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c6f4
	if (!cr0.eq) goto loc_8245C6F4;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C724:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r25
	r30.u64 = r25.u64;
	// lfd f30,-31368(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31368);
	// lfd f31,-31360(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_8245C74C:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x823ae0b8
	sub_823AE0B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245c764
	if (cr0.eq) goto loc_8245C764;
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64;
	// b 0x8245c768
	goto loc_8245C768;
loc_8245C764:
	// fmr f0,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = f30.f64;
loc_8245C768:
	// stfd f0,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, f0.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c74c
	if (!cr0.eq) goto loc_8245C74C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C77C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r30,r25
	r30.u64 = r25.u64;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r10
	r29.s64 = ctx.r10.s64 - r11.s64;
	// subf r28,r11,r26
	r28.s64 = r26.s64 - r11.s64;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lfd f31,264(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + 264);
loc_8245C7A4:
	// lfdx f2,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8239e6a0
	sub_8239E6A0(ctx, base);
	// lfd f0,0(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// fmul f0,f1,f0
	f0.f64 = ctx.f1.f64 * f0.f64;
	// stfdx f0,r31,r28
	PPC_STORE_U64(r31.u32 + r28.u32, f0.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245c7a4
	if (!cr0.eq) goto loc_8245C7A4;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C7CC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lfd f13,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// beq cr6,0x8245c400
	if (cr6.eq) goto loc_8245C400;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8245C7E8:
	// lfd f0,0(r10)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// fmadd f13,f0,f0,f13
	ctx.f13.f64 = f0.f64 * f0.f64 + ctx.f13.f64;
	// bne 0x8245c7e8
	if (!cr0.eq) goto loc_8245C7E8;
	// b 0x8245c400
	goto loc_8245C400;
loc_8245C800:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// subf r7,r10,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r10.s64;
	// subf r6,r10,r26
	ctx.r6.s64 = r26.s64 - ctx.r10.s64;
	// subf r8,r9,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r9.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245C828:
	// add r9,r7,r11
	ctx.r9.u64 = ctx.r7.u64 + r11.u64;
	// lfd f0,0(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lfdx f13,r9,r8
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r9.u32 + ctx.r8.u32);
	// fsub f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 - f0.f64;
	// lfd f12,0(r9)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// fmadd f0,f13,f12,f0
	f0.f64 = ctx.f13.f64 * ctx.f12.f64 + f0.f64;
	// stfdx f0,r11,r6
	PPC_STORE_U64(r11.u32 + ctx.r6.u32, f0.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245c828
	if (!cr0.eq) goto loc_8245C828;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C854:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,-31360(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// stfd f13,8(r26)
	PPC_STORE_U64(r26.u32 + 8, ctx.f13.u64);
	// stfd f13,56(r26)
	PPC_STORE_U64(r26.u32 + 56, ctx.f13.u64);
	// lfd f0,-31368(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stfd f0,24(r26)
	PPC_STORE_U64(r26.u32 + 24, f0.u64);
	// stfd f0,40(r26)
	PPC_STORE_U64(r26.u32 + 40, f0.u64);
	// lfd f13,8(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x8245d240
	if (!cr6.gt) goto loc_8245D240;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f13,24(r26)
	PPC_STORE_U64(r26.u32 + 24, ctx.f13.u64);
	// lfd f1,8(r11)
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// ble cr6,0x8245d240
	if (!cr6.gt) goto loc_8245D240;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lfd f2,8(r11)
	ctx.f2.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// bl 0x8239e6a0
	sub_8239E6A0(ctx, base);
	// stfd f1,40(r26)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r26.u32 + 40, ctx.f1.u64);
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C8AC:
	// mr r30,r24
	r30.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r26
	r29.s64 = r26.s64 - r11.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f31,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_8245C8CC:
	// lfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// ble cr6,0x8245d2a0
	if (!cr6.gt) goto loc_8245D2A0;
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + r29.u32, ctx.f1.u64);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// blt cr6,0x8245c8cc
	if (cr6.lt) goto loc_8245C8CC;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C8F4:
	// mr r30,r24
	r30.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r26
	r29.s64 = r26.s64 - r11.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f30,32128(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32128);
	// lfd f31,-31368(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_8245C91C:
	// lfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// ble cr6,0x8245d2a0
	if (!cr6.gt) goto loc_8245D2A0;
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = ctx.f1.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// fdiv f0,f29,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = f29.f64 / ctx.f1.f64;
	// stfdx f0,r31,r29
	PPC_STORE_U64(r31.u32 + r29.u32, f0.u64);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// blt cr6,0x8245c91c
	if (cr6.lt) goto loc_8245C91C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C954:
	// mr r30,r24
	r30.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r29,r11,r26
	r29.s64 = r26.s64 - r11.s64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f30,264(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + 264);
	// lfd f31,-31368(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_8245C97C:
	// lfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// ble cr6,0x8245d2a0
	if (!cr6.gt) goto loc_8245D2A0;
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = ctx.f1.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x8239ebe8
	sub_8239EBE8(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// fdiv f0,f29,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = f29.f64 / ctx.f1.f64;
	// stfdx f0,r29,r31
	PPC_STORE_U64(r29.u32 + r31.u32, f0.u64);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// blt cr6,0x8245c97c
	if (cr6.lt) goto loc_8245C97C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C9B4:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// subf r9,r11,r26
	ctx.r9.s64 = r26.s64 - r11.s64;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8245C9D4:
	// lfdx f0,r8,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r10.u32);
	// lfd f13,0(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x8245c9e8
	if (cr6.gt) goto loc_8245C9E8;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_8245C9E8:
	// stfdx f0,r9,r10
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r9.u32 + ctx.r10.u32, f0.u64);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245c9d4
	if (!cr0.eq) goto loc_8245C9D4;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245C9FC:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// subf r9,r11,r26
	ctx.r9.s64 = r26.s64 - r11.s64;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8245CA1C:
	// lfdx f0,r8,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r10.u32);
	// lfd f13,0(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x8245ca30
	if (cr6.lt) goto loc_8245CA30;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_8245CA30:
	// stfdx f0,r10,r9
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + ctx.r9.u32, f0.u64);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245ca1c
	if (!cr0.eq) goto loc_8245CA1C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CA44:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r26,8
	r11.s64 = r26.s64 + 8;
	// subf r9,r26,r10
	ctx.r9.s64 = ctx.r10.s64 - r26.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245CA5C:
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfdx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lfd f13,8(r8)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + 8);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245ca5c
	if (!cr0.eq) goto loc_8245CA5C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CA80:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r26,8
	r11.s64 = r26.s64 + 8;
	// subf r9,r26,r10
	ctx.r9.s64 = ctx.r10.s64 - r26.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245CA98:
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfdx f0,r11,r9
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lfd f13,8(r8)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + 8);
	// fmul f0,f0,f13
	f0.f64 = f0.f64 * ctx.f13.f64;
	// stfd f0,0(r11)
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245ca98
	if (!cr0.eq) goto loc_8245CA98;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CABC:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r28,24(r10)
	r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8245cae8
	if (!cr6.eq) goto loc_8245CAE8;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r30,20(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// b 0x8245caf0
	goto loc_8245CAF0;
loc_8245CAE8:
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r30,24(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_8245CAF0:
	// cmplw cr6,r28,r10
	cr6.compare<uint32_t>(r28.u32, ctx.r10.u32, xer);
	// bne cr6,0x8245d2a0
	if (!cr6.eq) goto loc_8245D2A0;
	// mullw r11,r30,r9
	r11.s64 = int64_t(r30.s32) * int64_t(ctx.r9.s32);
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x8245d2a0
	if (!cr6.eq) goto loc_8245D2A0;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r31,r30,4,0,27
	r31.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r29,r28,4,0,27
	r29.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r6,r11,8
	ctx.r6.s64 = r11.s64 + 8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r7,r26,8
	ctx.r7.s64 = r26.s64 + 8;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lfd f13,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_8245CB2C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245cb8c
	if (cr6.eq) goto loc_8245CB8C;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r8,r11,8
	ctx.r8.s64 = r11.s64 + 8;
loc_8245CB44:
	// fmr f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f13.f64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8245cb78
	if (cr6.eq) goto loc_8245CB78;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8245CB5C:
	// lfd f12,0(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lfd f11,0(r9)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// add r10,r31,r10
	ctx.r10.u64 = r31.u64 + ctx.r10.u64;
	// fmadd f0,f12,f11,f0
	f0.f64 = ctx.f12.f64 * ctx.f11.f64 + f0.f64;
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// bne 0x8245cb5c
	if (!cr0.eq) goto loc_8245CB5C;
loc_8245CB78:
	// stfd f0,0(r4)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r4.u32 + 0, f0.u64);
	// addic. r5,r5,-1
	xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// addi r8,r8,16
	ctx.r8.s64 = ctx.r8.s64 + 16;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// bne 0x8245cb44
	if (!cr0.eq) goto loc_8245CB44;
loc_8245CB8C:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// add r7,r7,r31
	ctx.r7.u64 = ctx.r7.u64 + r31.u64;
	// add r6,r29,r6
	ctx.r6.u64 = r29.u64 + ctx.r6.u64;
	// bne 0x8245cb2c
	if (!cr0.eq) goto loc_8245CB2C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CBA0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lfd f12,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fmr f0,f12
	f0.f64 = ctx.f12.f64;
	// beq cr6,0x8245cbdc
	if (cr6.eq) goto loc_8245CBDC;
	// addi r10,r9,8
	ctx.r10.s64 = ctx.r9.s64 + 8;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8245CBC0:
	// lfd f13,0(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// fmadd f0,f13,f13,f0
	f0.f64 = ctx.f13.f64 * ctx.f13.f64 + f0.f64;
	// bne 0x8245cbc0
	if (!cr0.eq) goto loc_8245CBC0;
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bne cr6,0x8245cbe4
	if (!cr6.eq) goto loc_8245CBE4;
loc_8245CBDC:
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f12.f64;
	// b 0x8245cbf4
	goto loc_8245CBF4;
loc_8245CBE4:
	// fsqrt f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = sqrt(f0.f64);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f0,-31360(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fdiv f0,f0,f13
	f0.f64 = f0.f64 / ctx.f13.f64;
loc_8245CBF4:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// addi r11,r26,8
	r11.s64 = r26.s64 + 8;
	// subf r9,r26,r9
	ctx.r9.s64 = ctx.r9.s64 - r26.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245CC08:
	// lfdx f13,r11,r9
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// fmul f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 * f0.f64;
	// stfd f13,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.f13.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245cc08
	if (!cr0.eq) goto loc_8245CC08;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CC24:
	// mr r28,r24
	r28.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r31,r11,8
	r31.s64 = r11.s64 + 8;
	// subf r30,r11,r10
	r30.s64 = ctx.r10.s64 - r11.s64;
	// subf r29,r11,r26
	r29.s64 = r26.s64 - r11.s64;
loc_8245CC44:
	// lfdx f2,r31,r30
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r31.u32 + r30.u32);
	// lfd f1,0(r31)
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// bl 0x8239e6a0
	sub_8239E6A0(ctx, base);
	// stfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + r29.u32, ctx.f1.u64);
	// bl 0x823ae100
	sub_823AE100(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble 0x8245cc68
	if (!cr0.gt) goto loc_8245CC68;
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// ble cr6,0x8245d2a0
	if (!cr6.gt) goto loc_8245D2A0;
loc_8245CC68:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r28,r25
	cr6.compare<uint32_t>(r28.u32, r25.u32, xer);
	// blt cr6,0x8245cc44
	if (cr6.lt) goto loc_8245CC44;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CC7C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r26,8
	r11.s64 = r26.s64 + 8;
	// subf r9,r26,r10
	ctx.r9.s64 = ctx.r10.s64 - r26.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// lfd f0,32120(r8)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + 32120);
loc_8245CC9C:
	// lfdx f13,r11,r9
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r9.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// fmul f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 * f0.f64;
	// stfd f13,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.f13.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245cc9c
	if (!cr0.eq) goto loc_8245CC9C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CCB8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lfd f0,-31368(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// addi r11,r9,8
	r11.s64 = ctx.r9.s64 + 8;
	// subf r7,r9,r10
	ctx.r7.s64 = ctx.r10.s64 - ctx.r9.s64;
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
loc_8245CCDC:
	// lfdx f13,r11,r7
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r7.u32);
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// lfd f12,0(r11)
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// fmadd f0,f13,f12,f0
	f0.f64 = ctx.f13.f64 * ctx.f12.f64 + f0.f64;
	// bne 0x8245ccdc
	if (!cr0.eq) goto loc_8245CCDC;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r7,-32251
	ctx.r7.s64 = -2113601536;
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// subf r8,r10,r26
	ctx.r8.s64 = r26.s64 - ctx.r10.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// lfd f13,264(r7)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + 264);
loc_8245CD14:
	// lfd f12,0(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// fmul f12,f0,f12
	ctx.f12.f64 = f0.f64 * ctx.f12.f64;
	// lfdx f11,r9,r11
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r9.u32 + r11.u32);
	// fnmsub f12,f12,f13,f11
	ctx.f12.f64 = -(ctx.f12.f64 * ctx.f13.f64 - ctx.f11.f64);
	// stfdx f12,r11,r8
	PPC_STORE_U64(r11.u32 + ctx.r8.u32, ctx.f12.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245cd14
	if (!cr0.eq) goto loc_8245CD14;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CD38:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfd f13,8(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f11,-31368(r11)
	ctx.f11.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fmr f0,f11
	f0.f64 = ctx.f11.f64;
	// beq cr6,0x8245cd80
	if (cr6.eq) goto loc_8245CD80;
	// addi r11,r8,8
	r11.s64 = ctx.r8.s64 + 8;
	// subf r7,r8,r10
	ctx.r7.s64 = ctx.r10.s64 - ctx.r8.s64;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
loc_8245CD68:
	// lfdx f12,r7,r11
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r7.u32 + r11.u32);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lfd f10,0(r11)
	ctx.f10.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// fmadd f0,f12,f10,f0
	f0.f64 = ctx.f12.f64 * ctx.f10.f64 + f0.f64;
	// bne 0x8245cd68
	if (!cr0.eq) goto loc_8245CD68;
loc_8245CD80:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f12,-31360(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + -31360);
	// fnmsub f10,f0,f0,f12
	ctx.f10.f64 = -(f0.f64 * f0.f64 - ctx.f12.f64);
	// fmul f10,f10,f13
	ctx.f10.f64 = ctx.f10.f64 * ctx.f13.f64;
	// fnmsub f12,f10,f13,f12
	ctx.f12.f64 = -(ctx.f10.f64 * ctx.f13.f64 - ctx.f12.f64);
	// fcmpu cr6,f12,f11
	cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// bge cr6,0x8245cdc0
	if (!cr6.lt) goto loc_8245CDC0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// addi r10,r26,8
	ctx.r10.s64 = r26.s64 + 8;
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8245CDAC:
	// stfd f11,0(r10)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.f11.u64);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245cdac
	if (!cr0.eq) goto loc_8245CDAC;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CDC0:
	// fsqrt f12,f12
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = sqrt(ctx.f12.f64);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// fmadd f0,f0,f13,f12
	f0.f64 = f0.f64 * ctx.f13.f64 + ctx.f12.f64;
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// subf r9,r10,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r10.s64;
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// subf r8,r10,r26
	ctx.r8.s64 = r26.s64 - ctx.r10.s64;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_8245CDE0:
	// lfd f12,0(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// fmul f12,f0,f12
	ctx.f12.f64 = f0.f64 * ctx.f12.f64;
	// lfdx f11,r9,r11
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r9.u32 + r11.u32);
	// fmsub f12,f11,f13,f12
	ctx.f12.f64 = ctx.f11.f64 * ctx.f13.f64 - ctx.f12.f64;
	// stfdx f12,r11,r8
	PPC_STORE_U64(r11.u32 + ctx.r8.u32, ctx.f12.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245cde0
	if (!cr0.eq) goto loc_8245CDE0;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CE04:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lfd f31,-28592(r11)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(r11.u32 + -28592);
loc_8245CE24:
	// lfdx f0,r29,r31
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r29.u32 + r31.u32);
	// fadd f1,f0,f31
	ctx.f1.f64 = f0.f64 + f31.f64;
	// bl 0x8239da30
	sub_8239DA30(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245ce24
	if (!cr0.eq) goto loc_8245CE24;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CE44:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// addi r11,r9,8
	r11.s64 = ctx.r9.s64 + 8;
	// subf r9,r9,r26
	ctx.r9.s64 = r26.s64 - ctx.r9.s64;
	// lfd f13,-31368(r7)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + -31368);
	// lfd f12,-31360(r8)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r8.u32 + -31360);
loc_8245CE6C:
	// lfd f0,0(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x8245d2a0
	if (cr6.lt) goto loc_8245D2A0;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x8245d2a0
	if (cr6.eq) goto loc_8245D2A0;
	// fsqrt f0,f0
	f0.f64 = sqrt(f0.f64);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// fdiv f0,f12,f0
	f0.f64 = ctx.f12.f64 / f0.f64;
	// cmplw cr6,r10,r25
	cr6.compare<uint32_t>(ctx.r10.u32, r25.u32, xer);
	// stfdx f0,r9,r11
	PPC_STORE_U64(ctx.r9.u32 + r11.u32, f0.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// blt cr6,0x8245ce6c
	if (cr6.lt) goto loc_8245CE6C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CEA0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// subf r7,r26,r10
	ctx.r7.s64 = ctx.r10.s64 - r26.s64;
	// addi r11,r26,8
	r11.s64 = r26.s64 + 8;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// lfd f12,-31368(r8)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r8.u32 + -31368);
	// lfd f13,-31360(r9)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r9.u32 + -31360);
loc_8245CEC8:
	// lfdx f0,r11,r7
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r7.u32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bge cr6,0x8245cedc
	if (!cr6.lt) goto loc_8245CEDC;
	// stfd f12,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.f12.u64);
	// b 0x8245cef0
	goto loc_8245CEF0;
loc_8245CEDC:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x8245ceec
	if (!cr6.gt) goto loc_8245CEEC;
	// stfd f13,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.f13.u64);
	// b 0x8245cef0
	goto loc_8245CEF0;
loc_8245CEEC:
	// stfd f0,0(r11)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + 0, f0.u64);
loc_8245CEF0:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245cec8
	if (!cr0.eq) goto loc_8245CEC8;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CF00:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// subf r6,r26,r10
	ctx.r6.s64 = ctx.r10.s64 - r26.s64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r11,r26,8
	r11.s64 = r26.s64 + 8;
	// lfd f13,-31368(r8)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + -31368);
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// lfd f11,-31360(r9)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r9.u32 + -31360);
	// lfd f12,-30984(r10)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + -30984);
loc_8245CF30:
	// lfdx f0,r11,r6
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r6.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x8245cf44
	if (!cr6.lt) goto loc_8245CF44;
	// stfd f12,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.f12.u64);
	// b 0x8245cf58
	goto loc_8245CF58;
loc_8245CF44:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x8245cf54
	if (!cr6.gt) goto loc_8245CF54;
	// stfd f11,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.f11.u64);
	// b 0x8245cf58
	goto loc_8245CF58;
loc_8245CF54:
	// stfd f13,0(r11)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r11.u32 + 0, ctx.f13.u64);
loc_8245CF58:
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// bne 0x8245cf30
	if (!cr0.eq) goto loc_8245CF30;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CF68:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245CF80:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x8239ddc0
	sub_8239DDC0(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245cf80
	if (!cr0.eq) goto loc_8245CF80;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CF9C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245CFB4:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x826a75a8
	sub_826A75A8(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245cfb4
	if (!cr0.eq) goto loc_8245CFB4;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245CFD0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r8,-32251
	ctx.r8.s64 = -2113601536;
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// subf r3,r11,r9
	ctx.r3.s64 = ctx.r9.s64 - r11.s64;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// subf r6,r11,r26
	ctx.r6.s64 = r26.s64 - r11.s64;
	// subf r5,r11,r9
	ctx.r5.s64 = ctx.r9.s64 - r11.s64;
	// lfd f10,32112(r7)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r7.u32 + 32112);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// lfd f11,264(r8)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r8.u32 + 264);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lfd f8,-31368(r9)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r9.u32 + -31368);
	// lfd f9,-31360(r11)
	ctx.f9.u64 = PPC_LOAD_U64(r11.u32 + -31360);
loc_8245D018:
	// lfd f12,0(r10)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// lfdx f0,r5,r10
	f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + ctx.r10.u32);
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// bge cr6,0x8245d030
	if (!cr6.lt) goto loc_8245D030;
	// stfdx f8,r6,r10
	PPC_STORE_U64(ctx.r6.u32 + ctx.r10.u32, ctx.f8.u64);
	// b 0x8245d068
	goto loc_8245D068;
loc_8245D030:
	// lfdx f13,r3,r10
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + ctx.r10.u32);
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// blt cr6,0x8245d044
	if (cr6.lt) goto loc_8245D044;
	// stfdx f9,r6,r10
	PPC_STORE_U64(ctx.r6.u32 + ctx.r10.u32, ctx.f9.u64);
	// b 0x8245d068
	goto loc_8245D068;
loc_8245D044:
	// lfdx f0,r5,r10
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + ctx.r10.u32);
	// fsub f12,f12,f0
	ctx.f12.f64 = ctx.f12.f64 - f0.f64;
	// fsub f0,f13,f0
	f0.f64 = ctx.f13.f64 - f0.f64;
	// fdiv f0,f12,f0
	f0.f64 = ctx.f12.f64 / f0.f64;
	// fmul f13,f0,f0
	ctx.f13.f64 = f0.f64 * f0.f64;
	// fmul f0,f13,f0
	f0.f64 = ctx.f13.f64 * f0.f64;
	// fmul f0,f0,f11
	f0.f64 = f0.f64 * ctx.f11.f64;
	// fmsub f0,f13,f10,f0
	f0.f64 = ctx.f13.f64 * ctx.f10.f64 - f0.f64;
	// stfdx f0,r6,r10
	PPC_STORE_U64(ctx.r6.u32 + ctx.r10.u32, f0.u64);
loc_8245D068:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245d018
	if (!cr0.eq) goto loc_8245D018;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245D078:
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r9,8
	r11.s64 = ctx.r9.s64 + 8;
	// subf r9,r9,r26
	ctx.r9.s64 = r26.s64 - ctx.r9.s64;
	// lfd f13,-31368(r8)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + -31368);
loc_8245D098:
	// lfd f0,0(r11)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x8245d2a0
	if (cr6.lt) goto loc_8245D2A0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// fsqrt f0,f0
	f0.f64 = sqrt(f0.f64);
	// stfdx f0,r11,r9
	PPC_STORE_U64(r11.u32 + ctx.r9.u32, f0.u64);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// cmplw cr6,r10,r25
	cr6.compare<uint32_t>(ctx.r10.u32, r25.u32, xer);
	// blt cr6,0x8245d098
	if (cr6.lt) goto loc_8245D098;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245D0C0:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lis r6,-32249
	ctx.r6.s64 = -2113470464;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// subf r8,r11,r9
	ctx.r8.s64 = ctx.r9.s64 - r11.s64;
	// subf r9,r11,r26
	ctx.r9.s64 = r26.s64 - r11.s64;
	// lfd f12,-31368(r6)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r6.u32 + -31368);
	// mr r11,r25
	r11.u64 = r25.u64;
	// lfd f13,-31360(r7)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + -31360);
loc_8245D0F0:
	// lfdx f0,r10,r8
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + ctx.r8.u32);
	// lfd f11,0(r10)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fcmpu cr6,f0,f11
	cr6.compare(f0.f64, ctx.f11.f64);
	// blt cr6,0x8245d108
	if (cr6.lt) goto loc_8245D108;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
	// b 0x8245d10c
	goto loc_8245D10C;
loc_8245D108:
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f12.f64;
loc_8245D10C:
	// stfdx f0,r10,r9
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r10.u32 + ctx.r9.u32, f0.u64);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8245d0f0
	if (!cr0.eq) goto loc_8245D0F0;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245D120:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245D138:
	// lfdx f1,r31,r29
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r31.u32 + r29.u32);
	// bl 0x8239d8c0
	sub_8239D8C0(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245d138
	if (!cr0.eq) goto loc_8245D138;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245D154:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d240
	if (cr6.eq) goto loc_8245D240;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r31,r26,8
	r31.s64 = r26.s64 + 8;
	// mr r30,r25
	r30.u64 = r25.u64;
	// subf r29,r26,r11
	r29.s64 = r11.s64 - r26.s64;
loc_8245D16C:
	// lfdx f1,r29,r31
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r29.u32 + r31.u32);
	// bl 0x826a74a8
	sub_826A74A8(ctx, base);
	// stfd f1,0(r31)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r31.u32 + 0, ctx.f1.u64);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// bne 0x8245d16c
	if (!cr0.eq) goto loc_8245D16C;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245D188:
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// lwz r11,24(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8245d240
	if (!cr6.gt) goto loc_8245D240;
	// lwz r8,20(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
loc_8245D1A0:
	// mr r11,r24
	r11.u64 = r24.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8245d1f0
	if (cr6.eq) goto loc_8245D1F0;
loc_8245D1AC:
	// lwz r8,24(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// lwz r6,24(r23)
	ctx.r6.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// mullw r7,r8,r11
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(r11.s32);
	// mullw r8,r6,r10
	ctx.r8.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r10.s32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r7,r7,r10
	ctx.r7.u64 = ctx.r7.u64 + ctx.r10.u64;
	// add r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 + r11.u64;
	// rlwinm r7,r7,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r8,r8,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// add r8,r8,r26
	ctx.r8.u64 = ctx.r8.u64 + r26.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lfd f0,8(r7)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// stfd f0,8(r8)
	PPC_STORE_U64(ctx.r8.u32 + 8, f0.u64);
	// lwz r8,20(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x8245d1ac
	if (cr6.lt) goto loc_8245D1AC;
loc_8245D1F0:
	// lwz r11,24(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x8245d1a0
	if (cr6.lt) goto loc_8245D1A0;
	// b 0x8245d240
	goto loc_8245D240;
loc_8245D204:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lfd f13,40(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// lfd f0,32016(r10)
	f0.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32016);
	// fmul f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 * f0.f64;
	// stfd f13,8(r26)
	PPC_STORE_U64(r26.u32 + 8, ctx.f13.u64);
	// lfd f13,24(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// fmul f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 * f0.f64;
	// stfd f13,24(r26)
	PPC_STORE_U64(r26.u32 + 24, ctx.f13.u64);
	// lfd f13,8(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// fmul f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 * f0.f64;
	// stfd f13,40(r26)
	PPC_STORE_U64(r26.u32 + 40, ctx.f13.u64);
	// lfd f13,56(r11)
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + 56);
	// fmul f0,f13,f0
	f0.f64 = ctx.f13.f64 * f0.f64;
loc_8245D23C:
	// stfd f0,56(r26)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r26.u32 + 56, f0.u64);
loc_8245D240:
	// lwz r11,12(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// b 0x8245d258
	goto loc_8245D258;
loc_8245D248:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8245d2a0
	if (!cr6.eq) goto loc_8245D2A0;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_8245D258:
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8245d248
	if (!cr0.eq) goto loc_8245D248;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245d298
	if (cr6.eq) goto loc_8245D298;
	// addi r6,r23,48
	ctx.r6.s64 = r23.s64 + 48;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
loc_8245D274:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lfd f1,8(r4)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r4.u32 + 8);
	// bl 0x8245a250
	sub_8245A250(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x8245d2a8
	if (cr0.lt) goto loc_8245D2A8;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// cmplw cr6,r10,r25
	cr6.compare<uint32_t>(ctx.r10.u32, r25.u32, xer);
	// blt cr6,0x8245d274
	if (cr6.lt) goto loc_8245D274;
loc_8245D298:
	// mr r31,r24
	r31.u64 = r24.u64;
	// b 0x8245d2a8
	goto loc_8245D2A8;
loc_8245D2A0:
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
loc_8245D2A8:
	// addi r29,r1,80
	r29.s64 = ctx.r1.s64 + 80;
	// li r30,4
	r30.s64 = 4;
loc_8245D2B0:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// bne 0x8245d2b0
	if (!cr0.eq) goto loc_8245D2B0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x8245d2d8
	goto loc_8245D2D8;
loc_8245D2D0:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8245D2D8:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// addi r12,r1,-96
	r12.s64 = ctx.r1.s64 + -96;
	// bl 0x8239d62c
	// b 0x8239bd2c
	return;
}

__attribute__((alias("__imp__sub_8245D2E8"))) PPC_WEAK_FUNC(sub_8245D2E8);
PPC_FUNC_IMPL(__imp__sub_8245D2E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245d358
	if (cr6.eq) goto loc_8245D358;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8245d358
	if (!cr6.eq) goto loc_8245D358;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne 0x8245d32c
	if (!cr0.eq) goto loc_8245D32C;
	// li r11,0
	r11.s64 = 0;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
loc_8245D324:
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// b 0x8245d358
	goto loc_8245D358;
loc_8245D32C:
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245d348
	if (!cr6.eq) goto loc_8245D348;
	// lwz r11,28(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,32(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// b 0x8245d324
	goto loc_8245D324;
loc_8245D348:
	// li r11,1
	r11.s64 = 1;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
loc_8245D358:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245D36C"))) PPC_WEAK_FUNC(sub_8245D36C);
PPC_FUNC_IMPL(__imp__sub_8245D36C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245D370"))) PPC_WEAK_FUNC(sub_8245D370);
PPC_FUNC_IMPL(__imp__sub_8245D370) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245d4b0
	if (cr6.eq) goto loc_8245D4B0;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245d4b0
	if (!cr6.eq) goto loc_8245D4B0;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x8245d3b0
	if (cr6.eq) goto loc_8245D3B0;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245d4b0
	if (!cr6.eq) goto loc_8245D4B0;
loc_8245D3B0:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8245d4b0
	if (cr6.eq) goto loc_8245D4B0;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245d4b0
	if (!cr6.eq) goto loc_8245D4B0;
	// addi r31,r29,16
	r31.s64 = r29.s64 + 16;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245d4b0
	if (!cr6.eq) goto loc_8245D4B0;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245d3f4
	if (cr0.eq) goto loc_8245D3F4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x824099d0
	sub_824099D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x8245d3f8
	goto loc_8245D3F8;
loc_8245D3F4:
	// li r27,0
	r27.s64 = 0;
loc_8245D3F8:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8245d4b0
	if (cr6.eq) goto loc_8245D4B0;
	// lwz r28,24(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// li r4,16
	ctx.r4.s64 = 16;
	// lwz r29,24(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// addi r5,r11,18988
	ctx.r5.s64 = r11.s64 + 18988;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_8245D428:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8245d428
	if (!cr6.eq) goto loc_8245D428;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// mr r11,r29
	r11.u64 = r29.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
loc_8245D44C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x8245d44c
	if (!cr6.eq) goto loc_8245D44C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// lwz r3,4(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x8245d4b0
	if (cr0.eq) goto loc_8245D4B0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r5,r11,-22868
	ctx.r5.s64 = r11.s64 + -22868;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r31,24(r27)
	PPC_STORE_U32(r27.u32 + 24, r31.u32);
	// b 0x8245d4b4
	goto loc_8245D4B4;
loc_8245D4B0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245D4B4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8245D4BC"))) PPC_WEAK_FUNC(sub_8245D4BC);
PPC_FUNC_IMPL(__imp__sub_8245D4BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245D4C0"))) PPC_WEAK_FUNC(sub_8245D4C0);
PPC_FUNC_IMPL(__imp__sub_8245D4C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245d5ec
	if (cr6.eq) goto loc_8245D5EC;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245d5ec
	if (!cr6.eq) goto loc_8245D5EC;
	// addi r30,r31,16
	r30.s64 = r31.s64 + 16;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// bne cr6,0x8245d5ec
	if (!cr6.eq) goto loc_8245D5EC;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8245d5ec
	if (cr6.eq) goto loc_8245D5EC;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245d5ec
	if (!cr6.eq) goto loc_8245D5EC;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// bne cr6,0x8245d5ec
	if (!cr6.eq) goto loc_8245D5EC;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245d53c
	if (cr0.eq) goto loc_8245D53C;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x824099d0
	sub_824099D0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// b 0x8245d540
	goto loc_8245D540;
loc_8245D53C:
	// li r27,0
	r27.s64 = 0;
loc_8245D540:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8245d5ec
	if (cr6.eq) goto loc_8245D5EC;
	// lwz r28,24(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r29,24(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_8245D558:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8245d558
	if (!cr6.eq) goto loc_8245D558;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// mr r11,r29
	r11.u64 = r29.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
loc_8245D57C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x8245d57c
	if (!cr6.eq) goto loc_8245D57C;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// lwz r3,4(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82409268
	sub_82409268(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x8245d5ec
	if (cr0.eq) goto loc_8245D5EC;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// addi r5,r11,26560
	ctx.r5.s64 = r11.s64 + 26560;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ebb10
	sub_823EBB10(ctx, base);
	// add r11,r31,r30
	r11.u64 = r31.u64 + r30.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stb r10,-1(r11)
	PPC_STORE_U8(r11.u32 + -1, ctx.r10.u8);
	// stw r31,24(r27)
	PPC_STORE_U32(r27.u32 + 24, r31.u32);
	// b 0x8245d5f0
	goto loc_8245D5F0;
loc_8245D5EC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245D5F0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8245D5F8"))) PPC_WEAK_FUNC(sub_8245D5F8);
PPC_FUNC_IMPL(__imp__sub_8245D5F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,3032(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 3032);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x8245a8d8
	sub_8245A8D8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245D644"))) PPC_WEAK_FUNC(sub_8245D644);
PPC_FUNC_IMPL(__imp__sub_8245D644) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245D648"))) PPC_WEAK_FUNC(sub_8245D648);
PPC_FUNC_IMPL(__imp__sub_8245D648) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x8245a8d8
	sub_8245A8D8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8245D690"))) PPC_WEAK_FUNC(sub_8245D690);
PPC_FUNC_IMPL(__imp__sub_8245D690) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-464(r1)
	ea = -464 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r17,r9
	r17.u64 = ctx.r9.u64;
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r20,r4
	r20.u64 = ctx.r4.u64;
	// mr r16,r6
	r16.u64 = ctx.r6.u64;
	// mr r15,r7
	r15.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// mr r14,r10
	r14.u64 = ctx.r10.u64;
	// li r18,0
	r18.s64 = 0;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x8245d6c8
	if (cr6.eq) goto loc_8245D6C8;
	// stw r18,0(r17)
	PPC_STORE_U32(r17.u32 + 0, r18.u32);
loc_8245D6C8:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x8245d6d4
	if (cr6.eq) goto loc_8245D6D4;
	// stw r18,0(r14)
	PPC_STORE_U32(r14.u32 + 0, r18.u32);
loc_8245D6D4:
	// mr r9,r18
	ctx.r9.u64 = r18.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8245d744
	if (cr6.eq) goto loc_8245D744;
loc_8245D6E4:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8245d72c
	if (cr0.eq) goto loc_8245D72C;
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r8,14
	cr6.compare<int32_t>(ctx.r8.s32, 14, xer);
	// bne cr6,0x8245d72c
	if (!cr6.eq) goto loc_8245D72C;
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8245d72c
	if (cr0.eq) goto loc_8245D72C;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// beq cr6,0x8245d71c
	if (cr6.eq) goto loc_8245D71C;
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8245d72c
	if (!cr6.eq) goto loc_8245D72C;
loc_8245D71C:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8245d6e4
	if (!cr0.eq) goto loc_8245D6E4;
loc_8245D72C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245d73c
	if (cr6.eq) goto loc_8245D73C;
loc_8245D734:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8245e0f8
	goto loc_8245E0F8;
loc_8245D73C:
	// cmplwi cr6,r9,7
	cr6.compare<uint32_t>(ctx.r9.u32, 7, xer);
	// bgt cr6,0x8245d734
	if (cr6.gt) goto loc_8245D734;
loc_8245D744:
	// mr r6,r18
	ctx.r6.u64 = r18.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8245d870
	if (cr6.eq) goto loc_8245D870;
	// lwz r4,8(r15)
	ctx.r4.u64 = PPC_LOAD_U32(r15.u32 + 8);
loc_8245D758:
	// add r11,r25,r6
	r11.u64 = r25.u64 + ctx.r6.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// rlwinm r11,r11,31,1,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// mulli r9,r11,228
	ctx.r9.s64 = r11.s64 * 228;
	// add r9,r9,r20
	ctx.r9.u64 = ctx.r9.u64 + r20.u64;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
loc_8245D770:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x8245d794
	if (cr0.eq) goto loc_8245D794;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x8245d770
	if (cr6.eq) goto loc_8245D770;
loc_8245D794:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// ble 0x8245d7a4
	if (!cr0.gt) goto loc_8245D7A4;
	// addi r6,r11,1
	ctx.r6.s64 = r11.s64 + 1;
	// b 0x8245d7b0
	goto loc_8245D7B0;
loc_8245D7A4:
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bge cr6,0x8245d7bc
	if (!cr6.lt) goto loc_8245D7BC;
	// mr r25,r11
	r25.u64 = r11.u64;
loc_8245D7B0:
	// cmplw cr6,r6,r25
	cr6.compare<uint32_t>(ctx.r6.u32, r25.u32, xer);
	// blt cr6,0x8245d758
	if (cr6.lt) goto loc_8245D758;
	// b 0x8245d870
	goto loc_8245D870;
loc_8245D7BC:
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// addi r25,r11,1
	r25.s64 = r11.s64 + 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245d818
	if (cr6.eq) goto loc_8245D818;
	// mulli r11,r11,228
	r11.s64 = r11.s64 * 228;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// addi r7,r11,-224
	ctx.r7.s64 = r11.s64 + -224;
loc_8245D7D8:
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_8245D7E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8245d804
	if (cr0.eq) goto loc_8245D804;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8245d7e0
	if (cr6.eq) goto loc_8245D7E0;
loc_8245D804:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8245d818
	if (!cr0.eq) goto loc_8245D818;
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r7,r7,-228
	ctx.r7.s64 = ctx.r7.s64 + -228;
	// bne 0x8245d7d8
	if (!cr0.eq) goto loc_8245D7D8;
loc_8245D818:
	// cmplw cr6,r25,r5
	cr6.compare<uint32_t>(r25.u32, ctx.r5.u32, xer);
	// bge cr6,0x8245d870
	if (!cr6.lt) goto loc_8245D870;
	// mulli r11,r25,228
	r11.s64 = r25.s64 * 228;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// addi r7,r11,4
	ctx.r7.s64 = r11.s64 + 4;
loc_8245D82C:
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_8245D834:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8245d858
	if (cr0.eq) goto loc_8245D858;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8245d834
	if (cr6.eq) goto loc_8245D834;
loc_8245D858:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8245d870
	if (!cr0.eq) goto loc_8245D870;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r7,r7,228
	ctx.r7.s64 = ctx.r7.s64 + 228;
	// cmplw cr6,r25,r5
	cr6.compare<uint32_t>(r25.u32, ctx.r5.u32, xer);
	// blt cr6,0x8245d82c
	if (cr6.lt) goto loc_8245D82C;
loc_8245D870:
	// cmplw cr6,r6,r25
	cr6.compare<uint32_t>(ctx.r6.u32, r25.u32, xer);
	// beq cr6,0x8245d734
	if (cr6.eq) goto loc_8245D734;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// li r22,-1
	r22.s64 = -1;
	// bge cr6,0x8245dc68
	if (!cr6.lt) goto loc_8245DC68;
	// mulli r11,r6,228
	r11.s64 = ctx.r6.s64 * 228;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// addi r26,r11,12
	r26.s64 = r11.s64 + 12;
loc_8245D890:
	// addi r27,r26,-12
	r27.s64 = r26.s64 + -12;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// li r11,7
	r11.s64 = 7;
	// mtctr r11
	ctr.u64 = r11.u64;
loc_8245D8A4:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x8245d8a4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8245D8A4;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r9,55
	ctx.r9.s64 = 55;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_8245D8C0:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8245d8c0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8245D8C0;
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// li r9,5
	ctx.r9.s64 = 5;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_8245D8DC:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8245d8dc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8245D8DC;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// li r29,1
	r29.s64 = 1;
	// mr r28,r24
	r28.u64 = r24.u64;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8245db18
	if (cr6.eq) goto loc_8245DB18;
	// addi r30,r26,24
	r30.s64 = r26.s64 + 24;
loc_8245D90C:
	// cmplwi cr6,r29,7
	cr6.compare<uint32_t>(r29.u32, 7, xer);
	// bge cr6,0x8245daf4
	if (!cr6.lt) goto loc_8245DAF4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245daf4
	if (cr6.eq) goto loc_8245DAF4;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8245dae0
	if (cr6.eq) goto loc_8245DAE0;
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r31,16(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x8245daf4
	if (!cr6.eq) goto loc_8245DAF4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// beq cr6,0x8245d9a0
	if (cr6.eq) goto loc_8245D9A0;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8245d970
	if (!cr6.eq) goto loc_8245D970;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8245d9a0
	if (cr6.eq) goto loc_8245D9A0;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x8245d9a0
	if (cr6.eq) goto loc_8245D9A0;
loc_8245D970:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8245d998
	if (!cr0.eq) goto loc_8245D998;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8245d9c0
	if (cr6.eq) goto loc_8245D9C0;
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x8245d9c0
	if (cr6.eq) goto loc_8245D9C0;
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
loc_8245D990:
	// bne cr6,0x8245daf4
	if (!cr6.eq) goto loc_8245DAF4;
	// b 0x8245d9c0
	goto loc_8245D9C0;
loc_8245D998:
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// b 0x8245d990
	goto loc_8245D990;
loc_8245D9A0:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r8,r1,272
	ctx.r8.s64 = ctx.r1.s64 + 272;
	// lwz r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r11,r8
	PPC_STORE_U32(r11.u32 + ctx.r8.u32, ctx.r10.u32);
	// stwx r7,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r7.u32);
loc_8245D9C0:
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r11,55
	cr6.compare<int32_t>(r11.s32, 55, xer);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bne cr6,0x8245d9fc
	if (!cr6.eq) goto loc_8245D9FC;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r7,r1,272
	ctx.r7.s64 = ctx.r1.s64 + 272;
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// stwx r8,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r8.u32);
	// b 0x8245da34
	goto loc_8245DA34;
loc_8245D9FC:
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// stw r11,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r11,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, r11.u32);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r11,r10
	ctx.r6.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x82459690
	sub_82459690(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245daf4
	if (cr0.lt) goto loc_8245DAF4;
loc_8245DA34:
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8245da7c
	if (cr0.eq) goto loc_8245DA7C;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bge 0x8245da70
	if (!cr0.lt) goto loc_8245DA70;
	// not r10,r11
	ctx.r10.u64 = ~r11.u64;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r10,r9
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// ble cr6,0x8245da7c
	if (!cr6.gt) goto loc_8245DA7C;
	// stwx r11,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r11.u32);
	// b 0x8245da7c
	goto loc_8245DA7C;
loc_8245DA70:
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x8245daf4
	if (cr6.lt) goto loc_8245DAF4;
loc_8245DA7C:
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8245dac0
	if (cr6.eq) goto loc_8245DAC0;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bge 0x8245dab4
	if (!cr0.lt) goto loc_8245DAB4;
	// not r10,r11
	ctx.r10.u64 = ~r11.u64;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// ble cr6,0x8245dac0
	if (!cr6.gt) goto loc_8245DAC0;
	// stwx r11,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r11.u32);
	// b 0x8245dac0
	goto loc_8245DAC0;
loc_8245DAB4:
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x8245daf4
	if (cr6.lt) goto loc_8245DAF4;
loc_8245DAC0:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245dae0
	if (cr0.eq) goto loc_8245DAE0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8245daf4
	if (!cr0.eq) goto loc_8245DAF4;
loc_8245DAE0:
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// addi r30,r30,32
	r30.s64 = r30.s64 + 32;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// bne 0x8245d90c
	if (!cr0.eq) goto loc_8245D90C;
loc_8245DAF4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x8245dc58
	if (!cr6.eq) goto loc_8245DC58;
	// cmplwi cr6,r29,7
	cr6.compare<uint32_t>(r29.u32, 7, xer);
	// bge cr6,0x8245db18
	if (!cr6.lt) goto loc_8245DB18;
	// rlwinm r11,r29,5,0,26
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 5) & 0xFFFFFFE0;
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8245dc58
	if (!cr6.eq) goto loc_8245DC58;
loc_8245DB18:
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245db74
	if (cr6.eq) goto loc_8245DB74;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8245db74
	if (cr6.eq) goto loc_8245DB74;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r9,5
	cr6.compare<int32_t>(ctx.r9.s32, 5, xer);
	// bne cr6,0x8245db50
	if (!cr6.eq) goto loc_8245DB50;
	// lwz r9,4(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_8245DB50:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r9,55
	cr6.compare<int32_t>(ctx.r9.s32, 55, xer);
	// bne cr6,0x8245db74
	if (!cr6.eq) goto loc_8245DB74;
	// lwz r9,12(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
loc_8245DB74:
	// mr r31,r18
	r31.u64 = r18.u64;
	// addi r5,r26,12
	ctx.r5.s64 = r26.s64 + 12;
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
loc_8245DB80:
	// lwz r11,-12(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + -12);
	// lwz r9,-8(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + -8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8245dc3c
	if (cr6.eq) goto loc_8245DC3C;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// lwzx r8,r10,r6
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// cmpwi cr6,r8,5
	cr6.compare<int32_t>(ctx.r8.s32, 5, xer);
	// beq cr6,0x8245dbec
	if (cr6.eq) goto loc_8245DBEC;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x8245dbd0
	if (!cr6.eq) goto loc_8245DBD0;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8245dbbc
	if (cr6.eq) goto loc_8245DBBC;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8245dbd0
	if (!cr6.eq) goto loc_8245DBD0;
loc_8245DBBC:
	// stwx r11,r10,r6
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, r11.u32);
	// b 0x8245dbdc
	goto loc_8245DBDC;
loc_8245DBC4:
	// cmpw cr6,r8,r11
	cr6.compare<int32_t>(ctx.r8.s32, r11.s32, xer);
	// beq cr6,0x8245dbdc
	if (cr6.eq) goto loc_8245DBDC;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
loc_8245DBD0:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// bne cr6,0x8245dbc4
	if (!cr6.eq) goto loc_8245DBC4;
loc_8245DBDC:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// beq cr6,0x8245dc50
	if (cr6.eq) goto loc_8245DC50;
	// b 0x8245dbfc
	goto loc_8245DBFC;
loc_8245DBEC:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8245dbfc
	if (cr6.eq) goto loc_8245DBFC;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stwx r11,r10,r6
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, r11.u32);
loc_8245DBFC:
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// lwz r8,0(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// lwzx r3,r10,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// cmpwi cr6,r3,55
	cr6.compare<int32_t>(ctx.r3.s32, 55, xer);
	// bne cr6,0x8245dca8
	if (!cr6.eq) goto loc_8245DCA8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245dc24
	if (cr6.eq) goto loc_8245DC24;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_8245DC20:
	// stwx r11,r10,r7
	PPC_STORE_U32(ctx.r10.u32 + ctx.r7.u32, r11.u32);
loc_8245DC24:
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r9,-1
	cr6.compare<int32_t>(ctx.r9.s32, -1, xer);
	// bne cr6,0x8245dc3c
	if (!cr6.eq) goto loc_8245DC3C;
	// li r9,1
	ctx.r9.s64 = 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
loc_8245DC3C:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r5,r5,32
	ctx.r5.s64 = ctx.r5.s64 + 32;
	// cmplwi cr6,r10,28
	cr6.compare<uint32_t>(ctx.r10.u32, 28, xer);
	// blt cr6,0x8245db80
	if (cr6.lt) goto loc_8245DB80;
loc_8245DC50:
	// cmplwi cr6,r31,7
	cr6.compare<uint32_t>(r31.u32, 7, xer);
	// beq cr6,0x8245dc68
	if (cr6.eq) goto loc_8245DC68;
loc_8245DC58:
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
	// addi r26,r26,228
	r26.s64 = r26.s64 + 228;
	// cmplw cr6,r21,r25
	cr6.compare<uint32_t>(r21.u32, r25.u32, xer);
	// blt cr6,0x8245d890
	if (cr6.lt) goto loc_8245D890;
loc_8245DC68:
	// cmplw cr6,r21,r25
	cr6.compare<uint32_t>(r21.u32, r25.u32, xer);
	// beq cr6,0x8245d734
	if (cr6.eq) goto loc_8245D734;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x8245e078
	if (cr6.eq) goto loc_8245E078;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245dcf4
	if (cr0.eq) goto loc_8245DCF4;
	// bl 0x8240afc8
	sub_8240AFC8(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// b 0x8245dcf8
	goto loc_8245DCF8;
loc_8245DC94:
	// cmpwi cr6,r9,54
	cr6.compare<int32_t>(ctx.r9.s32, 54, xer);
	// beq cr6,0x8245dc50
	if (cr6.eq) goto loc_8245DC50;
	// cmpw cr6,r3,r9
	cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, xer);
	// beq cr6,0x8245dcb4
	if (cr6.eq) goto loc_8245DCB4;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
loc_8245DCA8:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r9,55
	cr6.compare<int32_t>(ctx.r9.s32, 55, xer);
	// bne cr6,0x8245dc94
	if (!cr6.eq) goto loc_8245DC94;
loc_8245DCB4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r9,54
	cr6.compare<int32_t>(ctx.r9.s32, 54, xer);
	// beq cr6,0x8245dc50
	if (cr6.eq) goto loc_8245DC50;
	// lwzx r11,r10,r6
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245dce4
	if (!cr6.eq) goto loc_8245DCE4;
	// cmpwi cr6,r9,55
	cr6.compare<int32_t>(ctx.r9.s32, 55, xer);
	// bne cr6,0x8245dc24
	if (!cr6.eq) goto loc_8245DC24;
	// lwz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// bl 0x824592e8
	sub_824592E8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245dc50
	if (cr0.eq) goto loc_8245DC50;
loc_8245DCE4:
	// cmpwi cr6,r9,55
	cr6.compare<int32_t>(ctx.r9.s32, 55, xer);
	// bne cr6,0x8245dc24
	if (!cr6.eq) goto loc_8245DC24;
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// b 0x8245dc20
	goto loc_8245DC20;
loc_8245DCF4:
	// mr r24,r18
	r24.u64 = r18.u64;
loc_8245DCF8:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x8245dd0c
	if (!cr6.eq) goto loc_8245DD0C;
loc_8245DD00:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8245e0f8
	goto loc_8245E0F8;
loc_8245DD0C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r25,r24,44
	r25.s64 = r24.s64 + 44;
	// mr r27,r18
	r27.u64 = r18.u64;
	// mulli r26,r21,228
	r26.s64 = r21.s64 * 228;
	// addi r23,r11,-22852
	r23.s64 = r11.s64 + -22852;
loc_8245DD20:
	// rlwinm r11,r27,5,0,26
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 5) & 0xFFFFFFE0;
	// add r11,r11,r26
	r11.u64 = r11.u64 + r26.u64;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// addi r28,r11,4
	r28.s64 = r11.s64 + 4;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245e074
	if (cr6.eq) goto loc_8245E074;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245e068
	if (cr6.eq) goto loc_8245E068;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x8245de40
	if (!cr6.eq) goto loc_8245DE40;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245de24
	if (cr6.eq) goto loc_8245DE24;
	// lwz r11,28(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245de24
	if (cr6.eq) goto loc_8245DE24;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245dd88
	if (cr0.eq) goto loc_8245DD88;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8245dd8c
	goto loc_8245DD8C;
loc_8245DD88:
	// mr r30,r18
	r30.u64 = r18.u64;
loc_8245DD8C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bge 0x8245ddb4
	if (!cr0.lt) goto loc_8245DDB4;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x8245ddbc
	goto loc_8245DDBC;
loc_8245DDB4:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245ddc0
	if (cr6.eq) goto loc_8245DDC0;
loc_8245DDBC:
	// stw r11,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r11.u32);
loc_8245DDC0:
	// lwz r11,28(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bge 0x8245dde0
	if (!cr0.lt) goto loc_8245DDE0;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x8245dde8
	goto loc_8245DDE8;
loc_8245DDE0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245ddec
	if (cr6.eq) goto loc_8245DDEC;
loc_8245DDE8:
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
loc_8245DDEC:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8245e0f4
	if (!cr6.eq) goto loc_8245E0F4;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8245e0f4
	if (!cr6.eq) goto loc_8245E0F4;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245e0f4
	if (cr0.lt) goto loc_8245E0F4;
	// b 0x8245df2c
	goto loc_8245DF2C;
loc_8245DE24:
	// lwz r11,0(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 0);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8245df2c
	goto loc_8245DF2C;
loc_8245DE40:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245de5c
	if (cr0.eq) goto loc_8245DE5C;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8245de60
	goto loc_8245DE60;
loc_8245DE5C:
	// mr r30,r18
	r30.u64 = r18.u64;
loc_8245DE60:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bge 0x8245deac
	if (!cr0.lt) goto loc_8245DEAC;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
loc_8245DEAC:
	// stw r11,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r11.u32);
	// lwz r11,28(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 28);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bge 0x8245decc
	if (!cr0.lt) goto loc_8245DECC;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
loc_8245DECC:
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm r11,r11,0,20,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xC00;
	// stw r11,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r11.u32);
	// beq cr6,0x8245def0
	if (cr6.eq) goto loc_8245DEF0;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8245defc
	if (!cr0.eq) goto loc_8245DEFC;
loc_8245DEF0:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// ori r11,r11,512
	r11.u64 = r11.u64 | 512;
	// stw r11,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r11.u32);
loc_8245DEFC:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8245df10
	if (cr6.eq) goto loc_8245DF10;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8245df2c
	if (!cr6.eq) goto loc_8245DF2C;
loc_8245DF10:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8245df2c
	if (!cr6.eq) goto loc_8245DF2C;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8245df2c
	if (!cr6.eq) goto loc_8245DF2C;
	// stw r18,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r18.u32);
loc_8245DF2C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x8245df54
	if (!cr6.eq) goto loc_8245DF54;
	// add r11,r26,r20
	r11.u64 = r26.u64 + r20.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245e068
	if (cr6.eq) goto loc_8245E068;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r30,40(r24)
	PPC_STORE_U32(r24.u32 + 40, r30.u32);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// b 0x8245e068
	goto loc_8245E068;
loc_8245DF54:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245df78
	if (cr0.eq) goto loc_8245DF78;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245df7c
	goto loc_8245DF7C;
loc_8245DF78:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
loc_8245DF7C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r25)
	PPC_STORE_U32(r25.u32 + 0, ctx.r3.u32);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245dfb8
	if (cr0.eq) goto loc_8245DFB8;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x8245dfbc
	goto loc_8245DFBC;
loc_8245DFB8:
	// mr r29,r18
	r29.u64 = r18.u64;
loc_8245DFBC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// li r3,48
	ctx.r3.s64 = 48;
	// stw r29,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r29.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245dfec
	if (cr0.eq) goto loc_8245DFEC;
	// mr r4,r15
	ctx.r4.u64 = r15.u64;
	// bl 0x824099d0
	sub_824099D0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245dff0
	goto loc_8245DFF0;
loc_8245DFEC:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_8245DFF0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,20(r29)
	PPC_STORE_U32(r29.u32 + 20, r11.u32);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// li r3,88
	ctx.r3.s64 = 88;
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245e020
	if (cr0.eq) goto loc_8245E020;
	// bl 0x8240b568
	sub_8240B568(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245e024
	goto loc_8245E024;
loc_8245E020:
	// mr r31,r18
	r31.u64 = r18.u64;
loc_8245E024:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r31,24(r29)
	PPC_STORE_U32(r29.u32 + 24, r31.u32);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// stw r22,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r22.u32);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// li r11,2
	r11.s64 = 2;
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// stw r30,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r30.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// addi r25,r11,12
	r25.s64 = r11.s64 + 12;
loc_8245E068:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmplwi cr6,r27,7
	cr6.compare<uint32_t>(r27.u32, 7, xer);
	// blt cr6,0x8245dd20
	if (cr6.lt) goto loc_8245DD20;
loc_8245E074:
	// stw r24,0(r17)
	PPC_STORE_U32(r17.u32 + 0, r24.u32);
loc_8245E078:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x8245e0f4
	if (cr6.eq) goto loc_8245E0F4;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245e0ac
	if (cr0.eq) goto loc_8245E0AC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22860
	ctx.r6.s64 = r11.s64 + -22860;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245e0b0
	goto loc_8245E0B0;
loc_8245E0AC:
	// mr r31,r18
	r31.u64 = r18.u64;
loc_8245E0B0:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245e0e0
	if (cr0.eq) goto loc_8245E0E0;
	// mulli r11,r21,228
	r11.s64 = r21.s64 * 228;
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// lwzx r5,r11,r20
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x8245e0e4
	goto loc_8245E0E4;
loc_8245E0E0:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
loc_8245E0E4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// beq cr6,0x8245dd00
	if (cr6.eq) goto loc_8245DD00;
	// stw r31,0(r14)
	PPC_STORE_U32(r14.u32 + 0, r31.u32);
loc_8245E0F4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245E0F8:
	// addi r1,r1,464
	ctx.r1.s64 = ctx.r1.s64 + 464;
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_8245E100"))) PPC_WEAK_FUNC(sub_8245E100);
PPC_FUNC_IMPL(__imp__sub_8245E100) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r23,0
	r23.s64 = 0;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245e154
	if (cr0.eq) goto loc_8245E154;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245e268
	goto loc_8245E268;
loc_8245E154:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// li r27,0
	r27.s64 = 0;
	// li r25,0
	r25.s64 = 0;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8245e234
	if (cr6.eq) goto loc_8245E234;
loc_8245E178:
	// cmplw cr6,r30,r24
	cr6.compare<uint32_t>(r30.u32, r24.u32, xer);
	// bge cr6,0x8245e234
	if (!cr6.lt) goto loc_8245E234;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245e210
	if (cr0.lt) goto loc_8245E210;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245e210
	if (cr0.lt) goto loc_8245E210;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82459690
	sub_82459690(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245e210
	if (cr0.lt) goto loc_8245E210;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,116(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// bl 0x824593d8
	sub_824593D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245e1f4
	if (cr0.eq) goto loc_8245E1F4;
	// li r27,1
	r27.s64 = 1;
loc_8245E1F4:
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// lwz r5,164(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824593d8
	sub_824593D8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245e218
	if (cr0.eq) goto loc_8245E218;
	// b 0x8245e214
	goto loc_8245E214;
loc_8245E210:
	// li r27,1
	r27.s64 = 1;
loc_8245E214:
	// li r25,1
	r25.s64 = 1;
loc_8245E218:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x8245e228
	if (cr6.eq) goto loc_8245E228;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x8245e234
	if (!cr6.eq) goto loc_8245E234;
loc_8245E228:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// blt cr6,0x8245e178
	if (cr6.lt) goto loc_8245E178;
loc_8245E234:
	// cmplw cr6,r24,r26
	cr6.compare<uint32_t>(r24.u32, r26.u32, xer);
	// bge cr6,0x8245e240
	if (!cr6.lt) goto loc_8245E240;
	// li r23,4
	r23.s64 = 4;
loc_8245E240:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x8245e24c
	if (cr6.eq) goto loc_8245E24C;
	// addi r23,r23,512
	r23.s64 = r23.s64 + 512;
loc_8245E24C:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x8245e258
	if (cr6.eq) goto loc_8245E258;
	// addis r23,r23,1
	r23.s64 = r23.s64 + 65536;
loc_8245E258:
	// cmplw cr6,r26,r24
	cr6.compare<uint32_t>(r26.u32, r24.u32, xer);
	// bge cr6,0x8245e264
	if (!cr6.lt) goto loc_8245E264;
	// addis r23,r23,128
	r23.s64 = r23.s64 + 8388608;
loc_8245E264:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
loc_8245E268:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_8245E270"))) PPC_WEAK_FUNC(sub_8245E270);
PPC_FUNC_IMPL(__imp__sub_8245E270) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,16(r4)
	r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// rlwinm. r11,r31,0,22,22
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245e29c
	if (cr0.eq) goto loc_8245E29C;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
loc_8245E29C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8245e330
	if (cr6.eq) goto loc_8245E330;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245e330
	if (!cr6.eq) goto loc_8245E330;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8245e330
	if (!cr6.eq) goto loc_8245E330;
	// rlwinm. r11,r31,0,20,21
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0xC00;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8245e2d0
	if (!cr0.eq) goto loc_8245E2D0;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r11,56(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// or r31,r11,r31
	r31.u64 = r11.u64 | r31.u64;
loc_8245E2D0:
	// rlwinm. r11,r31,0,20,21
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0xC00;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8245e2f8
	if (!cr0.eq) goto loc_8245E2F8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8245e2ec
	if (cr0.eq) goto loc_8245E2EC;
	// ori r31,r31,1024
	r31.u64 = r31.u64 | 1024;
	// b 0x8245e2f8
	goto loc_8245E2F8;
loc_8245E2EC:
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245e2f8
	if (cr0.eq) goto loc_8245E2F8;
	// ori r31,r31,2048
	r31.u64 = r31.u64 | 2048;
loc_8245E2F8:
	// rlwinm. r10,r31,0,21,21
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x8245e310
	if (cr0.eq) goto loc_8245E310;
	// lwz r10,36(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 36);
	// rlwimi r10,r11,10,20,21
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 10) & 0xC00) | (ctx.r10.u64 & 0xFFFFFFFFFFFFF3FF);
	// stw r10,36(r29)
	PPC_STORE_U32(r29.u32 + 36, ctx.r10.u32);
loc_8245E310:
	// rlwinm. r10,r31,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8245e324
	if (cr0.eq) goto loc_8245E324;
	// lwz r10,36(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 36);
	// rlwimi r10,r11,11,20,21
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 11) & 0xC00) | (ctx.r10.u64 & 0xFFFFFFFFFFFFF3FF);
	// stw r10,36(r29)
	PPC_STORE_U32(r29.u32 + 36, ctx.r10.u32);
loc_8245E324:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245E328:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd4c
	return;
loc_8245E330:
	// rlwinm. r11,r31,0,20,21
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0xC00;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245e324
	if (cr0.eq) goto loc_8245E324;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3077
	ctx.r5.s64 = 3077;
	// addi r6,r11,-22840
	ctx.r6.s64 = r11.s64 + -22840;
	// addi r4,r30,40
	ctx.r4.s64 = r30.s64 + 40;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8245e328
	goto loc_8245E328;
}

__attribute__((alias("__imp__sub_8245E35C"))) PPC_WEAK_FUNC(sub_8245E35C);
PPC_FUNC_IMPL(__imp__sub_8245E35C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245E360"))) PPC_WEAK_FUNC(sub_8245E360);
PPC_FUNC_IMPL(__imp__sub_8245E360) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// and. r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245e39c
	if (cr0.eq) goto loc_8245E39C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3048
	ctx.r5.s64 = 3048;
	// addi r6,r11,-22664
	ctx.r6.s64 = r11.s64 + -22664;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_8245E39C:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245e3ec
	if (cr6.eq) goto loc_8245E3EC;
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8245e3ec
	if (cr0.eq) goto loc_8245E3EC;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r10,r31,40
	ctx.r10.s64 = r31.s64 + 40;
	// addi r4,r9,12644
	ctx.r4.s64 = ctx.r9.s64 + 12644;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// std r9,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 16);
	// std r9,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	r11.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// std r11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, r11.u64);
	// bl 0x8245d648
	sub_8245D648(ctx, base);
loc_8245E3EC:
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// rlwinm. r10,r11,0,12,12
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8245e428
	if (cr0.eq) goto loc_8245E428;
	// andis. r11,r11,22
	r11.u64 = r11.u64 & 1441792;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8245e428
	if (cr0.eq) goto loc_8245E428;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3048
	ctx.r5.s64 = 3048;
	// addi r6,r11,-22744
	ctx.r6.s64 = r11.s64 + -22744;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_8245E428:
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r11,0
	r11.s64 = 0;
	// rlwinm. r9,r10,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8245e43c
	if (cr0.eq) goto loc_8245E43C;
	// li r11,1
	r11.s64 = 1;
loc_8245E43C:
	// rlwinm. r9,r10,0,18,18
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8245e448
	if (cr0.eq) goto loc_8245E448;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_8245E448:
	// rlwinm. r9,r10,0,17,17
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8245e454
	if (cr0.eq) goto loc_8245E454;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_8245E454:
	// rlwinm. r9,r10,0,16,16
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8245e460
	if (cr0.eq) goto loc_8245E460;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_8245E460:
	// rlwinm. r10,r10,0,15,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8245e46c
	if (cr0.eq) goto loc_8245E46C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_8245E46C:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x8245e48c
	if (!cr6.gt) goto loc_8245E48C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3083
	ctx.r5.s64 = 3083;
	// addi r6,r11,-22772
	ctx.r6.s64 = r11.s64 + -22772;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_8245E48C:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8245e4c0
	if (!cr6.eq) goto loc_8245E4C0;
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245e4c0
	if (cr0.eq) goto loc_8245E4C0;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r30)
	PPC_STORE_U32(r30.u32 + 20, ctx.r3.u32);
	// bne 0x8245e4c0
	if (!cr0.eq) goto loc_8245E4C0;
loc_8245E4B4:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8245e548
	goto loc_8245E548;
loc_8245E4C0:
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8245e4e4
	if (!cr6.eq) goto loc_8245E4E4;
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r30)
	PPC_STORE_U32(r30.u32 + 28, ctx.r3.u32);
	// bne 0x8245e544
	if (!cr0.eq) goto loc_8245E544;
	// b 0x8245e4b4
	goto loc_8245E4B4;
loc_8245E4E4:
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245e544
	if (cr6.eq) goto loc_8245E544;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x8245e4b4
	if (cr0.eq) goto loc_8245E4B4;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245e534
	if (cr0.eq) goto loc_8245E534;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,28(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r6,r11,-23840
	ctx.r6.s64 = r11.s64 + -23840;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245e538
	goto loc_8245E538;
loc_8245E534:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245E538:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r30)
	PPC_STORE_U32(r30.u32 + 28, ctx.r3.u32);
	// beq cr6,0x8245e4b4
	if (cr6.eq) goto loc_8245E4B4;
loc_8245E544:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245E548:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245E550"))) PPC_WEAK_FUNC(sub_8245E550);
PPC_FUNC_IMPL(__imp__sub_8245E550) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce8
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x8245e598
	if (cr6.eq) goto loc_8245E598;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x8245e584
	if (!cr6.eq) goto loc_8245E584;
loc_8245E57C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8245e590
	goto loc_8245E590;
loc_8245E584:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x8245e5ac
	if (!cr6.eq) goto loc_8245E5AC;
loc_8245E58C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245E590:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8239bd38
	return;
loc_8245E598:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x8245e584
	if (!cr6.eq) goto loc_8245E584;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x8245e58c
	if (!cr6.eq) goto loc_8245E58C;
	// b 0x8245e57c
	goto loc_8245E57C;
loc_8245E5AC:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// li r30,4
	r30.s64 = 4;
	// li r31,1
	r31.s64 = 1;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245e5d8
	if (!cr6.eq) goto loc_8245E5D8;
	// mr r27,r26
	r27.u64 = r26.u64;
	// b 0x8245e614
	goto loc_8245E614;
loc_8245E5D8:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// stw r30,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r30.u32);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// stw r31,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r31.u32);
	// addi r27,r1,128
	r27.s64 = ctx.r1.s64 + 128;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// stw r3,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r3.u32);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x8245e614
	if (cr6.eq) goto loc_8245E614;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245e614
	if (cr0.eq) goto loc_8245E614;
	// stw r31,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r31.u32);
loc_8245E614:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245e628
	if (!cr6.eq) goto loc_8245E628;
	// mr r29,r25
	r29.u64 = r25.u64;
	// b 0x8245e664
	goto loc_8245E664;
loc_8245E628:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// addi r29,r1,80
	r29.s64 = ctx.r1.s64 + 80;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// stw r3,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r3.u32);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x8245e664
	if (cr6.eq) goto loc_8245E664;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245e664
	if (cr0.eq) goto loc_8245E664;
	// stw r31,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r31.u32);
loc_8245E664:
	// lwz r10,16(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// beq cr6,0x8245e880
	if (cr6.eq) goto loc_8245E880;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x8245e880
	if (cr6.eq) goto loc_8245E880;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8245e690
	if (!cr6.eq) goto loc_8245E690;
loc_8245E684:
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245e57c
	if (!cr6.eq) goto loc_8245E57C;
	// b 0x8245e58c
	goto loc_8245E58C;
loc_8245E690:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8245e71c
	if (!cr6.eq) goto loc_8245E71C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245e6bc
	if (!cr6.eq) goto loc_8245E6BC;
loc_8245E6A8:
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// lwz r10,32(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8245e57c
	if (!cr6.gt) goto loc_8245E57C;
	// b 0x8245e58c
	goto loc_8245E58C;
loc_8245E6BC:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8245e684
	if (!cr6.eq) goto loc_8245E684;
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x8245e6e0
	if (!cr6.eq) goto loc_8245E6E0;
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8245e58c
	if (cr6.gt) goto loc_8245E58C;
loc_8245E6E0:
	// lwz r11,32(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8245e6f8
	if (!cr6.eq) goto loc_8245E6F8;
	// lwz r9,32(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8245e58c
	if (cr6.gt) goto loc_8245E58C;
loc_8245E6F8:
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// lwz r9,32(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 32);
loc_8245E70C:
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// b 0x8245e58c
	goto loc_8245E58C;
loc_8245E71C:
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x8245e79c
	if (!cr6.eq) goto loc_8245E79C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245e780
	if (!cr6.eq) goto loc_8245E780;
	// lwz r10,28(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x8245e750
	if (!cr6.eq) goto loc_8245E750;
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8245e58c
	if (cr6.gt) goto loc_8245E58C;
loc_8245E750:
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8245e768
	if (!cr6.eq) goto loc_8245E768;
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8245e58c
	if (cr6.gt) goto loc_8245E58C;
loc_8245E768:
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// b 0x8245e70c
	goto loc_8245E70C;
loc_8245E780:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8245e684
	if (!cr6.eq) goto loc_8245E684;
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8245e58c
	if (cr6.gt) goto loc_8245E58C;
	// b 0x8245e6a8
	goto loc_8245E6A8;
loc_8245E79C:
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x8245e57c
	if (!cr6.eq) goto loc_8245E57C;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245e58c
	if (!cr6.eq) goto loc_8245E58C;
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// cmpwi cr6,r10,22
	cr6.compare<int32_t>(ctx.r10.s32, 22, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// addi r9,r11,-47
	ctx.r9.s64 = r11.s64 + -47;
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// bgt cr6,0x8245e7e0
	if (cr6.gt) goto loc_8245E7E0;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
	// addi r11,r10,-47
	r11.s64 = ctx.r10.s64 + -47;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x8245e590
	goto loc_8245E590;
loc_8245E7E0:
	// cmpwi cr6,r10,24
	cr6.compare<int32_t>(ctx.r10.s32, 24, xer);
	// bne cr6,0x8245e824
	if (!cr6.eq) goto loc_8245E824;
	// cmpwi cr6,r11,24
	cr6.compare<int32_t>(r11.s32, 24, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
loc_8245E81C:
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// b 0x8245e58c
	goto loc_8245E58C;
loc_8245E824:
	// cmpwi cr6,r10,33
	cr6.compare<int32_t>(ctx.r10.s32, 33, xer);
	// beq cr6,0x8245e83c
	if (cr6.eq) goto loc_8245E83C;
	// cmpwi cr6,r10,47
	cr6.compare<int32_t>(ctx.r10.s32, 47, xer);
	// beq cr6,0x8245e83c
	if (cr6.eq) goto loc_8245E83C;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// b 0x8245e81c
	goto loc_8245E81C;
loc_8245E83C:
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,34
	cr6.compare<int32_t>(r11.s32, 34, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,35
	cr6.compare<int32_t>(r11.s32, 35, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,36
	cr6.compare<int32_t>(r11.s32, 36, xer);
	// beq cr6,0x8245e864
	if (cr6.eq) goto loc_8245E864;
	// cmpwi cr6,r11,37
	cr6.compare<int32_t>(r11.s32, 37, xer);
	// bne cr6,0x8245e58c
	if (!cr6.eq) goto loc_8245E58C;
loc_8245E864:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lwz r5,24(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r4,24(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245e58c
	if (cr0.eq) goto loc_8245E58C;
	// b 0x8245e57c
	goto loc_8245E57C;
loc_8245E880:
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// lwz r9,28(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// lwz r8,32(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// lwz r7,28(r29)
	ctx.r7.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// mullw r30,r11,r9
	r30.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// mullw r11,r8,r7
	r11.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r7.s32);
	// beq cr6,0x8245e918
	if (cr6.eq) goto loc_8245E918;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bgt cr6,0x8245e58c
	if (cr6.gt) goto loc_8245E58C;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
loc_8245E8B4:
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245e58c
	if (cr0.lt) goto loc_8245E58C;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245e58c
	if (cr0.lt) goto loc_8245E58C;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245e58c
	if (cr0.eq) goto loc_8245E58C;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// blt cr6,0x8245e8b4
	if (cr6.lt) goto loc_8245E8B4;
	// b 0x8245e57c
	goto loc_8245E57C;
loc_8245E918:
	// lwz r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bne cr6,0x8245e58c
	if (!cr6.eq) goto loc_8245E58C;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x8245e58c
	if (!cr6.eq) goto loc_8245E58C;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245e57c
	if (cr6.eq) goto loc_8245E57C;
loc_8245E938:
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245e58c
	if (cr0.lt) goto loc_8245E58C;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245e58c
	if (cr0.lt) goto loc_8245E58C;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245e58c
	if (cr0.eq) goto loc_8245E58C;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// blt cr6,0x8245e938
	if (cr6.lt) goto loc_8245E938;
	// b 0x8245e57c
	goto loc_8245E57C;
}

__attribute__((alias("__imp__sub_8245E998"))) PPC_WEAK_FUNC(sub_8245E998);
PPC_FUNC_IMPL(__imp__sub_8245E998) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-832(r1)
	ea = -832 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x8245ed94
	if (!cr6.eq) goto loc_8245ED94;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245eac8
	if (cr6.eq) goto loc_8245EAC8;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8240ad78
	sub_8240AD78(ctx, base);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// li r31,4
	r31.s64 = 4;
	// li r28,1
	r28.s64 = 1;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245e9fc
	if (!cr6.eq) goto loc_8245E9FC;
	// mr r30,r26
	r30.u64 = r26.u64;
	// b 0x8245ea30
	goto loc_8245EA30;
loc_8245E9FC:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// stw r31,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r31.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r28,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r28.u32);
	// addi r30,r1,144
	r30.s64 = ctx.r1.s64 + 144;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// stw r3,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r3.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245ea30
	if (cr0.eq) goto loc_8245EA30;
	// stw r28,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r28.u32);
loc_8245EA30:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245ea44
	if (!cr6.eq) goto loc_8245EA44;
	// mr r29,r25
	r29.u64 = r25.u64;
	// b 0x8245ea78
	goto loc_8245EA78;
loc_8245EA44:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// stw r31,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, r31.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r28,220(r1)
	PPC_STORE_U32(ctx.r1.u32 + 220, r28.u32);
	// addi r29,r1,192
	r29.s64 = ctx.r1.s64 + 192;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// stw r3,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r3.u32);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245ea78
	if (cr0.eq) goto loc_8245EA78;
	// stw r28,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, r28.u32);
loc_8245EA78:
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// beq cr6,0x8245ecfc
	if (cr6.eq) goto loc_8245ECFC;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// beq cr6,0x8245ecfc
	if (cr6.eq) goto loc_8245ECFC;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8245eaa0
	if (!cr6.eq) goto loc_8245EAA0;
loc_8245EA98:
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// b 0x8245ed90
	goto loc_8245ED90;
loc_8245EAA0:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x8245eb88
	if (!cr6.eq) goto loc_8245EB88;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245eb28
	if (!cr6.eq) goto loc_8245EB28;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r10,32(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8245ed94
	if (!cr6.gt) goto loc_8245ED94;
loc_8245EAC8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r31,r11,-22556
	r31.s64 = r11.s64 + -22556;
loc_8245EAD0:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// li r5,255
	ctx.r5.s64 = 255;
	// addi r4,r1,240
	ctx.r4.s64 = ctx.r1.s64 + 240;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b700
	sub_8245B700(ctx, base);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// li r5,255
	ctx.r5.s64 = 255;
	// addi r4,r1,496
	ctx.r4.s64 = ctx.r1.s64 + 496;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b700
	sub_8245B700(ctx, base);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// li r5,3017
	ctx.r5.s64 = 3017;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bne cr6,0x8245eda0
	if (!cr6.eq) goto loc_8245EDA0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r9,r1,240
	ctx.r9.s64 = ctx.r1.s64 + 240;
	// addi r6,r11,-22592
	ctx.r6.s64 = r11.s64 + -22592;
	// addi r8,r1,496
	ctx.r8.s64 = ctx.r1.s64 + 496;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x8245edbc
	goto loc_8245EDBC;
loc_8245EB28:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8245ea98
	if (!cr6.eq) goto loc_8245EA98;
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x8245eb4c
	if (!cr6.eq) goto loc_8245EB4C;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8245eac8
	if (cr6.gt) goto loc_8245EAC8;
loc_8245EB4C:
	// lwz r11,32(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8245eb64
	if (!cr6.eq) goto loc_8245EB64;
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8245eac8
	if (cr6.gt) goto loc_8245EAC8;
loc_8245EB64:
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 32);
loc_8245EB78:
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x8245eac8
	if (!cr6.eq) goto loc_8245EAC8;
	// b 0x8245ed94
	goto loc_8245ED94;
loc_8245EB88:
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x8245ec18
	if (!cr6.eq) goto loc_8245EC18;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245ebec
	if (!cr6.eq) goto loc_8245EBEC;
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x8245ebbc
	if (!cr6.eq) goto loc_8245EBBC;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8245eac8
	if (cr6.gt) goto loc_8245EAC8;
loc_8245EBBC:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8245ebd4
	if (!cr6.eq) goto loc_8245EBD4;
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8245eac8
	if (cr6.gt) goto loc_8245EAC8;
loc_8245EBD4:
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// b 0x8245eb78
	goto loc_8245EB78;
loc_8245EBEC:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8245ea98
	if (!cr6.eq) goto loc_8245EA98;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8245eac8
	if (cr6.gt) goto loc_8245EAC8;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r10,32(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x8245ed94
	if (!cr6.gt) goto loc_8245ED94;
	// b 0x8245eac8
	goto loc_8245EAC8;
loc_8245EC18:
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x8245ed94
	if (!cr6.eq) goto loc_8245ED94;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245eac8
	if (!cr6.eq) goto loc_8245EAC8;
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// cmpwi cr6,r10,22
	cr6.compare<int32_t>(ctx.r10.s32, 22, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// addi r9,r11,-47
	ctx.r9.s64 = r11.s64 + -47;
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// bgt cr6,0x8245ec5c
	if (cr6.gt) goto loc_8245EC5C;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x8245ed94
	if (cr6.eq) goto loc_8245ED94;
	// addi r11,r10,-47
	r11.s64 = ctx.r10.s64 + -47;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x8245ed8c
	goto loc_8245ED8C;
loc_8245EC5C:
	// cmpwi cr6,r10,24
	cr6.compare<int32_t>(ctx.r10.s32, 24, xer);
	// bne cr6,0x8245ec9c
	if (!cr6.eq) goto loc_8245EC9C;
	// cmpwi cr6,r11,24
	cr6.compare<int32_t>(r11.s32, 24, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// b 0x8245ecdc
	goto loc_8245ECDC;
loc_8245EC9C:
	// cmpwi cr6,r10,33
	cr6.compare<int32_t>(ctx.r10.s32, 33, xer);
	// beq cr6,0x8245ecb8
	if (cr6.eq) goto loc_8245ECB8;
	// cmpwi cr6,r10,47
	cr6.compare<int32_t>(ctx.r10.s32, 47, xer);
	// beq cr6,0x8245ecb8
	if (cr6.eq) goto loc_8245ECB8;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// b 0x8245eac8
	goto loc_8245EAC8;
loc_8245ECB8:
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,34
	cr6.compare<int32_t>(r11.s32, 34, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,35
	cr6.compare<int32_t>(r11.s32, 35, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,36
	cr6.compare<int32_t>(r11.s32, 36, xer);
	// beq cr6,0x8245ece0
	if (cr6.eq) goto loc_8245ECE0;
	// cmpwi cr6,r11,37
	cr6.compare<int32_t>(r11.s32, 37, xer);
loc_8245ECDC:
	// bne cr6,0x8245eac8
	if (!cr6.eq) goto loc_8245EAC8;
loc_8245ECE0:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,24(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245eac8
	if (cr0.eq) goto loc_8245EAC8;
	// b 0x8245ed94
	goto loc_8245ED94;
loc_8245ECFC:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// lwz r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// mullw r30,r11,r10
	r30.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// mullw r11,r9,r11
	r11.s64 = int64_t(ctx.r9.s32) * int64_t(r11.s32);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bgt cr6,0x8245eac8
	if (cr6.gt) goto loc_8245EAC8;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245ed88
	if (cr6.eq) goto loc_8245ED88;
loc_8245ED28:
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245eac8
	if (cr0.lt) goto loc_8245EAC8;
	// addi r6,r1,192
	ctx.r6.s64 = ctx.r1.s64 + 192;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245bb28
	sub_8245BB28(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245eac8
	if (cr0.lt) goto loc_8245EAC8;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245eac8
	if (cr0.eq) goto loc_8245EAC8;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// blt cr6,0x8245ed28
	if (cr6.lt) goto loc_8245ED28;
loc_8245ED88:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8245ED8C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
loc_8245ED90:
	// beq cr6,0x8245eac8
	if (cr6.eq) goto loc_8245EAC8;
loc_8245ED94:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r31,r11,9120
	r31.s64 = r11.s64 + 9120;
	// b 0x8245ead0
	goto loc_8245EAD0;
loc_8245EDA0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// addi r6,r11,-22636
	ctx.r6.s64 = r11.s64 + -22636;
	// addi r9,r1,496
	ctx.r9.s64 = ctx.r1.s64 + 496;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_8245EDBC:
	// addi r1,r1,832
	ctx.r1.s64 = ctx.r1.s64 + 832;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_8245EDC4"))) PPC_WEAK_FUNC(sub_8245EDC4);
PPC_FUNC_IMPL(__imp__sub_8245EDC4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245EDC8"))) PPC_WEAK_FUNC(sub_8245EDC8);
PPC_FUNC_IMPL(__imp__sub_8245EDC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r27,r8
	r27.u64 = ctx.r8.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8245ef58
	if (cr6.eq) goto loc_8245EF58;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8245ef58
	if (cr6.eq) goto loc_8245EF58;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// beq cr6,0x8245ee14
	if (cr6.eq) goto loc_8245EE14;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
loc_8245EE14:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8245ee2c
	if (!cr6.eq) goto loc_8245EE2C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x8245ef58
	if (!cr6.eq) goto loc_8245EF58;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245ef60
	goto loc_8245EF60;
loc_8245EE2C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8245ef58
	if (cr6.eq) goto loc_8245EF58;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// cmplw cr6,r31,r3
	cr6.compare<uint32_t>(r31.u32, ctx.r3.u32, xer);
	// blt cr6,0x8245ee74
	if (cr6.lt) goto loc_8245EE74;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8245eeb4
	if (!cr0.eq) goto loc_8245EEB4;
loc_8245EE74:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245ee98
	if (cr0.eq) goto loc_8245EE98;
	// mr r31,r29
	r31.u64 = r29.u64;
	// b 0x8245eeb8
	goto loc_8245EEB8;
loc_8245EE98:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8245ef58
	if (cr0.eq) goto loc_8245EF58;
loc_8245EEB4:
	// mr r31,r30
	r31.u64 = r30.u64;
loc_8245EEB8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82459690
	sub_82459690(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8245ef60
	if (cr0.lt) goto loc_8245EF60;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// beq cr6,0x8245ef14
	if (cr6.eq) goto loc_8245EF14;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x8245ef0c
	if (!cr0.eq) goto loc_8245EF0C;
loc_8245EF00:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8245ef60
	goto loc_8245EF60;
loc_8245EF0C:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r30,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r30.u32);
loc_8245EF14:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8245ef48
	if (cr6.eq) goto loc_8245EF48;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr. r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// stw r4,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r4.u32);
	// beq 0x8245ef00
	if (cr0.eq) goto loc_8245EF00;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
loc_8245EF48:
	// stw r31,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r31.u32);
	// b 0x8245ef60
	goto loc_8245EF60;
loc_8245EF58:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8245EF60:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_8245EF68"))) PPC_WEAK_FUNC(sub_8245EF68);
PPC_FUNC_IMPL(__imp__sub_8245EF68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// li r29,2
	r29.s64 = 2;
	// cmpwi cr6,r31,5
	cr6.compare<int32_t>(r31.s32, 5, xer);
	// bgt cr6,0x8245eff4
	if (cr6.gt) goto loc_8245EFF4;
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// bge cr6,0x8245efec
	if (!cr6.lt) goto loc_8245EFEC;
	// cmplwi cr6,r31,1
	cr6.compare<uint32_t>(r31.u32, 1, xer);
	// blt cr6,0x8245efe4
	if (cr6.lt) goto loc_8245EFE4;
	// bne cr6,0x8245efb0
	if (!cr6.eq) goto loc_8245EFB0;
loc_8245EFAC:
	// li r29,2
	r29.s64 = 2;
loc_8245EFB0:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f014
	if (cr0.eq) goto loc_8245F014;
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8245f018
	goto loc_8245F018;
loc_8245EFE4:
	// li r29,0
	r29.s64 = 0;
	// b 0x8245efb0
	goto loc_8245EFB0;
loc_8245EFEC:
	// li r29,1
	r29.s64 = 1;
	// b 0x8245efb0
	goto loc_8245EFB0;
loc_8245EFF4:
	// cmpwi cr6,r31,6
	cr6.compare<int32_t>(r31.s32, 6, xer);
	// blt cr6,0x8245efb0
	if (cr6.lt) goto loc_8245EFB0;
	// cmpwi cr6,r31,9
	cr6.compare<int32_t>(r31.s32, 9, xer);
	// ble cr6,0x8245efac
	if (!cr6.gt) goto loc_8245EFAC;
	// cmpwi cr6,r31,13
	cr6.compare<int32_t>(r31.s32, 13, xer);
	// bgt cr6,0x8245efb0
	if (cr6.gt) goto loc_8245EFB0;
	// li r29,3
	r29.s64 = 3;
	// b 0x8245efb0
	goto loc_8245EFB0;
loc_8245F014:
	// li r30,0
	r30.s64 = 0;
loc_8245F018:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8245f028
	if (!cr6.eq) goto loc_8245F028;
loc_8245F020:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245f114
	goto loc_8245F114;
loc_8245F028:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f058
	if (cr0.eq) goto loc_8245F058;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8245f05c
	goto loc_8245F05C;
loc_8245F058:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F05C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8245f020
	if (cr6.eq) goto loc_8245F020;
	// cmpwi cr6,r29,3
	cr6.compare<int32_t>(r29.s32, 3, xer);
	// li r3,64
	ctx.r3.s64 = 64;
	// bne cr6,0x8245f094
	if (!cr6.eq) goto loc_8245F094;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f0b4
	if (cr0.eq) goto loc_8245F0B4;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8240c528
	sub_8240C528(ctx, base);
	// b 0x8245f0b8
	goto loc_8245F0B8;
loc_8245F094:
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f0b4
	if (cr0.eq) goto loc_8245F0B4;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x8245f0b8
	goto loc_8245F0B8;
loc_8245F0B4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F0B8:
	// rotlwi r11,r3,0
	r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245f020
	if (cr6.eq) goto loc_8245F020;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f0f4
	if (cr0.eq) goto loc_8245F0F4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245f0f8
	goto loc_8245F0F8;
loc_8245F0F4:
	// li r11,0
	r11.s64 = 0;
loc_8245F0F8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245f020
	if (cr6.eq) goto loc_8245F020;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8245F114:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8245F120"))) PPC_WEAK_FUNC(sub_8245F120);
PPC_FUNC_IMPL(__imp__sub_8245F120) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r7,r3,40
	ctx.r7.s64 = ctx.r3.s64 + 40;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// lfd f1,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// li r11,6
	r11.s64 = 6;
	// beq cr6,0x8245f1e0
	if (cr6.eq) goto loc_8245F1E0;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// bne cr6,0x8245f1e0
	if (!cr6.eq) goto loc_8245F1E0;
	// addi r7,r4,16
	ctx.r7.s64 = ctx.r4.s64 + 16;
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x8245f1d8
	if (cr6.eq) goto loc_8245F1D8;
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beq cr6,0x8245f1c0
	if (cr6.eq) goto loc_8245F1C0;
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// beq cr6,0x8245f1b8
	if (cr6.eq) goto loc_8245F1B8;
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// beq cr6,0x8245f1ac
	if (cr6.eq) goto loc_8245F1AC;
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// beq cr6,0x8245f1a0
	if (cr6.eq) goto loc_8245F1A0;
	// cmpwi cr6,r10,7
	cr6.compare<int32_t>(ctx.r10.s32, 7, xer);
	// beq cr6,0x8245f194
	if (cr6.eq) goto loc_8245F194;
	// cmpwi cr6,r10,8
	cr6.compare<int32_t>(ctx.r10.s32, 8, xer);
	// bne cr6,0x8245f1e0
	if (!cr6.eq) goto loc_8245F1E0;
	// lfd f1,8(r7)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// li r11,13
	r11.s64 = 13;
	// b 0x8245f1e0
	goto loc_8245F1E0;
loc_8245F194:
	// lfd f1,8(r7)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// li r11,12
	r11.s64 = 12;
	// b 0x8245f1e0
	goto loc_8245F1E0;
loc_8245F1A0:
	// lfd f1,8(r7)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// li r11,11
	r11.s64 = 11;
	// b 0x8245f1e0
	goto loc_8245F1E0;
loc_8245F1AC:
	// lfd f1,8(r7)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// li r11,10
	r11.s64 = 10;
	// b 0x8245f1e0
	goto loc_8245F1E0;
loc_8245F1B8:
	// li r11,9
	r11.s64 = 9;
	// b 0x8245f1dc
	goto loc_8245F1DC;
loc_8245F1C0:
	// lwz r5,8(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// li r11,5
	r11.s64 = 5;
	// rlwinm. r10,r5,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8245f1e0
	if (!cr0.eq) goto loc_8245F1E0;
	// li r11,1
	r11.s64 = 1;
	// b 0x8245f1e0
	goto loc_8245F1E0;
loc_8245F1D8:
	// li r11,6
	r11.s64 = 6;
loc_8245F1DC:
	// lwz r5,8(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
loc_8245F1E0:
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// b 0x8245ef68
	sub_8245EF68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8245F1E8"))) PPC_WEAK_FUNC(sub_8245F1E8);
PPC_FUNC_IMPL(__imp__sub_8245F1E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x8245f208
	if (!cr6.eq) goto loc_8245F208;
loc_8245F200:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245f334
	goto loc_8245F334;
loc_8245F208:
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r31,r4,16
	r31.s64 = ctx.r4.s64 + 16;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f240
	if (cr0.eq) goto loc_8245F240;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8245f244
	goto loc_8245F244;
loc_8245F240:
	// li r30,0
	r30.s64 = 0;
loc_8245F244:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245f200
	if (cr6.eq) goto loc_8245F200;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f27c
	if (cr0.eq) goto loc_8245F27C;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,23
	ctx.r5.s64 = 23;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8245f280
	goto loc_8245F280;
loc_8245F27C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F280:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8245f200
	if (cr6.eq) goto loc_8245F200;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f2d8
	if (cr0.eq) goto loc_8245F2D8;
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8245F2A8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8245f2a8
	if (!cr6.eq) goto loc_8245F2A8;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// li r4,5
	ctx.r4.s64 = 5;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r6,r11,1
	ctx.r6.s64 = r11.s64 + 1;
	// bl 0x8240c580
	sub_8240C580(ctx, base);
	// b 0x8245f2dc
	goto loc_8245F2DC;
loc_8245F2D8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F2DC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq cr6,0x8245f200
	if (cr6.eq) goto loc_8245F200;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f314
	if (cr0.eq) goto loc_8245F314;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245f318
	goto loc_8245F318;
loc_8245F314:
	// li r11,0
	r11.s64 = 0;
loc_8245F318:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245f200
	if (cr6.eq) goto loc_8245F200;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8245F334:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245F33C"))) PPC_WEAK_FUNC(sub_8245F33C);
PPC_FUNC_IMPL(__imp__sub_8245F33C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245F340"))) PPC_WEAK_FUNC(sub_8245F340);
PPC_FUNC_IMPL(__imp__sub_8245F340) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r3,80
	ctx.r3.s64 = 80;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f388
	if (cr0.eq) goto loc_8245F388;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245f38c
	goto loc_8245F38C;
loc_8245F388:
	// li r31,0
	r31.s64 = 0;
loc_8245F38C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8245f39c
	if (!cr6.eq) goto loc_8245F39C;
loc_8245F394:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245f460
	goto loc_8245F460;
loc_8245F39C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f3cc
	if (cr0.eq) goto loc_8245F3CC;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,22
	ctx.r5.s64 = 22;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8245f3d0
	goto loc_8245F3D0;
loc_8245F3CC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F3D0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8245f394
	if (cr6.eq) goto loc_8245F394;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f404
	if (cr0.eq) goto loc_8245F404;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,5
	ctx.r4.s64 = 5;
	// bl 0x8240c580
	sub_8240C580(ctx, base);
	// b 0x8245f408
	goto loc_8245F408;
loc_8245F404:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F408:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq cr6,0x8245f394
	if (cr6.eq) goto loc_8245F394;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f440
	if (cr0.eq) goto loc_8245F440;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245f444
	goto loc_8245F444;
loc_8245F440:
	// li r11,0
	r11.s64 = 0;
loc_8245F444:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245f394
	if (cr6.eq) goto loc_8245F394;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8245F460:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8245F468"))) PPC_WEAK_FUNC(sub_8245F468);
PPC_FUNC_IMPL(__imp__sub_8245F468) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// b 0x8245f488
	goto loc_8245F488;
loc_8245F484:
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
loc_8245F488:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245f484
	if (!cr6.eq) goto loc_8245F484;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f4c8
	if (cr0.eq) goto loc_8245F4C8;
	// addi r9,r31,16
	ctx.r9.s64 = r31.s64 + 16;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x8245f4cc
	goto loc_8245F4CC;
loc_8245F4C8:
	// li r29,0
	r29.s64 = 0;
loc_8245F4CC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x8245f4dc
	if (!cr6.eq) goto loc_8245F4DC;
loc_8245F4D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245f5b4
	goto loc_8245F5B4;
loc_8245F4DC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8245f504
	if (cr6.eq) goto loc_8245F504;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r29)
	PPC_STORE_U32(r29.u32 + 32, ctx.r3.u32);
	// beq 0x8245f4d4
	if (cr0.eq) goto loc_8245F4D4;
loc_8245F504:
	// lwz r28,32(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// addi r30,r29,16
	r30.s64 = r29.s64 + 16;
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x8245f5a4
	if (cr0.eq) goto loc_8245F5A4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r27,r11,-22536
	r27.s64 = r11.s64 + -22536;
loc_8245F51C:
	// lwz r31,8(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x8245f598
	if (cr0.eq) goto loc_8245F598;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8245f598
	if (!cr6.eq) goto loc_8245F598;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245f598
	if (cr6.eq) goto loc_8245F598;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f564
	if (cr0.eq) goto loc_8245F564;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245f568
	goto loc_8245F568;
loc_8245F564:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F568:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x8245f4d4
	if (cr6.eq) goto loc_8245F4D4;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8245f4d4
	if (cr6.eq) goto loc_8245F4D4;
	// addi r30,r11,12
	r30.s64 = r11.s64 + 12;
loc_8245F598:
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// bne 0x8245f51c
	if (!cr0.eq) goto loc_8245F51C;
loc_8245F5A4:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_8245F5B4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_8245F5BC"))) PPC_WEAK_FUNC(sub_8245F5BC);
PPC_FUNC_IMPL(__imp__sub_8245F5BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245F5C0"))) PPC_WEAK_FUNC(sub_8245F5C0);
PPC_FUNC_IMPL(__imp__sub_8245F5C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// mr r15,r4
	r15.u64 = ctx.r4.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8245f6ec
	if (cr6.eq) goto loc_8245F6EC;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8245f6ec
	if (!cr6.eq) goto loc_8245F6EC;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x8245f6ec
	if (cr6.eq) goto loc_8245F6EC;
	// lwz r11,4(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8245f6ec
	if (!cr6.eq) goto loc_8245F6EC;
	// li r3,80
	ctx.r3.s64 = 80;
	// lwz r21,16(r15)
	r21.u64 = PPC_LOAD_U32(r15.u32 + 16);
	// addi r17,r5,16
	r17.s64 = ctx.r5.s64 + 16;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f638
	if (cr0.eq) goto loc_8245F638;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,29
	ctx.r5.s64 = 29;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// b 0x8245f63c
	goto loc_8245F63C;
loc_8245F638:
	// li r16,0
	r16.s64 = 0;
loc_8245F63C:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x8245f6ec
	if (cr6.eq) goto loc_8245F6EC;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8245f6d0
	if (cr6.eq) goto loc_8245F6D0;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245f754
	if (!cr6.eq) goto loc_8245F754;
	// li r30,0
	r30.s64 = 0;
	// mr r31,r21
	r31.u64 = r21.u64;
loc_8245F660:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8245f6c4
	if (cr0.eq) goto loc_8245F6C4;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x8245f6c4
	if (!cr6.eq) goto loc_8245F6C4;
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// lwz r7,24(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r11,8(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// lwz r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
loc_8245F688:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8245f6ac
	if (cr0.eq) goto loc_8245F6AC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8245f688
	if (cr6.eq) goto loc_8245F688;
loc_8245F6AC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8245f6f8
	if (cr0.eq) goto loc_8245F6F8;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// lwz r4,48(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// add r30,r3,r30
	r30.u64 = ctx.r3.u64 + r30.u64;
loc_8245F6C4:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x8245f660
	if (!cr0.eq) goto loc_8245F660;
loc_8245F6D0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r17)
	ctx.r7.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// li r5,3018
	ctx.r5.s64 = 3018;
	// addi r6,r11,-22520
	ctx.r6.s64 = r11.s64 + -22520;
	// mr r4,r17
	ctx.r4.u64 = r17.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_8245F6EC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F6F0:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x8239bd10
	return;
loc_8245F6F8:
	// lwz r11,48(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245f724
	if (cr6.eq) goto loc_8245F724;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r16)
	PPC_STORE_U32(r16.u32 + 16, ctx.r3.u32);
	// beq 0x8245f6ec
	if (cr0.eq) goto loc_8245F6EC;
loc_8245F724:
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245f748
	if (cr0.eq) goto loc_8245F748;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x8245f74c
	goto loc_8245F74C;
loc_8245F748:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245F74C:
	// stw r3,36(r16)
	PPC_STORE_U32(r16.u32 + 36, ctx.r3.u32);
	// b 0x8245fb0c
	goto loc_8245FB0C;
loc_8245F754:
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
	// lwz r11,36(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 36);
	// lwz r31,8(r17)
	r31.u64 = PPC_LOAD_U32(r17.u32 + 8);
	// rlwinm r18,r11,0,22,22
	r18.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// lwz r19,28(r21)
	r19.u64 = PPC_LOAD_U32(r21.u32 + 28);
	// mr r11,r31
	r11.u64 = r31.u64;
	// lwz r20,32(r21)
	r20.u64 = PPC_LOAD_U32(r21.u32 + 32);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8245F778:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8245f778
	if (!cr6.eq) goto loc_8245F778;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// addi r9,r11,-1
	ctx.r9.s64 = r11.s64 + -1;
	// extsb r11,r10
	r11.s64 = ctx.r10.s8;
	// rotlwi r10,r9,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// cmpwi cr6,r11,95
	cr6.compare<int32_t>(r11.s32, 95, xer);
	// add r25,r10,r31
	r25.u64 = ctx.r10.u64 + r31.u64;
	// beq cr6,0x8245f80c
	if (cr6.eq) goto loc_8245F80C;
	// cmpwi cr6,r11,96
	cr6.compare<int32_t>(r11.s32, 96, xer);
	// ble cr6,0x8245f6d0
	if (!cr6.gt) goto loc_8245F6D0;
	// cmpwi cr6,r11,98
	cr6.compare<int32_t>(r11.s32, 98, xer);
	// ble cr6,0x8245f7f0
	if (!cr6.gt) goto loc_8245F7F0;
	// cmpwi cr6,r11,103
	cr6.compare<int32_t>(r11.s32, 103, xer);
	// beq cr6,0x8245f7f0
	if (cr6.eq) goto loc_8245F7F0;
	// cmpwi cr6,r11,114
	cr6.compare<int32_t>(r11.s32, 114, xer);
	// beq cr6,0x8245f7f0
	if (cr6.eq) goto loc_8245F7F0;
	// addi r11,r11,-119
	r11.s64 = r11.s64 + -119;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bgt cr6,0x8245f6d0
	if (cr6.gt) goto loc_8245F6D0;
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245f7e8
	if (cr0.eq) goto loc_8245F7E8;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
loc_8245F7E8:
	// li r24,0
	r24.s64 = 0;
	// b 0x8245f838
	goto loc_8245F838;
loc_8245F7F0:
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8245f804
	if (cr0.eq) goto loc_8245F804;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
loc_8245F804:
	// li r24,1
	r24.s64 = 1;
	// b 0x8245f838
	goto loc_8245F838;
loc_8245F80C:
	// lwz r11,16(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bge cr6,0x8245f834
	if (!cr6.lt) goto loc_8245F834;
	// lbz r11,0(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// li r24,3
	r24.s64 = 3;
	// cmplwi cr6,r11,109
	cr6.compare<uint32_t>(r11.u32, 109, xer);
	// beq cr6,0x8245f838
	if (cr6.eq) goto loc_8245F838;
loc_8245F834:
	// li r24,2
	r24.s64 = 2;
loc_8245F838:
	// addi r22,r16,36
	r22.s64 = r16.s64 + 36;
	// li r26,0
	r26.s64 = 0;
	// cmplw cr6,r31,r25
	cr6.compare<uint32_t>(r31.u32, r25.u32, xer);
	// mr r27,r22
	r27.u64 = r22.u64;
	// bge cr6,0x8245fa6c
	if (!cr6.lt) goto loc_8245FA6C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r29,r31,2
	r29.s64 = r31.s64 + 2;
	// addi r28,r31,3
	r28.s64 = r31.s64 + 3;
	// addi r23,r11,-22528
	r23.s64 = r11.s64 + -22528;
loc_8245F85C:
	// cmplwi cr6,r26,4
	cr6.compare<uint32_t>(r26.u32, 4, xer);
	// bge cr6,0x8245fa5c
	if (!cr6.lt) goto loc_8245FA5C;
	// li r11,0
	r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r24,1
	cr6.compare<uint32_t>(r24.u32, 1, xer);
	// blt cr6,0x8245f978
	if (cr6.lt) goto loc_8245F978;
	// beq cr6,0x8245f948
	if (cr6.eq) goto loc_8245F948;
	// cmplwi cr6,r24,3
	cr6.compare<uint32_t>(r24.u32, 3, xer);
	// blt cr6,0x8245f8ec
	if (cr6.lt) goto loc_8245F8EC;
	// bne cr6,0x8245f9c4
	if (!cr6.eq) goto loc_8245F9C4;
	// cmplw cr6,r28,r25
	cr6.compare<uint32_t>(r28.u32, r25.u32, xer);
	// bge cr6,0x8245f6d0
	if (!cr6.lt) goto loc_8245F6D0;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,95
	cr6.compare<uint32_t>(r11.u32, 95, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// cmplwi cr6,r11,109
	cr6.compare<uint32_t>(r11.u32, 109, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,48
	cr6.compare<int32_t>(r11.s32, 48, xer);
	// blt cr6,0x8245f6d0
	if (cr6.lt) goto loc_8245F6D0;
	// cmpwi cr6,r11,57
	cr6.compare<int32_t>(r11.s32, 57, xer);
	// bgt cr6,0x8245f6d0
	if (cr6.gt) goto loc_8245F6D0;
	// lbz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,48
	cr6.compare<int32_t>(ctx.r10.s32, 48, xer);
	// blt cr6,0x8245f6d0
	if (cr6.lt) goto loc_8245F6D0;
	// cmpwi cr6,r10,57
	cr6.compare<int32_t>(ctx.r10.s32, 57, xer);
	// bgt cr6,0x8245f6d0
	if (cr6.gt) goto loc_8245F6D0;
	// addi r11,r11,-48
	r11.s64 = r11.s64 + -48;
	// addi r10,r10,-48
	ctx.r10.s64 = ctx.r10.s64 + -48;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// b 0x8245f9c4
	goto loc_8245F9C4;
loc_8245F8EC:
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// bge cr6,0x8245f6d0
	if (!cr6.lt) goto loc_8245F6D0;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,95
	cr6.compare<uint32_t>(r11.u32, 95, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x8245f6d0
	if (cr6.lt) goto loc_8245F6D0;
	// cmpwi cr6,r11,57
	cr6.compare<int32_t>(r11.s32, 57, xer);
	// bgt cr6,0x8245f6d0
	if (cr6.gt) goto loc_8245F6D0;
	// lbz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,49
	cr6.compare<int32_t>(ctx.r10.s32, 49, xer);
	// blt cr6,0x8245f6d0
	if (cr6.lt) goto loc_8245F6D0;
	// cmpwi cr6,r10,57
	cr6.compare<int32_t>(ctx.r10.s32, 57, xer);
	// bgt cr6,0x8245f6d0
	if (cr6.gt) goto loc_8245F6D0;
	// addi r11,r11,-49
	r11.s64 = r11.s64 + -49;
	// addi r10,r10,-49
	ctx.r10.s64 = ctx.r10.s64 + -49;
	// addi r31,r31,3
	r31.s64 = r31.s64 + 3;
	// addi r28,r28,3
	r28.s64 = r28.s64 + 3;
	// addi r29,r29,3
	r29.s64 = r29.s64 + 3;
	// b 0x8245f9c4
	goto loc_8245F9C4;
loc_8245F948:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,97
	cr6.compare<int32_t>(r11.s32, 97, xer);
	// beq cr6,0x8245f9b0
	if (cr6.eq) goto loc_8245F9B0;
	// cmpwi cr6,r11,98
	cr6.compare<int32_t>(r11.s32, 98, xer);
	// beq cr6,0x8245f9a0
	if (cr6.eq) goto loc_8245F9A0;
	// cmpwi cr6,r11,103
	cr6.compare<int32_t>(r11.s32, 103, xer);
	// beq cr6,0x8245f9a8
	if (cr6.eq) goto loc_8245F9A8;
	// cmpwi cr6,r11,114
	cr6.compare<int32_t>(r11.s32, 114, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
loc_8245F970:
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x8245f9b4
	goto loc_8245F9B4;
loc_8245F978:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,119
	cr6.compare<int32_t>(r11.s32, 119, xer);
	// beq cr6,0x8245f9b0
	if (cr6.eq) goto loc_8245F9B0;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// beq cr6,0x8245f970
	if (cr6.eq) goto loc_8245F970;
	// cmpwi cr6,r11,121
	cr6.compare<int32_t>(r11.s32, 121, xer);
	// beq cr6,0x8245f9a8
	if (cr6.eq) goto loc_8245F9A8;
	// cmpwi cr6,r11,122
	cr6.compare<int32_t>(r11.s32, 122, xer);
	// bne cr6,0x8245f6d0
	if (!cr6.eq) goto loc_8245F6D0;
loc_8245F9A0:
	// li r10,2
	ctx.r10.s64 = 2;
	// b 0x8245f9b4
	goto loc_8245F9B4;
loc_8245F9A8:
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x8245f9b4
	goto loc_8245F9B4;
loc_8245F9B0:
	// li r10,3
	ctx.r10.s64 = 3;
loc_8245F9B4:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// li r11,0
	r11.s64 = 0;
loc_8245F9C4:
	// cmplw cr6,r11,r19
	cr6.compare<uint32_t>(r11.u32, r19.u32, xer);
	// bge cr6,0x8245f6d0
	if (!cr6.lt) goto loc_8245F6D0;
	// cmplw cr6,r10,r20
	cr6.compare<uint32_t>(ctx.r10.u32, r20.u32, xer);
	// bge cr6,0x8245f6d0
	if (!cr6.lt) goto loc_8245F6D0;
	// mullw r11,r11,r20
	r11.s64 = int64_t(r11.s32) * int64_t(r20.s32);
	// li r3,20
	ctx.r3.s64 = 20;
	// add r30,r11,r10
	r30.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fa00
	if (cr0.eq) goto loc_8245FA00;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8245fa04
	goto loc_8245FA04;
loc_8245FA00:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245FA04:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
	// beq cr6,0x8245f6ec
	if (cr6.eq) goto loc_8245F6EC;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fa34
	if (cr0.eq) goto loc_8245FA34;
	// mr r6,r17
	ctx.r6.u64 = r17.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x8245fa38
	goto loc_8245FA38;
loc_8245FA34:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245FA38:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// beq cr6,0x8245f6ec
	if (cr6.eq) goto loc_8245F6EC;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmplw cr6,r31,r25
	cr6.compare<uint32_t>(r31.u32, r25.u32, xer);
	// addi r27,r11,12
	r27.s64 = r11.s64 + 12;
	// blt cr6,0x8245f85c
	if (cr6.lt) goto loc_8245F85C;
loc_8245FA5C:
	// cmplw cr6,r31,r25
	cr6.compare<uint32_t>(r31.u32, r25.u32, xer);
	// blt cr6,0x8245f6d0
	if (cr6.lt) goto loc_8245F6D0;
	// cmplwi cr6,r26,4
	cr6.compare<uint32_t>(r26.u32, 4, xer);
	// bgt cr6,0x8245f6d0
	if (cr6.gt) goto loc_8245F6D0;
loc_8245FA6C:
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8245fac0
	if (cr0.eq) goto loc_8245FAC0;
loc_8245FA78:
	// cmpwi cr6,r18,0
	cr6.compare<int32_t>(r18.s32, 0, xer);
	// bne cr6,0x8245fac0
	if (!cr6.eq) goto loc_8245FAC0;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr. r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8245fab8
	if (cr0.eq) goto loc_8245FAB8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_8245FA94:
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r8,24(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x8245fab4
	if (cr6.eq) goto loc_8245FAB4;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne 0x8245fa94
	if (!cr0.eq) goto loc_8245FA94;
	// b 0x8245fab8
	goto loc_8245FAB8;
loc_8245FAB4:
	// li r18,1
	r18.s64 = 1;
loc_8245FAB8:
	// mr. r11,r9
	r11.u64 = ctx.r9.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8245fa78
	if (!cr0.eq) goto loc_8245FA78;
loc_8245FAC0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fb04
	if (cr0.eq) goto loc_8245FB04;
	// subfic r11,r18,0
	xer.ca = r18.u32 <= 0;
	r11.s64 = 0 - r18.s64;
	// lwz r5,20(r21)
	ctx.r5.u64 = PPC_LOAD_U32(r21.u32 + 20);
	// addi r10,r26,-1
	ctx.r10.s64 = r26.s64 + -1;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r9,r11,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// rlwinm r11,r10,27,31,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// xori r4,r11,1
	ctx.r4.u64 = r11.u64 ^ 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8245fb08
	goto loc_8245FB08;
loc_8245FB04:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245FB08:
	// stw r3,16(r16)
	PPC_STORE_U32(r16.u32 + 16, ctx.r3.u32);
loc_8245FB0C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8245f6ec
	if (cr6.eq) goto loc_8245F6EC;
	// lwz r11,0(r15)
	r11.u64 = PPC_LOAD_U32(r15.u32 + 0);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r16)
	PPC_STORE_U32(r16.u32 + 32, ctx.r3.u32);
	// beq 0x8245f6d0
	if (cr0.eq) goto loc_8245F6D0;
	// mr r4,r16
	ctx.r4.u64 = r16.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// b 0x8245f6f0
	goto loc_8245F6F0;
}

__attribute__((alias("__imp__sub_8245FB48"))) PPC_WEAK_FUNC(sub_8245FB48);
PPC_FUNC_IMPL(__imp__sub_8245FB48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8245fd00
	if (cr6.eq) goto loc_8245FD00;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x8245fb84
	if (!cr6.eq) goto loc_8245FB84;
	// lwz r11,116(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 116);
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// b 0x8245fd04
	goto loc_8245FD04;
loc_8245FB84:
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// bne cr6,0x8245fd00
	if (!cr6.eq) goto loc_8245FD00;
	// lwz r11,48(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8245fd00
	if (cr0.eq) goto loc_8245FD00;
	// lwz r10,52(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 52);
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// blt cr6,0x8245fd00
	if (cr6.lt) goto loc_8245FD00;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lis r10,4138
	ctx.r10.s64 = 271187968;
	// ori r10,r10,4352
	ctx.r10.u64 = ctx.r10.u64 | 4352;
	// rlwinm r9,r11,0,0,23
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF00;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x8245fbd0
	if (!cr6.eq) goto loc_8245FBD0;
	// clrlwi r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x8245fbf4
	if (cr6.eq) goto loc_8245FBF4;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8245fbec
	if (cr6.eq) goto loc_8245FBEC;
loc_8245FBD0:
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8245fbf4
	if (cr6.eq) goto loc_8245FBF4;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8245fd00
	if (!cr6.eq) goto loc_8245FD00;
loc_8245FBEC:
	// li r30,42
	r30.s64 = 42;
	// b 0x8245fbf8
	goto loc_8245FBF8;
loc_8245FBF4:
	// li r30,43
	r30.s64 = 43;
loc_8245FBF8:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fc2c
	if (cr0.eq) goto loc_8245FC2C;
	// addi r9,r29,16
	ctx.r9.s64 = r29.s64 + 16;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245fc30
	goto loc_8245FC30;
loc_8245FC2C:
	// li r31,0
	r31.s64 = 0;
loc_8245FC30:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245fd00
	if (cr6.eq) goto loc_8245FD00;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fc68
	if (cr0.eq) goto loc_8245FC68;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8245fc6c
	goto loc_8245FC6C;
loc_8245FC68:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245FC6C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8245fd00
	if (cr6.eq) goto loc_8245FD00;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fca0
	if (cr0.eq) goto loc_8245FCA0;
	// addi r7,r29,16
	ctx.r7.s64 = r29.s64 + 16;
	// lwz r6,52(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 52);
	// li r4,5
	ctx.r4.s64 = 5;
	// lwz r5,48(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// bl 0x8240c580
	sub_8240C580(ctx, base);
	// b 0x8245fca4
	goto loc_8245FCA4;
loc_8245FCA0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245FCA4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq cr6,0x8245fd00
	if (cr6.eq) goto loc_8245FD00;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fcdc
	if (cr0.eq) goto loc_8245FCDC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245fce0
	goto loc_8245FCE0;
loc_8245FCDC:
	// li r11,0
	r11.s64 = 0;
loc_8245FCE0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245fd00
	if (cr6.eq) goto loc_8245FD00;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x8245fd04
	goto loc_8245FD04;
loc_8245FD00:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245FD04:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8245FD0C"))) PPC_WEAK_FUNC(sub_8245FD0C);
PPC_FUNC_IMPL(__imp__sub_8245FD0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245FD10"))) PPC_WEAK_FUNC(sub_8245FD10);
PPC_FUNC_IMPL(__imp__sub_8245FD10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r3,80
	ctx.r3.s64 = 80;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fd58
	if (cr0.eq) goto loc_8245FD58;
	// addi r9,r28,40
	ctx.r9.s64 = r28.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8245fd5c
	goto loc_8245FD5C;
loc_8245FD58:
	// li r30,0
	r30.s64 = 0;
loc_8245FD5C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8245fd6c
	if (!cr6.eq) goto loc_8245FD6C;
loc_8245FD64:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245fe4c
	goto loc_8245FE4C;
loc_8245FD6C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fd9c
	if (cr0.eq) goto loc_8245FD9C;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,33
	ctx.r5.s64 = 33;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8245fda0
	goto loc_8245FDA0;
loc_8245FD9C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245FDA0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8245fd64
	if (cr6.eq) goto loc_8245FD64;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fdd4
	if (cr0.eq) goto loc_8245FDD4;
	// addi r6,r28,40
	ctx.r6.s64 = r28.s64 + 40;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245fdd8
	goto loc_8245FDD8;
loc_8245FDD4:
	// li r31,0
	r31.s64 = 0;
loc_8245FDD8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245fd64
	if (cr6.eq) goto loc_8245FD64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r31,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r31.u32);
	// beq cr6,0x8245fe00
	if (cr6.eq) goto loc_8245FE00;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8245fd64
	if (cr0.eq) goto loc_8245FD64;
loc_8245FE00:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fe2c
	if (cr0.eq) goto loc_8245FE2C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245fe30
	goto loc_8245FE30;
loc_8245FE2C:
	// li r11,0
	r11.s64 = 0;
loc_8245FE30:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245fd64
	if (cr6.eq) goto loc_8245FD64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8245FE4C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8245FE54"))) PPC_WEAK_FUNC(sub_8245FE54);
PPC_FUNC_IMPL(__imp__sub_8245FE54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245FE58"))) PPC_WEAK_FUNC(sub_8245FE58);
PPC_FUNC_IMPL(__imp__sub_8245FE58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r3,80
	ctx.r3.s64 = 80;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fea0
	if (cr0.eq) goto loc_8245FEA0;
	// addi r9,r28,40
	ctx.r9.s64 = r28.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8245fea4
	goto loc_8245FEA4;
loc_8245FEA0:
	// li r30,0
	r30.s64 = 0;
loc_8245FEA4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8245feb4
	if (!cr6.eq) goto loc_8245FEB4;
loc_8245FEAC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8245ff94
	goto loc_8245FF94;
loc_8245FEB4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245fee4
	if (cr0.eq) goto loc_8245FEE4;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,47
	ctx.r5.s64 = 47;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8245fee8
	goto loc_8245FEE8;
loc_8245FEE4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8245FEE8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8245feac
	if (cr6.eq) goto loc_8245FEAC;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245ff1c
	if (cr0.eq) goto loc_8245FF1C;
	// addi r6,r28,40
	ctx.r6.s64 = r28.s64 + 40;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8245ff20
	goto loc_8245FF20;
loc_8245FF1C:
	// li r31,0
	r31.s64 = 0;
loc_8245FF20:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8245feac
	if (cr6.eq) goto loc_8245FEAC;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r31,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r31.u32);
	// beq cr6,0x8245ff48
	if (cr6.eq) goto loc_8245FF48;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x8245feac
	if (cr0.eq) goto loc_8245FEAC;
loc_8245FF48:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8245ff74
	if (cr0.eq) goto loc_8245FF74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8245ff78
	goto loc_8245FF78;
loc_8245FF74:
	// li r11,0
	r11.s64 = 0;
loc_8245FF78:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8245feac
	if (cr6.eq) goto loc_8245FEAC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8245FF94:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_8245FF9C"))) PPC_WEAK_FUNC(sub_8245FF9C);
PPC_FUNC_IMPL(__imp__sub_8245FF9C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8245FFA0"))) PPC_WEAK_FUNC(sub_8245FFA0);
PPC_FUNC_IMPL(__imp__sub_8245FFA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcdc
	// stfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, f30.u64);
	// stfd f31,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x824607f0
	if (cr6.eq) goto loc_824607F0;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x824607f0
	if (!cr6.eq) goto loc_824607F0;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r4,16(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// mullw r24,r11,r10
	r24.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// bl 0x824598e8
	sub_824598E8(ctx, base);
	// cmplw cr6,r24,r3
	cr6.compare<uint32_t>(r24.u32, ctx.r3.u32, xer);
	// bne cr6,0x824607f0
	if (!cr6.eq) goto loc_824607F0;
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// blt cr6,0x8246002c
	if (cr6.lt) goto loc_8246002C;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// ble cr6,0x824607f0
	if (!cr6.gt) goto loc_824607F0;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// ble cr6,0x8246002c
	if (!cr6.gt) goto loc_8246002C;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// ble cr6,0x824607f0
	if (!cr6.gt) goto loc_824607F0;
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x824607f0
	if (cr6.eq) goto loc_824607F0;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// beq cr6,0x824600c8
	if (cr6.eq) goto loc_824600C8;
	// cmpwi cr6,r11,34
	cr6.compare<int32_t>(r11.s32, 34, xer);
	// beq cr6,0x824607f0
	if (cr6.eq) goto loc_824607F0;
loc_8246002C:
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// li r30,0
	r30.s64 = 0;
	// li r29,0
	r29.s64 = 0;
	// li r22,0
	r22.s64 = 0;
	// li r21,0
	r21.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82460080
	if (cr0.eq) goto loc_82460080;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x82460080
	if (!cr6.eq) goto loc_82460080;
	// mr r30,r11
	r30.u64 = r11.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mullw r26,r11,r10
	r26.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r3,r26,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r22,r3
	r22.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// beq 0x824600bc
	if (cr0.eq) goto loc_824600BC;
loc_82460080:
	// lwz r11,36(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 36);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824600dc
	if (cr0.eq) goto loc_824600DC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x824600dc
	if (!cr6.eq) goto loc_824600DC;
	// mr r29,r11
	r29.u64 = r11.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mullw r28,r11,r10
	r28.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r3,r28,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r21,r3
	r21.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r21.s32, 0, xer);
	// bne 0x824600dc
	if (!cr0.eq) goto loc_824600DC;
loc_824600BC:
	// lis r31,-32761
	r31.s64 = -2147024896;
	// ori r31,r31,14
	r31.u64 = r31.u64 | 14;
	// b 0x82460560
	goto loc_82460560;
loc_824600C8:
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245bce0
	sub_8245BCE0(ctx, base);
	// b 0x824607f8
	goto loc_824607F8;
loc_824600DC:
	// lwz r11,40(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 40);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246011c
	if (cr6.eq) goto loc_8246011C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82460108
	if (cr6.eq) goto loc_82460108;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245ffa0
	sub_8245FFA0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
loc_82460108:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8246015c
	if (cr6.eq) goto loc_8246015C;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// b 0x8246014c
	goto loc_8246014C;
loc_8246011C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8246013c
	if (cr6.eq) goto loc_8246013C;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245ffa0
	sub_8245FFA0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
loc_8246013C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8246015c
	if (cr6.eq) goto loc_8246015C;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_8246014C:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245ffa0
	sub_8245FFA0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
loc_8246015C:
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// blt cr6,0x824605c4
	if (cr6.lt) goto loc_824605C4;
	// cmplwi cr6,r11,28
	cr6.compare<uint32_t>(r11.u32, 28, xer);
	// beq cr6,0x82460510
	if (cr6.eq) goto loc_82460510;
	// cmplwi cr6,r11,29
	cr6.compare<uint32_t>(r11.u32, 29, xer);
	// beq cr6,0x8246042c
	if (cr6.eq) goto loc_8246042C;
	// cmplwi cr6,r11,30
	cr6.compare<uint32_t>(r11.u32, 30, xer);
	// beq cr6,0x824603a8
	if (cr6.eq) goto loc_824603A8;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,3
	ctx.r9.s64 = 3;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x824601c0
	if (cr6.eq) goto loc_824601C0;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
loc_82460198:
	// addi r4,r5,8
	ctx.r4.s64 = ctx.r5.s64 + 8;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459a90
	sub_82459A90(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
	// addi r5,r5,16
	ctx.r5.s64 = ctx.r5.s64 + 16;
	// cmplw cr6,r10,r26
	cr6.compare<uint32_t>(ctx.r10.u32, r26.u32, xer);
	// blt cr6,0x82460198
	if (cr6.lt) goto loc_82460198;
loc_824601C0:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x824601fc
	if (cr6.eq) goto loc_824601FC;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
loc_824601D4:
	// addi r4,r5,8
	ctx.r4.s64 = ctx.r5.s64 + 8;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459a90
	sub_82459A90(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
	// addi r5,r5,16
	ctx.r5.s64 = ctx.r5.s64 + 16;
	// cmplw cr6,r10,r28
	cr6.compare<uint32_t>(ctx.r10.u32, r28.u32, xer);
	// blt cr6,0x824601d4
	if (cr6.lt) goto loc_824601D4;
loc_824601FC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8246020c
	if (cr6.eq) goto loc_8246020C;
	// cmplw cr6,r26,r24
	cr6.compare<uint32_t>(r26.u32, r24.u32, xer);
	// bne cr6,0x82460558
	if (!cr6.eq) goto loc_82460558;
loc_8246020C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8246021c
	if (cr6.eq) goto loc_8246021C;
	// cmplw cr6,r28,r24
	cr6.compare<uint32_t>(r28.u32, r24.u32, xer);
	// bne cr6,0x82460558
	if (!cr6.eq) goto loc_82460558;
loc_8246021C:
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824602c4
	if (cr6.eq) goto loc_824602C4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r31,r21,8
	r31.s64 = r21.s64 + 8;
	// subf r28,r21,r22
	r28.s64 = r22.s64 - r21.s64;
	// subf r30,r21,r25
	r30.s64 = r25.s64 - r21.s64;
	// lfd f30,-31360(r10)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r10.u32 + -31360);
	// lfd f31,-31368(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_82460244:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82460254
	if (cr6.eq) goto loc_82460254;
	// lfdx f1,r28,r31
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r28.u32 + r31.u32);
	// b 0x82460258
	goto loc_82460258;
loc_82460254:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
loc_82460258:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82460268
	if (cr6.eq) goto loc_82460268;
	// lfd f2,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(r31.u32 + 0);
	// b 0x8246026c
	goto loc_8246026C;
loc_82460268:
	// fmr f2,f31
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f31.f64;
loc_8246026C:
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bgt cr6,0x82460558
	if (cr6.gt) goto loc_82460558;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-26144
	r12.s64 = r12.s64 + -26144;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = __builtin_rotateleft64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,676
	r12.s64 = r12.s64 + 676;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_824602A4;
	case 1:
		goto loc_82460304;
	case 2:
		goto loc_824602B0;
	case 3:
		goto loc_82460558;
	case 4:
		goto loc_8246030C;
	case 5:
		goto loc_82460314;
	case 6:
		goto loc_82460324;
	case 7:
		goto loc_82460334;
	case 8:
		goto loc_8246033C;
	case 9:
		goto loc_82460558;
	case 10:
		goto loc_82460558;
	case 11:
		goto loc_82460344;
	case 12:
		goto loc_82460350;
	case 13:
		goto loc_8246035C;
	case 14:
		goto loc_82460368;
	case 15:
		goto loc_82460374;
	case 16:
		goto loc_8246037C;
	case 17:
		goto loc_82460558;
	case 18:
		goto loc_82460558;
	case 19:
		goto loc_82460558;
	case 20:
		goto loc_82460384;
	case 21:
		goto loc_82460390;
	default:
		__builtin_unreachable();
	}
loc_824602A4:
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
loc_824602A8:
	// bne cr6,0x824603a0
	if (!cr6.eq) goto loc_824603A0;
loc_824602AC:
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
loc_824602B0:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// stfdx f1,r30,r31
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(r30.u32 + r31.u32, ctx.f1.u64);
	// addi r31,r31,16
	r31.s64 = r31.s64 + 16;
	// cmplw cr6,r29,r24
	cr6.compare<uint32_t>(r29.u32, r24.u32, xer);
	// blt cr6,0x82460244
	if (cr6.lt) goto loc_82460244;
loc_824602C4:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824602fc
	if (cr6.eq) goto loc_824602FC;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_824602D8:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lfd f1,8(r4)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r4.u32 + 8);
	// bl 0x8245a250
	sub_8245A250(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// cmplw cr6,r10,r24
	cr6.compare<uint32_t>(ctx.r10.u32, r24.u32, xer);
	// blt cr6,0x824602d8
	if (cr6.lt) goto loc_824602D8;
loc_824602FC:
	// li r31,0
	r31.s64 = 0;
	// b 0x82460560
	goto loc_82460560;
loc_82460304:
	// fneg f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = ctx.f1.u64 ^ 0x8000000000000000;
	// b 0x824602b0
	goto loc_824602B0;
loc_8246030C:
	// fmul f1,f2,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f2.f64 * ctx.f1.f64;
	// b 0x824602b0
	goto loc_824602B0;
loc_82460314:
	// fcmpu cr6,f2,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f2.f64, f31.f64);
	// beq cr6,0x82460558
	if (cr6.eq) goto loc_82460558;
	// fdiv f1,f1,f2
	ctx.f1.f64 = ctx.f1.f64 / ctx.f2.f64;
	// b 0x824602b0
	goto loc_824602B0;
loc_82460324:
	// fcmpu cr6,f2,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f2.f64, f31.f64);
	// beq cr6,0x82460558
	if (cr6.eq) goto loc_82460558;
	// bl 0x8239da70
	sub_8239DA70(ctx, base);
	// b 0x824602b0
	goto loc_824602B0;
loc_82460334:
	// fadd f1,f2,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f2.f64 + ctx.f1.f64;
	// b 0x824602b0
	goto loc_824602B0;
loc_8246033C:
	// fsub f1,f1,f2
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f1.f64 - ctx.f2.f64;
	// b 0x824602b0
	goto loc_824602B0;
loc_82460344:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// blt cr6,0x824602ac
	if (cr6.lt) goto loc_824602AC;
	// b 0x824603a0
	goto loc_824603A0;
loc_82460350:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// bgt cr6,0x824602ac
	if (cr6.gt) goto loc_824602AC;
	// b 0x824603a0
	goto loc_824603A0;
loc_8246035C:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// ble cr6,0x824602ac
	if (!cr6.gt) goto loc_824602AC;
	// b 0x824603a0
	goto loc_824603A0;
loc_82460368:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// bge cr6,0x824602ac
	if (!cr6.lt) goto loc_824602AC;
	// b 0x824603a0
	goto loc_824603A0;
loc_82460374:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// b 0x824602a8
	goto loc_824602A8;
loc_8246037C:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// b 0x8246039c
	goto loc_8246039C;
loc_82460384:
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
	// beq cr6,0x824603a0
	if (cr6.eq) goto loc_824603A0;
	// b 0x82460398
	goto loc_82460398;
loc_82460390:
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
	// bne cr6,0x824602ac
	if (!cr6.eq) goto loc_824602AC;
loc_82460398:
	// fcmpu cr6,f2,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f2.f64, f31.f64);
loc_8246039C:
	// bne cr6,0x824602ac
	if (!cr6.eq) goto loc_824602AC;
loc_824603A0:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// b 0x824602b0
	goto loc_824602B0;
loc_824603A8:
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x824602fc
	if (cr6.eq) goto loc_824602FC;
	// rlwinm r11,r24,4,0,27
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// add r9,r11,r21
	ctx.r9.u64 = r11.u64 + r21.u64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// subf r7,r21,r22
	ctx.r7.s64 = r22.s64 - r21.s64;
	// subf r8,r21,r25
	ctx.r8.s64 = r25.s64 - r21.s64;
	// lfd f12,-31368(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + -31368);
loc_824603D4:
	// add r5,r10,r7
	ctx.r5.u64 = ctx.r10.u64 + ctx.r7.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459a90
	sub_82459A90(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bne cr6,0x82460400
	if (!cr6.eq) goto loc_82460400;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
loc_82460400:
	// add r4,r10,r8
	ctx.r4.u64 = ctx.r10.u64 + ctx.r8.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// blt cr6,0x824603d4
	if (cr6.lt) goto loc_824603D4;
	// b 0x824602fc
	goto loc_824602FC;
loc_8246042C:
	// lwz r11,36(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 36);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// bne cr6,0x8246049c
	if (!cr6.eq) goto loc_8246049C;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245a1d0
	sub_8245A1D0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824602fc
	if (cr6.eq) goto loc_824602FC;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r5,r11,r22
	ctx.r5.u64 = r11.u64 + r22.u64;
loc_82460474:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r5,r5,16
	ctx.r5.s64 = ctx.r5.s64 + 16;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// cmplw cr6,r10,r24
	cr6.compare<uint32_t>(ctx.r10.u32, r24.u32, xer);
	// blt cr6,0x82460474
	if (cr6.lt) goto loc_82460474;
	// b 0x824602fc
	goto loc_824602FC;
loc_8246049C:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82460558
	if (!cr6.eq) goto loc_82460558;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824602fc
	if (cr6.eq) goto loc_824602FC;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_824604BC:
	// lwz r11,8(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// bl 0x8245a1d0
	sub_8245A1D0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r5,r11,r22
	ctx.r5.u64 = r11.u64 + r22.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r8,r24
	cr6.compare<uint32_t>(ctx.r8.u32, r24.u32, xer);
	// blt cr6,0x824604bc
	if (cr6.lt) goto loc_824604BC;
	// b 0x824602fc
	goto loc_824602FC;
loc_82460510:
	// addi r9,r27,48
	ctx.r9.s64 = r27.s64 + 48;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
	// bl 0x8245a1d0
	sub_8245A1D0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mullw r11,r11,r24
	r11.s64 = int64_t(r11.s32) * int64_t(r24.s32);
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// blt cr6,0x82460580
	if (cr6.lt) goto loc_82460580;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3030
	ctx.r5.s64 = 3030;
	// addi r6,r11,32272
	ctx.r6.s64 = r11.s64 + 32272;
	// mr r4,r9
	ctx.r4.u64 = ctx.r9.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82460558:
	// lis r31,-32768
	r31.s64 = -2147483648;
	// ori r31,r31,16389
	r31.u64 = r31.u64 | 16389;
loc_82460560:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x824607f8
	goto loc_824607F8;
loc_82460580:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824602fc
	if (cr6.eq) goto loc_824602FC;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// add r5,r11,r22
	ctx.r5.u64 = r11.u64 + r22.u64;
loc_82460598:
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r5,r5,16
	ctx.r5.s64 = ctx.r5.s64 + 16;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// cmplw cr6,r10,r24
	cr6.compare<uint32_t>(ctx.r10.u32, r24.u32, xer);
	// blt cr6,0x82460598
	if (cr6.lt) goto loc_82460598;
	// b 0x824602fc
	goto loc_824602FC;
loc_824605C4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824606ec
	if (cr6.eq) goto loc_824606EC;
	// cmplwi cr6,r26,1
	cr6.compare<uint32_t>(r26.u32, 1, xer);
	// bne cr6,0x82460610
	if (!cr6.eq) goto loc_82460610;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824602fc
	if (cr6.eq) goto loc_824602FC;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_824605E8:
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// cmplw cr6,r10,r24
	cr6.compare<uint32_t>(ctx.r10.u32, r24.u32, xer);
	// blt cr6,0x824605e8
	if (cr6.lt) goto loc_824605E8;
	// b 0x824602fc
	goto loc_824602FC;
loc_82460610:
	// cmplw cr6,r24,r26
	cr6.compare<uint32_t>(r24.u32, r26.u32, xer);
	// beq cr6,0x824606ac
	if (cr6.eq) goto loc_824606AC;
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bgt cr6,0x824606ac
	if (cr6.gt) goto loc_824606AC;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lwz r9,24(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x824606ac
	if (cr6.gt) goto loc_824606AC;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x824602fc
	if (cr6.eq) goto loc_824602FC;
loc_82460644:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82460698
	if (cr6.eq) goto loc_82460698;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
loc_82460654:
	// lwz r8,24(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// mullw r11,r11,r9
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// mullw r8,r8,r9
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r9.s32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// add r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r8,r8,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// add r4,r11,r25
	ctx.r4.u64 = r11.u64 + r25.u64;
	// add r5,r8,r22
	ctx.r5.u64 = ctx.r8.u64 + r22.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82460654
	if (cr6.lt) goto loc_82460654;
loc_82460698:
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x82460644
	if (cr6.lt) goto loc_82460644;
	// b 0x824602fc
	goto loc_824602FC;
loc_824606AC:
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824602fc
	if (cr6.eq) goto loc_824602FC;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// subf r10,r25,r22
	ctx.r10.s64 = r22.s64 - r25.s64;
loc_824606C4:
	// add r5,r10,r4
	ctx.r5.u64 = ctx.r10.u64 + ctx.r4.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// cmplw cr6,r9,r24
	cr6.compare<uint32_t>(ctx.r9.u32, r24.u32, xer);
	// blt cr6,0x824606c4
	if (cr6.lt) goto loc_824606C4;
	// b 0x824602fc
	goto loc_824602FC;
loc_824606EC:
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82460738
	if (cr0.eq) goto loc_82460738;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// bne cr6,0x82460738
	if (!cr6.eq) goto loc_82460738;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x82460558
	if (cr6.eq) goto loc_82460558;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// beq cr6,0x82460558
	if (cr6.eq) goto loc_82460558;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// b 0x824602fc
	goto loc_824602FC;
loc_82460738:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82460558
	if (cr6.eq) goto loc_82460558;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82460558
	if (!cr6.eq) goto loc_82460558;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_82460750:
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x824607a0
	if (cr0.eq) goto loc_824607A0;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x824607a0
	if (!cr6.eq) goto loc_824607A0;
	// addi r5,r4,16
	ctx.r5.s64 = ctx.r4.s64 + 16;
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x82460558
	if (cr6.eq) goto loc_82460558;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// beq cr6,0x82460558
	if (cr6.eq) goto loc_82460558;
	// addi r6,r27,48
	ctx.r6.s64 = r27.s64 + 48;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82459ff0
	sub_82459FF0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// addi r25,r25,16
	r25.s64 = r25.s64 + 16;
	// b 0x824607e0
	goto loc_824607E0;
loc_824607A0:
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x824607e0
	if (cr6.eq) goto loc_824607E0;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x824607e0
	if (!cr6.eq) goto loc_824607E0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245ffa0
	sub_8245FFA0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// blt 0x82460560
	if (cr0.lt) goto loc_82460560;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r25,r11,r25
	r25.u64 = r11.u64 + r25.u64;
loc_824607E0:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x82460750
	if (!cr0.eq) goto loc_82460750;
	// b 0x824602fc
	goto loc_824602FC;
loc_824607F0:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_824607F8:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x8239bd2c
	return;
}

__attribute__((alias("__imp__sub_82460808"))) PPC_WEAK_FUNC(sub_82460808);
PPC_FUNC_IMPL(__imp__sub_82460808) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// li r23,0
	r23.s64 = 0;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r25,r23
	r25.u64 = r23.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x824608f4
	if (cr6.eq) goto loc_824608F4;
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824608f4
	if (cr0.eq) goto loc_824608F4;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824608b4
	if (cr0.lt) goto loc_824608B4;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824608b4
	if (cr0.lt) goto loc_824608B4;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x8246091c
	if (cr6.eq) goto loc_8246091C;
	// xor r9,r11,r10
	ctx.r9.u64 = r11.u64 ^ ctx.r10.u64;
	// rlwinm. r9,r9,0,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFF0000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x824608ec
	if (!cr0.eq) goto loc_824608EC;
	// clrlwi. r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824608a0
	if (cr0.eq) goto loc_824608A0;
	// clrlwi. r10,r11,16
	ctx.r10.u64 = r11.u32 & 0xFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824608ec
	if (!cr0.eq) goto loc_824608EC;
loc_824608A0:
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r25,r11,1
	r25.s64 = r11.s64 + 1;
	// b 0x8246091c
	goto loc_8246091C;
loc_824608B4:
	// lwz r10,36(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
loc_824608C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824608e4
	if (cr0.eq) goto loc_824608E4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824608c0
	if (cr6.eq) goto loc_824608C0;
loc_824608E4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8246091c
	if (cr0.eq) goto loc_8246091C;
loc_824608EC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82460a50
	goto loc_82460A50;
loc_824608F4:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// subf r10,r23,r31
	ctx.r10.s64 = r31.s64 - r23.s64;
	// subf r11,r23,r11
	r11.s64 = r11.s64 - r23.s64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x8246091c
	if (cr6.eq) goto loc_8246091C;
	// li r25,2
	r25.s64 = 2;
loc_8246091C:
	// lwz r28,44(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// mr r27,r29
	r27.u64 = r29.u64;
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x82460a40
	if (cr0.eq) goto loc_82460A40;
	// rlwinm r26,r26,0,27,27
	r26.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x10;
loc_82460930:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x8246095c
	if (cr0.eq) goto loc_8246095C;
	// lwz r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,12
	cr6.compare<int32_t>(ctx.r9.s32, 12, xer);
	// bne cr6,0x8246095c
	if (!cr6.eq) goto loc_8246095C;
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// li r10,1
	ctx.r10.s64 = 1;
loc_8246095C:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82460974
	if (cr6.eq) goto loc_82460974;
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r9,44(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 44);
	// rlwinm. r9,r9,0,25,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82460a38
	if (cr0.eq) goto loc_82460A38;
loc_82460974:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82460a30
	if (cr6.eq) goto loc_82460A30;
	// lwz r29,24(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r30,48(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// beq 0x82460998
	if (cr0.eq) goto loc_82460998;
	// lwz r31,16(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// b 0x8246099c
	goto loc_8246099C;
loc_82460998:
	// mr r31,r23
	r31.u64 = r23.u64;
loc_8246099C:
	// lwz r11,44(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824609d8
	if (cr0.eq) goto loc_824609D8;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824608ec
	if (cr0.eq) goto loc_824608EC;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245e100
	sub_8245E100(ctx, base);
	// add r25,r3,r25
	r25.u64 = ctx.r3.u64 + r25.u64;
loc_824609D8:
	// lwz r11,44(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82460a28
	if (cr0.eq) goto loc_82460A28;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824608ec
	if (!cr0.eq) goto loc_824608EC;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824608ec
	if (cr0.eq) goto loc_824608EC;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8245e100
	sub_8245E100(ctx, base);
	// add r25,r3,r25
	r25.u64 = ctx.r3.u64 + r25.u64;
loc_82460A28:
	// lwz r27,12(r27)
	r27.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// b 0x82460a38
	goto loc_82460A38;
loc_82460A30:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x824608ec
	if (cr6.eq) goto loc_824608EC;
loc_82460A38:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82460930
	if (!cr6.eq) goto loc_82460930;
loc_82460A40:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// li r3,-1
	ctx.r3.s64 = -1;
	// bne cr6,0x82460a50
	if (!cr6.eq) goto loc_82460A50;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_82460A50:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_82460A58"))) PPC_WEAK_FUNC(sub_82460A58);
PPC_FUNC_IMPL(__imp__sub_82460A58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82460a98
	if (cr0.eq) goto loc_82460A98;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r5,24(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r6,r11,-22496
	ctx.r6.s64 = r11.s64 + -22496;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82460a9c
	goto loc_82460A9C;
loc_82460A98:
	// li r30,0
	r30.s64 = 0;
loc_82460A9C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82460abc
	if (!cr6.eq) goto loc_82460ABC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
loc_82460AA8:
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82460b04
	goto loc_82460B04;
loc_82460ABC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stw r30,24(r29)
	PPC_STORE_U32(r29.u32 + 24, r30.u32);
	// beq cr6,0x82460b00
	if (cr6.eq) goto loc_82460B00;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r31,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r31.u32);
	// beq 0x82460aa8
	if (cr0.eq) goto loc_82460AA8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8245e270
	sub_8245E270(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82460b04
	if (cr0.lt) goto loc_82460B04;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r11,r11,0,23,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFF1FF;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
loc_82460B00:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82460B04:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_82460B0C"))) PPC_WEAK_FUNC(sub_82460B0C);
PPC_FUNC_IMPL(__imp__sub_82460B0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82460B10"))) PPC_WEAK_FUNC(sub_82460B10);
PPC_FUNC_IMPL(__imp__sub_82460B10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82460ca4
	if (cr6.eq) goto loc_82460CA4;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82460ca4
	if (!cr6.eq) goto loc_82460CA4;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mullw r25,r11,r10
	r25.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r3,r25,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82121108
	sub_82121108(ctx, base);
	// mr. r24,r3
	r24.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// beq 0x82460c98
	if (cr0.eq) goto loc_82460C98;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245ffa0
	sub_8245FFA0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82460c98
	if (cr0.lt) goto loc_82460C98;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82460ba4
	if (cr0.eq) goto loc_82460BA4;
	// addi r9,r27,48
	ctx.r9.s64 = r27.s64 + 48;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x82460ba8
	goto loc_82460BA8;
loc_82460BA4:
	// li r28,0
	r28.s64 = 0;
loc_82460BA8:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82460c98
	if (cr6.eq) goto loc_82460C98;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82460bdc
	if (cr6.eq) goto loc_82460BDC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r28)
	PPC_STORE_U32(r28.u32 + 16, ctx.r3.u32);
	// beq 0x82460c98
	if (cr0.eq) goto loc_82460C98;
loc_82460BDC:
	// addi r31,r28,32
	r31.s64 = r28.s64 + 32;
	// li r29,0
	r29.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82460c78
	if (cr6.eq) goto loc_82460C78;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r30,r24
	r30.u64 = r24.u64;
	// addi r26,r11,-22544
	r26.s64 = r11.s64 + -22544;
loc_82460BF8:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82460c1c
	if (cr0.eq) goto loc_82460C1C;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82460c20
	goto loc_82460C20;
loc_82460C1C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82460C20:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82460c98
	if (cr6.eq) goto loc_82460C98;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82460c4c
	if (cr0.eq) goto loc_82460C4C;
	// addi r5,r27,48
	ctx.r5.s64 = r27.s64 + 48;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8240c420
	sub_8240C420(ctx, base);
	// b 0x82460c50
	goto loc_82460C50;
loc_82460C4C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82460C50:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// beq cr6,0x82460c98
	if (cr6.eq) goto loc_82460C98;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,16
	r30.s64 = r30.s64 + 16;
	// addi r31,r11,12
	r31.s64 = r11.s64 + 12;
	// cmplw cr6,r29,r25
	cr6.compare<uint32_t>(r29.u32, r25.u32, xer);
	// blt cr6,0x82460bf8
	if (cr6.lt) goto loc_82460BF8;
loc_82460C78:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// b 0x82460ca8
	goto loc_82460CA8;
loc_82460C98:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82120e68
	sub_82120E68(ctx, base);
loc_82460CA4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82460CA8:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_82460CB0"))) PPC_WEAK_FUNC(sub_82460CB0);
PPC_FUNC_IMPL(__imp__sub_82460CB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x82460b10
	sub_82460B10(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82460d34
	if (cr0.eq) goto loc_82460D34;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82460d34
	if (cr0.eq) goto loc_82460D34;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x82460d34
	if (!cr6.eq) goto loc_82460D34;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x82460d34
	if (!cr6.eq) goto loc_82460D34;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82460d34
	if (!cr6.eq) goto loc_82460D34;
	// lwz r11,32(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// addi r6,r3,48
	ctx.r6.s64 = ctx.r3.s64 + 48;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// bl 0x8245a1d0
	sub_8245A1D0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82460d3c
	if (cr0.lt) goto loc_82460D3C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82460d3c
	goto loc_82460D3C;
loc_82460D34:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82460D3C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82460D54"))) PPC_WEAK_FUNC(sub_82460D54);
PPC_FUNC_IMPL(__imp__sub_82460D54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82460D58"))) PPC_WEAK_FUNC(sub_82460D58);
PPC_FUNC_IMPL(__imp__sub_82460D58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82460dc4
	if (!cr6.eq) goto loc_82460DC4;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// beq 0x82460dac
	if (cr0.eq) goto loc_82460DAC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,9
	cr6.compare<int32_t>(ctx.r10.s32, 9, xer);
	// bne cr6,0x82460dac
	if (!cr6.eq) goto loc_82460DAC;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82460de0
	if (cr6.eq) goto loc_82460DE0;
loc_82460DAC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-22456
	ctx.r6.s64 = r11.s64 + -22456;
loc_82460DB4:
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r4,r31,48
	ctx.r4.s64 = r31.s64 + 48;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82460DC4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82460DC8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82460DE0:
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82460e04
	if (!cr0.lt) goto loc_82460E04;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-22484
	ctx.r6.s64 = r11.s64 + -22484;
	// b 0x82460db4
	goto loc_82460DB4;
loc_82460E04:
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82460e2c
	if (cr0.eq) goto loc_82460E2C;
	// addi r6,r31,48
	ctx.r6.s64 = r31.s64 + 48;
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82460e30
	goto loc_82460E30;
loc_82460E2C:
	// li r31,0
	r31.s64 = 0;
loc_82460E30:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82460dc4
	if (cr6.eq) goto loc_82460DC4;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82460dc4
	if (cr0.eq) goto loc_82460DC4;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8240a808
	sub_8240A808(ctx, base);
	// b 0x82460dc8
	goto loc_82460DC8;
}

__attribute__((alias("__imp__sub_82460E54"))) PPC_WEAK_FUNC(sub_82460E54);
PPC_FUNC_IMPL(__imp__sub_82460E54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82460E58"))) PPC_WEAK_FUNC(sub_82460E58);
PPC_FUNC_IMPL(__imp__sub_82460E58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// lwz r27,8(r23)
	r27.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// mr r24,r9
	r24.u64 = ctx.r9.u64;
	// mr r30,r10
	r30.u64 = ctx.r10.u64;
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmpw cr6,r5,r11
	cr6.compare<int32_t>(ctx.r5.s32, r11.s32, xer);
	// beq cr6,0x82460ed8
	if (cr6.eq) goto loc_82460ED8;
	// andi. r10,r30,5
	ctx.r10.u64 = r30.u64 & 5;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82460ecc
	if (cr0.eq) goto loc_82460ECC;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lwz r7,8(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// rlwinm r9,r5,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,-22236
	ctx.r10.s64 = ctx.r10.s64 + -22236;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3005
	ctx.r5.s64 = 3005;
	// addi r6,r11,-22280
	ctx.r6.s64 = r11.s64 + -22280;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwzx r9,r9,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lwzx r8,r8,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82460ECC:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82461060
	goto loc_82461060;
loc_82460ED8:
	// rlwinm. r11,r30,0,29,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r31,0
	r31.s64 = 0;
	// beq 0x82460f00
	if (cr0.eq) goto loc_82460F00;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r4,24(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82460808
	sub_82460808(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_82460F00:
	// rlwinm. r11,r30,0,28,28
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82460f24
	if (cr0.eq) goto loc_82460F24;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r4,24(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82459dd0
	sub_82459DD0(ctx, base);
	// add r31,r3,r31
	r31.u64 = ctx.r3.u64 + r31.u64;
loc_82460F24:
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// beq cr6,0x8246105c
	if (cr6.eq) goto loc_8246105C;
	// lwz r9,340(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// lwz r11,348(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// bge cr6,0x82460f4c
	if (!cr6.lt) goto loc_82460F4C;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r31.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_82460F4C:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r31,r10
	cr6.compare<uint32_t>(r31.u32, ctx.r10.u32, xer);
	// bne cr6,0x82460f7c
	if (!cr6.eq) goto loc_82460F7C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,64
	cr6.compare<uint32_t>(ctx.r10.u32, 64, xer);
	// bge cr6,0x82460f7c
	if (!cr6.lt) goto loc_82460F7C;
	// lwz r8,356(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r27,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, r27.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_82460F7C:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8246105c
	if (cr6.eq) goto loc_8246105C;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8246105c
	if (!cr6.eq) goto loc_8246105C;
	// lwz r11,48(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 48);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246105c
	if (cr6.eq) goto loc_8246105C;
	// lwz r11,44(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8246105c
	if (!cr6.eq) goto loc_8246105C;
	// lwz r5,32(r24)
	ctx.r5.u64 = PPC_LOAD_U32(r24.u32 + 32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r30,1
	r30.s64 = 1;
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// addi r31,r11,-22424
	r31.s64 = r11.s64 + -22424;
	// beq 0x82461018
	if (cr0.eq) goto loc_82461018;
	// lwz r11,16(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x82461018
	if (!cr6.eq) goto loc_82461018;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82459368
	sub_82459368(ctx, base);
	// b 0x82460ff0
	goto loc_82460FF0;
loc_82460FDC:
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,48(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82460ffc
	if (cr6.eq) goto loc_82460FFC;
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
loc_82460FF0:
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x82460fdc
	if (!cr0.eq) goto loc_82460FDC;
	// b 0x82461018
	goto loc_82461018;
loc_82460FFC:
	// li r5,3078
	ctx.r5.s64 = 3078;
	// lwz r7,8(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245ab70
	sub_8245AB70(ctx, base);
	// stw r30,44(r27)
	PPC_STORE_U32(r27.u32 + 44, r30.u32);
loc_82461018:
	// lwz r11,12(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// b 0x82461034
	goto loc_82461034;
loc_82461020:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,48(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82461040
	if (cr6.eq) goto loc_82461040;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_82461034:
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82461020
	if (!cr0.eq) goto loc_82461020;
	// b 0x8246105c
	goto loc_8246105C;
loc_82461040:
	// li r5,3078
	ctx.r5.s64 = 3078;
	// lwz r7,8(r25)
	ctx.r7.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245ab70
	sub_8245AB70(ctx, base);
	// stw r30,44(r27)
	PPC_STORE_U32(r27.u32 + 44, r30.u32);
loc_8246105C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82461060:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x8239bd34
	return;
}

__attribute__((alias("__imp__sub_82461068"))) PPC_WEAK_FUNC(sub_82461068);
PPC_FUNC_IMPL(__imp__sub_82461068) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stwu r1,-736(r1)
	ea = -736 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r21,0
	r21.s64 = 0;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// mr r22,r9
	r22.u64 = ctx.r9.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r20,r4
	r20.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// stb r21,112(r1)
	PPC_STORE_U8(ctx.r1.u32 + 112, r21.u8);
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
loc_824610A0:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x824610a0
	if (!cr6.eq) goto loc_824610A0;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r27,r11,0
	r27.u64 = __builtin_rotateleft32(r11.u32, 0);
	// cmplwi cr6,r27,509
	cr6.compare<uint32_t>(r27.u32, 509, xer);
	// blt cr6,0x824610d0
	if (cr6.lt) goto loc_824610D0;
loc_824610C4:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82461274
	goto loc_82461274;
loc_824610D0:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82461114
	if (cr6.eq) goto loc_82461114;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8239d2a8
	sub_8239D2A8(ctx, base);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82461114
	if (cr6.eq) goto loc_82461114;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// li r10,58
	ctx.r10.s64 = 58;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// stbx r10,r27,r11
	PPC_STORE_U8(r27.u32 + r11.u32, ctx.r10.u8);
	// addi r11,r27,1
	r11.s64 = r27.s64 + 1;
	// addi r27,r11,1
	r27.s64 = r11.s64 + 1;
	// stbx r10,r11,r9
	PPC_STORE_U8(r11.u32 + ctx.r9.u32, ctx.r10.u8);
	// stbx r21,r27,r8
	PPC_STORE_U8(r27.u32 + ctx.r8.u32, r21.u8);
loc_82461114:
	// cmplwi cr6,r27,511
	cr6.compare<uint32_t>(r27.u32, 511, xer);
	// bge cr6,0x824610c4
	if (!cr6.lt) goto loc_824610C4;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461270
	if (cr6.eq) goto loc_82461270;
	// lwz r30,836(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// lwz r29,828(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	// lwz r28,820(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 820);
loc_82461130:
	// lwz r8,8(r20)
	ctx.r8.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x82461264
	if (cr0.eq) goto loc_82461264;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x82461264
	if (!cr6.eq) goto loc_82461264;
	// lwz r11,20(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_82461154:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82461154
	if (!cr6.eq) goto loc_82461154;
	// subf r10,r10,r11
	ctx.r10.s64 = r11.s64 - ctx.r10.s64;
	// mr r11,r27
	r11.u64 = r27.u64;
	// addi r9,r10,-1
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// rotlwi r9,r9,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
loc_82461178:
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x824611a4
	if (!cr6.lt) goto loc_824611A4;
	// lwz r7,20(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lwz r7,24(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	// lbzx r7,r7,r10
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r10.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stbx r7,r11,r6
	PPC_STORE_U8(r11.u32 + ctx.r6.u32, ctx.r7.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r11,511
	cr6.compare<uint32_t>(r11.u32, 511, xer);
	// blt cr6,0x82461178
	if (cr6.lt) goto loc_82461178;
loc_824611A4:
	// cmplwi cr6,r11,511
	cr6.compare<uint32_t>(r11.u32, 511, xer);
	// bge cr6,0x824610c4
	if (!cr6.lt) goto loc_824610C4;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stbx r21,r11,r7
	PPC_STORE_U8(r11.u32 + ctx.r7.u32, r21.u8);
	// lwz r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x824611f4
	if (!cr6.eq) goto loc_824611F4;
	// lwz r4,24(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r29.u32);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82461068
	sub_82461068(ctx, base);
	// b 0x8246125c
	goto loc_8246125C;
loc_824611F4:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// stbx r21,r11,r7
	PPC_STORE_U8(r11.u32 + ctx.r7.u32, r21.u8);
loc_82461200:
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// subf r8,r8,r11
	ctx.r8.s64 = r11.s64 - ctx.r8.s64;
	// beq 0x82461224
	if (cr0.eq) goto loc_82461224;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82461200
	if (cr6.eq) goto loc_82461200;
loc_82461224:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82461264
	if (!cr0.eq) goto loc_82461264;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r29.u32);
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r20
	ctx.r4.u64 = r20.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82460e58
	sub_82460E58(ctx, base);
loc_8246125C:
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82461274
	if (cr0.lt) goto loc_82461274;
loc_82461264:
	// lwz r20,12(r20)
	r20.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// cmplwi r20,0
	cr0.compare<uint32_t>(r20.u32, 0, xer);
	// bne 0x82461130
	if (!cr0.eq) goto loc_82461130;
loc_82461270:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82461274:
	// addi r1,r1,736
	ctx.r1.s64 = ctx.r1.s64 + 736;
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_8246127C"))) PPC_WEAK_FUNC(sub_8246127C);
PPC_FUNC_IMPL(__imp__sub_8246127C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82461280"))) PPC_WEAK_FUNC(sub_82461280);
PPC_FUNC_IMPL(__imp__sub_82461280) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd4
	// stwu r1,-544(r1)
	ea = -544 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r20,r10
	r20.u64 = ctx.r10.u64;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// mr r29,r8
	r29.u64 = ctx.r8.u64;
	// mr r22,r9
	r22.u64 = ctx.r9.u64;
	// li r19,0
	r19.s64 = 0;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x824612bc
	if (cr6.eq) goto loc_824612BC;
	// stw r19,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r19.u32);
loc_824612BC:
	// lwz r24,628(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824612cc
	if (cr6.eq) goto loc_824612CC;
	// stw r19,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r19.u32);
loc_824612CC:
	// lwz r8,8(r23)
	ctx.r8.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_824612D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x824612d8
	if (!cr6.eq) goto loc_824612D8;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// rlwinm. r10,r22,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r7,r11,0
	ctx.r7.u64 = __builtin_rotateleft32(r11.u32, 0);
	// beq 0x82461454
	if (cr0.eq) goto loc_82461454;
	// cmplwi cr6,r7,3
	cr6.compare<uint32_t>(ctx.r7.u32, 3, xer);
	// blt cr6,0x82461440
	if (cr6.lt) goto loc_82461440;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r9,r11,3
	ctx.r9.s64 = r11.s64 + 3;
	// addi r10,r10,25892
	ctx.r10.s64 = ctx.r10.s64 + 25892;
loc_82461314:
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r6,r5,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r5.s64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x82461334
	if (!cr0.eq) goto loc_82461334;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x82461314
	if (!cr6.eq) goto loc_82461314;
loc_82461334:
	// cmpwi r6,0
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x82461440
	if (!cr0.eq) goto loc_82461440;
	// addi r11,r7,-3
	r11.s64 = ctx.r7.s64 + -3;
	// addi r31,r8,3
	r31.s64 = ctx.r8.s64 + 3;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x824613c0
	if (!cr6.eq) goto loc_824613C0;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461440
	if (cr6.lt) goto loc_82461440;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461440
	if (!cr6.lt) goto loc_82461440;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// li r5,9
	ctx.r5.s64 = 9;
loc_82461380:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// addi r8,r11,-48
	ctx.r8.s64 = r11.s64 + -48;
loc_8246138C:
	// li r4,1
	ctx.r4.s64 = 1;
loc_82461390:
	// li r7,1
	ctx.r7.s64 = 1;
loc_82461394:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x824613a8
	goto loc_824613A8;
loc_824613A4:
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
loc_824613A8:
	// stw r3,0(r20)
	PPC_STORE_U32(r20.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82461894
	if (!cr6.eq) goto loc_82461894;
loc_824613B4:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82461d00
	goto loc_82461D00;
loc_824613C0:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x82461440
	if (!cr6.eq) goto loc_82461440;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461440
	if (cr6.lt) goto loc_82461440;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461440
	if (!cr6.lt) goto loc_82461440;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// cmplwi cr6,r11,120
	cr6.compare<uint32_t>(r11.u32, 120, xer);
	// bne cr6,0x82461440
	if (!cr6.eq) goto loc_82461440;
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461440
	if (cr6.lt) goto loc_82461440;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461440
	if (!cr6.lt) goto loc_82461440;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// li r5,9
	ctx.r5.s64 = 9;
loc_82461420:
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// lbz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r10,r11
	ctx.r10.s64 = r11.s8;
	// extsb r11,r8
	r11.s64 = ctx.r8.s8;
loc_82461430:
	// addi r8,r10,-48
	ctx.r8.s64 = ctx.r10.s64 + -48;
	// addi r7,r11,-48
	ctx.r7.s64 = r11.s64 + -48;
loc_82461438:
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x82461394
	goto loc_82461394;
loc_82461440:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// addi r6,r11,-21992
	ctx.r6.s64 = r11.s64 + -21992;
	// li r5,3085
	ctx.r5.s64 = 3085;
	// b 0x82461cf0
	goto loc_82461CF0;
loc_82461454:
	// rlwinm. r11,r22,0,24,25
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0xC0;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82461598
	if (cr0.eq) goto loc_82461598;
	// cmplwi cr6,r7,5
	cr6.compare<uint32_t>(ctx.r7.u32, 5, xer);
	// blt cr6,0x82461568
	if (cr6.lt) goto loc_82461568;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r9,r11,5
	ctx.r9.s64 = r11.s64 + 5;
	// addi r10,r10,-28056
	ctx.r10.s64 = ctx.r10.s64 + -28056;
loc_82461474:
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r6,r5,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r5.s64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x82461494
	if (!cr0.eq) goto loc_82461494;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bne cr6,0x82461474
	if (!cr6.eq) goto loc_82461474;
loc_82461494:
	// cmpwi r6,0
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x82461568
	if (!cr0.eq) goto loc_82461568;
	// addi r11,r7,-5
	r11.s64 = ctx.r7.s64 + -5;
	// addi r31,r8,5
	r31.s64 = ctx.r8.s64 + 5;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x824614ec
	if (!cr6.eq) goto loc_824614EC;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461568
	if (cr6.lt) goto loc_82461568;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461568
	if (!cr6.lt) goto loc_82461568;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// li r5,16
	ctx.r5.s64 = 16;
	// not r10,r22
	ctx.r10.u64 = ~r22.u64;
	// rlwimi r5,r10,27,29,29
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r10.u32, 27) & 0x4) | (ctx.r5.u64 & 0xFFFFFFFFFFFFFFFB);
	// b 0x82461380
	goto loc_82461380;
loc_824614EC:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x82461568
	if (!cr6.eq) goto loc_82461568;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461568
	if (cr6.lt) goto loc_82461568;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461568
	if (!cr6.lt) goto loc_82461568;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// cmplwi cr6,r11,120
	cr6.compare<uint32_t>(r11.u32, 120, xer);
	// bne cr6,0x82461568
	if (!cr6.eq) goto loc_82461568;
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461568
	if (cr6.lt) goto loc_82461568;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461568
	if (!cr6.lt) goto loc_82461568;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// li r5,16
	ctx.r5.s64 = 16;
	// lbz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// not r8,r22
	ctx.r8.u64 = ~r22.u64;
	// extsb r10,r11
	ctx.r10.s64 = r11.s8;
	// extsb r11,r9
	r11.s64 = ctx.r9.s8;
	// rlwimi r5,r8,27,29,29
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r8.u32, 27) & 0x4) | (ctx.r5.u64 & 0xFFFFFFFFFFFFFFFB);
	// b 0x82461430
	goto loc_82461430;
loc_82461568:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// rlwinm r10,r22,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x80;
	// addi r6,r11,-22028
	ctx.r6.s64 = r11.s64 + -22028;
	// subfic r11,r10,0
	xer.ca = ctx.r10.u32 <= 0;
	r11.s64 = 0 - ctx.r10.s64;
	// li r5,3085
	ctx.r5.s64 = 3085;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// rlwinm r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// addi r7,r11,117
	ctx.r7.s64 = r11.s64 + 117;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82461cfc
	goto loc_82461CFC;
loc_82461598:
	// li r11,-1
	r11.s64 = -1;
	// stw r19,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r19.u32);
	// mr r25,r19
	r25.u64 = r19.u64;
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r11.u32);
	// lbz r11,0(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824615dc
	if (cr6.eq) goto loc_824615DC;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_824615B8:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,58
	cr6.compare<int32_t>(ctx.r10.s32, 58, xer);
	// beq cr6,0x824615d8
	if (cr6.eq) goto loc_824615D8;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x824615b8
	if (!cr6.eq) goto loc_824615B8;
	// b 0x824615dc
	goto loc_824615DC;
loc_824615D8:
	// li r25,1
	r25.s64 = 1;
loc_824615DC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8246189c
	if (cr6.eq) goto loc_8246189C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r30,r11,9120
	r30.s64 = r11.s64 + 9120;
loc_824615EC:
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824616dc
	if (cr6.eq) goto loc_824616DC;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x82461678
	if (!cr6.eq) goto loc_82461678;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82459368
	sub_82459368(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x824616d0
	if (cr0.eq) goto loc_824616D0;
loc_82461618:
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824616d0
	if (cr6.eq) goto loc_824616D0;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// addi r5,r1,164
	ctx.r5.s64 = ctx.r1.s64 + 164;
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82460e58
	sub_82460E58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824617a8
	if (cr0.lt) goto loc_824617A8;
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x82461618
	if (!cr0.eq) goto loc_82461618;
	// b 0x824616d0
	goto loc_824616D0;
loc_82461678:
	// lwz r4,24(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x824616d0
	if (cr0.eq) goto loc_824616D0;
	// lwz r11,32(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824616d0
	if (!cr6.eq) goto loc_824616D0;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,164
	ctx.r6.s64 = ctx.r1.s64 + 164;
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// stw r7,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r7.u32);
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82461068
	sub_82461068(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824617a8
	if (cr0.lt) goto loc_824617A8;
loc_824616D0:
	// lwz r29,32(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// bne 0x824615ec
	if (!cr0.eq) goto loc_824615EC;
loc_824616DC:
	// lwz r11,164(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8246189c
	if (cr6.eq) goto loc_8246189C;
	// rlwinm. r11,r22,0,29,29
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82461788
	if (cr0.eq) goto loc_82461788;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r29,1
	r29.s64 = 1;
	// lwz r31,24(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x82461788
	if (!cr6.gt) goto loc_82461788;
	// addi r30,r1,180
	r30.s64 = ctx.r1.s64 + 180;
loc_8246170C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r5,40(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82461760
	if (cr0.eq) goto loc_82461760;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r6,44(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 44);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82459dd0
	sub_82459DD0(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82461760
	if (cr6.eq) goto loc_82461760;
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x8246170c
	if (cr6.lt) goto loc_8246170C;
loc_82461760:
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// bge cr6,0x82461788
	if (!cr6.lt) goto loc_82461788;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r23)
	ctx.r7.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// li r5,3067
	ctx.r5.s64 = 3067;
	// addi r6,r11,-22060
	ctx.r6.s64 = r11.s64 + -22060;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82461788:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x824617d4
	if (cr6.eq) goto loc_824617D4;
	// rlwinm. r11,r22,0,30,30
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// beq 0x824617b8
	if (cr0.eq) goto loc_824617B8;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r11.u32);
	// b 0x824617d4
	goto loc_824617D4;
loc_824617A8:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461d00
	if (cr6.eq) goto loc_82461D00;
	// stw r19,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r19.u32);
	// b 0x82461d00
	goto loc_82461D00;
loc_824617B8:
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824617d4
	if (cr0.eq) goto loc_824617D4;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r20)
	PPC_STORE_U32(r20.u32 + 0, ctx.r3.u32);
	// beq 0x824613b4
	if (cr0.eq) goto loc_824613B4;
loc_824617D4:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// addi r31,r1,168
	r31.s64 = ctx.r1.s64 + 168;
	// stw r19,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, r19.u32);
	// mr r29,r19
	r29.u64 = r19.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8246188c
	if (cr6.eq) goto loc_8246188C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r30,r1,176
	r30.s64 = ctx.r1.s64 + 176;
	// addi r28,r11,-22860
	r28.s64 = r11.s64 + -22860;
loc_82461800:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82461824
	if (cr0.eq) goto loc_82461824;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82461828
	goto loc_82461828;
loc_82461824:
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
loc_82461828:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// beq cr6,0x824613b4
	if (cr6.eq) goto loc_824613B4;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246185c
	if (cr0.eq) goto loc_8246185C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r5,40(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x82461860
	goto loc_82461860;
loc_8246185C:
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
loc_82461860:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// beq cr6,0x824613b4
	if (cr6.eq) goto loc_824613B4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// addi r31,r11,12
	r31.s64 = r11.s64 + 12;
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// blt cr6,0x82461800
	if (cr6.lt) goto loc_82461800;
loc_8246188C:
	// lwz r11,168(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
loc_82461894:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82461d00
	goto loc_82461D00;
loc_8246189C:
	// rlwinm. r11,r22,0,30,30
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82461cd8
	if (!cr0.eq) goto loc_82461CD8;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x82461cd8
	if (!cr6.eq) goto loc_82461CD8;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x82461cd8
	if (!cr6.eq) goto loc_82461CD8;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r3,8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r4,r11,-22068
	ctx.r4.s64 = r11.s64 + -22068;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824618d4
	if (!cr0.eq) goto loc_824618D4;
	// li r31,9
	r31.s64 = 9;
	// b 0x824618f4
	goto loc_824618F4;
loc_824618D4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r3,8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r31,r11,-28056
	r31.s64 = r11.s64 + -28056;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8246191c
	if (!cr0.eq) goto loc_8246191C;
	// li r31,12
	r31.s64 = 12;
loc_824618F4:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x82461390
	goto loc_82461390;
loc_8246191C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r3,8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r4,r11,7600
	ctx.r4.s64 = r11.s64 + 7600;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82461958
	if (!cr0.eq) goto loc_82461958;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r5,12
	ctx.r5.s64 = 12;
	// b 0x8246138c
	goto loc_8246138C;
loc_82461958:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r3,8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r4,r11,-22076
	ctx.r4.s64 = r11.s64 + -22076;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82461998
	if (!cr0.eq) goto loc_82461998;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,4
	ctx.r7.s64 = 4;
	// li r5,12
	ctx.r5.s64 = 12;
	// b 0x82461438
	goto loc_82461438;
loc_82461998:
	// lwz r11,80(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82461a4c
	if (cr6.eq) goto loc_82461A4C;
	// lwz r11,0(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82461a4c
	if (!cr0.eq) goto loc_82461A4C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r3,8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r4,r11,-18504
	ctx.r4.s64 = r11.s64 + -18504;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824619d0
	if (!cr0.eq) goto loc_824619D0;
	// li r31,42
	r31.s64 = 42;
	// b 0x82461a24
	goto loc_82461A24;
loc_824619D0:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r3,8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r4,r11,-18520
	ctx.r4.s64 = r11.s64 + -18520;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824619f0
	if (!cr0.eq) goto loc_824619F0;
	// li r31,43
	r31.s64 = 43;
	// b 0x82461a24
	goto loc_82461A24;
loc_824619F0:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lwz r3,8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r4,r11,27080
	ctx.r4.s64 = r11.s64 + 27080;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82461a20
	if (cr0.eq) goto loc_82461A20;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// lwz r3,8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// addi r4,r11,-18396
	ctx.r4.s64 = r11.s64 + -18396;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82461a4c
	if (!cr0.eq) goto loc_82461A4C;
loc_82461A20:
	// li r31,24
	r31.s64 = 24;
loc_82461A24:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x82461390
	goto loc_82461390;
loc_82461A4C:
	// lwz r10,8(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
loc_82461A58:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x82461a58
	if (!cr6.eq) goto loc_82461A58;
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r6,r11,0
	ctx.r6.u64 = __builtin_rotateleft32(r11.u32, 0);
	// cmplwi cr6,r6,4
	cr6.compare<uint32_t>(ctx.r6.u32, 4, xer);
	// blt cr6,0x82461ac4
	if (cr6.lt) goto loc_82461AC4;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lis r9,-32253
	ctx.r9.s64 = -2113732608;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
	// addi r9,r9,-24640
	ctx.r9.s64 = ctx.r9.s64 + -24640;
loc_82461A8C:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r7,r5,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r5.s64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461aac
	if (!cr0.eq) goto loc_82461AAC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x82461a8c
	if (!cr6.eq) goto loc_82461A8C;
loc_82461AAC:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461ac4
	if (!cr0.eq) goto loc_82461AC4;
	// mr r30,r19
	r30.u64 = r19.u64;
loc_82461AB8:
	// addi r31,r10,4
	r31.s64 = ctx.r10.s64 + 4;
	// addi r11,r6,-4
	r11.s64 = ctx.r6.s64 + -4;
	// b 0x82461c34
	goto loc_82461C34;
loc_82461AC4:
	// cmplwi cr6,r6,3
	cr6.compare<uint32_t>(ctx.r6.u32, 3, xer);
	// blt cr6,0x82461b54
	if (cr6.lt) goto loc_82461B54;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lis r9,-32251
	ctx.r9.s64 = -2113601536;
	// addi r8,r11,3
	ctx.r8.s64 = r11.s64 + 3;
	// addi r9,r9,25892
	ctx.r9.s64 = ctx.r9.s64 + 25892;
loc_82461ADC:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r7,r5,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r5.s64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461afc
	if (!cr0.eq) goto loc_82461AFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x82461adc
	if (!cr6.eq) goto loc_82461ADC;
loc_82461AFC:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461b14
	if (!cr0.eq) goto loc_82461B14;
	// li r30,5
	r30.s64 = 5;
	// addi r31,r10,3
	r31.s64 = ctx.r10.s64 + 3;
	// addi r11,r6,-3
	r11.s64 = ctx.r6.s64 + -3;
	// b 0x82461c34
	goto loc_82461C34;
loc_82461B14:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r8,r11,3
	ctx.r8.s64 = r11.s64 + 3;
	// addi r9,r9,-22936
	ctx.r9.s64 = ctx.r9.s64 + -22936;
loc_82461B24:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r7,r5,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r5.s64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461b44
	if (!cr0.eq) goto loc_82461B44;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x82461b24
	if (!cr6.eq) goto loc_82461B24;
loc_82461B44:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461b54
	if (!cr0.eq) goto loc_82461B54;
	// li r30,9
	r30.s64 = 9;
	// b 0x82461ab8
	goto loc_82461AB8;
loc_82461B54:
	// cmplwi cr6,r6,4
	cr6.compare<uint32_t>(ctx.r6.u32, 4, xer);
	// blt cr6,0x82461b9c
	if (cr6.lt) goto loc_82461B9C;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lis r9,-32246
	ctx.r9.s64 = -2113273856;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
	// addi r9,r9,-22944
	ctx.r9.s64 = ctx.r9.s64 + -22944;
loc_82461B6C:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r7,r5,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r5.s64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461b8c
	if (!cr0.eq) goto loc_82461B8C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x82461b6c
	if (!cr6.eq) goto loc_82461B6C;
loc_82461B8C:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461b9c
	if (!cr0.eq) goto loc_82461B9C;
	// li r30,11
	r30.s64 = 11;
	// b 0x82461ab8
	goto loc_82461AB8;
loc_82461B9C:
	// cmplwi cr6,r6,5
	cr6.compare<uint32_t>(ctx.r6.u32, 5, xer);
	// blt cr6,0x82461be8
	if (cr6.lt) goto loc_82461BE8;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// addi r8,r11,5
	ctx.r8.s64 = r11.s64 + 5;
loc_82461BB0:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r7,r5,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r5.s64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461bd0
	if (!cr0.eq) goto loc_82461BD0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x82461bb0
	if (!cr6.eq) goto loc_82461BB0;
loc_82461BD0:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461be8
	if (!cr0.eq) goto loc_82461BE8;
	// li r30,12
	r30.s64 = 12;
	// addi r31,r10,5
	r31.s64 = ctx.r10.s64 + 5;
	// addi r11,r6,-5
	r11.s64 = ctx.r6.s64 + -5;
	// b 0x82461c34
	goto loc_82461C34;
loc_82461BE8:
	// cmplwi cr6,r6,6
	cr6.compare<uint32_t>(ctx.r6.u32, 6, xer);
	// blt cr6,0x82461cd8
	if (cr6.lt) goto loc_82461CD8;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r8,r11,6
	ctx.r8.s64 = r11.s64 + 6;
	// addi r9,r9,-28064
	ctx.r9.s64 = ctx.r9.s64 + -28064;
loc_82461C00:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// subf. r7,r5,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r5.s64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461c20
	if (!cr0.eq) goto loc_82461C20;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x82461c00
	if (!cr6.eq) goto loc_82461C00;
loc_82461C20:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x82461cd8
	if (!cr0.eq) goto loc_82461CD8;
	// li r30,13
	r30.s64 = 13;
	// addi r31,r10,6
	r31.s64 = ctx.r10.s64 + 6;
	// addi r11,r6,-6
	r11.s64 = ctx.r6.s64 + -6;
loc_82461C34:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82461c74
	if (!cr6.eq) goto loc_82461C74;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461cd8
	if (cr6.lt) goto loc_82461CD8;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461cd8
	if (!cr6.lt) goto loc_82461CD8;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// b 0x82461380
	goto loc_82461380;
loc_82461C74:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x82461cd8
	if (!cr6.eq) goto loc_82461CD8;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461cd8
	if (cr6.lt) goto loc_82461CD8;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461cd8
	if (!cr6.lt) goto loc_82461CD8;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// cmplwi cr6,r11,120
	cr6.compare<uint32_t>(r11.u32, 120, xer);
	// bne cr6,0x82461cd8
	if (!cr6.eq) goto loc_82461CD8;
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// blt cr6,0x82461cd8
	if (cr6.lt) goto loc_82461CD8;
	// cmpwi cr6,r11,53
	cr6.compare<int32_t>(r11.s32, 53, xer);
	// bge cr6,0x82461cd8
	if (!cr6.lt) goto loc_82461CD8;
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82461894
	if (cr6.eq) goto loc_82461894;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824613a4
	if (cr0.eq) goto loc_824613A4;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// b 0x82461420
	goto loc_82461420;
loc_82461CD8:
	// clrlwi. r11,r22,31
	r11.u64 = r22.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82461cfc
	if (cr0.eq) goto loc_82461CFC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r23)
	ctx.r7.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// li r5,3004
	ctx.r5.s64 = 3004;
	// addi r6,r11,-22104
	ctx.r6.s64 = r11.s64 + -22104;
loc_82461CF0:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82461CFC:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82461D00:
	// addi r1,r1,544
	ctx.r1.s64 = ctx.r1.s64 + 544;
	// b 0x8239bd24
	return;
}

__attribute__((alias("__imp__sub_82461D08"))) PPC_WEAK_FUNC(sub_82461D08);
PPC_FUNC_IMPL(__imp__sub_82461D08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcdc
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// addi r26,r1,128
	r26.s64 = ctx.r1.s64 + 128;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r11.u32);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82461f38
	if (cr6.eq) goto loc_82461F38;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r23,1
	r23.s64 = 1;
	// addi r21,r11,-21792
	r21.s64 = r11.s64 + -21792;
loc_82461D40:
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82461f38
	if (cr6.eq) goto loc_82461F38;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82461d70
	if (cr0.eq) goto loc_82461D70;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82461d74
	goto loc_82461D74;
loc_82461D70:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82461D74:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82461f38
	if (cr6.eq) goto loc_82461F38;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82461db0
	if (cr0.eq) goto loc_82461DB0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x82461db4
	goto loc_82461DB4;
loc_82461DB0:
	// li r29,0
	r29.s64 = 0;
loc_82461DB4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82461f38
	if (cr6.eq) goto loc_82461F38;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r27,r23
	r27.u64 = r23.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// stw r29,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r29.u32);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r26,r11,12
	r26.s64 = r11.s64 + 12;
	// beq cr6,0x82461df0
	if (cr6.eq) goto loc_82461DF0;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r29)
	PPC_STORE_U32(r29.u32 + 24, ctx.r3.u32);
	// beq 0x82461f38
	if (cr0.eq) goto loc_82461F38;
loc_82461DF0:
	// lwz r30,8(r22)
	r30.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// b 0x82461e68
	goto loc_82461E68;
loc_82461DF8:
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82461e10
	if (cr0.eq) goto loc_82461E10;
	// bl 0x8240abc0
	sub_8240ABC0(ctx, base);
	// b 0x82461e14
	goto loc_82461E14;
loc_82461E10:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82461E14:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82461f38
	if (cr6.eq) goto loc_82461F38;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// addi r31,r3,20
	r31.s64 = ctx.r3.s64 + 20;
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r3,24(r29)
	PPC_STORE_U32(r29.u32 + 24, ctx.r3.u32);
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x82461e54
	if (cr0.eq) goto loc_82461E54;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82461e5c
	if (!cr0.lt) goto loc_82461E5C;
	// li r28,3058
	r28.s64 = 3058;
	// b 0x82461e58
	goto loc_82461E58;
loc_82461E54:
	// li r28,3072
	r28.s64 = 3072;
loc_82461E58:
	// stw r23,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r23.u32);
loc_82461E5C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mullw r27,r11,r27
	r27.s64 = int64_t(r11.s32) * int64_t(r27.s32);
loc_82461E68:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82461df8
	if (!cr6.eq) goto loc_82461DF8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r29)
	PPC_STORE_U32(r29.u32 + 20, ctx.r3.u32);
	// beq 0x82461f38
	if (cr0.eq) goto loc_82461F38;
	// addi r4,r30,16
	ctx.r4.s64 = r30.s64 + 16;
	// cmplwi cr6,r28,3058
	cr6.compare<uint32_t>(r28.u32, 3058, xer);
	// beq cr6,0x82461f20
	if (cr6.eq) goto loc_82461F20;
	// cmplwi cr6,r28,3072
	cr6.compare<uint32_t>(r28.u32, 3072, xer);
	// beq cr6,0x82461f10
	if (cr6.eq) goto loc_82461F10;
	// cmplwi cr6,r27,1
	cr6.compare<uint32_t>(r27.u32, 1, xer);
	// blt cr6,0x82461f00
	if (cr6.lt) goto loc_82461F00;
	// lis r11,1
	r11.s64 = 65536;
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// bgt cr6,0x82461f00
	if (cr6.gt) goto loc_82461F00;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82461ed0
	if (cr0.eq) goto loc_82461ED0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82461ed0
	if (!cr6.eq) goto loc_82461ED0;
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
loc_82461ED0:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8245af30
	sub_8245AF30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82461f38
	if (cr0.lt) goto loc_82461F38;
	// lwz r22,12(r22)
	r22.u64 = PPC_LOAD_U32(r22.u32 + 12);
	// cmplwi r22,0
	cr0.compare<uint32_t>(r22.u32, 0, xer);
	// bne 0x82461d40
	if (!cr0.eq) goto loc_82461D40;
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_82461EF8:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8239bd2c
	return;
loc_82461F00:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3059
	ctx.r5.s64 = 3059;
	// addi r6,r11,-21844
	ctx.r6.s64 = r11.s64 + -21844;
	// b 0x82461f2c
	goto loc_82461F2C;
loc_82461F10:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3072
	ctx.r5.s64 = 3072;
	// addi r6,r11,-21892
	ctx.r6.s64 = r11.s64 + -21892;
	// b 0x82461f2c
	goto loc_82461F2C;
loc_82461F20:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3058
	ctx.r5.s64 = 3058;
	// addi r6,r11,-21952
	ctx.r6.s64 = r11.s64 + -21952;
loc_82461F2C:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r7,8(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82461F38:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82461ef8
	goto loc_82461EF8;
}

__attribute__((alias("__imp__sub_82461F40"))) PPC_WEAK_FUNC(sub_82461F40);
PPC_FUNC_IMPL(__imp__sub_82461F40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82461f80
	if (cr0.eq) goto loc_82461F80;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82461f84
	goto loc_82461F84;
loc_82461F80:
	// li r31,0
	r31.s64 = 0;
loc_82461F84:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82461f94
	if (!cr6.eq) goto loc_82461F94;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82461fac
	goto loc_82461FAC;
loc_82461F94:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82461d08
	sub_82461D08(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_82461FAC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_82461FB4"))) PPC_WEAK_FUNC(sub_82461FB4);
PPC_FUNC_IMPL(__imp__sub_82461FB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82461FB8"))) PPC_WEAK_FUNC(sub_82461FB8);
PPC_FUNC_IMPL(__imp__sub_82461FB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462060
	if (cr6.eq) goto loc_82462060;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82462004
	if (!cr0.lt) goto loc_82462004;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3060
	ctx.r5.s64 = 3060;
	// addi r6,r11,-21732
	ctx.r6.s64 = r11.s64 + -21732;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82462060
	goto loc_82462060;
loc_82462004:
	// lwz r29,128(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r11,r29,-1
	r11.s64 = r29.s64 + -1;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bgt cr6,0x82462044
	if (cr6.gt) goto loc_82462044;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462060
	if (cr0.eq) goto loc_82462060;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r5,20(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x82462064
	goto loc_82462064;
loc_82462044:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r6,r11,-21776
	ctx.r6.s64 = r11.s64 + -21776;
	// li r5,3052
	ctx.r5.s64 = 3052;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82462060:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462064:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_8246206C"))) PPC_WEAK_FUNC(sub_8246206C);
PPC_FUNC_IMPL(__imp__sub_8246206C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82462070"))) PPC_WEAK_FUNC(sub_82462070);
PPC_FUNC_IMPL(__imp__sub_82462070) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462144
	if (cr6.eq) goto loc_82462144;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8246212c
	if (cr0.lt) goto loc_8246212C;
	// addi r5,r1,132
	ctx.r5.s64 = ctx.r1.s64 + 132;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8246212c
	if (cr0.lt) goto loc_8246212C;
	// lwz r28,128(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r11,r28,-1
	r11.s64 = r28.s64 + -1;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bgt cr6,0x8246210c
	if (cr6.gt) goto loc_8246210C;
	// lwz r29,132(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// addi r11,r29,-1
	r11.s64 = r29.s64 + -1;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bgt cr6,0x8246210c
	if (cr6.gt) goto loc_8246210C;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462144
	if (cr0.eq) goto loc_82462144;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r5,20(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x82462148
	goto loc_82462148;
loc_8246210C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r6,r11,-21620
	ctx.r6.s64 = r11.s64 + -21620;
	// li r5,3053
	ctx.r5.s64 = 3053;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82462144
	goto loc_82462144;
loc_8246212C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3061
	ctx.r5.s64 = 3061;
	// addi r6,r11,-21676
	ctx.r6.s64 = r11.s64 + -21676;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82462144:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462148:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_82462150"))) PPC_WEAK_FUNC(sub_82462150);
PPC_FUNC_IMPL(__imp__sub_82462150) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r30,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, r30.u32);
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x824621a4
	if (!cr0.lt) goto loc_824621A4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3058
	ctx.r5.s64 = 3058;
	// addi r6,r11,-21576
	ctx.r6.s64 = r11.s64 + -21576;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_8246219C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8246220c
	goto loc_8246220C;
loc_824621A4:
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824621c4
	if (cr0.eq) goto loc_824621C4;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// bl 0x8240abf0
	sub_8240ABF0(ctx, base);
	// b 0x824621c8
	goto loc_824621C8;
loc_824621C4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_824621C8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8246219c
	if (cr6.eq) goto loc_8246219C;
	// addi r11,r1,172
	r11.s64 = ctx.r1.s64 + 172;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824621fc
	if (cr6.eq) goto loc_824621FC;
loc_824621DC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r9,8
	cr6.compare<int32_t>(ctx.r9.s32, 8, xer);
	// bne cr6,0x824621fc
	if (!cr6.eq) goto loc_824621FC;
	// addi r11,r10,16
	r11.s64 = ctx.r10.s64 + 16;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x824621dc
	if (!cr6.eq) goto loc_824621DC;
loc_824621FC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r10.u32);
	// stw r3,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r3.u32);
	// lwz r3,172(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
loc_8246220C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82462224"))) PPC_WEAK_FUNC(sub_82462224);
PPC_FUNC_IMPL(__imp__sub_82462224) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82462228"))) PPC_WEAK_FUNC(sub_82462228);
PPC_FUNC_IMPL(__imp__sub_82462228) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r26,0
	r26.s64 = 0;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r29,r26
	r29.u64 = r26.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r26.u32);
	// beq cr6,0x8246232c
	if (cr6.eq) goto loc_8246232C;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8246232c
	if (!cr6.eq) goto loc_8246232C;
	// addi r28,r4,16
	r28.s64 = ctx.r4.s64 + 16;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x82462338
	if (!cr6.eq) goto loc_82462338;
	// lwz r11,80(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 80);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,20(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// xori r9,r11,1
	ctx.r9.u64 = r11.u64 ^ 1;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82462340
	if (cr0.eq) goto loc_82462340;
	// lwz r11,80(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82462458
	if (!cr6.eq) goto loc_82462458;
	// li r3,88
	ctx.r3.s64 = 88;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824622c8
	if (cr0.eq) goto loc_824622C8;
	// bl 0x8240b568
	sub_8240B568(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x824622cc
	goto loc_824622CC;
loc_824622C8:
	// mr r31,r26
	r31.u64 = r26.u64;
loc_824622CC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8246232c
	if (cr6.eq) goto loc_8246232C;
	// li r29,1
	r29.s64 = 1;
	// li r11,514
	r11.s64 = 514;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r29,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r29.u32);
	// stw r26,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r26.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246231c
	if (cr0.eq) goto loc_8246231C;
	// lis r9,32
	ctx.r9.s64 = 2097152;
	// li r8,1
	ctx.r8.s64 = 1;
	// ori r9,r9,512
	ctx.r9.u64 = ctx.r9.u64 | 512;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x82462320
	goto loc_82462320;
loc_8246231C:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82462320:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r3.u32);
	// bne cr6,0x82462344
	if (!cr6.eq) goto loc_82462344;
loc_8246232C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462330:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd3c
	return;
loc_82462338:
	// mr r31,r27
	r31.u64 = r27.u64;
	// b 0x82462344
	goto loc_82462344;
loc_82462340:
	// lwz r31,96(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_82462344:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462378
	if (cr0.eq) goto loc_82462378;
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8246237c
	goto loc_8246237C;
loc_82462378:
	// mr r30,r26
	r30.u64 = r26.u64;
loc_8246237C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462458
	if (cr6.eq) goto loc_82462458;
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824623b4
	if (cr6.eq) goto loc_824623B4;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq 0x82462458
	if (cr0.eq) goto loc_82462458;
	// b 0x824623fc
	goto loc_824623FC;
loc_824623B4:
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824623ec
	if (cr0.eq) goto loc_824623EC;
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// addi r4,r11,6
	ctx.r4.s64 = r11.s64 + 6;
	// bl 0x8240c580
	sub_8240C580(ctx, base);
	// b 0x824623f0
	goto loc_824623F0;
loc_824623EC:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_824623F0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq cr6,0x82462458
	if (cr6.eq) goto loc_82462458;
loc_824623FC:
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// stw r4,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r4.u32);
	// beq cr6,0x82462420
	if (cr6.eq) goto loc_82462420;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
loc_82462420:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246244c
	if (cr0.eq) goto loc_8246244C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x82462450
	goto loc_82462450;
loc_8246244C:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82462450:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82462460
	if (!cr6.eq) goto loc_82462460;
loc_82462458:
	// mr r30,r26
	r30.u64 = r26.u64;
	// b 0x82462470
	goto loc_82462470;
loc_82462460:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r11,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r11.u32);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
loc_82462470:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x82462330
	goto loc_82462330;
}

__attribute__((alias("__imp__sub_82462478"))) PPC_WEAK_FUNC(sub_82462478);
PPC_FUNC_IMPL(__imp__sub_82462478) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r24,0
	r24.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// stw r24,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r24.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x824624dc
	if (cr6.eq) goto loc_824624DC;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x824624dc
	if (!cr6.eq) goto loc_824624DC;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r24,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r24.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r30,16
	ctx.r5.s64 = r30.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// lwz r30,128(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_824624DC:
	// addi r26,r31,40
	r26.s64 = r31.s64 + 40;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x82462548
	if (cr6.eq) goto loc_82462548;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462538
	if (cr6.eq) goto loc_82462538;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82462538
	if (!cr6.eq) goto loc_82462538;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82462538
	if (cr0.eq) goto loc_82462538;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82462524
	if (cr6.eq) goto loc_82462524;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82462774
	if (!cr6.eq) goto loc_82462774;
loc_82462524:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// b 0x824625d0
	goto loc_824625D0;
loc_82462538:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3037
	ctx.r5.s64 = 3037;
	// addi r6,r11,-21412
	ctx.r6.s64 = r11.s64 + -21412;
	// b 0x82462768
	goto loc_82462768;
loc_82462548:
	// mr r29,r24
	r29.u64 = r24.u64;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82462568
	if (cr6.eq) goto loc_82462568;
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82462774
	if (!cr6.eq) goto loc_82462774;
	// lwz r29,16(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// addi r26,r27,48
	r26.s64 = r27.s64 + 48;
loc_82462568:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne 0x824625a4
	if (!cr0.eq) goto loc_824625A4;
	// mr r8,r28
	ctx.r8.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8245e998
	sub_8245E998(ctx, base);
	// b 0x82462774
	goto loc_82462774;
loc_824625A4:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824625cc
	if (!cr0.eq) goto loc_824625CC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// beq 0x824625d0
	if (cr0.eq) goto loc_824625D0;
loc_824625CC:
	// li r10,1
	ctx.r10.s64 = 1;
loc_824625D0:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82459b10
	sub_82459B10(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,80
	ctx.r3.s64 = 80;
	// or r29,r11,r10
	r29.u64 = r11.u64 | ctx.r10.u64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462618
	if (cr0.eq) goto loc_82462618;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x8246261c
	goto loc_8246261C;
loc_82462618:
	// mr r28,r24
	r28.u64 = r24.u64;
loc_8246261C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82462774
	if (cr6.eq) goto loc_82462774;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8246264c
	if (cr6.eq) goto loc_8246264C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r28)
	PPC_STORE_U32(r28.u32 + 16, ctx.r3.u32);
	// beq 0x82462774
	if (cr0.eq) goto loc_82462774;
loc_8246264C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82462674
	if (cr6.eq) goto loc_82462674;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r28)
	PPC_STORE_U32(r28.u32 + 32, ctx.r3.u32);
	// beq 0x82462774
	if (cr0.eq) goto loc_82462774;
loc_82462674:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x824626d8
	if (cr6.eq) goto loc_824626D8;
	// lwz r30,32(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// b 0x824626d0
	goto loc_824626D0;
loc_82462684:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824626cc
	if (cr0.eq) goto loc_824626CC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x824626cc
	if (!cr6.eq) goto loc_824626CC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82462704
	if (cr0.eq) goto loc_82462704;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x824626cc
	if (!cr6.eq) goto loc_824626CC;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_824626CC:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
loc_824626D0:
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x82462684
	if (!cr0.eq) goto loc_82462684;
loc_824626D8:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x824626f0
	if (cr6.eq) goto loc_824626F0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,16(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
loc_824626F0:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x8246277c
	if (cr6.eq) goto loc_8246277C;
	// lwz r30,32(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 32);
	// mr r29,r24
	r29.u64 = r24.u64;
	// b 0x82462740
	goto loc_82462740;
loc_82462704:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3017
	ctx.r5.s64 = 3017;
	// addi r6,r11,-21464
	ctx.r6.s64 = r11.s64 + -21464;
	// b 0x82462768
	goto loc_82462768;
loc_82462714:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8246273c
	if (cr0.eq) goto loc_8246273C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x8246273c
	if (!cr6.eq) goto loc_8246273C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// add r29,r3,r29
	r29.u64 = ctx.r3.u64 + r29.u64;
loc_8246273C:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
loc_82462740:
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x82462714
	if (!cr0.eq) goto loc_82462714;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r28)
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// cmplw cr6,r29,r3
	cr6.compare<uint32_t>(r29.u32, ctx.r3.u32, xer);
	// beq cr6,0x8246277c
	if (cr6.eq) goto loc_8246277C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3014
	ctx.r5.s64 = 3014;
	// addi r6,r11,-21524
	ctx.r6.s64 = r11.s64 + -21524;
loc_82462768:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82462774:
	// mr r28,r24
	r28.u64 = r24.u64;
	// b 0x82462788
	goto loc_82462788;
loc_8246277C:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
loc_82462788:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8239bd38
	return;
}

__attribute__((alias("__imp__sub_82462794"))) PPC_WEAK_FUNC(sub_82462794);
PPC_FUNC_IMPL(__imp__sub_82462794) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82462798"))) PPC_WEAK_FUNC(sub_82462798);
PPC_FUNC_IMPL(__imp__sub_82462798) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcdc
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x824627d0
	if (cr6.eq) goto loc_824627D0;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x824627d0
	if (cr6.eq) goto loc_824627D0;
loc_824627C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82462c50
	goto loc_82462C50;
loc_824627D0:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x824627e4
	if (cr6.eq) goto loc_824627E4;
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x824627c8
	if (!cr6.eq) goto loc_824627C8;
loc_824627E4:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824627f8
	if (cr6.eq) goto loc_824627F8;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x824627c8
	if (!cr6.eq) goto loc_824627C8;
loc_824627F8:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// addi r27,r28,48
	r27.s64 = r28.s64 + 48;
	// bne cr6,0x8246280c
	if (!cr6.eq) goto loc_8246280C;
	// addi r27,r25,40
	r27.s64 = r25.s64 + 40;
	// beq cr6,0x82462814
	if (cr6.eq) goto loc_82462814;
loc_8246280C:
	// lwz r29,16(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// b 0x82462818
	goto loc_82462818;
loc_82462814:
	// li r29,0
	r29.s64 = 0;
loc_82462818:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82462828
	if (cr6.eq) goto loc_82462828;
	// lwz r26,16(r22)
	r26.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// b 0x8246282c
	goto loc_8246282C;
loc_82462828:
	// li r26,0
	r26.s64 = 0;
loc_8246282C:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x8246283c
	if (cr6.eq) goto loc_8246283C;
	// lwz r23,16(r21)
	r23.u64 = PPC_LOAD_U32(r21.u32 + 16);
	// b 0x82462840
	goto loc_82462840;
loc_8246283C:
	// li r23,0
	r23.s64 = 0;
loc_82462840:
	// li r3,80
	ctx.r3.s64 = 80;
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r26.u32);
	// stw r23,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r23.u32);
	// li r30,0
	r30.s64 = 0;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462880
	if (cr0.eq) goto loc_82462880;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,30
	ctx.r5.s64 = 30;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// b 0x82462884
	goto loc_82462884;
loc_82462880:
	// li r24,0
	r24.s64 = 0;
loc_82462884:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bne 0x824628b0
	if (!cr0.eq) goto loc_824628B0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-21268
	ctx.r6.s64 = r11.s64 + -21268;
	// b 0x8246298c
	goto loc_8246298C;
loc_824628B0:
	// addi r31,r24,16
	r31.s64 = r24.s64 + 16;
	// addi r7,r1,116
	ctx.r7.s64 = ctx.r1.s64 + 116;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// bl 0x8245edc8
	sub_8245EDC8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x824628e0
	if (!cr0.lt) goto loc_824628E0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-21312
	ctx.r6.s64 = r11.s64 + -21312;
	// b 0x82462988
	goto loc_82462988;
loc_824628E0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824629a0
	if (cr0.eq) goto loc_824629A0;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r3,40
	ctx.r3.s64 = 40;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82462918
	if (!cr6.eq) goto loc_82462918;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462958
	if (cr0.eq) goto loc_82462958;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r8,32(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// lwz r7,28(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// b 0x8246293c
	goto loc_8246293C;
loc_82462918:
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x82462958
	if (cr0.eq) goto loc_82462958;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8246293C:
	// li r9,512
	ctx.r9.s64 = 512;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8246295c
	goto loc_8246295C;
loc_82462958:
	// li r30,0
	r30.s64 = 0;
loc_8246295C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824629a0
	if (!cr0.eq) goto loc_824629A0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-21360
	ctx.r6.s64 = r11.s64 + -21360;
loc_82462988:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_8246298C:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82462998:
	// li r24,0
	r24.s64 = 0;
	// b 0x82462c4c
	goto loc_82462C4C;
loc_824629A0:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x824629cc
	if (cr6.eq) goto loc_824629CC;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r24)
	PPC_STORE_U32(r24.u32 + 32, ctx.r3.u32);
	// beq 0x82462998
	if (cr0.eq) goto loc_82462998;
loc_824629CC:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462a00
	if (cr0.eq) goto loc_82462A00;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82462a04
	goto loc_82462A04;
loc_82462A00:
	// li r31,0
	r31.s64 = 0;
loc_82462A04:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stw r31,36(r24)
	PPC_STORE_U32(r24.u32 + 36, r31.u32);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// addi r28,r11,-22536
	r28.s64 = r11.s64 + -22536;
	// beq 0x82462a3c
	if (cr0.eq) goto loc_82462A3C;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82462a40
	goto loc_82462A40;
loc_82462A3C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462A40:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
	// lwz r30,112(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462a84
	if (cr6.eq) goto loc_82462A84;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
loc_82462A84:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// addi r29,r11,-22544
	r29.s64 = r11.s64 + -22544;
	// beq 0x82462ab0
	if (cr0.eq) goto loc_82462AB0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82462ab4
	goto loc_82462AB4;
loc_82462AB0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462AB4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82462b24
	if (cr6.eq) goto loc_82462B24;
	// cmplw cr6,r26,r30
	cr6.compare<uint32_t>(r26.u32, r30.u32, xer);
	// beq cr6,0x82462b04
	if (cr6.eq) goto loc_82462B04;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82462b04
	if (!cr0.eq) goto loc_82462B04;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// b 0x82462b0c
	goto loc_82462B0C;
loc_82462B04:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
loc_82462B0C:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
loc_82462B24:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462b48
	if (cr0.eq) goto loc_82462B48;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82462b4c
	goto loc_82462B4C;
loc_82462B48:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462B4C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r3.u32);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
	// lwz r30,116(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462b9c
	if (cr6.eq) goto loc_82462B9C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
loc_82462B9C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462bc0
	if (cr0.eq) goto loc_82462BC0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82462bc4
	goto loc_82462BC4;
loc_82462BC0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462BC4:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r3.u32);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82462c34
	if (cr6.eq) goto loc_82462C34;
	// cmplw cr6,r23,r30
	cr6.compare<uint32_t>(r23.u32, r30.u32, xer);
	// beq cr6,0x82462c58
	if (cr6.eq) goto loc_82462C58;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82462c58
	if (!cr0.eq) goto loc_82462C58;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
loc_82462C14:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82462998
	if (cr6.eq) goto loc_82462998;
loc_82462C34:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
loc_82462C4C:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
loc_82462C50:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8239bd2c
	return;
loc_82462C58:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// b 0x82462c14
	goto loc_82462C14;
}

__attribute__((alias("__imp__sub_82462C64"))) PPC_WEAK_FUNC(sub_82462C64);
PPC_FUNC_IMPL(__imp__sub_82462C64) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82462C68"))) PPC_WEAK_FUNC(sub_82462C68);
PPC_FUNC_IMPL(__imp__sub_82462C68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82462f20
	if (cr6.eq) goto loc_82462F20;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82462f20
	if (!cr6.eq) goto loc_82462F20;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82462f20
	if (cr6.eq) goto loc_82462F20;
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82462f20
	if (!cr6.eq) goto loc_82462F20;
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r27,r25,48
	r27.s64 = r25.s64 + 48;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462ce0
	if (cr0.eq) goto loc_82462CE0;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,28
	ctx.r5.s64 = 28;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82462ce4
	goto loc_82462CE4;
loc_82462CE0:
	// li r30,0
	r30.s64 = 0;
loc_82462CE4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462f20
	if (cr6.eq) goto loc_82462F20;
	// lwz r31,16(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// lwz r29,16(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x82462f08
	if (cr0.eq) goto loc_82462F08;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x82462d38
	if (!cr6.eq) goto loc_82462D38;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82462dfc
	if (cr6.eq) goto loc_82462DFC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq 0x82462f20
	if (cr0.eq) goto loc_82462F20;
	// b 0x82462dfc
	goto loc_82462DFC;
loc_82462D38:
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82462f08
	if (!cr6.eq) goto loc_82462F08;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x82462d68
	if (!cr6.eq) goto loc_82462D68;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462dec
	if (cr0.eq) goto loc_82462DEC;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm r9,r11,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// b 0x82462dd0
	goto loc_82462DD0;
loc_82462D68:
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82462f08
	if (!cr6.eq) goto loc_82462F08;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x82462da0
	if (!cr6.eq) goto loc_82462DA0;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462dec
	if (cr0.eq) goto loc_82462DEC;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm r9,r11,0,22,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// b 0x82462dd8
	goto loc_82462DD8;
loc_82462DA0:
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82462f08
	if (!cr6.eq) goto loc_82462F08;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm. r11,r11,0,10,10
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82462f08
	if (cr0.eq) goto loc_82462F08;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462dec
	if (cr0.eq) goto loc_82462DEC;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm r9,r11,0,10,22
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x3FFE00;
	// rlwinm r9,r9,0,22,10
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFE003FF;
loc_82462DD0:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
loc_82462DD8:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r7,1
	ctx.r7.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x82462df0
	goto loc_82462DF0;
loc_82462DEC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462DF0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq cr6,0x82462f20
	if (cr6.eq) goto loc_82462F20;
loc_82462DFC:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82462e1c
	if (cr6.eq) goto loc_82462E1C;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82462e1c
	if (!cr6.eq) goto loc_82462E1C;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82462e2c
	if (cr6.eq) goto loc_82462E2C;
loc_82462E1C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3051
	ctx.r5.s64 = 3051;
	// addi r6,r11,-21224
	ctx.r6.s64 = r11.s64 + -21224;
	// b 0x82462f14
	goto loc_82462F14;
loc_82462E2C:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq 0x82462f20
	if (cr0.eq) goto loc_82462F20;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462e80
	if (cr0.eq) goto loc_82462E80;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82462e84
	goto loc_82462E84;
loc_82462E80:
	// li r31,0
	r31.s64 = 0;
loc_82462E84:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82462f20
	if (cr6.eq) goto loc_82462F20;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bne 0x82462ec8
	if (!cr0.eq) goto loc_82462EC8;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,8(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8245e998
	sub_8245E998(ctx, base);
	// b 0x82462f20
	goto loc_82462F20;
loc_82462EC8:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// oris r11,r11,64
	r11.u64 = r11.u64 | 4194304;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// bl 0x82462478
	sub_82462478(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// beq 0x82462f20
	if (cr0.eq) goto loc_82462F20;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x82462f24
	goto loc_82462F24;
loc_82462F08:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3021
	ctx.r5.s64 = 3021;
	// addi r6,r11,-21240
	ctx.r6.s64 = r11.s64 + -21240;
loc_82462F14:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82462F20:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82462F24:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_82462F2C"))) PPC_WEAK_FUNC(sub_82462F2C);
PPC_FUNC_IMPL(__imp__sub_82462F2C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82462F30"))) PPC_WEAK_FUNC(sub_82462F30);
PPC_FUNC_IMPL(__imp__sub_82462F30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd8
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r20,0
	r20.s64 = 0;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r23,r20
	r23.u64 = r20.u64;
	// mr r21,r20
	r21.u64 = r20.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// stw r23,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r23.u32);
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// stw r21,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r21.u32);
	// mr r26,r20
	r26.u64 = r20.u64;
	// mr r22,r20
	r22.u64 = r20.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82462f8c
	if (cr6.eq) goto loc_82462F8C;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x82462f8c
	if (cr6.eq) goto loc_82462F8C;
loc_82462F84:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x824637d8
	goto loc_824637D8;
loc_82462F8C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82462fa8
	if (cr6.eq) goto loc_82462FA8;
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82462f84
	if (!cr6.eq) goto loc_82462F84;
	// addi r25,r28,48
	r25.s64 = r28.s64 + 48;
	// b 0x82462fb8
	goto loc_82462FB8;
loc_82462FA8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// addi r25,r29,48
	r25.s64 = r29.s64 + 48;
	// bne cr6,0x82462fb8
	if (!cr6.eq) goto loc_82462FB8;
	// addi r25,r27,40
	r25.s64 = r27.s64 + 40;
loc_82462FB8:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82462fec
	if (cr0.eq) goto loc_82462FEC;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82462ff0
	goto loc_82462FF0;
loc_82462FEC:
	// mr r30,r20
	r30.u64 = r20.u64;
loc_82462FF0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82462f84
	if (cr6.eq) goto loc_82462F84;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82463020
	if (cr6.eq) goto loc_82463020;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq 0x824637d0
	if (cr0.eq) goto loc_824637D0;
loc_82463020:
	// cmpwi cr6,r31,35
	cr6.compare<int32_t>(r31.s32, 35, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,36
	cr6.compare<int32_t>(r31.s32, 36, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,37
	cr6.compare<int32_t>(r31.s32, 37, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,38
	cr6.compare<int32_t>(r31.s32, 38, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,39
	cr6.compare<int32_t>(r31.s32, 39, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,45
	cr6.compare<int32_t>(r31.s32, 45, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,46
	cr6.compare<int32_t>(r31.s32, 46, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,40
	cr6.compare<int32_t>(r31.s32, 40, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,41
	cr6.compare<int32_t>(r31.s32, 41, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,42
	cr6.compare<int32_t>(r31.s32, 42, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,43
	cr6.compare<int32_t>(r31.s32, 43, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmpwi cr6,r31,44
	cr6.compare<int32_t>(r31.s32, 44, xer);
	// beq cr6,0x824630ac
	if (cr6.eq) goto loc_824630AC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82463174
	if (cr6.eq) goto loc_82463174;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// bne 0x82463174
	if (!cr0.eq) goto loc_82463174;
	// b 0x824637d0
	goto loc_824637D0;
loc_824630AC:
	// addi r11,r31,-35
	r11.s64 = r31.s64 + -35;
	// li r4,8
	ctx.r4.s64 = 8;
	// cmplwi cr6,r11,11
	cr6.compare<uint32_t>(r11.u32, 11, xer);
	// bgt cr6,0x8246314c
	if (cr6.gt) goto loc_8246314C;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-26120
	r12.s64 = r12.s64 + -26120;
	// lbzx r0,r12,r11
	r0.u64 = PPC_LOAD_U8(r12.u32 + r11.u32);
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,12516
	r12.s64 = r12.s64 + 12516;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_824630E4;
	case 1:
		goto loc_824630EC;
	case 2:
		goto loc_824630F4;
	case 3:
		goto loc_824630FC;
	case 4:
		goto loc_82463104;
	case 5:
		goto loc_82463124;
	case 6:
		goto loc_8246312C;
	case 7:
		goto loc_82463134;
	case 8:
		goto loc_8246313C;
	case 9:
		goto loc_82463144;
	case 10:
		goto loc_8246310C;
	case 11:
		goto loc_82463118;
	default:
		__builtin_unreachable();
	}
loc_824630E4:
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x82463148
	goto loc_82463148;
loc_824630EC:
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x82463148
	goto loc_82463148;
loc_824630F4:
	// li r4,10
	ctx.r4.s64 = 10;
	// b 0x82463148
	goto loc_82463148;
loc_824630FC:
	// li r4,11
	ctx.r4.s64 = 11;
	// b 0x82463148
	goto loc_82463148;
loc_82463104:
	// li r4,12
	ctx.r4.s64 = 12;
	// b 0x82463148
	goto loc_82463148;
loc_8246310C:
	// li r31,1
	r31.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x8246314c
	goto loc_8246314C;
loc_82463118:
	// li r31,1
	r31.s64 = 1;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x8246314c
	goto loc_8246314C;
loc_82463124:
	// li r4,13
	ctx.r4.s64 = 13;
	// b 0x82463148
	goto loc_82463148;
loc_8246312C:
	// li r4,14
	ctx.r4.s64 = 14;
	// b 0x82463148
	goto loc_82463148;
loc_82463134:
	// li r4,21
	ctx.r4.s64 = 21;
	// b 0x82463148
	goto loc_82463148;
loc_8246313C:
	// li r4,22
	ctx.r4.s64 = 22;
	// b 0x82463148
	goto loc_82463148;
loc_82463144:
	// li r4,23
	ctx.r4.s64 = 23;
loc_82463148:
	// li r31,27
	r31.s64 = 27;
loc_8246314C:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82462f30
	sub_82462F30(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// beq 0x824637d0
	if (cr0.eq) goto loc_824637D0;
	// stw r31,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r31.u32);
loc_82463174:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8246318c
	if (cr0.eq) goto loc_8246318C;
	// lwz r26,16(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r23,r26
	r23.u64 = r26.u64;
	// stw r23,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r23.u32);
loc_8246318C:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// beq cr6,0x8246328c
	if (cr6.eq) goto loc_8246328C;
	// cmpwi cr6,r31,1
	cr6.compare<int32_t>(r31.s32, 1, xer);
	// beq cr6,0x8246328c
	if (cr6.eq) goto loc_8246328C;
	// cmpwi cr6,r31,26
	cr6.compare<int32_t>(r31.s32, 26, xer);
	// beq cr6,0x8246328c
	if (cr6.eq) goto loc_8246328C;
	// cmpwi cr6,r31,27
	cr6.compare<int32_t>(r31.s32, 27, xer);
	// beq cr6,0x8246328c
	if (cr6.eq) goto loc_8246328C;
	// cmpwi cr6,r31,19
	cr6.compare<int32_t>(r31.s32, 19, xer);
	// beq cr6,0x8246328c
	if (cr6.eq) goto loc_8246328C;
	// cmpwi cr6,r31,20
	cr6.compare<int32_t>(r31.s32, 20, xer);
	// beq cr6,0x8246328c
	if (cr6.eq) goto loc_8246328C;
	// cmpwi cr6,r31,7
	cr6.compare<int32_t>(r31.s32, 7, xer);
	// bne cr6,0x824631f4
	if (!cr6.eq) goto loc_824631F4;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x824631e4
	if (cr6.eq) goto loc_824631E4;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x824631e4
	if (!cr6.eq) goto loc_824631E4;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// blt cr6,0x82463318
	if (cr6.lt) goto loc_82463318;
loc_824631E4:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3082
	ctx.r5.s64 = 3082;
	// addi r6,r11,-20948
	ctx.r6.s64 = r11.s64 + -20948;
	// b 0x824637c4
	goto loc_824637C4;
loc_824631F4:
	// cmpwi cr6,r31,13
	cr6.compare<int32_t>(r31.s32, 13, xer);
	// beq cr6,0x82463254
	if (cr6.eq) goto loc_82463254;
	// cmpwi cr6,r31,14
	cr6.compare<int32_t>(r31.s32, 14, xer);
	// beq cr6,0x82463254
	if (cr6.eq) goto loc_82463254;
	// cmpwi cr6,r31,21
	cr6.compare<int32_t>(r31.s32, 21, xer);
	// beq cr6,0x82463254
	if (cr6.eq) goto loc_82463254;
	// cmpwi cr6,r31,22
	cr6.compare<int32_t>(r31.s32, 22, xer);
	// beq cr6,0x82463254
	if (cr6.eq) goto loc_82463254;
	// cmpwi cr6,r31,23
	cr6.compare<int32_t>(r31.s32, 23, xer);
	// beq cr6,0x82463254
	if (cr6.eq) goto loc_82463254;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82463244
	if (cr6.eq) goto loc_82463244;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x82463244
	if (!cr6.eq) goto loc_82463244;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8246328c
	if (!cr0.eq) goto loc_8246328C;
loc_82463244:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3022
	ctx.r5.s64 = 3022;
	// addi r6,r11,-20984
	ctx.r6.s64 = r11.s64 + -20984;
	// b 0x824637c4
	goto loc_824637C4;
loc_82463254:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x824631e4
	if (cr6.eq) goto loc_824631E4;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x824631e4
	if (!cr6.eq) goto loc_824631E4;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bge cr6,0x824631e4
	if (!cr6.lt) goto loc_824631E4;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
loc_8246328C:
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// beq cr6,0x824632ac
	if (cr6.eq) goto loc_824632AC;
	// cmpwi cr6,r31,3
	cr6.compare<int32_t>(r31.s32, 3, xer);
	// beq cr6,0x824632ac
	if (cr6.eq) goto loc_824632AC;
	// cmpwi cr6,r31,26
	cr6.compare<int32_t>(r31.s32, 26, xer);
	// beq cr6,0x824632ac
	if (cr6.eq) goto loc_824632AC;
	// cmpwi cr6,r31,27
	cr6.compare<int32_t>(r31.s32, 27, xer);
	// bne cr6,0x82463318
	if (!cr6.eq) goto loc_82463318;
loc_824632AC:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824637b8
	if (!cr0.eq) goto loc_824637B8;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// bl 0x82459b10
	sub_82459B10(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824637b8
	if (!cr0.eq) goto loc_824637B8;
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x824632ec
	if (cr6.eq) goto loc_824632EC;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x82463318
	if (!cr6.eq) goto loc_82463318;
loc_824632EC:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x82463318
	if (!cr6.eq) goto loc_82463318;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82463318
	if (!cr0.eq) goto loc_82463318;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3065
	ctx.r5.s64 = 3065;
	// addi r6,r11,-21036
	ctx.r6.s64 = r11.s64 + -21036;
	// b 0x824637c4
	goto loc_824637C4;
loc_82463318:
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82463330
	if (cr0.eq) goto loc_82463330;
	// lwz r22,16(r11)
	r22.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r21,r22
	r21.u64 = r22.u64;
	// stw r21,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r21.u32);
loc_82463330:
	// cmpwi cr6,r31,26
	cr6.compare<int32_t>(r31.s32, 26, xer);
	// beq cr6,0x8246376c
	if (cr6.eq) goto loc_8246376C;
	// cmpwi cr6,r31,27
	cr6.compare<int32_t>(r31.s32, 27, xer);
	// beq cr6,0x8246376c
	if (cr6.eq) goto loc_8246376C;
	// cmpwi cr6,r31,13
	cr6.compare<int32_t>(r31.s32, 13, xer);
	// beq cr6,0x82463710
	if (cr6.eq) goto loc_82463710;
	// cmpwi cr6,r31,14
	cr6.compare<int32_t>(r31.s32, 14, xer);
	// beq cr6,0x82463710
	if (cr6.eq) goto loc_82463710;
	// cmpwi cr6,r31,21
	cr6.compare<int32_t>(r31.s32, 21, xer);
	// beq cr6,0x824636ec
	if (cr6.eq) goto loc_824636EC;
	// cmpwi cr6,r31,22
	cr6.compare<int32_t>(r31.s32, 22, xer);
	// beq cr6,0x824636ec
	if (cr6.eq) goto loc_824636EC;
	// cmpwi cr6,r31,23
	cr6.compare<int32_t>(r31.s32, 23, xer);
	// beq cr6,0x824636ec
	if (cr6.eq) goto loc_824636EC;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x8246339c
	if (!cr6.eq) goto loc_8246339C;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82463508
	if (cr6.eq) goto loc_82463508;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq 0x824637d0
	if (cr0.eq) goto loc_824637D0;
	// b 0x82463508
	goto loc_82463508;
loc_8246339C:
	// cmpwi cr6,r31,7
	cr6.compare<int32_t>(r31.s32, 7, xer);
	// beq cr6,0x824636c0
	if (cr6.eq) goto loc_824636C0;
	// cmpwi cr6,r31,5
	cr6.compare<int32_t>(r31.s32, 5, xer);
	// beq cr6,0x824636c0
	if (cr6.eq) goto loc_824636C0;
	// cmpwi cr6,r31,6
	cr6.compare<int32_t>(r31.s32, 6, xer);
	// beq cr6,0x824636c0
	if (cr6.eq) goto loc_824636C0;
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// beq cr6,0x824636c0
	if (cr6.eq) goto loc_824636C0;
	// cmpwi cr6,r31,3
	cr6.compare<int32_t>(r31.s32, 3, xer);
	// beq cr6,0x824636c0
	if (cr6.eq) goto loc_824636C0;
	// cmpwi cr6,r31,1
	cr6.compare<int32_t>(r31.s32, 1, xer);
	// beq cr6,0x824636c0
	if (cr6.eq) goto loc_824636C0;
	// cmpwi cr6,r31,4
	cr6.compare<int32_t>(r31.s32, 4, xer);
	// bne cr6,0x8246345c
	if (!cr6.eq) goto loc_8246345C;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x824637d0
	if (cr6.eq) goto loc_824637D0;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463410
	if (cr0.eq) goto loc_82463410;
	// li r9,512
	ctx.r9.s64 = 512;
	// lwz r8,32(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 32);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r7,28(r26)
	ctx.r7.u64 = PPC_LOAD_U32(r26.u32 + 28);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,16(r26)
	ctx.r4.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// b 0x82463414
	goto loc_82463414;
loc_82463410:
	// mr r23,r20
	r23.u64 = r20.u64;
loc_82463414:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x824637d0
	if (cr6.eq) goto loc_824637D0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82463450
	if (cr0.eq) goto loc_82463450;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82463688
	goto loc_82463688;
loc_82463450:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-21100
	ctx.r6.s64 = r11.s64 + -21100;
	// b 0x82463698
	goto loc_82463698;
loc_8246345C:
	// cmpwi cr6,r31,24
	cr6.compare<int32_t>(r31.s32, 24, xer);
	// beq cr6,0x824635f8
	if (cr6.eq) goto loc_824635F8;
	// cmpwi cr6,r31,25
	cr6.compare<int32_t>(r31.s32, 25, xer);
	// beq cr6,0x824635f8
	if (cr6.eq) goto loc_824635F8;
	// cmpwi cr6,r31,15
	cr6.compare<int32_t>(r31.s32, 15, xer);
	// beq cr6,0x824634d0
	if (cr6.eq) goto loc_824634D0;
	// cmpwi cr6,r31,16
	cr6.compare<int32_t>(r31.s32, 16, xer);
	// beq cr6,0x824634d0
	if (cr6.eq) goto loc_824634D0;
	// cmpwi cr6,r31,17
	cr6.compare<int32_t>(r31.s32, 17, xer);
	// beq cr6,0x824634d0
	if (cr6.eq) goto loc_824634D0;
	// cmpwi cr6,r31,18
	cr6.compare<int32_t>(r31.s32, 18, xer);
	// beq cr6,0x824634d0
	if (cr6.eq) goto loc_824634D0;
	// cmpwi cr6,r31,19
	cr6.compare<int32_t>(r31.s32, 19, xer);
	// beq cr6,0x824634d0
	if (cr6.eq) goto loc_824634D0;
	// cmpwi cr6,r31,20
	cr6.compare<int32_t>(r31.s32, 20, xer);
	// beq cr6,0x824634d0
	if (cr6.eq) goto loc_824634D0;
loc_8246349C:
	// addi r8,r30,16
	ctx.r8.s64 = r30.s64 + 16;
	// addi r7,r1,132
	ctx.r7.s64 = ctx.r1.s64 + 132;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245edc8
	sub_8245EDC8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82463500
	if (!cr0.lt) goto loc_82463500;
loc_824634C0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,-21116
	ctx.r6.s64 = r11.s64 + -21116;
	// b 0x824637c4
	goto loc_824637C4;
loc_824634D0:
	// addi r31,r30,16
	r31.s64 = r30.s64 + 16;
	// addi r7,r1,132
	ctx.r7.s64 = ctx.r1.s64 + 132;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// bl 0x8245edc8
	sub_8245EDC8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824634c0
	if (cr0.lt) goto loc_824634C0;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r20,20(r11)
	PPC_STORE_U32(r11.u32 + 20, r20.u32);
loc_82463500:
	// lwz r21,132(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r23,128(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_82463508:
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82463558
	if (cr0.eq) goto loc_82463558;
	// cmplw cr6,r26,r23
	cr6.compare<uint32_t>(r26.u32, r23.u32, xer);
	// beq cr6,0x82463558
	if (cr6.eq) goto loc_82463558;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82463558
	if (!cr0.eq) goto loc_82463558;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824637d0
	if (cr0.eq) goto loc_824637D0;
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
loc_82463558:
	// lwz r9,36(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x824635a8
	if (cr0.eq) goto loc_824635A8;
	// cmplw cr6,r22,r21
	cr6.compare<uint32_t>(r22.u32, r21.u32, xer);
	// beq cr6,0x824635a8
	if (cr6.eq) goto loc_824635A8;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824635a8
	if (!cr0.eq) goto loc_824635A8;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824637d0
	if (cr0.eq) goto loc_824637D0;
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
loc_824635A8:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824635b8
	if (!cr6.eq) goto loc_824635B8;
	// stw r20,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r20.u32);
loc_824635B8:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82459bf0
	sub_82459BF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824637d4
	if (cr0.eq) goto loc_824637D4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82460b10
	sub_82460B10(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824637d4
	if (cr0.eq) goto loc_824637D4;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x824637d4
	goto loc_824637D4;
loc_824635F8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246362c
	if (cr0.eq) goto loc_8246362C;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// b 0x82463630
	goto loc_82463630;
loc_8246362C:
	// mr r23,r20
	r23.u64 = r20.u64;
loc_82463630:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x824637d0
	if (cr6.eq) goto loc_824637D0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82463690
	if (cr0.eq) goto loc_82463690;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82463690
	if (cr0.eq) goto loc_82463690;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r21,r23
	r21.u64 = r23.u64;
loc_82463688:
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// b 0x824636ac
	goto loc_824636AC;
loc_82463690:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-21176
	ctx.r6.s64 = r11.s64 + -21176;
loc_82463698:
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r4,r30,48
	ctx.r4.s64 = r30.s64 + 48;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// stw r20,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r20.u32);
loc_824636AC:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
	// b 0x82463508
	goto loc_82463508;
loc_824636C0:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x824636ac
	if (cr6.eq) goto loc_824636AC;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq 0x824637d0
	if (cr0.eq) goto loc_824637D0;
	// b 0x824636ac
	goto loc_824636AC;
loc_824636EC:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x8246349c
	if (cr6.eq) goto loc_8246349C;
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x824631e4
	if (!cr6.eq) goto loc_824631E4;
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// blt cr6,0x8246349c
	if (cr6.lt) goto loc_8246349C;
	// b 0x824631e4
	goto loc_824631E4;
loc_82463710:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82463730
	if (cr6.eq) goto loc_82463730;
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x824631e4
	if (!cr6.eq) goto loc_824631E4;
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bge cr6,0x824631e4
	if (!cr6.lt) goto loc_824631E4;
loc_82463730:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824637b0
	if (!cr0.eq) goto loc_824637B0;
loc_8246374C:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e998
	sub_8245E998(ctx, base);
	// b 0x824637d0
	goto loc_824637D0;
loc_8246376C:
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8246374c
	if (cr0.eq) goto loc_8246374C;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x824637b0
	if (cr6.eq) goto loc_824637B0;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq 0x824637d0
	if (cr0.eq) goto loc_824637D0;
loc_824637B0:
	// mr r21,r26
	r21.u64 = r26.u64;
	// b 0x82463508
	goto loc_82463508;
loc_824637B8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3025
	ctx.r5.s64 = 3025;
	// addi r6,r11,-21208
	ctx.r6.s64 = r11.s64 + -21208;
loc_824637C4:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_824637D0:
	// mr r30,r20
	r30.u64 = r20.u64;
loc_824637D4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_824637D8:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8239bd28
	return;
}

__attribute__((alias("__imp__sub_824637E0"))) PPC_WEAK_FUNC(sub_824637E0);
PPC_FUNC_IMPL(__imp__sub_824637E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcfc
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82463934
	if (cr6.eq) goto loc_82463934;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246381c
	if (cr0.eq) goto loc_8246381C;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82463820
	goto loc_82463820;
loc_8246381C:
	// li r30,0
	r30.s64 = 0;
loc_82463820:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82463934
	if (cr6.eq) goto loc_82463934;
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r11.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// beq cr6,0x82463870
	if (cr6.eq) goto loc_82463870;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x824638a0
	if (!cr6.eq) goto loc_824638A0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3079
	ctx.r5.s64 = 3079;
	// addi r6,r11,-20888
	ctx.r6.s64 = r11.s64 + -20888;
	// b 0x8246388c
	goto loc_8246388C;
loc_82463870:
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824638bc
	if (cr6.eq) goto loc_824638BC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,3080
	ctx.r5.s64 = 3080;
	// addi r6,r11,32500
	ctx.r6.s64 = r11.s64 + 32500;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8246388C:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// lwz r7,20(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x824638bc
	goto loc_824638BC;
loc_824638A0:
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,52(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r4,27
	ctx.r4.s64 = 27;
	// bl 0x82462f30
	sub_82462F30(ctx, base);
	// stw r3,20(r30)
	PPC_STORE_U32(r30.u32 + 20, ctx.r3.u32);
loc_824638BC:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824638f0
	if (cr0.eq) goto loc_824638F0;
	// addi r9,r31,40
	ctx.r9.s64 = r31.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x824638f4
	goto loc_824638F4;
loc_824638F0:
	// li r11,0
	r11.s64 = 0;
loc_824638F4:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82463934
	if (cr6.eq) goto loc_82463934;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463928
	if (cr0.eq) goto loc_82463928;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8246392c
	goto loc_8246392C;
loc_82463928:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8246392C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82463938
	if (!cr6.eq) goto loc_82463938;
loc_82463934:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82463938:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd4c
	return;
}

__attribute__((alias("__imp__sub_82463940"))) PPC_WEAK_FUNC(sub_82463940);
PPC_FUNC_IMPL(__imp__sub_82463940) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82463ba0
	if (cr6.eq) goto loc_82463BA0;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82463b88
	if (!cr6.eq) goto loc_82463B88;
	// lwz r4,16(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82463b88
	if (cr0.eq) goto loc_82463B88;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824639c0
	if (cr0.eq) goto loc_824639C0;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x824639c4
	goto loc_824639C4;
loc_824639C0:
	// li r28,0
	r28.s64 = 0;
loc_824639C4:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82463ba0
	if (cr6.eq) goto loc_82463BA0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,16(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82463a00
	if (!cr0.eq) goto loc_82463A00;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,-20780
	ctx.r6.s64 = r11.s64 + -20780;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82463A00:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82459bf0
	sub_82459BF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82463a70
	if (cr0.eq) goto loc_82463A70;
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245ffa0
	sub_8245FFA0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82463a70
	if (cr0.lt) goto loc_82463A70;
	// addi r6,r29,48
	ctx.r6.s64 = r29.s64 + 48;
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82459a90
	sub_82459A90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82463a70
	if (cr0.lt) goto loc_82463A70;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lfd f13,128(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lfd f0,-31368(r11)
	f0.u64 = PPC_LOAD_U64(r11.u32 + -31368);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x82463a68
	if (!cr6.eq) goto loc_82463A68;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82463A68:
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// b 0x82463ba4
	goto loc_82463BA4;
loc_82463A70:
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463a8c
	if (cr0.eq) goto loc_82463A8C;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82463a90
	goto loc_82463A90;
loc_82463A8C:
	// li r30,0
	r30.s64 = 0;
loc_82463A90:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82463ba0
	if (cr6.eq) goto loc_82463BA0;
	// li r11,2
	r11.s64 = 2;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// stw r11,16(r30)
	PPC_STORE_U32(r30.u32 + 16, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r11.u32);
	// bl 0x82462478
	sub_82462478(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
	// beq 0x82463ba0
	if (cr0.eq) goto loc_82463BA0;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82463b00
	if (cr6.eq) goto loc_82463B00;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r30)
	PPC_STORE_U32(r30.u32 + 28, ctx.r3.u32);
	// beq 0x82463ba0
	if (cr0.eq) goto loc_82463BA0;
loc_82463B00:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82463b28
	if (cr6.eq) goto loc_82463B28;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq 0x82463ba0
	if (cr0.eq) goto loc_82463BA0;
loc_82463B28:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82463b50
	if (cr6.eq) goto loc_82463B50;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,44(r30)
	PPC_STORE_U32(r30.u32 + 44, ctx.r3.u32);
	// beq 0x82463ba0
	if (cr0.eq) goto loc_82463BA0;
loc_82463B50:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463b78
	if (cr0.eq) goto loc_82463B78;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82463b7c
	goto loc_82463B7C;
loc_82463B78:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82463B7C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82463ba0
	if (cr6.eq) goto loc_82463BA0;
	// b 0x82463ba4
	goto loc_82463BA4;
loc_82463B88:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3019
	ctx.r5.s64 = 3019;
	// addi r6,r11,-20844
	ctx.r6.s64 = r11.s64 + -20844;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82463BA0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82463BA4:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_82463BAC"))) PPC_WEAK_FUNC(sub_82463BAC);
PPC_FUNC_IMPL(__imp__sub_82463BAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82463BB0"))) PPC_WEAK_FUNC(sub_82463BB0);
PPC_FUNC_IMPL(__imp__sub_82463BB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf0
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// lwz r11,116(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 116);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// beq cr6,0x82463c98
	if (cr6.eq) goto loc_82463C98;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82463c7c
	if (!cr6.eq) goto loc_82463C7C;
	// lwz r4,16(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82463c7c
	if (cr0.eq) goto loc_82463C7C;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463c38
	if (cr0.eq) goto loc_82463C38;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,9
	ctx.r5.s64 = 9;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x82463c3c
	goto loc_82463C3C;
loc_82463C38:
	// li r28,0
	r28.s64 = 0;
loc_82463C3C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82463d98
	if (cr6.eq) goto loc_82463D98;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,16(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82463c9c
	if (!cr0.eq) goto loc_82463C9C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,-20720
	ctx.r6.s64 = r11.s64 + -20720;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82463c9c
	goto loc_82463C9C;
loc_82463C7C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3019
	ctx.r5.s64 = 3019;
	// addi r6,r11,-20744
	ctx.r6.s64 = r11.s64 + -20744;
	// addi r4,r29,48
	ctx.r4.s64 = r29.s64 + 48;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82463d98
	goto loc_82463D98;
loc_82463C98:
	// lwz r28,112(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82463C9C:
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463cb8
	if (cr0.eq) goto loc_82463CB8;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82463cbc
	goto loc_82463CBC;
loc_82463CB8:
	// li r31,0
	r31.s64 = 0;
loc_82463CBC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82463d98
	if (cr6.eq) goto loc_82463D98;
	// li r11,12
	r11.s64 = 12;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r30)
	PPC_STORE_U32(r30.u32 + 108, r11.u32);
	// beq cr6,0x82463d14
	if (cr6.eq) goto loc_82463D14;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82463d98
	if (cr6.eq) goto loc_82463D98;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x82463d98
	if (cr0.eq) goto loc_82463D98;
loc_82463D14:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82463d3c
	if (cr6.eq) goto loc_82463D3C;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// beq 0x82463d98
	if (cr0.eq) goto loc_82463D98;
loc_82463D3C:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82463d64
	if (cr6.eq) goto loc_82463D64;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// beq 0x82463d98
	if (cr0.eq) goto loc_82463D98;
loc_82463D64:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463d8c
	if (cr0.eq) goto loc_82463D8C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82463d90
	goto loc_82463D90;
loc_82463D8C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82463D90:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82463d9c
	if (!cr6.eq) goto loc_82463D9C;
loc_82463D98:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82463D9C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8239bd40
	return;
}

__attribute__((alias("__imp__sub_82463DA4"))) PPC_WEAK_FUNC(sub_82463DA4);
PPC_FUNC_IMPL(__imp__sub_82463DA4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82463DA8"))) PPC_WEAK_FUNC(sub_82463DA8);
PPC_FUNC_IMPL(__imp__sub_82463DA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce8
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// li r28,0
	r28.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82463e70
	if (cr6.eq) goto loc_82463E70;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82463e8c
	if (!cr6.eq) goto loc_82463E8C;
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82463e8c
	if (cr0.eq) goto loc_82463E8C;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463e30
	if (cr0.eq) goto loc_82463E30;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x82463e34
	goto loc_82463E34;
loc_82463E30:
	// li r28,0
	r28.s64 = 0;
loc_82463E34:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82463fb4
	if (cr6.eq) goto loc_82463FB4;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,16(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82463e70
	if (!cr0.eq) goto loc_82463E70;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,-20780
	ctx.r6.s64 = r11.s64 + -20780;
	// addi r4,r30,48
	ctx.r4.s64 = r30.s64 + 48;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82463E70:
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463ea8
	if (cr0.eq) goto loc_82463EA8;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82463eac
	goto loc_82463EAC;
loc_82463E8C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3019
	ctx.r5.s64 = 3019;
	// addi r6,r11,-20744
	ctx.r6.s64 = r11.s64 + -20744;
	// addi r4,r30,48
	ctx.r4.s64 = r30.s64 + 48;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82463fb4
	goto loc_82463FB4;
loc_82463EA8:
	// li r31,0
	r31.s64 = 0;
loc_82463EAC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82463fb4
	if (cr6.eq) goto loc_82463FB4;
	// li r11,3
	r11.s64 = 3;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,108(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r29)
	PPC_STORE_U32(r29.u32 + 108, r11.u32);
	// bne cr6,0x82463efc
	if (!cr6.eq) goto loc_82463EFC;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x82463ee8
	if (!cr6.eq) goto loc_82463EE8;
	// li r11,4
	r11.s64 = 4;
	// b 0x82463ef8
	goto loc_82463EF8;
loc_82463EE8:
	// cmplw cr6,r27,r24
	cr6.compare<uint32_t>(r27.u32, r24.u32, xer);
	// bne cr6,0x82463efc
	if (!cr6.eq) goto loc_82463EFC;
	// li r11,5
	r11.s64 = 5;
	// li r27,0
	r27.s64 = 0;
loc_82463EF8:
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
loc_82463EFC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r27,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r27.u32);
	// beq cr6,0x82463f34
	if (cr6.eq) goto loc_82463F34;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82463fb4
	if (cr6.eq) goto loc_82463FB4;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
	// beq 0x82463fb4
	if (cr0.eq) goto loc_82463FB4;
loc_82463F34:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// stw r24,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r24.u32);
	// beq cr6,0x82463f60
	if (cr6.eq) goto loc_82463F60;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// beq 0x82463fb4
	if (cr0.eq) goto loc_82463FB4;
loc_82463F60:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82463f80
	if (cr6.eq) goto loc_82463F80;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8245a308
	sub_8245A308(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r3.u32);
	// beq 0x82463fb4
	if (cr0.eq) goto loc_82463FB4;
loc_82463F80:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82463fa8
	if (cr0.eq) goto loc_82463FA8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82463fac
	goto loc_82463FAC;
loc_82463FA8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82463FAC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82463fb8
	if (!cr6.eq) goto loc_82463FB8;
loc_82463FB4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82463FB8:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8239bd38
	return;
}

__attribute__((alias("__imp__sub_82463FC0"))) PPC_WEAK_FUNC(sub_82463FC0);
PPC_FUNC_IMPL(__imp__sub_82463FC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf4
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r29,r30,40
	r29.s64 = r30.s64 + 40;
loc_82463FD4:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x823e4de0
	sub_823E4DE0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82463ffc
	if (!cr0.lt) goto loc_82463FFC;
	// li r11,1
	r11.s64 = 1;
	// stw r11,72(r30)
	PPC_STORE_U32(r30.u32 + 72, r11.u32);
loc_82463FF0:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82463FF4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8239bd44
	return;
loc_82463FFC:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bgt cr6,0x82463fd4
	if (cr6.gt) goto loc_82463FD4;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-25992
	r12.s64 = r12.s64 + -25992;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,16340
	r12.s64 = r12.s64 + 16340;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82464030;
	case 1:
		goto loc_82464038;
	case 2:
		goto loc_824641DC;
	case 3:
		goto loc_824641E4;
	case 4:
		goto loc_824641EC;
	case 5:
		goto loc_824641F4;
	case 6:
		goto loc_824641FC;
	case 7:
		goto loc_82464204;
	case 8:
		goto loc_8246420C;
	case 9:
		goto loc_82464214;
	case 10:
		goto loc_82466678;
	case 11:
		goto loc_82463FD4;
	case 12:
		goto loc_82463FD4;
	case 13:
		goto loc_82463FF0;
	default:
		__builtin_unreachable();
	}
loc_82464030:
	// li r3,386
	ctx.r3.s64 = 386;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464038:
	// lbz r11,49(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 49);
	// extsb. r10,r11
	ctx.r10.s64 = r11.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82464050
	if (!cr0.eq) goto loc_82464050;
	// lbz r11,48(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 48);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464050:
	// lbz r11,50(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 50);
	// extsb. r11,r11
	r11.s64 = r11.s8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82464198
	if (!cr0.eq) goto loc_82464198;
	// lbz r11,48(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 48);
	// cmpwi cr6,r10,61
	cr6.compare<int32_t>(ctx.r10.s32, 61, xer);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// bne cr6,0x82464130
	if (!cr6.eq) goto loc_82464130;
	// cmpwi cr6,r11,47
	cr6.compare<int32_t>(r11.s32, 47, xer);
	// bgt cr6,0x824640e0
	if (cr6.gt) goto loc_824640E0;
	// beq cr6,0x824640d8
	if (cr6.eq) goto loc_824640D8;
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// beq cr6,0x824640d0
	if (cr6.eq) goto loc_824640D0;
	// cmpwi cr6,r11,37
	cr6.compare<int32_t>(r11.s32, 37, xer);
	// beq cr6,0x824640c8
	if (cr6.eq) goto loc_824640C8;
	// cmpwi cr6,r11,38
	cr6.compare<int32_t>(r11.s32, 38, xer);
	// beq cr6,0x824640c0
	if (cr6.eq) goto loc_824640C0;
	// cmpwi cr6,r11,42
	cr6.compare<int32_t>(r11.s32, 42, xer);
	// beq cr6,0x824640b8
	if (cr6.eq) goto loc_824640B8;
	// cmpwi cr6,r11,43
	cr6.compare<int32_t>(r11.s32, 43, xer);
	// beq cr6,0x824640b0
	if (cr6.eq) goto loc_824640B0;
	// cmpwi cr6,r11,45
	cr6.compare<int32_t>(r11.s32, 45, xer);
	// bne cr6,0x82464030
	if (!cr6.eq) goto loc_82464030;
	// li r3,368
	ctx.r3.s64 = 368;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824640B0:
	// li r3,367
	ctx.r3.s64 = 367;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824640B8:
	// li r3,364
	ctx.r3.s64 = 364;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824640C0:
	// li r3,373
	ctx.r3.s64 = 373;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824640C8:
	// li r3,366
	ctx.r3.s64 = 366;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824640D0:
	// li r3,361
	ctx.r3.s64 = 361;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824640D8:
	// li r3,365
	ctx.r3.s64 = 365;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824640E0:
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// beq cr6,0x82464128
	if (cr6.eq) goto loc_82464128;
	// cmpwi cr6,r11,61
	cr6.compare<int32_t>(r11.s32, 61, xer);
	// beq cr6,0x82464120
	if (cr6.eq) goto loc_82464120;
	// cmpwi cr6,r11,62
	cr6.compare<int32_t>(r11.s32, 62, xer);
	// beq cr6,0x82464118
	if (cr6.eq) goto loc_82464118;
	// cmpwi cr6,r11,94
	cr6.compare<int32_t>(r11.s32, 94, xer);
	// beq cr6,0x82464110
	if (cr6.eq) goto loc_82464110;
	// cmpwi cr6,r11,124
	cr6.compare<int32_t>(r11.s32, 124, xer);
	// bne cr6,0x82464030
	if (!cr6.eq) goto loc_82464030;
	// li r3,374
	ctx.r3.s64 = 374;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464110:
	// li r3,375
	ctx.r3.s64 = 375;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464118:
	// li r3,359
	ctx.r3.s64 = 359;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464120:
	// li r3,360
	ctx.r3.s64 = 360;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464128:
	// li r3,358
	ctx.r3.s64 = 358;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464130:
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82464030
	if (!cr6.eq) goto loc_82464030;
	// cmpwi cr6,r11,38
	cr6.compare<int32_t>(r11.s32, 38, xer);
	// beq cr6,0x82464190
	if (cr6.eq) goto loc_82464190;
	// cmpwi cr6,r11,43
	cr6.compare<int32_t>(r11.s32, 43, xer);
	// beq cr6,0x82464188
	if (cr6.eq) goto loc_82464188;
	// cmpwi cr6,r11,45
	cr6.compare<int32_t>(r11.s32, 45, xer);
	// beq cr6,0x82464180
	if (cr6.eq) goto loc_82464180;
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// beq cr6,0x82464178
	if (cr6.eq) goto loc_82464178;
	// cmpwi cr6,r11,62
	cr6.compare<int32_t>(r11.s32, 62, xer);
	// beq cr6,0x82464170
	if (cr6.eq) goto loc_82464170;
	// cmpwi cr6,r11,124
	cr6.compare<int32_t>(r11.s32, 124, xer);
	// bne cr6,0x82464030
	if (!cr6.eq) goto loc_82464030;
	// li r3,363
	ctx.r3.s64 = 363;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464170:
	// li r3,370
	ctx.r3.s64 = 370;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464178:
	// li r3,369
	ctx.r3.s64 = 369;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464180:
	// li r3,357
	ctx.r3.s64 = 357;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464188:
	// li r3,356
	ctx.r3.s64 = 356;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464190:
	// li r3,362
	ctx.r3.s64 = 362;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464198:
	// lbz r9,51(r30)
	ctx.r9.u64 = PPC_LOAD_U8(r30.u32 + 51);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82464030
	if (!cr6.eq) goto loc_82464030;
	// cmpwi cr6,r11,61
	cr6.compare<int32_t>(r11.s32, 61, xer);
	// bne cr6,0x82464030
	if (!cr6.eq) goto loc_82464030;
	// lbz r11,48(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 48);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82464030
	if (!cr6.eq) goto loc_82464030;
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// beq cr6,0x824641d4
	if (cr6.eq) goto loc_824641D4;
	// cmpwi cr6,r11,62
	cr6.compare<int32_t>(r11.s32, 62, xer);
	// bne cr6,0x82464030
	if (!cr6.eq) goto loc_82464030;
	// li r3,372
	ctx.r3.s64 = 372;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824641D4:
	// li r3,371
	ctx.r3.s64 = 371;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824641DC:
	// li r3,376
	ctx.r3.s64 = 376;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824641E4:
	// li r3,377
	ctx.r3.s64 = 377;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824641EC:
	// li r3,378
	ctx.r3.s64 = 378;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824641F4:
	// li r3,379
	ctx.r3.s64 = 379;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824641FC:
	// li r3,380
	ctx.r3.s64 = 380;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464204:
	// li r3,381
	ctx.r3.s64 = 381;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246420C:
	// li r3,382
	ctx.r3.s64 = 382;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464214:
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// addi r28,r10,-22172
	r28.s64 = ctx.r10.s64 + -22172;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r31,r10,-22148
	r31.s64 = ctx.r10.s64 + -22148;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// addi r27,r10,-19332
	r27.s64 = ctx.r10.s64 + -19332;
	// addi r11,r11,-66
	r11.s64 = r11.s64 + -66;
	// cmplwi cr6,r11,53
	cr6.compare<uint32_t>(r11.u32, 53, xer);
	// bgt cr6,0x8246488c
	if (cr6.gt) goto loc_8246488C;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-26104
	r12.s64 = r12.s64 + -26104;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32186
	r12.s64 = -2109341696;
	// addi r12,r12,17004
	r12.s64 = r12.s64 + 17004;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8246437C;
	case 1:
		goto loc_824646DC;
	case 2:
		goto loc_824648E8;
	case 3:
		goto loc_8246488C;
	case 4:
		goto loc_8246488C;
	case 5:
		goto loc_82464BC0;
	case 6:
		goto loc_8246488C;
	case 7:
		goto loc_8246488C;
	case 8:
		goto loc_8246488C;
	case 9:
		goto loc_8246488C;
	case 10:
		goto loc_82464E90;
	case 11:
		goto loc_8246488C;
	case 12:
		goto loc_8246503C;
	case 13:
		goto loc_8246488C;
	case 14:
		goto loc_82465314;
	case 15:
		goto loc_8246488C;
	case 16:
		goto loc_824654A0;
	case 17:
		goto loc_824659CC;
	case 18:
		goto loc_82465FD0;
	case 19:
		goto loc_8246488C;
	case 20:
		goto loc_82466504;
	case 21:
		goto loc_8246488C;
	case 22:
		goto loc_8246488C;
	case 23:
		goto loc_8246488C;
	case 24:
		goto loc_8246488C;
	case 25:
		goto loc_8246488C;
	case 26:
		goto loc_8246488C;
	case 27:
		goto loc_8246488C;
	case 28:
		goto loc_8246488C;
	case 29:
		goto loc_8246488C;
	case 30:
		goto loc_8246488C;
	case 31:
		goto loc_8246426C;
	case 32:
		goto loc_824642FC;
	case 33:
		goto loc_824643FC;
	case 34:
		goto loc_8246471C;
	case 35:
		goto loc_82464968;
	case 36:
		goto loc_82464A58;
	case 37:
		goto loc_82464B8C;
	case 38:
		goto loc_82464C0C;
	case 39:
		goto loc_82464C4C;
	case 40:
		goto loc_8246488C;
	case 41:
		goto loc_8246488C;
	case 42:
		goto loc_82464D8C;
	case 43:
		goto loc_82464ED0;
	case 44:
		goto loc_82464F44;
	case 45:
		goto loc_8246507C;
	case 46:
		goto loc_824650F0;
	case 47:
		goto loc_8246488C;
	case 48:
		goto loc_824653A8;
	case 49:
		goto loc_82465520;
	case 50:
		goto loc_82465A7C;
	case 51:
		goto loc_824661FC;
	case 52:
		goto loc_82466368;
	case 53:
		goto loc_82466558;
	default:
		__builtin_unreachable();
	}
loc_8246426C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19340
	ctx.r10.s64 = r11.s64 + -19340;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464278:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246429c
	if (cr0.eq) goto loc_8246429C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464278
	if (cr6.eq) goto loc_82464278;
loc_8246429C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19356
	ctx.r10.s64 = r11.s64 + -19356;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824642B0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824642d4
	if (cr0.eq) goto loc_824642D4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824642b0
	if (cr6.eq) goto loc_824642B0;
loc_824642D4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824642e4
	if (!cr0.eq) goto loc_824642E4;
	// li r3,258
	ctx.r3.s64 = 258;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824642E4:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
loc_824642F4:
	// li r3,257
	ctx.r3.s64 = 257;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824642FC:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r10,r11,-24640
	ctx.r10.s64 = r11.s64 + -24640;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464308:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246432c
	if (cr0.eq) goto loc_8246432C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464308
	if (cr6.eq) goto loc_82464308;
loc_8246432C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246433c
	if (!cr0.eq) goto loc_8246433C;
	// li r3,260
	ctx.r3.s64 = 260;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246433C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,14860
	ctx.r10.s64 = r11.s64 + 14860;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464348:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246436c
	if (cr0.eq) goto loc_8246436C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464348
	if (cr6.eq) goto loc_82464348;
loc_8246436C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,261
	ctx.r3.s64 = 261;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246437C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19368
	ctx.r10.s64 = r11.s64 + -19368;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464388:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824643ac
	if (cr0.eq) goto loc_824643AC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464388
	if (cr6.eq) goto loc_82464388;
loc_824643AC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824643bc
	if (!cr0.eq) goto loc_824643BC;
	// li r3,259
	ctx.r3.s64 = 259;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824643BC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23144
	ctx.r10.s64 = r11.s64 + -23144;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824643C8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824643ec
	if (cr0.eq) goto loc_824643EC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824643c8
	if (cr6.eq) goto loc_824643C8;
loc_824643EC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,262
	ctx.r3.s64 = 262;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824643FC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19376
	ctx.r10.s64 = r11.s64 + -19376;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464408:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246442c
	if (cr0.eq) goto loc_8246442C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464408
	if (cr6.eq) goto loc_82464408;
loc_8246442C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246443c
	if (!cr0.eq) goto loc_8246443C;
	// li r3,263
	ctx.r3.s64 = 263;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246443C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19384
	ctx.r10.s64 = r11.s64 + -19384;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464448:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246446c
	if (cr0.eq) goto loc_8246446C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464448
	if (cr6.eq) goto loc_82464448;
loc_8246446C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-22128
	ctx.r10.s64 = r11.s64 + -22128;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464480:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824644a4
	if (cr0.eq) goto loc_824644A4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464480
	if (cr6.eq) goto loc_82464480;
loc_824644A4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824644b4
	if (!cr0.eq) goto loc_824644B4;
	// li r3,264
	ctx.r3.s64 = 264;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824644B4:
	// lis r11,-32252
	r11.s64 = -2113667072;
	// addi r10,r11,6584
	ctx.r10.s64 = r11.s64 + 6584;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824644C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824644e4
	if (cr0.eq) goto loc_824644E4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824644c0
	if (cr6.eq) goto loc_824644C0;
loc_824644E4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19392
	ctx.r10.s64 = r11.s64 + -19392;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824644F8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246451c
	if (cr0.eq) goto loc_8246451C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824644f8
	if (cr6.eq) goto loc_824644F8;
loc_8246451C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,28116
	ctx.r10.s64 = r11.s64 + 28116;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464530:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464554
	if (cr0.eq) goto loc_82464554;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464530
	if (cr6.eq) goto loc_82464530;
loc_82464554:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464564
	if (!cr0.eq) goto loc_82464564;
	// li r3,265
	ctx.r3.s64 = 265;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464564:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,12264
	ctx.r10.s64 = r11.s64 + 12264;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464570:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464594
	if (cr0.eq) goto loc_82464594;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464570
	if (cr6.eq) goto loc_82464570;
loc_82464594:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824645a4
	if (!cr0.eq) goto loc_824645A4;
	// li r3,266
	ctx.r3.s64 = 266;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824645A4:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19400
	ctx.r10.s64 = r11.s64 + -19400;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824645B0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824645d4
	if (cr0.eq) goto loc_824645D4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824645b0
	if (cr6.eq) goto loc_824645B0;
loc_824645D4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824645e4
	if (!cr0.eq) goto loc_824645E4;
	// li r3,267
	ctx.r3.s64 = 267;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824645E4:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19420
	ctx.r10.s64 = r11.s64 + -19420;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824645F0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464614
	if (cr0.eq) goto loc_82464614;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824645f0
	if (cr6.eq) goto loc_824645F0;
loc_82464614:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464624
	if (!cr0.eq) goto loc_82464624;
	// li r3,269
	ctx.r3.s64 = 269;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464624:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-28148
	ctx.r10.s64 = r11.s64 + -28148;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464630:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464654
	if (cr0.eq) goto loc_82464654;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464630
	if (cr6.eq) goto loc_82464630;
loc_82464654:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464664
	if (!cr0.eq) goto loc_82464664;
	// li r3,270
	ctx.r3.s64 = 270;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464664:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19432
	ctx.r10.s64 = r11.s64 + -19432;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464670:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464694
	if (cr0.eq) goto loc_82464694;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464670
	if (cr6.eq) goto loc_82464670;
loc_82464694:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r10,r11,-26816
	ctx.r10.s64 = r11.s64 + -26816;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824646A8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824646cc
	if (cr0.eq) goto loc_824646CC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824646a8
	if (cr6.eq) goto loc_824646A8;
loc_824646CC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,272
	ctx.r3.s64 = 272;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824646DC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19448
	ctx.r10.s64 = r11.s64 + -19448;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824646E8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246470c
	if (cr0.eq) goto loc_8246470C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824646e8
	if (cr6.eq) goto loc_824646E8;
loc_8246470C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,268
	ctx.r3.s64 = 268;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246471C:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r10,r11,19528
	ctx.r10.s64 = r11.s64 + 19528;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464728:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246474c
	if (cr0.eq) goto loc_8246474C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464728
	if (cr6.eq) goto loc_82464728;
loc_8246474C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246475c
	if (!cr0.eq) goto loc_8246475C;
	// li r3,274
	ctx.r3.s64 = 274;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246475C:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,25812
	ctx.r10.s64 = r11.s64 + 25812;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464768:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246478c
	if (cr0.eq) goto loc_8246478C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464768
	if (cr6.eq) goto loc_82464768;
loc_8246478C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19456
	ctx.r10.s64 = r11.s64 + -19456;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824647A0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824647c4
	if (cr0.eq) goto loc_824647C4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824647a0
	if (cr6.eq) goto loc_824647A0;
loc_824647C4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824647d4
	if (!cr0.eq) goto loc_824647D4;
	// li r3,277
	ctx.r3.s64 = 277;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824647D4:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,25824
	ctx.r10.s64 = r11.s64 + 25824;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824647E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464804
	if (cr0.eq) goto loc_82464804;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824647e0
	if (cr6.eq) goto loc_824647E0;
loc_82464804:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464814
	if (!cr0.eq) goto loc_82464814;
	// li r3,279
	ctx.r3.s64 = 279;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464814:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-28064
	ctx.r10.s64 = r11.s64 + -28064;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464820:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464844
	if (cr0.eq) goto loc_82464844;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464820
	if (cr6.eq) goto loc_82464820;
loc_82464844:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464854
	if (!cr0.eq) goto loc_82464854;
	// li r3,278
	ctx.r3.s64 = 278;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464854:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19472
	ctx.r10.s64 = r11.s64 + -19472;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464860:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464884
	if (cr0.eq) goto loc_82464884;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464860
	if (cr6.eq) goto loc_82464860;
loc_82464884:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
loc_8246488C:
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// lbz r11,0(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x8239f330
	sub_8239F330(ctx, base);
	// cmpwi cr6,r3,97
	cr6.compare<int32_t>(ctx.r3.s32, 97, xer);
	// beq cr6,0x824665fc
	if (cr6.eq) goto loc_824665FC;
	// cmpwi cr6,r3,100
	cr6.compare<int32_t>(ctx.r3.s32, 100, xer);
	// beq cr6,0x824665c4
	if (cr6.eq) goto loc_824665C4;
	// cmpwi cr6,r3,112
	cr6.compare<int32_t>(ctx.r3.s32, 112, xer);
	// beq cr6,0x82466598
	if (cr6.eq) goto loc_82466598;
	// cmpwi cr6,r3,116
	cr6.compare<int32_t>(ctx.r3.s32, 116, xer);
	// bne cr6,0x82466634
	if (!cr6.eq) goto loc_82466634;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82466634
	if (!cr0.eq) goto loc_82466634;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82465d08
	if (cr0.eq) goto loc_82465D08;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-19536
	ctx.r6.s64 = r11.s64 + -19536;
	// b 0x82466624
	goto loc_82466624;
loc_824648E8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19556
	ctx.r10.s64 = r11.s64 + -19556;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824648F4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464918
	if (cr0.eq) goto loc_82464918;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824648f4
	if (cr6.eq) goto loc_824648F4;
loc_82464918:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464928
	if (!cr0.eq) goto loc_82464928;
	// li r3,275
	ctx.r3.s64 = 275;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464928:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19576
	ctx.r10.s64 = r11.s64 + -19576;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464934:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464958
	if (cr0.eq) goto loc_82464958;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464934
	if (cr6.eq) goto loc_82464934;
loc_82464958:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,276
	ctx.r3.s64 = 276;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464968:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,12412
	ctx.r10.s64 = r11.s64 + 12412;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464974:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464998
	if (cr0.eq) goto loc_82464998;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464974
	if (cr6.eq) goto loc_82464974;
loc_82464998:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824649a8
	if (!cr0.eq) goto loc_824649A8;
	// li r3,280
	ctx.r3.s64 = 280;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824649A8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19584
	ctx.r10.s64 = r11.s64 + -19584;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824649B4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824649d8
	if (cr0.eq) goto loc_824649D8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824649b4
	if (cr6.eq) goto loc_824649B4;
loc_824649D8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19596
	ctx.r10.s64 = r11.s64 + -19596;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824649EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464a10
	if (cr0.eq) goto loc_82464A10;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824649ec
	if (cr6.eq) goto loc_824649EC;
loc_82464A10:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19604
	ctx.r10.s64 = r11.s64 + -19604;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464A24:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464a48
	if (cr0.eq) goto loc_82464A48;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464a24
	if (cr6.eq) goto loc_82464A24;
loc_82464A48:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,281
	ctx.r3.s64 = 281;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464A58:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r10,r11,-24612
	ctx.r10.s64 = r11.s64 + -24612;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464A64:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464a88
	if (cr0.eq) goto loc_82464A88;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464a64
	if (cr6.eq) goto loc_82464A64;
loc_82464A88:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464a98
	if (!cr0.eq) goto loc_82464A98;
	// li r3,282
	ctx.r3.s64 = 282;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464A98:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-28056
	ctx.r10.s64 = r11.s64 + -28056;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464AA4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464ac8
	if (cr0.eq) goto loc_82464AC8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464aa4
	if (cr6.eq) goto loc_82464AA4;
loc_82464AC8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464ad8
	if (!cr0.eq) goto loc_82464AD8;
	// li r3,283
	ctx.r3.s64 = 283;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464AD8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,6632
	ctx.r10.s64 = r11.s64 + 6632;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464AE4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464b08
	if (cr0.eq) goto loc_82464B08;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464ae4
	if (cr6.eq) goto loc_82464AE4;
loc_82464B08:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464b18
	if (!cr0.eq) goto loc_82464B18;
	// li r3,284
	ctx.r3.s64 = 284;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464B18:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19612
	ctx.r10.s64 = r11.s64 + -19612;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464B24:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464b48
	if (cr0.eq) goto loc_82464B48;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464b24
	if (cr6.eq) goto loc_82464B24;
loc_82464B48:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464b58
	if (!cr0.eq) goto loc_82464B58;
	// li r3,285
	ctx.r3.s64 = 285;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464B58:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19620
	ctx.r10.s64 = r11.s64 + -19620;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464B64:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464884
	if (cr0.eq) goto loc_82464884;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464b64
	if (cr6.eq) goto loc_82464B64;
	// b 0x82464884
	goto loc_82464884;
loc_82464B8C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19628
	ctx.r10.s64 = r11.s64 + -19628;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464B98:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464884
	if (cr0.eq) goto loc_82464884;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464b98
	if (cr6.eq) goto loc_82464B98;
	// b 0x82464884
	goto loc_82464884;
loc_82464BC0:
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19644
	ctx.r10.s64 = r11.s64 + -19644;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464BD8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464bfc
	if (cr0.eq) goto loc_82464BFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464bd8
	if (cr6.eq) goto loc_82464BD8;
loc_82464BFC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,286
	ctx.r3.s64 = 286;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464C0C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-22944
	ctx.r10.s64 = r11.s64 + -22944;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464C18:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464c3c
	if (cr0.eq) goto loc_82464C3C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464c18
	if (cr6.eq) goto loc_82464C18;
loc_82464C3C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,287
	ctx.r3.s64 = 287;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464C4C:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,25880
	ctx.r10.s64 = r11.s64 + 25880;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464C58:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464c7c
	if (cr0.eq) goto loc_82464C7C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464c58
	if (cr6.eq) goto loc_82464C58;
loc_82464C7C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464c8c
	if (!cr0.eq) goto loc_82464C8C;
	// li r3,288
	ctx.r3.s64 = 288;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464C8C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19648
	ctx.r10.s64 = r11.s64 + -19648;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464C98:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464cbc
	if (cr0.eq) goto loc_82464CBC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464c98
	if (cr6.eq) goto loc_82464C98;
loc_82464CBC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464ccc
	if (!cr0.eq) goto loc_82464CCC;
	// li r3,289
	ctx.r3.s64 = 289;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464CCC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19656
	ctx.r10.s64 = r11.s64 + -19656;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464CD8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464cfc
	if (cr0.eq) goto loc_82464CFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464cd8
	if (cr6.eq) goto loc_82464CD8;
loc_82464CFC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464d0c
	if (!cr0.eq) goto loc_82464D0C;
	// li r3,290
	ctx.r3.s64 = 290;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464D0C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19664
	ctx.r10.s64 = r11.s64 + -19664;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464D18:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464d3c
	if (cr0.eq) goto loc_82464D3C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464d18
	if (cr6.eq) goto loc_82464D18;
loc_82464D3C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464d4c
	if (!cr0.eq) goto loc_82464D4C;
	// li r3,291
	ctx.r3.s64 = 291;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464D4C:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,25892
	ctx.r10.s64 = r11.s64 + 25892;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464D58:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464d7c
	if (cr0.eq) goto loc_82464D7C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464d58
	if (cr6.eq) goto loc_82464D58;
loc_82464D7C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,292
	ctx.r3.s64 = 292;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464D8C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,12452
	ctx.r10.s64 = r11.s64 + 12452;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464D98:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464dbc
	if (cr0.eq) goto loc_82464DBC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464d98
	if (cr6.eq) goto loc_82464D98;
loc_82464DBC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464dcc
	if (!cr0.eq) goto loc_82464DCC;
	// li r3,293
	ctx.r3.s64 = 293;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464DCC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19672
	ctx.r10.s64 = r11.s64 + -19672;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464DD8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464dfc
	if (cr0.eq) goto loc_82464DFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464dd8
	if (cr6.eq) goto loc_82464DD8;
loc_82464DFC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464e0c
	if (!cr0.eq) goto loc_82464E0C;
	// li r3,294
	ctx.r3.s64 = 294;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464E0C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-28048
	ctx.r10.s64 = r11.s64 + -28048;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464E18:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464e3c
	if (cr0.eq) goto loc_82464E3C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464e18
	if (cr6.eq) goto loc_82464E18;
loc_82464E3C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r10,r11,18980
	ctx.r10.s64 = r11.s64 + 18980;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464E5C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464e80
	if (cr0.eq) goto loc_82464E80;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464e5c
	if (cr6.eq) goto loc_82464E5C;
loc_82464E80:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,295
	ctx.r3.s64 = 295;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464E90:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23260
	ctx.r10.s64 = r11.s64 + -23260;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464E9C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464ec0
	if (cr0.eq) goto loc_82464EC0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464e9c
	if (cr6.eq) goto loc_82464E9C;
loc_82464EC0:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,296
	ctx.r3.s64 = 296;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464ED0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-22076
	ctx.r10.s64 = r11.s64 + -22076;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464EDC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464f00
	if (cr0.eq) goto loc_82464F00;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464edc
	if (cr6.eq) goto loc_82464EDC;
loc_82464F00:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464f10
	if (!cr0.eq) goto loc_82464F10;
	// li r3,297
	ctx.r3.s64 = 297;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464F10:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19680
	ctx.r10.s64 = r11.s64 + -19680;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464F1C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464884
	if (cr0.eq) goto loc_82464884;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464f1c
	if (cr6.eq) goto loc_82464F1C;
	// b 0x82464884
	goto loc_82464884;
loc_82464F44:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-7516
	ctx.r10.s64 = r11.s64 + -7516;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464F50:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464f74
	if (cr0.eq) goto loc_82464F74;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464f50
	if (cr6.eq) goto loc_82464F50;
loc_82464F74:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464f84
	if (!cr0.eq) goto loc_82464F84;
	// li r3,271
	ctx.r3.s64 = 271;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464F84:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-22140
	ctx.r10.s64 = r11.s64 + -22140;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464F90:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464fb4
	if (cr0.eq) goto loc_82464FB4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464f90
	if (cr6.eq) goto loc_82464F90;
loc_82464FB4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82464fc4
	if (!cr0.eq) goto loc_82464FC4;
	// li r3,298
	ctx.r3.s64 = 298;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82464FC4:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,25820
	ctx.r10.s64 = r11.s64 + 25820;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82464FD0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464ff4
	if (cr0.eq) goto loc_82464FF4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82464fd0
	if (cr6.eq) goto loc_82464FD0;
loc_82464FF4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19696
	ctx.r10.s64 = r11.s64 + -19696;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465008:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246502c
	if (cr0.eq) goto loc_8246502C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465008
	if (cr6.eq) goto loc_82465008;
loc_8246502C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,299
	ctx.r3.s64 = 299;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246503C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-28652
	ctx.r10.s64 = r11.s64 + -28652;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465048:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246506c
	if (cr0.eq) goto loc_8246506C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465048
	if (cr6.eq) goto loc_82465048;
loc_8246506C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,300
	ctx.r3.s64 = 300;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246507C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19700
	ctx.r10.s64 = r11.s64 + -19700;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465088:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824650ac
	if (cr0.eq) goto loc_824650AC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465088
	if (cr6.eq) goto loc_82465088;
loc_824650AC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824650bc
	if (!cr0.eq) goto loc_824650BC;
	// li r3,301
	ctx.r3.s64 = 301;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824650BC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-29524
	ctx.r10.s64 = r11.s64 + -29524;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824650C8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464884
	if (cr0.eq) goto loc_82464884;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824650c8
	if (cr6.eq) goto loc_824650C8;
	// b 0x82464884
	goto loc_82464884;
loc_824650F0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19712
	ctx.r10.s64 = r11.s64 + -19712;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824650FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465120
	if (cr0.eq) goto loc_82465120;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824650fc
	if (cr6.eq) goto loc_824650FC;
loc_82465120:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465130
	if (!cr0.eq) goto loc_82465130;
	// li r3,302
	ctx.r3.s64 = 302;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465130:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_82465138:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246515c
	if (cr0.eq) goto loc_8246515C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465138
	if (cr6.eq) goto loc_82465138;
loc_8246515C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246516c
	if (!cr0.eq) goto loc_8246516C;
loc_82465164:
	// li r3,303
	ctx.r3.s64 = 303;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246516C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23224
	ctx.r10.s64 = r11.s64 + -23224;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465178:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246519c
	if (cr0.eq) goto loc_8246519C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465178
	if (cr6.eq) goto loc_82465178;
loc_8246519C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824651ac
	if (!cr0.eq) goto loc_824651AC;
	// li r3,304
	ctx.r3.s64 = 304;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824651AC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19720
	ctx.r10.s64 = r11.s64 + -19720;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824651B8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824651dc
	if (cr0.eq) goto loc_824651DC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824651b8
	if (cr6.eq) goto loc_824651B8;
loc_824651DC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19732
	ctx.r10.s64 = r11.s64 + -19732;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824651F0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465214
	if (cr0.eq) goto loc_82465214;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824651f0
	if (cr6.eq) goto loc_824651F0;
loc_82465214:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19740
	ctx.r10.s64 = r11.s64 + -19740;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465228:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246524c
	if (cr0.eq) goto loc_8246524C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465228
	if (cr6.eq) goto loc_82465228;
loc_8246524C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-18924
	ctx.r10.s64 = r11.s64 + -18924;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246526C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465290
	if (cr0.eq) goto loc_82465290;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246526c
	if (cr6.eq) goto loc_8246526C;
loc_82465290:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824652ac
	if (!cr0.eq) goto loc_824652AC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824652ac
	if (!cr0.eq) goto loc_824652AC;
	// li r3,306
	ctx.r3.s64 = 306;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824652AC:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-18504
	ctx.r10.s64 = r11.s64 + -18504;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824652B8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824652dc
	if (cr0.eq) goto loc_824652DC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824652b8
	if (cr6.eq) goto loc_824652B8;
loc_824652DC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824652f8
	if (!cr0.eq) goto loc_824652F8;
loc_824652F0:
	// li r3,305
	ctx.r3.s64 = 305;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824652F8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-19808
	ctx.r6.s64 = r11.s64 + -19808;
loc_82465300:
	// li r5,3086
	ctx.r5.s64 = 3086;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x8246488c
	goto loc_8246488C;
loc_82465314:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23248
	ctx.r10.s64 = r11.s64 + -23248;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465320:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465344
	if (cr0.eq) goto loc_82465344;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465320
	if (cr6.eq) goto loc_82465320;
loc_82465344:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465354
	if (!cr0.eq) goto loc_82465354;
	// li r3,307
	ctx.r3.s64 = 307;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465354:
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-18940
	ctx.r10.s64 = r11.s64 + -18940;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246536C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465390
	if (cr0.eq) goto loc_82465390;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246536c
	if (cr6.eq) goto loc_8246536C;
loc_82465390:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// b 0x824652f0
	goto loc_824652F0;
loc_824653A8:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r10,r11,20164
	ctx.r10.s64 = r11.s64 + 20164;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824653B4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824653d8
	if (cr0.eq) goto loc_824653D8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824653b4
	if (cr6.eq) goto loc_824653B4;
loc_824653D8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824653e8
	if (!cr0.eq) goto loc_824653E8;
	// li r3,309
	ctx.r3.s64 = 309;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824653E8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19828
	ctx.r10.s64 = r11.s64 + -19828;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824653F4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465418
	if (cr0.eq) goto loc_82465418;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824653f4
	if (cr6.eq) goto loc_824653F4;
loc_82465418:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,12280
	ctx.r10.s64 = r11.s64 + 12280;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246542C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465450
	if (cr0.eq) goto loc_82465450;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246542c
	if (cr6.eq) goto loc_8246542C;
loc_82465450:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465460
	if (!cr0.eq) goto loc_82465460;
	// li r3,312
	ctx.r3.s64 = 312;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465460:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r10,r11,28384
	ctx.r10.s64 = r11.s64 + 28384;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246546C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465490
	if (cr0.eq) goto loc_82465490;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246546c
	if (cr6.eq) goto loc_8246546C;
loc_82465490:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,311
	ctx.r3.s64 = 311;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824654A0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19844
	ctx.r10.s64 = r11.s64 + -19844;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824654AC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824654d0
	if (cr0.eq) goto loc_824654D0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824654ac
	if (cr6.eq) goto loc_824654AC;
loc_824654D0:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824654e0
	if (!cr0.eq) goto loc_824654E0;
	// li r3,308
	ctx.r3.s64 = 308;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824654E0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19864
	ctx.r10.s64 = r11.s64 + -19864;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824654EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465510
	if (cr0.eq) goto loc_82465510;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824654ec
	if (cr6.eq) goto loc_824654EC;
loc_82465510:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,310
	ctx.r3.s64 = 310;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465520:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23156
	ctx.r10.s64 = r11.s64 + -23156;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246552C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465550
	if (cr0.eq) goto loc_82465550;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246552c
	if (cr6.eq) goto loc_8246552C;
loc_82465550:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465560
	if (!cr0.eq) goto loc_82465560;
	// li r3,315
	ctx.r3.s64 = 315;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465560:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23168
	ctx.r10.s64 = r11.s64 + -23168;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246556C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465590
	if (cr0.eq) goto loc_82465590;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246556c
	if (cr6.eq) goto loc_8246556C;
loc_82465590:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824655a0
	if (!cr0.eq) goto loc_824655A0;
	// li r3,316
	ctx.r3.s64 = 316;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824655A0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23180
	ctx.r10.s64 = r11.s64 + -23180;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824655AC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824655d0
	if (cr0.eq) goto loc_824655D0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824655ac
	if (cr6.eq) goto loc_824655AC;
loc_824655D0:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824655e0
	if (!cr0.eq) goto loc_824655E0;
	// li r3,317
	ctx.r3.s64 = 317;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824655E0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23192
	ctx.r10.s64 = r11.s64 + -23192;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824655EC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465610
	if (cr0.eq) goto loc_82465610;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824655ec
	if (cr6.eq) goto loc_824655EC;
loc_82465610:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465620
	if (!cr0.eq) goto loc_82465620;
	// li r3,318
	ctx.r3.s64 = 318;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465620:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19880
	ctx.r10.s64 = r11.s64 + -19880;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246562C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465650
	if (cr0.eq) goto loc_82465650;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246562c
	if (cr6.eq) goto loc_8246562C;
loc_82465650:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465660
	if (!cr0.eq) goto loc_82465660;
	// li r3,319
	ctx.r3.s64 = 319;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465660:
	// lis r11,-32252
	r11.s64 = -2113667072;
	// addi r10,r11,6324
	ctx.r10.s64 = r11.s64 + 6324;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246566C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465690
	if (cr0.eq) goto loc_82465690;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246566c
	if (cr6.eq) goto loc_8246566C;
loc_82465690:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824656a0
	if (!cr0.eq) goto loc_824656A0;
	// li r3,320
	ctx.r3.s64 = 320;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824656A0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-28040
	ctx.r10.s64 = r11.s64 + -28040;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824656AC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824656d0
	if (cr0.eq) goto loc_824656D0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824656ac
	if (cr6.eq) goto loc_824656AC;
loc_824656D0:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19888
	ctx.r10.s64 = r11.s64 + -19888;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824656E4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465708
	if (cr0.eq) goto loc_82465708;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824656e4
	if (cr6.eq) goto loc_824656E4;
loc_82465708:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19896
	ctx.r10.s64 = r11.s64 + -19896;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246571C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465740
	if (cr0.eq) goto loc_82465740;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246571c
	if (cr6.eq) goto loc_8246571C;
loc_82465740:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19904
	ctx.r10.s64 = r11.s64 + -19904;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465754:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465778
	if (cr0.eq) goto loc_82465778;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465754
	if (cr6.eq) goto loc_82465754;
loc_82465778:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465788
	if (!cr0.eq) goto loc_82465788;
	// li r3,321
	ctx.r3.s64 = 321;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465788:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19924
	ctx.r10.s64 = r11.s64 + -19924;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465794:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824657b8
	if (cr0.eq) goto loc_824657B8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465794
	if (cr6.eq) goto loc_82465794;
loc_824657B8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824657c8
	if (!cr0.eq) goto loc_824657C8;
	// li r3,323
	ctx.r3.s64 = 323;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824657C8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19932
	ctx.r10.s64 = r11.s64 + -19932;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824657D4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824657f8
	if (cr0.eq) goto loc_824657F8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824657d4
	if (cr6.eq) goto loc_824657D4;
loc_824657F8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465808
	if (!cr0.eq) goto loc_82465808;
	// li r3,324
	ctx.r3.s64 = 324;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465808:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19944
	ctx.r10.s64 = r11.s64 + -19944;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465814:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465838
	if (cr0.eq) goto loc_82465838;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465814
	if (cr6.eq) goto loc_82465814;
loc_82465838:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r10,r11,27388
	ctx.r10.s64 = r11.s64 + 27388;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246584C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465870
	if (cr0.eq) goto loc_82465870;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246584c
	if (cr6.eq) goto loc_8246584C;
loc_82465870:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465880
	if (!cr0.eq) goto loc_82465880;
	// li r3,325
	ctx.r3.s64 = 325;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465880:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-18396
	ctx.r10.s64 = r11.s64 + -18396;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246588C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824658b0
	if (cr0.eq) goto loc_824658B0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246588c
	if (cr6.eq) goto loc_8246588C;
loc_824658B0:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824658c0
	if (!cr0.eq) goto loc_824658C0;
loc_824658B8:
	// li r3,326
	ctx.r3.s64 = 326;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824658C0:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-18388
	ctx.r10.s64 = r11.s64 + -18388;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824658CC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824658f0
	if (cr0.eq) goto loc_824658F0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824658cc
	if (cr6.eq) goto loc_824658CC;
loc_824658F0:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465900
	if (!cr0.eq) goto loc_82465900;
	// li r3,327
	ctx.r3.s64 = 327;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465900:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,25696
	ctx.r10.s64 = r11.s64 + 25696;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246590C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465930
	if (cr0.eq) goto loc_82465930;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246590c
	if (cr6.eq) goto loc_8246590C;
loc_82465930:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465940
	if (!cr0.eq) goto loc_82465940;
	// li r3,328
	ctx.r3.s64 = 328;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465940:
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-18344
	ctx.r10.s64 = r11.s64 + -18344;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465958:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246597c
	if (cr0.eq) goto loc_8246597C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465958
	if (cr6.eq) goto loc_82465958;
loc_8246597C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246598c
	if (!cr0.eq) goto loc_8246598C;
loc_82465984:
	// li r3,313
	ctx.r3.s64 = 313;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246598C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23236
	ctx.r10.s64 = r11.s64 + -23236;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465998:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824659bc
	if (cr0.eq) goto loc_824659BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465998
	if (cr6.eq) goto loc_82465998;
loc_824659BC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,322
	ctx.r3.s64 = 322;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824659CC:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,18588
	ctx.r10.s64 = r11.s64 + 18588;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824659D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824659fc
	if (cr0.eq) goto loc_824659FC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824659d8
	if (cr6.eq) goto loc_824659D8;
loc_824659FC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x824658b8
	if (cr0.eq) goto loc_824658B8;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19960
	ctx.r10.s64 = r11.s64 + -19960;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465A10:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465a34
	if (cr0.eq) goto loc_82465A34;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465a10
	if (cr6.eq) goto loc_82465A10;
loc_82465A34:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82465984
	if (cr0.eq) goto loc_82465984;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19984
	ctx.r10.s64 = r11.s64 + -19984;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465A48:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465a6c
	if (cr0.eq) goto loc_82465A6C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465a48
	if (cr6.eq) goto loc_82465A48;
loc_82465A6C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,314
	ctx.r3.s64 = 314;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465A7C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-22120
	ctx.r10.s64 = r11.s64 + -22120;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465A88:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465aac
	if (cr0.eq) goto loc_82465AAC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465a88
	if (cr6.eq) goto loc_82465A88;
loc_82465AAC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465abc
	if (!cr0.eq) goto loc_82465ABC;
	// li r3,329
	ctx.r3.s64 = 329;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465ABC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-19996
	ctx.r10.s64 = r11.s64 + -19996;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465AC8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465aec
	if (cr0.eq) goto loc_82465AEC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465ac8
	if (cr6.eq) goto loc_82465AC8;
loc_82465AEC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,15008
	ctx.r10.s64 = r11.s64 + 15008;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465B00:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465b24
	if (cr0.eq) goto loc_82465B24;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465b00
	if (cr6.eq) goto loc_82465B00;
loc_82465B24:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20008
	ctx.r10.s64 = r11.s64 + -20008;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465B38:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465b5c
	if (cr0.eq) goto loc_82465B5C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465b38
	if (cr6.eq) goto loc_82465B38;
loc_82465B5C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465b6c
	if (!cr0.eq) goto loc_82465B6C;
	// li r3,341
	ctx.r3.s64 = 341;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465B6C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20020
	ctx.r10.s64 = r11.s64 + -20020;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465B78:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465b9c
	if (cr0.eq) goto loc_82465B9C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465b78
	if (cr6.eq) goto loc_82465B78;
loc_82465B9C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465bac
	if (!cr0.eq) goto loc_82465BAC;
	// li r3,342
	ctx.r3.s64 = 342;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465BAC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20028
	ctx.r10.s64 = r11.s64 + -20028;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465BB8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465bdc
	if (cr0.eq) goto loc_82465BDC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465bb8
	if (cr6.eq) goto loc_82465BB8;
loc_82465BDC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r10,r11,-24604
	ctx.r10.s64 = r11.s64 + -24604;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465BF0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465c14
	if (cr0.eq) goto loc_82465C14;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465bf0
	if (cr6.eq) goto loc_82465BF0;
loc_82465C14:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465c24
	if (!cr0.eq) goto loc_82465C24;
	// li r3,344
	ctx.r3.s64 = 344;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465C24:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r10,r11,-26672
	ctx.r10.s64 = r11.s64 + -26672;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465C30:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465c54
	if (cr0.eq) goto loc_82465C54;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465c30
	if (cr6.eq) goto loc_82465C30;
loc_82465C54:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20036
	ctx.r10.s64 = r11.s64 + -20036;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465C68:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465c8c
	if (cr0.eq) goto loc_82465C8C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465c68
	if (cr6.eq) goto loc_82465C68;
loc_82465C8C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465c9c
	if (!cr0.eq) goto loc_82465C9C;
	// li r3,345
	ctx.r3.s64 = 345;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465C9C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20048
	ctx.r10.s64 = r11.s64 + -20048;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465CA8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465ccc
	if (cr0.eq) goto loc_82465CCC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465ca8
	if (cr6.eq) goto loc_82465CA8;
loc_82465CCC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_82465CDC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465d00
	if (cr0.eq) goto loc_82465D00;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465cdc
	if (cr6.eq) goto loc_82465CDC;
loc_82465D00:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465d10
	if (!cr0.eq) goto loc_82465D10;
loc_82465D08:
	// li r3,330
	ctx.r3.s64 = 330;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465D10:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-22160
	ctx.r10.s64 = r11.s64 + -22160;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465D1C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465d40
	if (cr0.eq) goto loc_82465D40;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465d1c
	if (cr6.eq) goto loc_82465D1C;
loc_82465D40:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465d50
	if (!cr0.eq) goto loc_82465D50;
	// li r3,331
	ctx.r3.s64 = 331;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465D50:
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r10,r11,27080
	ctx.r10.s64 = r11.s64 + 27080;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465D68:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465d8c
	if (cr0.eq) goto loc_82465D8C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465d68
	if (cr6.eq) goto loc_82465D68;
loc_82465D8C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465d9c
	if (!cr0.eq) goto loc_82465D9C;
	// li r3,332
	ctx.r3.s64 = 332;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465D9C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20060
	ctx.r10.s64 = r11.s64 + -20060;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// bne 0x82465ea8
	if (!cr0.eq) goto loc_82465EA8;
loc_82465DB4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465dd8
	if (cr0.eq) goto loc_82465DD8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465db4
	if (cr6.eq) goto loc_82465DB4;
loc_82465DD8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465de8
	if (!cr0.eq) goto loc_82465DE8;
loc_82465DE0:
	// li r3,333
	ctx.r3.s64 = 333;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465DE8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20072
	ctx.r10.s64 = r11.s64 + -20072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465DF4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465e18
	if (cr0.eq) goto loc_82465E18;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465df4
	if (cr6.eq) goto loc_82465DF4;
loc_82465E18:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465e28
	if (!cr0.eq) goto loc_82465E28;
loc_82465E20:
	// li r3,335
	ctx.r3.s64 = 335;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465E28:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20084
	ctx.r10.s64 = r11.s64 + -20084;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465E34:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465e58
	if (cr0.eq) goto loc_82465E58;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465e34
	if (cr6.eq) goto loc_82465E34;
loc_82465E58:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465e68
	if (!cr0.eq) goto loc_82465E68;
loc_82465E60:
	// li r3,337
	ctx.r3.s64 = 337;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465E68:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20096
	ctx.r10.s64 = r11.s64 + -20096;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465E74:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465e98
	if (cr0.eq) goto loc_82465E98;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465e74
	if (cr6.eq) goto loc_82465E74;
loc_82465E98:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
loc_82465EA0:
	// li r3,338
	ctx.r3.s64 = 338;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82465EA8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465ecc
	if (cr0.eq) goto loc_82465ECC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465ea8
	if (cr6.eq) goto loc_82465EA8;
loc_82465ECC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465eec
	if (!cr0.eq) goto loc_82465EEC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3086
	ctx.r5.s64 = 3086;
	// addi r6,r11,-20160
	ctx.r6.s64 = r11.s64 + -20160;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82465EEC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20072
	ctx.r10.s64 = r11.s64 + -20072;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
loc_82465EF8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465f1c
	if (cr0.eq) goto loc_82465F1C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465ef8
	if (cr6.eq) goto loc_82465EF8;
loc_82465F1C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465f3c
	if (!cr0.eq) goto loc_82465F3C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3086
	ctx.r5.s64 = 3086;
	// addi r6,r11,-20224
	ctx.r6.s64 = r11.s64 + -20224;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82465F3C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20084
	ctx.r10.s64 = r11.s64 + -20084;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
loc_82465F48:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465f6c
	if (cr0.eq) goto loc_82465F6C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465f48
	if (cr6.eq) goto loc_82465F48;
loc_82465F6C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82465f8c
	if (!cr0.eq) goto loc_82465F8C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3086
	ctx.r5.s64 = 3086;
	// addi r6,r11,-20288
	ctx.r6.s64 = r11.s64 + -20288;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82465F8C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20096
	ctx.r10.s64 = r11.s64 + -20096;
	// lwz r11,48(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 48);
loc_82465F98:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82465fbc
	if (cr0.eq) goto loc_82465FBC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465f98
	if (cr6.eq) goto loc_82465F98;
loc_82465FBC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-20352
	ctx.r6.s64 = r11.s64 + -20352;
	// b 0x82465300
	goto loc_82465300;
loc_82465FD0:
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23036
	ctx.r10.s64 = r11.s64 + -23036;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82465FE8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246600c
	if (cr0.eq) goto loc_8246600C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82465fe8
	if (cr6.eq) goto loc_82465FE8;
loc_8246600C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82465de0
	if (cr0.eq) goto loc_82465DE0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23088
	ctx.r10.s64 = r11.s64 + -23088;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466020:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466044
	if (cr0.eq) goto loc_82466044;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466020
	if (cr6.eq) goto loc_82466020;
loc_82466044:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82466054
	if (!cr0.eq) goto loc_82466054;
	// li r3,334
	ctx.r3.s64 = 334;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82466054:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23048
	ctx.r10.s64 = r11.s64 + -23048;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466060:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466084
	if (cr0.eq) goto loc_82466084;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466060
	if (cr6.eq) goto loc_82466060;
loc_82466084:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82465e20
	if (cr0.eq) goto loc_82465E20;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23104
	ctx.r10.s64 = r11.s64 + -23104;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466098:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824660bc
	if (cr0.eq) goto loc_824660BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466098
	if (cr6.eq) goto loc_82466098;
loc_824660BC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824660cc
	if (!cr0.eq) goto loc_824660CC;
	// li r3,336
	ctx.r3.s64 = 336;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824660CC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23060
	ctx.r10.s64 = r11.s64 + -23060;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824660D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824660fc
	if (cr0.eq) goto loc_824660FC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824660d8
	if (cr6.eq) goto loc_824660D8;
loc_824660FC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82465e60
	if (cr0.eq) goto loc_82465E60;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23072
	ctx.r10.s64 = r11.s64 + -23072;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466110:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466134
	if (cr0.eq) goto loc_82466134;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466110
	if (cr6.eq) goto loc_82466110;
loc_82466134:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82465ea0
	if (cr0.eq) goto loc_82465EA0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23276
	ctx.r10.s64 = r11.s64 + -23276;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466148:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246616c
	if (cr0.eq) goto loc_8246616C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466148
	if (cr6.eq) goto loc_82466148;
loc_8246616C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246617c
	if (!cr0.eq) goto loc_8246617C;
	// li r3,343
	ctx.r3.s64 = 343;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246617C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-23116
	ctx.r10.s64 = r11.s64 + -23116;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466188:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824661ac
	if (cr0.eq) goto loc_824661AC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466188
	if (cr6.eq) goto loc_82466188;
loc_824661AC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824661bc
	if (!cr0.eq) goto loc_824661BC;
	// li r3,339
	ctx.r3.s64 = 339;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824661BC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20372
	ctx.r10.s64 = r11.s64 + -20372;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824661C8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824661ec
	if (cr0.eq) goto loc_824661EC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824661c8
	if (cr6.eq) goto loc_824661C8;
loc_824661EC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,340
	ctx.r3.s64 = 340;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824661FC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-22936
	ctx.r10.s64 = r11.s64 + -22936;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466208:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246622c
	if (cr0.eq) goto loc_8246622C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466208
	if (cr6.eq) goto loc_82466208;
loc_8246622C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246623c
	if (!cr0.eq) goto loc_8246623C;
	// li r3,348
	ctx.r3.s64 = 348;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246623C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20380
	ctx.r10.s64 = r11.s64 + -20380;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466248:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x8246626c
	if (cr0.eq) goto loc_8246626C;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466248
	if (cr6.eq) goto loc_82466248;
loc_8246626C:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246627c
	if (!cr0.eq) goto loc_8246627C;
	// li r3,346
	ctx.r3.s64 = 346;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_8246627C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20388
	ctx.r10.s64 = r11.s64 + -20388;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466288:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824662ac
	if (cr0.eq) goto loc_824662AC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466288
	if (cr6.eq) goto loc_82466288;
loc_824662AC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20396
	ctx.r10.s64 = r11.s64 + -20396;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824662C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824662e4
	if (cr0.eq) goto loc_824662E4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824662c0
	if (cr6.eq) goto loc_824662C0;
loc_824662E4:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824662f4
	if (!cr0.eq) goto loc_824662F4;
	// li r3,349
	ctx.r3.s64 = 349;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824662F4:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20408
	ctx.r10.s64 = r11.s64 + -20408;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466300:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466324
	if (cr0.eq) goto loc_82466324;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466300
	if (cr6.eq) goto loc_82466300;
loc_82466324:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82466334
	if (!cr0.eq) goto loc_82466334;
	// li r3,347
	ctx.r3.s64 = 347;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82466334:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20416
	ctx.r10.s64 = r11.s64 + -20416;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466340:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82464884
	if (cr0.eq) goto loc_82464884;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466340
	if (cr6.eq) goto loc_82466340;
	// b 0x82464884
	goto loc_82464884;
loc_82466368:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r10,r11,7600
	ctx.r10.s64 = r11.s64 + 7600;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466374:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466398
	if (cr0.eq) goto loc_82466398;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466374
	if (cr6.eq) goto loc_82466374;
loc_82466398:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824663a8
	if (!cr0.eq) goto loc_824663A8;
	// li r3,350
	ctx.r3.s64 = 350;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824663A8:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-18552
	ctx.r10.s64 = r11.s64 + -18552;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824663B4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824663d8
	if (cr0.eq) goto loc_824663D8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824663b4
	if (cr6.eq) goto loc_824663B4;
loc_824663D8:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824663e8
	if (!cr0.eq) goto loc_824663E8;
	// li r3,351
	ctx.r3.s64 = 351;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824663E8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r10,r11,-20424
	ctx.r10.s64 = r11.s64 + -20424;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824663F4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466418
	if (cr0.eq) goto loc_82466418;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824663f4
	if (cr6.eq) goto loc_824663F4;
loc_82466418:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82464030
	if (cr0.eq) goto loc_82464030;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-28732
	ctx.r10.s64 = r11.s64 + -28732;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246642C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466450
	if (cr0.eq) goto loc_82466450;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246642c
	if (cr6.eq) goto loc_8246642C;
loc_82466450:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82466460
	if (!cr0.eq) goto loc_82466460;
	// li r3,353
	ctx.r3.s64 = 353;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82466460:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-28172
	ctx.r10.s64 = r11.s64 + -28172;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246646C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466490
	if (cr0.eq) goto loc_82466490;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246646c
	if (cr6.eq) goto loc_8246646C;
loc_82466490:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x824664a0
	if (!cr0.eq) goto loc_824664A0;
	// li r3,354
	ctx.r3.s64 = 354;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824664A0:
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32248
	r11.s64 = -2113404928;
	// addi r10,r11,-18520
	ctx.r10.s64 = r11.s64 + -18520;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_824664B8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x824664dc
	if (cr0.eq) goto loc_824664DC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x824664b8
	if (cr6.eq) goto loc_824664B8;
loc_824664DC:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824664f8
	if (!cr0.eq) goto loc_824664F8;
loc_824664F0:
	// li r3,352
	ctx.r3.s64 = 352;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824664F8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-20496
	ctx.r6.s64 = r11.s64 + -20496;
	// b 0x82465300
	goto loc_82465300;
loc_82466504:
	// lwz r11,80(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246488c
	if (cr6.eq) goto loc_8246488C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r11,-18928
	ctx.r10.s64 = r11.s64 + -18928;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8246651C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466540
	if (cr0.eq) goto loc_82466540;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x8246651c
	if (cr6.eq) goto loc_8246651C;
loc_82466540:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// b 0x824664f0
	goto loc_824664F0;
loc_82466558:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r10,r11,25828
	ctx.r10.s64 = r11.s64 + 25828;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82466564:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82466588
	if (cr0.eq) goto loc_82466588;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82466564
	if (cr6.eq) goto loc_82466564;
loc_82466588:
	// cmpwi r8,0
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x8246488c
	if (!cr0.eq) goto loc_8246488C;
	// li r3,355
	ctx.r3.s64 = 355;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82466598:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82466634
	if (!cr0.eq) goto loc_82466634;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82465164
	if (cr0.eq) goto loc_82465164;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-20560
	ctx.r6.s64 = r11.s64 + -20560;
	// b 0x82466624
	goto loc_82466624;
loc_824665C4:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// addi r4,r11,-20568
	ctx.r4.s64 = r11.s64 + -20568;
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82466634
	if (!cr0.eq) goto loc_82466634;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824665f0
	if (!cr0.eq) goto loc_824665F0;
	// li r3,273
	ctx.r3.s64 = 273;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_824665F0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-20628
	ctx.r6.s64 = r11.s64 + -20628;
	// b 0x82466624
	goto loc_82466624;
loc_824665FC:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 48);
	// bl 0x823a12f0
	sub_823A12F0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82466634
	if (!cr0.eq) goto loc_82466634;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824642f4
	if (cr0.eq) goto loc_824642F4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-20684
	ctx.r6.s64 = r11.s64 + -20684;
loc_82466624:
	// li r5,3086
	ctx.r5.s64 = 3086;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82466634:
	// li r31,0
	r31.s64 = 0;
	// lwz r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// subf r11,r31,r3
	r11.s64 = ctx.r3.s64 - r31.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// addi r3,r11,384
	ctx.r3.s64 = r11.s64 + 384;
	// b 0x82463ff4
	goto loc_82463FF4;
loc_82466678:
	// li r3,383
	ctx.r3.s64 = 383;
	// b 0x82463ff4
	goto loc_82463FF4;
}

__attribute__((alias("__imp__sub_82466680"))) PPC_WEAK_FUNC(sub_82466680);
PPC_FUNC_IMPL(__imp__sub_82466680) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r21,r7
	r21.u64 = ctx.r7.u64;
	// addi r9,r11,-18184
	ctx.r9.s64 = r11.s64 + -18184;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r19,r4
	r19.u64 = ctx.r4.u64;
	// addi r20,r11,-18204
	r20.s64 = r11.s64 + -18204;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lis r4,-32246
	ctx.r4.s64 = -2113273856;
	// stw r9,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r9.u32);
	// addi r16,r11,-18224
	r16.s64 = r11.s64 + -18224;
	// stw r9,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r9.u32);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// stw r20,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r20.u32);
	// addi r7,r11,-18252
	ctx.r7.s64 = r11.s64 + -18252;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r17,r4,-18236
	r17.s64 = ctx.r4.s64 + -18236;
	// stw r16,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r16.u32);
	// addi r6,r11,-18276
	ctx.r6.s64 = r11.s64 + -18276;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lis r4,-32246
	ctx.r4.s64 = -2113273856;
	// stw r7,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r7.u32);
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// addi r5,r11,-18296
	ctx.r5.s64 = r11.s64 + -18296;
	// stw r17,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, r17.u32);
	// addi r15,r4,-18312
	r15.s64 = ctx.r4.s64 + -18312;
	// stw r6,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r6.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// lis r4,-32256
	ctx.r4.s64 = -2113929216;
	// stw r5,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r5.u32);
	// addi r11,r11,9120
	r11.s64 = r11.s64 + 9120;
	// stw r15,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, r15.u32);
	// addi r10,r10,-18328
	ctx.r10.s64 = ctx.r10.s64 + -18328;
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r4,r4,17416
	ctx.r4.s64 = ctx.r4.s64 + 17416;
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// stw r11,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, r11.u32);
	// stw r11,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, r11.u32);
	// stw r10,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r10.u32);
	// stw r10,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r10.u32);
	// stw r10,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, ctx.r10.u32);
	// stw r4,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r4.u32);
	// stw r11,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, r11.u32);
	// stw r11,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, r11.u32);
	// stw r10,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, ctx.r10.u32);
	// beq 0x82467448
	if (cr0.eq) goto loc_82467448;
	// lwz r22,8(r8)
	r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmplwi r22,0
	cr0.compare<uint32_t>(r22.u32, 0, xer);
	// beq 0x82467448
	if (cr0.eq) goto loc_82467448;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82467448
	if (cr6.eq) goto loc_82467448;
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x82467448
	if (cr6.eq) goto loc_82467448;
	// li r3,20
	ctx.r3.s64 = 20;
	// lwz r23,24(r22)
	r23.u64 = PPC_LOAD_U32(r22.u32 + 24);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// li r18,0
	r18.s64 = 0;
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824667a4
	if (cr0.eq) goto loc_824667A4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-18344
	ctx.r6.s64 = r11.s64 + -18344;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// stw r28,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r28.u32);
	// b 0x824667ac
	goto loc_824667AC;
loc_824667A4:
	// stw r18,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r18.u32);
	// rotlwi r28,r18,0
	r28.u64 = __builtin_rotateleft32(r18.u32, 0);
loc_824667AC:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82467448
	if (cr6.eq) goto loc_82467448;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824667e4
	if (cr0.eq) goto loc_824667E4;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// b 0x824667e8
	goto loc_824667E8;
loc_824667E4:
	// mr r14,r18
	r14.u64 = r18.u64;
loc_824667E8:
	// cmplwi cr6,r14,0
	cr6.compare<uint32_t>(r14.u32, 0, xer);
	// beq cr6,0x82467448
	if (cr6.eq) goto loc_82467448;
	// li r3,88
	ctx.r3.s64 = 88;
	// stw r14,8(r28)
	PPC_STORE_U32(r28.u32 + 8, r14.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82466810
	if (cr0.eq) goto loc_82466810;
	// bl 0x8240b568
	sub_8240B568(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// b 0x82466814
	goto loc_82466814;
loc_82466810:
	// mr r25,r18
	r25.u64 = r18.u64;
loc_82466814:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82467448
	if (cr6.eq) goto loc_82467448;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r25,24(r14)
	PPC_STORE_U32(r14.u32 + 24, r25.u32);
	// beq cr6,0x8246683c
	if (cr6.eq) goto loc_8246683C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,28(r14)
	PPC_STORE_U32(r14.u32 + 28, ctx.r3.u32);
	// beq 0x82467448
	if (cr0.eq) goto loc_82467448;
loc_8246683C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8246688c
	if (cr6.eq) goto loc_8246688C;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,64(r25)
	PPC_STORE_U32(r25.u32 + 64, ctx.r3.u32);
	// beq 0x82467448
	if (cr0.eq) goto loc_82467448;
loc_82466858:
	// lwz r3,8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82466880
	if (cr0.eq) goto loc_82466880;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82466880
	if (!cr6.eq) goto loc_82466880;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,60(r25)
	PPC_STORE_U32(r25.u32 + 60, ctx.r3.u32);
	// beq 0x82467448
	if (cr0.eq) goto loc_82467448;
loc_82466880:
	// lwz r29,12(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// bne 0x82466858
	if (!cr0.eq) goto loc_82466858;
loc_8246688C:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x824668b4
	if (cr6.eq) goto loc_824668B4;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x824668b4
	if (cr6.eq) goto loc_824668B4;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245f468
	sub_8245F468(ctx, base);
	// stw r3,52(r25)
	PPC_STORE_U32(r25.u32 + 52, ctx.r3.u32);
loc_824668B4:
	// li r26,1
	r26.s64 = 1;
	// mr r24,r18
	r24.u64 = r18.u64;
	// mr r28,r26
	r28.u64 = r26.u64;
	// mr r27,r18
	r27.u64 = r18.u64;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82466964
	if (cr6.eq) goto loc_82466964;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,48(r25)
	PPC_STORE_U32(r25.u32 + 48, ctx.r3.u32);
	// beq 0x82467448
	if (cr0.eq) goto loc_82467448;
	// b 0x82466964
	goto loc_82466964;
loc_824668E4:
	// li r3,24
	ctx.r3.s64 = 24;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82466900
	if (cr0.eq) goto loc_82466900;
	// bl 0x8240abc0
	sub_8240ABC0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x82466904
	goto loc_82466904;
loc_82466900:
	// mr r29,r18
	r29.u64 = r18.u64;
loc_82466904:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82467448
	if (cr6.eq) goto loc_82467448;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x82466918
	if (cr6.eq) goto loc_82466918;
	// li r27,3073
	r27.s64 = 3073;
loc_82466918:
	// lwz r11,48(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// addi r30,r29,20
	r30.s64 = r29.s64 + 20;
	// stw r11,16(r29)
	PPC_STORE_U32(r29.u32 + 16, r11.u32);
	// lwz r4,12(r19)
	ctx.r4.u64 = PPC_LOAD_U32(r19.u32 + 12);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x8246694c
	if (cr0.eq) goto loc_8246694C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82466954
	if (!cr0.lt) goto loc_82466954;
	// li r27,3058
	r27.s64 = 3058;
	// b 0x82466950
	goto loc_82466950;
loc_8246694C:
	// mr r24,r30
	r24.u64 = r30.u64;
loc_82466950:
	// stw r26,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r26.u32);
loc_82466954:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r29,48(r25)
	PPC_STORE_U32(r25.u32 + 48, r29.u32);
	// lwz r19,8(r19)
	r19.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// mullw r28,r11,r28
	r28.s64 = int64_t(r11.s32) * int64_t(r28.s32);
loc_82466964:
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x824668e4
	if (!cr6.eq) goto loc_824668E4;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r14)
	PPC_STORE_U32(r14.u32 + 20, ctx.r3.u32);
	// beq 0x82467448
	if (cr0.eq) goto loc_82467448;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r30,r19,16
	r30.s64 = r19.s64 + 16;
	// cmplwi cr6,r27,3058
	cr6.compare<uint32_t>(r27.u32, 3058, xer);
	// lwz r26,16(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// beq cr6,0x8246742c
	if (cr6.eq) goto loc_8246742C;
	// cmplwi cr6,r27,3073
	cr6.compare<uint32_t>(r27.u32, 3073, xer);
	// beq cr6,0x8246741c
	if (cr6.eq) goto loc_8246741C;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x82466a88
	if (cr6.eq) goto loc_82466A88;
	// cmpwi cr6,r26,9
	cr6.compare<int32_t>(r26.s32, 9, xer);
	// beq cr6,0x824669e4
	if (cr6.eq) goto loc_824669E4;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x824669e4
	if (cr6.eq) goto loc_824669E4;
	// cmpwi cr6,r26,3
	cr6.compare<int32_t>(r26.s32, 3, xer);
	// beq cr6,0x824669e4
	if (cr6.eq) goto loc_824669E4;
	// cmpwi cr6,r26,4
	cr6.compare<int32_t>(r26.s32, 4, xer);
	// beq cr6,0x824669e4
	if (cr6.eq) goto loc_824669E4;
	// cmpwi cr6,r26,5
	cr6.compare<int32_t>(r26.s32, 5, xer);
	// beq cr6,0x824669e4
	if (cr6.eq) goto loc_824669E4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// addi r6,r11,-18392
	ctx.r6.s64 = r11.s64 + -18392;
	// li r5,3072
	ctx.r5.s64 = 3072;
	// b 0x82466a40
	goto loc_82466A40;
loc_824669E4:
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// mullw. r29,r3,r28
	r29.s64 = int64_t(ctx.r3.s32) * int64_t(r28.s32);
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x82466a80
	if (cr0.eq) goto loc_82466A80;
	// lwz r11,52(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82466a70
	if (cr0.eq) goto loc_82466A70;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// bne cr6,0x82466a70
	if (!cr6.eq) goto loc_82466A70;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// divwu r11,r3,r29
	r11.u32 = ctx.r3.u32 / r29.u32;
	// twllei r29,0
	// mullw r11,r11,r29
	r11.s64 = int64_t(r11.s32) * int64_t(r29.s32);
	// subf. r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466a5c
	if (cr0.eq) goto loc_82466A5C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3075
	ctx.r5.s64 = 3075;
	// addi r6,r11,-18436
	ctx.r6.s64 = r11.s64 + -18436;
loc_82466A3C:
	// addi r9,r1,224
	ctx.r9.s64 = ctx.r1.s64 + 224;
loc_82466A40:
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82467448
	goto loc_82467448;
loc_82466A5C:
	// divwu r11,r3,r29
	r11.u32 = ctx.r3.u32 / r29.u32;
	// twllei r29,0
	// mullw r28,r11,r28
	r28.s64 = int64_t(r11.s32) * int64_t(r28.s32);
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// b 0x82466a88
	goto loc_82466A88;
loc_82466A70:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3074
	ctx.r5.s64 = 3074;
	// addi r6,r11,-18468
	ctx.r6.s64 = r11.s64 + -18468;
	// b 0x82466a3c
	goto loc_82466A3C;
loc_82466A80:
	// mr r28,r18
	r28.u64 = r18.u64;
	// stw r18,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r18.u32);
loc_82466A88:
	// addi r11,r28,-1
	r11.s64 = r28.s64 + -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,65535
	cr6.compare<uint32_t>(r11.u32, 65535, xer);
	// bgt cr6,0x8246740c
	if (cr6.gt) goto loc_8246740C;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// stw r3,20(r25)
	PPC_STORE_U32(r25.u32 + 20, ctx.r3.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r11,40(r25)
	PPC_STORE_U32(r25.u32 + 40, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x82466b24
	if (cr6.eq) goto loc_82466B24;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// stw r11,16(r25)
	PPC_STORE_U32(r25.u32 + 16, r11.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// stw r11,24(r25)
	PPC_STORE_U32(r25.u32 + 24, r11.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// stw r11,28(r25)
	PPC_STORE_U32(r25.u32 + 28, r11.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// lwz r10,16(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82466b2c
	if (cr0.eq) goto loc_82466B2C;
	// stw r11,32(r25)
	PPC_STORE_U32(r25.u32 + 32, r11.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// stw r11,36(r25)
	PPC_STORE_U32(r25.u32 + 36, r11.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// b 0x82466b2c
	goto loc_82466B2C;
loc_82466B24:
	// li r11,-1
	r11.s64 = -1;
	// stw r11,16(r25)
	PPC_STORE_U32(r25.u32 + 16, r11.u32);
loc_82466B2C:
	// lwz r11,20(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// lwz r27,16(r22)
	r27.u64 = PPC_LOAD_U32(r22.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82466ba0
	if (cr0.eq) goto loc_82466BA0;
	// addi r5,r1,152
	ctx.r5.s64 = ctx.r1.s64 + 152;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bge 0x82466b80
	if (!cr0.lt) goto loc_82466B80;
	// lwz r10,20(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 20);
	// rlwinm r9,r26,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3089
	ctx.r5.s64 = 3089;
	// addi r6,r11,-18504
	ctx.r6.s64 = r11.s64 + -18504;
	// lwz r7,24(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwzx r8,r9,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// b 0x82466b9c
	goto loc_82466B9C;
loc_82466B80:
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3039
	ctx.r5.s64 = 3039;
	// addi r6,r11,-18540
	ctx.r6.s64 = r11.s64 + -18540;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
loc_82466B9C:
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82466BA0:
	// rlwinm. r11,r27,0,23,23
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466bd0
	if (cr0.eq) goto loc_82466BD0;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3055
	ctx.r5.s64 = 3055;
	// addi r6,r11,-18580
	ctx.r6.s64 = r11.s64 + -18580;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82466BD0:
	// cmpwi cr6,r26,1
	cr6.compare<int32_t>(r26.s32, 1, xer);
	// bne cr6,0x82466c0c
	if (!cr6.eq) goto loc_82466C0C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82466ca8
	if (cr0.eq) goto loc_82466CA8;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
	// addi r6,r11,-18616
	ctx.r6.s64 = r11.s64 + -18616;
	// li r5,3035
	ctx.r5.s64 = 3035;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82466C0C:
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// bne cr6,0x82466c4c
	if (!cr6.eq) goto loc_82466C4C;
	// rlwinm. r11,r27,0,27,27
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82466ca8
	if (!cr0.eq) goto loc_82466CA8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82466ca8
	if (cr0.eq) goto loc_82466CA8;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r5,3046
	ctx.r5.s64 = 3046;
	// addi r6,r11,-18668
	ctx.r6.s64 = r11.s64 + -18668;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82466C4C:
	// cmpwi cr6,r26,3
	cr6.compare<int32_t>(r26.s32, 3, xer);
	// beq cr6,0x82466c5c
	if (cr6.eq) goto loc_82466C5C;
	// cmpwi cr6,r26,4
	cr6.compare<int32_t>(r26.s32, 4, xer);
	// bne cr6,0x82466c98
	if (!cr6.eq) goto loc_82466C98;
loc_82466C5C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82466c98
	if (!cr0.eq) goto loc_82466C98;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3038
	ctx.r5.s64 = 3038;
	// addi r6,r11,-18696
	ctx.r6.s64 = r11.s64 + -18696;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82466C98:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x82466dd0
	if (cr6.eq) goto loc_82466DD0;
	// cmpwi cr6,r26,9
	cr6.compare<int32_t>(r26.s32, 9, xer);
	// beq cr6,0x82466dd0
	if (cr6.eq) goto loc_82466DD0;
loc_82466CA8:
	// rlwinm. r11,r27,0,30,30
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466cec
	if (cr0.eq) goto loc_82466CEC;
	// cmpwi cr6,r26,3
	cr6.compare<int32_t>(r26.s32, 3, xer);
	// beq cr6,0x82466cec
	if (cr6.eq) goto loc_82466CEC;
	// cmpwi cr6,r26,4
	cr6.compare<int32_t>(r26.s32, 4, xer);
	// beq cr6,0x82466cec
	if (cr6.eq) goto loc_82466CEC;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3007
	ctx.r5.s64 = 3007;
	// addi r6,r11,-18736
	ctx.r6.s64 = r11.s64 + -18736;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// rlwinm r27,r27,0,31,29
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
loc_82466CEC:
	// rlwinm. r11,r27,0,25,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466d28
	if (cr0.eq) goto loc_82466D28;
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// beq cr6,0x82466d28
	if (cr6.eq) goto loc_82466D28;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3047
	ctx.r5.s64 = 3047;
	// addi r6,r11,-18776
	ctx.r6.s64 = r11.s64 + -18776;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// rlwinm r27,r27,0,26,24
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFBF;
loc_82466D28:
	// rlwinm. r11,r27,0,25,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466d64
	if (cr0.eq) goto loc_82466D64;
	// rlwinm. r11,r27,0,26,26
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466d64
	if (cr0.eq) goto loc_82466D64;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3062
	ctx.r5.s64 = 3062;
	// addi r6,r11,-18820
	ctx.r6.s64 = r11.s64 + -18820;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// rlwinm r27,r27,0,26,24
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFBF;
loc_82466D64:
	// clrlwi. r11,r27,31
	r11.u64 = r27.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466d98
	if (cr0.eq) goto loc_82466D98;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3006
	ctx.r5.s64 = 3006;
	// addi r6,r11,-18860
	ctx.r6.s64 = r11.s64 + -18860;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// rlwinm r27,r27,0,0,30
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFE;
loc_82466D98:
	// rlwinm. r11,r27,0,28,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466e54
	if (cr0.eq) goto loc_82466E54;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3054
	ctx.r5.s64 = 3054;
	// addi r6,r11,-18900
	ctx.r6.s64 = r11.s64 + -18900;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// rlwinm r27,r27,0,29,27
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// b 0x82466e54
	goto loc_82466E54;
loc_82466DD0:
	// rlwinm. r11,r27,0,30,30
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466e0c
	if (cr0.eq) goto loc_82466E0C;
	// clrlwi. r11,r27,31
	r11.u64 = r27.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466e0c
	if (cr0.eq) goto loc_82466E0C;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3007
	ctx.r5.s64 = 3007;
	// addi r6,r11,-18944
	ctx.r6.s64 = r11.s64 + -18944;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// rlwinm r27,r27,0,31,29
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
loc_82466E0C:
	// rlwinm. r11,r27,0,30,30
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466e48
	if (cr0.eq) goto loc_82466E48;
	// rlwinm. r11,r27,0,25,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466e48
	if (cr0.eq) goto loc_82466E48;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3007
	ctx.r5.s64 = 3007;
	// addi r6,r11,-18992
	ctx.r6.s64 = r11.s64 + -18992;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// rlwinm r27,r27,0,31,29
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
loc_82466E48:
	// rlwinm. r11,r27,0,30,30
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82466e54
	if (!cr0.eq) goto loc_82466E54;
	// ori r27,r27,65
	r27.u64 = r27.u64 | 65;
loc_82466E54:
	// rlwinm. r11,r27,0,29,29
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82466ea0
	if (cr0.eq) goto loc_82466EA0;
	// cmpwi cr6,r26,3
	cr6.compare<int32_t>(r26.s32, 3, xer);
	// beq cr6,0x82466ea0
	if (cr6.eq) goto loc_82466EA0;
	// cmpwi cr6,r26,4
	cr6.compare<int32_t>(r26.s32, 4, xer);
	// beq cr6,0x82466ea0
	if (cr6.eq) goto loc_82466EA0;
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// beq cr6,0x82466ea0
	if (cr6.eq) goto loc_82466EA0;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3008
	ctx.r5.s64 = 3008;
	// addi r6,r11,-19032
	ctx.r6.s64 = r11.s64 + -19032;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// rlwinm r27,r27,0,30,28
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
loc_82466EA0:
	// cmpwi cr6,r26,5
	cr6.compare<int32_t>(r26.s32, 5, xer);
	// bne cr6,0x82466ebc
	if (!cr6.eq) goto loc_82466EBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
	// ori r27,r27,64
	r27.u64 = r27.u64 | 64;
loc_82466EBC:
	// stw r27,44(r25)
	PPC_STORE_U32(r25.u32 + 44, r27.u32);
	// lwz r3,28(r22)
	ctx.r3.u64 = PPC_LOAD_U32(r22.u32 + 28);
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// stw r3,72(r25)
	PPC_STORE_U32(r25.u32 + 72, ctx.r3.u32);
	// rlwinm. r24,r27,0,25,25
	r24.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// beq 0x82466eec
	if (cr0.eq) goto loc_82466EEC;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82466eec
	if (cr0.eq) goto loc_82466EEC;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,68(r25)
	PPC_STORE_U32(r25.u32 + 68, r11.u32);
	// b 0x82466ef0
	goto loc_82466EF0;
loc_82466EEC:
	// stw r18,68(r25)
	PPC_STORE_U32(r25.u32 + 68, r18.u32);
loc_82466EF0:
	// mr r23,r18
	r23.u64 = r18.u64;
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82466f74
	if (cr6.eq) goto loc_82466F74;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x82466f14
	if (!cr6.eq) goto loc_82466F14;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// b 0x824670a8
	goto loc_824670A8;
loc_82466F14:
	// lwz r28,52(r25)
	r28.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x82466f28
	if (cr0.eq) goto loc_82466F28;
	// lwz r29,16(r28)
	r29.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// b 0x82466f2c
	goto loc_82466F2C;
loc_82466F28:
	// mr r29,r18
	r29.u64 = r18.u64;
loc_82466F2C:
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x82466f54
	if (!cr6.eq) goto loc_82466F54;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// b 0x824670ac
	goto loc_824670AC;
loc_82466F54:
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r6,48(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8245e998
	sub_8245E998(ctx, base);
	// stw r18,52(r25)
	PPC_STORE_U32(r25.u32 + 52, r18.u32);
	// b 0x824670bc
	goto loc_824670BC;
loc_82466F74:
	// cmpwi cr6,r26,9
	cr6.compare<int32_t>(r26.s32, 9, xer);
	// beq cr6,0x82466f94
	if (cr6.eq) goto loc_82466F94;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x82466f94
	if (cr6.eq) goto loc_82466F94;
	// cmpwi cr6,r26,3
	cr6.compare<int32_t>(r26.s32, 3, xer);
	// beq cr6,0x82466f94
	if (cr6.eq) goto loc_82466F94;
	// cmpwi cr6,r26,4
	cr6.compare<int32_t>(r26.s32, 4, xer);
	// bne cr6,0x824670bc
	if (!cr6.eq) goto loc_824670BC;
loc_82466F94:
	// rlwinm. r11,r27,0,30,30
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824670bc
	if (cr0.eq) goto loc_824670BC;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82466fd0
	if (cr0.eq) goto loc_82466FD0;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x82466fd4
	goto loc_82466FD4;
loc_82466FD0:
	// mr r29,r18
	r29.u64 = r18.u64;
loc_82466FD4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82466fe4
	if (!cr6.eq) goto loc_82466FE4;
loc_82466FDC:
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// b 0x824670a4
	goto loc_824670A4;
loc_82466FE4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467014
	if (cr0.eq) goto loc_82467014;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x82467018
	goto loc_82467018;
loc_82467014:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
loc_82467018:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r29)
	PPC_STORE_U32(r29.u32 + 16, ctx.r3.u32);
	// beq cr6,0x82466fdc
	if (cr6.eq) goto loc_82466FDC;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467048
	if (cr0.eq) goto loc_82467048;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x8246704c
	goto loc_8246704C;
loc_82467048:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
loc_8246704C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r29)
	PPC_STORE_U32(r29.u32 + 32, ctx.r3.u32);
	// beq cr6,0x82466fdc
	if (cr6.eq) goto loc_82466FDC;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467084
	if (cr0.eq) goto loc_82467084;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x82467088
	goto loc_82467088;
loc_82467084:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_82467088:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82466fdc
	if (cr6.eq) goto loc_82466FDC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// stw r11,32(r29)
	PPC_STORE_U32(r29.u32 + 32, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_824670A4:
	// li r7,1
	ctx.r7.s64 = 1;
loc_824670A8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_824670AC:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x82462478
	sub_82462478(ctx, base);
	// stw r3,52(r25)
	PPC_STORE_U32(r25.u32 + 52, ctx.r3.u32);
loc_824670BC:
	// lwz r11,52(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824672a0
	if (cr6.eq) goto loc_824672A0;
	// cmpwi cr6,r26,1
	cr6.compare<int32_t>(r26.s32, 1, xer);
	// bne cr6,0x824670f8
	if (!cr6.eq) goto loc_824670F8;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// addi r6,r11,-19060
	ctx.r6.s64 = r11.s64 + -19060;
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
loc_824670E0:
	// li r5,3009
	ctx.r5.s64 = 3009;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82467374
	goto loc_82467374;
loc_824670F8:
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// bne cr6,0x82467128
	if (!cr6.eq) goto loc_82467128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82467128
	if (!cr0.eq) goto loc_82467128;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// mr r9,r15
	ctx.r9.u64 = r15.u64;
	// addi r6,r11,-19108
	ctx.r6.s64 = r11.s64 + -19108;
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// b 0x824670e0
	goto loc_824670E0;
loc_82467128:
	// rlwinm. r28,r27,0,27,27
	r28.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// bne 0x8246716c
	if (!cr0.eq) goto loc_8246716C;
	// rlwinm. r11,r27,0,26,26
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8246716c
	if (cr0.eq) goto loc_8246716C;
	// rlwinm r11,r26,2,0,29
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,224
	ctx.r9.s64 = ctx.r1.s64 + 224;
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// lis r10,-32246
	ctx.r10.s64 = -2113273856;
	// li r5,3045
	ctx.r5.s64 = 3045;
	// addi r6,r10,-19148
	ctx.r6.s64 = ctx.r10.s64 + -19148;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r11,r8
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x824671fc
	goto loc_824671FC;
loc_8246716C:
	// andi. r29,r27,80
	r29.u64 = r27.u64 & 80;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x824671bc
	if (cr0.eq) goto loc_824671BC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,52(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82459bf0
	sub_82459BF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824671bc
	if (!cr0.eq) goto loc_824671BC;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,224
	ctx.r9.s64 = ctx.r1.s64 + 224;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3011
	ctx.r5.s64 = 3011;
	// addi r6,r11,-19188
	ctx.r6.s64 = r11.s64 + -19188;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x824671fc
	goto loc_824671FC;
loc_824671BC:
	// lwz r11,52(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// lwz r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82467204
	if (!cr0.eq) goto loc_82467204;
	// lwz r11,52(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r6,48(r25)
	ctx.r6.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x8245e998
	sub_8245E998(ctx, base);
loc_824671FC:
	// stw r18,52(r25)
	PPC_STORE_U32(r25.u32 + 52, r18.u32);
	// b 0x82467320
	goto loc_82467320;
loc_82467204:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8246721c
	if (cr6.eq) goto loc_8246721C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,52(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// bl 0x82460b10
	sub_82460B10(ctx, base);
	// stw r3,56(r25)
	PPC_STORE_U32(r25.u32 + 56, ctx.r3.u32);
loc_8246721C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82467254
	if (!cr6.eq) goto loc_82467254;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82467254
	if (cr0.eq) goto loc_82467254;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,52(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// bl 0x82460b10
	sub_82460B10(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467254
	if (cr0.eq) goto loc_82467254;
	// stw r3,52(r25)
	PPC_STORE_U32(r25.u32 + 52, ctx.r3.u32);
	// b 0x82467320
	goto loc_82467320;
loc_82467254:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82467264
	if (!cr6.eq) goto loc_82467264;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x824671fc
	if (!cr6.eq) goto loc_824671FC;
loc_82467264:
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// lwz r29,52(r25)
	r29.u64 = PPC_LOAD_U32(r25.u32 + 52);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r18,52(r25)
	PPC_STORE_U32(r25.u32 + 52, r18.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82462228
	sub_82462228(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r4,26
	ctx.r4.s64 = 26;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82462f30
	sub_82462F30(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// b 0x82467320
	goto loc_82467320;
loc_824672A0:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x824672b0
	if (cr6.eq) goto loc_824672B0;
	// cmpwi cr6,r26,9
	cr6.compare<int32_t>(r26.s32, 9, xer);
	// bne cr6,0x824672cc
	if (!cr6.eq) goto loc_824672CC;
loc_824672B0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824672cc
	if (cr0.eq) goto loc_824672CC;
	// rlwinm. r11,r27,0,30,30
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824672f8
	if (!cr0.eq) goto loc_824672F8;
loc_824672CC:
	// cmpwi cr6,r26,3
	cr6.compare<int32_t>(r26.s32, 3, xer);
	// beq cr6,0x824672dc
	if (cr6.eq) goto loc_824672DC;
	// cmpwi cr6,r26,4
	cr6.compare<int32_t>(r26.s32, 4, xer);
	// bne cr6,0x824672f0
	if (!cr6.eq) goto loc_824672F0;
loc_824672DC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,48(r25)
	ctx.r4.u64 = PPC_LOAD_U32(r25.u32 + 48);
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824672f8
	if (!cr0.eq) goto loc_824672F8;
loc_824672F0:
	// cmpwi cr6,r26,5
	cr6.compare<int32_t>(r26.s32, 5, xer);
	// bne cr6,0x82467320
	if (!cr6.eq) goto loc_82467320;
loc_824672F8:
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,224
	ctx.r9.s64 = ctx.r1.s64 + 224;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3012
	ctx.r5.s64 = 3012;
	// addi r6,r11,-19208
	ctx.r6.s64 = r11.s64 + -19208;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82467320:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x82467378
	if (cr6.eq) goto loc_82467378;
	// cmpwi cr6,r26,9
	cr6.compare<int32_t>(r26.s32, 9, xer);
	// beq cr6,0x82467378
	if (cr6.eq) goto loc_82467378;
	// cmpwi cr6,r26,1
	cr6.compare<int32_t>(r26.s32, 1, xer);
	// beq cr6,0x82467378
	if (cr6.eq) goto loc_82467378;
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// beq cr6,0x82467378
	if (cr6.eq) goto loc_82467378;
	// lwz r11,60(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82467378
	if (cr6.eq) goto loc_82467378;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3043
	ctx.r5.s64 = 3043;
	// addi r6,r11,-19240
	ctx.r6.s64 = r11.s64 + -19240;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82467374:
	// stw r18,52(r25)
	PPC_STORE_U32(r25.u32 + 52, r18.u32);
loc_82467378:
	// lwz r11,28(r14)
	r11.u64 = PPC_LOAD_U32(r14.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824673c8
	if (cr6.eq) goto loc_824673C8;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x824673c8
	if (cr6.eq) goto loc_824673C8;
	// cmpwi cr6,r26,9
	cr6.compare<int32_t>(r26.s32, 9, xer);
	// beq cr6,0x824673c8
	if (cr6.eq) goto loc_824673C8;
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// beq cr6,0x824673c8
	if (cr6.eq) goto loc_824673C8;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r9,r1,176
	ctx.r9.s64 = ctx.r1.s64 + 176;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3040
	ctx.r5.s64 = 3040;
	// addi r6,r11,-19276
	ctx.r6.s64 = r11.s64 + -19276;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// stw r18,28(r14)
	PPC_STORE_U32(r14.u32 + 28, r18.u32);
loc_824673C8:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = r14.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245af30
	sub_8245AF30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82467448
	if (cr0.lt) goto loc_82467448;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82467404
	if (cr6.eq) goto loc_82467404;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245a308
	sub_8245A308(ctx, base);
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r3.u32);
	// beq 0x82467448
	if (cr0.eq) goto loc_82467448;
loc_82467404:
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// b 0x8246744c
	goto loc_8246744C;
loc_8246740C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3059
	ctx.r5.s64 = 3059;
	// addi r6,r11,-21844
	ctx.r6.s64 = r11.s64 + -21844;
	// b 0x8246743c
	goto loc_8246743C;
loc_8246741C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3073
	ctx.r5.s64 = 3073;
	// addi r6,r11,-19328
	ctx.r6.s64 = r11.s64 + -19328;
	// b 0x82467438
	goto loc_82467438;
loc_8246742C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3058
	ctx.r5.s64 = 3058;
	// addi r6,r11,-21952
	ctx.r6.s64 = r11.s64 + -21952;
loc_82467438:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8246743C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82467448:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8246744C:
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_82467454"))) PPC_WEAK_FUNC(sub_82467454);
PPC_FUNC_IMPL(__imp__sub_82467454) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82467458"))) PPC_WEAK_FUNC(sub_82467458);
PPC_FUNC_IMPL(__imp__sub_82467458) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcd0
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r19,0
	r19.s64 = 0;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r18,r5
	r18.u64 = ctx.r5.u64;
	// mr r22,r6
	r22.u64 = ctx.r6.u64;
	// lwz r11,24(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 24);
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// stw r19,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r19.u32);
	// mr r28,r19
	r28.u64 = r19.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82467494
	if (cr0.eq) goto loc_82467494;
	// lwz r28,8(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 8);
loc_82467494:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x8240b568
	sub_8240B568(ctx, base);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82467818
	if (cr6.eq) goto loc_82467818;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x82467818
	if (cr6.eq) goto loc_82467818;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// addi r24,r18,16
	r24.s64 = r18.s64 + 16;
	// lwz r27,24(r28)
	r27.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824674dc
	if (cr0.eq) goto loc_824674DC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r5,3047
	ctx.r5.s64 = 3047;
	// addi r6,r11,-17932
	ctx.r6.s64 = r11.s64 + -17932;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_824674DC:
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82467504
	if (cr0.eq) goto loc_82467504;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r5,3006
	ctx.r5.s64 = 3006;
	// addi r6,r11,-17976
	ctx.r6.s64 = r11.s64 + -17976;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82467504:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245b548
	sub_8245B548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82467534
	if (!cr0.eq) goto loc_82467534;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r5,3038
	ctx.r5.s64 = 3038;
	// addi r6,r11,-18020
	ctx.r6.s64 = r11.s64 + -18020;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82467534:
	// mr r30,r19
	r30.u64 = r19.u64;
	// mr r31,r22
	r31.u64 = r22.u64;
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x824675c0
	if (cr6.eq) goto loc_824675C0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r29,r11,-18068
	r29.s64 = r11.s64 + -18068;
loc_8246754C:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x824675b4
	if (cr0.eq) goto loc_824675B4;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x824675b4
	if (!cr6.eq) goto loc_824675B4;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8246758c
	if (cr0.eq) goto loc_8246758C;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,12
	cr6.compare<int32_t>(ctx.r9.s32, 12, xer);
	// bne cr6,0x8246758c
	if (!cr6.eq) goto loc_8246758C;
	// li r30,1
	r30.s64 = 1;
	// mr r31,r11
	r31.u64 = r11.u64;
	// b 0x824675b4
	goto loc_824675B4;
loc_8246758C:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x824675b4
	if (cr6.eq) goto loc_824675B4;
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// li r5,3044
	ctx.r5.s64 = 3044;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_824675B4:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x8246754c
	if (!cr0.eq) goto loc_8246754C;
loc_824675C0:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824675ec
	if (cr0.eq) goto loc_824675EC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// b 0x824675f0
	goto loc_824675F0;
loc_824675EC:
	// mr r21,r19
	r21.u64 = r19.u64;
loc_824675F0:
	// cmplwi cr6,r21,0
	cr6.compare<uint32_t>(r21.u32, 0, xer);
	// beq cr6,0x82467818
	if (cr6.eq) goto loc_82467818;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467628
	if (cr0.eq) goto loc_82467628;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// b 0x8246762c
	goto loc_8246762C;
loc_82467628:
	// mr r23,r19
	r23.u64 = r19.u64;
loc_8246762C:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82467818
	if (cr6.eq) goto loc_82467818;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// stw r23,8(r21)
	PPC_STORE_U32(r21.u32 + 8, r23.u32);
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,20(r23)
	PPC_STORE_U32(r23.u32 + 20, ctx.r3.u32);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467668
	if (cr0.eq) goto loc_82467668;
	// bl 0x8240afc8
	sub_8240AFC8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246766c
	goto loc_8246766C;
loc_82467668:
	// mr r31,r19
	r31.u64 = r19.u64;
loc_8246766C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82467818
	if (cr6.eq) goto loc_82467818;
	// stw r31,24(r23)
	PPC_STORE_U32(r23.u32 + 24, r31.u32);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// lwz r3,20(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246769c
	if (cr0.eq) goto loc_8246769C;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
loc_8246769C:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x824676b8
	if (cr6.eq) goto loc_824676B8;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r3.u32);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
loc_824676B8:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x824676d4
	if (cr6.eq) goto loc_824676D4;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,68(r31)
	PPC_STORE_U32(r31.u32 + 68, ctx.r3.u32);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
loc_824676D4:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82467768
	if (cr6.eq) goto loc_82467768;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82467718
	if (!cr6.eq) goto loc_82467718;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r5,3076
	ctx.r5.s64 = 3076;
	// addi r6,r11,-18112
	ctx.r6.s64 = r11.s64 + -18112;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// mr r20,r19
	r20.u64 = r19.u64;
loc_82467718:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82467768
	if (cr6.eq) goto loc_82467768;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r3.u32);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
loc_82467734:
	// lwz r3,8(r20)
	ctx.r3.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246775c
	if (cr0.eq) goto loc_8246775C;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8246775c
	if (!cr6.eq) goto loc_8246775C;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,56(r31)
	PPC_STORE_U32(r31.u32 + 56, ctx.r3.u32);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
loc_8246775C:
	// lwz r20,12(r20)
	r20.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// cmplwi r20,0
	cr0.compare<uint32_t>(r20.u32, 0, xer);
	// bne 0x82467734
	if (!cr0.eq) goto loc_82467734;
loc_82467768:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82467790
	if (cr6.eq) goto loc_82467790;
	// lwz r11,8(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82467790
	if (cr6.eq) goto loc_82467790;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r3.u32);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
loc_82467790:
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lwz r6,36(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// addi r10,r1,132
	ctx.r10.s64 = ctx.r1.s64 + 132;
	// lwz r7,44(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r9,10
	ctx.r9.s64 = 10;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,20(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// lwz r8,32(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x82461280
	sub_82461280(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x824677d8
	if (!cr0.lt) goto loc_824677D8;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3003
	ctx.r5.s64 = 3003;
	// addi r6,r11,-23524
	ctx.r6.s64 = r11.s64 + -23524;
	// b 0x82467808
	goto loc_82467808;
loc_824677D8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lwz r25,132(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bne cr6,0x824678dc
	if (!cr6.eq) goto loc_824678DC;
	// lwz r5,40(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 40);
	// bl 0x82459548
	sub_82459548(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82467824
	if (!cr0.eq) goto loc_82467824;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3068
	ctx.r5.s64 = 3068;
	// addi r6,r11,-18164
	ctx.r6.s64 = r11.s64 + -18164;
loc_82467808:
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82467818:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8246781C:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// b 0x8239bd20
	return;
loc_82467824:
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,20(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,40(r23)
	PPC_STORE_U32(r23.u32 + 40, r11.u32);
	// lwz r30,44(r25)
	r30.u64 = PPC_LOAD_U32(r25.u32 + 44);
	// lwz r29,44(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// b 0x824678d0
	goto loc_824678D0;
loc_82467850:
	// lwz r27,8(r30)
	r27.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r27,0
	cr0.compare<uint32_t>(r27.u32, 0, xer);
	// beq 0x824678f8
	if (cr0.eq) goto loc_824678F8;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82467818
	if (cr6.eq) goto loc_82467818;
	// lwz r28,8(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi r28,0
	cr0.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
	// lwz r11,20(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r5,20(r26)
	ctx.r5.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// bl 0x82459368
	sub_82459368(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r8,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r8.u32);
	// stw r8,16(r9)
	PPC_STORE_U32(ctx.r9.u32 + 16, ctx.r8.u32);
	// lwz r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r8,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, ctx.r8.u32);
	// stw r8,24(r9)
	PPC_STORE_U32(ctx.r9.u32 + 24, ctx.r8.u32);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// stw r11,28(r10)
	PPC_STORE_U32(ctx.r10.u32 + 28, r11.u32);
	// stw r11,28(r9)
	PPC_STORE_U32(ctx.r9.u32 + 28, r11.u32);
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r29,12(r29)
	r29.u64 = PPC_LOAD_U32(r29.u32 + 12);
loc_824678D0:
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x82467850
	if (!cr0.eq) goto loc_82467850;
	// b 0x824678f8
	goto loc_824678F8;
loc_824678DC:
	// lwz r11,100(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 100);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// bl 0x8245b618
	sub_8245B618(ctx, base);
	// stw r3,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r3.u32);
	// lwz r11,100(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 100);
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// stw r11,100(r26)
	PPC_STORE_U32(r26.u32 + 100, r11.u32);
loc_824678F8:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r11.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r19,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r19.u32);
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r11.u32);
	// li r11,3
	r11.s64 = 3;
	// stw r11,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r11.u32);
	// lwz r3,40(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// stw r3,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r3.u32);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// stw r3,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r3.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r4,192(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82467944
	if (cr6.eq) goto loc_82467944;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82467818
	if (cr6.eq) goto loc_82467818;
loc_82467944:
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// beq cr6,0x82467954
	if (cr6.eq) goto loc_82467954;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82467818
	if (cr6.eq) goto loc_82467818;
loc_82467954:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245b390
	sub_8245B390(ctx, base);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// mr r4,r18
	ctx.r4.u64 = r18.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82462228
	sub_82462228(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,52(r31)
	PPC_STORE_U32(r31.u32 + 52, ctx.r3.u32);
	// beq 0x82467818
	if (cr0.eq) goto loc_82467818;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x824679b8
	if (!cr6.eq) goto loc_824679B8;
	// lwz r30,20(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,20(r26)
	PPC_STORE_U32(r26.u32 + 20, r11.u32);
	// bl 0x8245af30
	sub_8245AF30(ctx, base);
	// stw r30,20(r26)
	PPC_STORE_U32(r26.u32 + 20, r30.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82467818
	if (cr0.lt) goto loc_82467818;
	// lwz r11,96(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 96);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,96(r26)
	PPC_STORE_U32(r26.u32 + 96, r11.u32);
loc_824679B8:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// stw r11,20(r10)
	PPC_STORE_U32(ctx.r10.u32 + 20, r11.u32);
	// stw r31,32(r26)
	PPC_STORE_U32(r26.u32 + 32, r31.u32);
	// b 0x8246781c
	goto loc_8246781C;
}

__attribute__((alias("__imp__sub_824679D0"))) PPC_WEAK_FUNC(sub_824679D0);
PPC_FUNC_IMPL(__imp__sub_824679D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc0
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r14,0
	r14.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r16,r14
	r16.u64 = r14.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r17,r5
	r17.u64 = ctx.r5.u64;
	// mr r15,r6
	r15.u64 = ctx.r6.u64;
	// stw r14,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r14.u32);
	// stw r14,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r14.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r16,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r16.u32);
	// stw r14,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r14.u32);
	// stw r14,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r14.u32);
	// stw r14,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r14.u32);
	// beq cr6,0x82468014
	if (cr6.eq) goto loc_82468014;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82468014
	if (!cr6.eq) goto loc_82468014;
	// lwz r11,32(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 32);
	// addi r19,r29,16
	r19.s64 = r29.s64 + 16;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82467a38
	if (cr0.eq) goto loc_82467A38;
	// lwz r6,36(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// b 0x82467a3c
	goto loc_82467A3C;
loc_82467A38:
	// mr r6,r14
	ctx.r6.u64 = r14.u64;
loc_82467A3C:
	// li r9,6
	ctx.r9.s64 = 6;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x82467a4c
	if (cr6.eq) goto loc_82467A4C;
	// li r9,22
	ctx.r9.s64 = 22;
loc_82467A4C:
	// addi r11,r1,148
	r11.s64 = ctx.r1.s64 + 148;
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// addi r10,r1,152
	ctx.r10.s64 = ctx.r1.s64 + 152;
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r31,r14
	r31.u64 = r14.u64;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82467ffc
	if (cr0.lt) goto loc_82467FFC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82467a88
	if (!cr6.eq) goto loc_82467A88;
	// li r31,1
	r31.s64 = 1;
loc_82467A88:
	// lis r11,-32248
	r11.s64 = -2113404928;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// addi r30,r11,21984
	r30.s64 = r11.s64 + 21984;
	// bne cr6,0x82467adc
	if (!cr6.eq) goto loc_82467ADC;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x82467bc8
	if (!cr6.eq) goto loc_82467BC8;
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r8,r17
	ctx.r8.u64 = r17.u64;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,98
	ctx.r5.s64 = 98;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245d690
	sub_8245D690(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82467ffc
	if (cr0.lt) goto loc_82467FFC;
	// lwz r16,144(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82467ae4
	if (!cr6.eq) goto loc_82467AE4;
	// li r31,1
	r31.s64 = 1;
loc_82467ADC:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x82467b24
	if (!cr6.eq) goto loc_82467B24;
loc_82467AE4:
	// addi r11,r1,148
	r11.s64 = ctx.r1.s64 + 148;
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 20);
	// addi r10,r1,152
	ctx.r10.s64 = ctx.r1.s64 + 152;
	// li r9,2
	ctx.r9.s64 = 2;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82467ffc
	if (cr0.lt) goto loc_82467FFC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82467b24
	if (!cr6.eq) goto loc_82467B24;
	// li r31,1
	r31.s64 = 1;
loc_82467B24:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// bne cr6,0x82467b70
	if (!cr6.eq) goto loc_82467B70;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x82467bbc
	if (!cr6.eq) goto loc_82467BBC;
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r19
	ctx.r7.u64 = r19.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,98
	ctx.r5.s64 = 98;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245d690
	sub_8245D690(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82467ffc
	if (cr0.lt) goto loc_82467FFC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82467b78
	if (!cr6.eq) goto loc_82467B78;
	// lwz r16,144(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r31,1
	r31.s64 = 1;
loc_82467B70:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x82467bbc
	if (!cr6.eq) goto loc_82467BBC;
loc_82467B78:
	// addi r6,r1,164
	ctx.r6.s64 = ctx.r1.s64 + 164;
	// mr r5,r17
	ctx.r5.u64 = r17.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x824879b0
	sub_824879B0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82467ffc
	if (cr0.lt) goto loc_82467FFC;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8246800c
	if (cr6.eq) goto loc_8246800C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// li r5,3004
	ctx.r5.s64 = 3004;
	// addi r6,r11,-22104
	ctx.r6.s64 = r11.s64 + -22104;
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82467ffc
	goto loc_82467FFC;
loc_82467BBC:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// mr r18,r16
	r18.u64 = r16.u64;
	// bne cr6,0x82467bcc
	if (!cr6.eq) goto loc_82467BCC;
loc_82467BC8:
	// lwz r18,152(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
loc_82467BCC:
	// lwz r24,44(r18)
	r24.u64 = PPC_LOAD_U32(r18.u32 + 44);
	// addi r23,r1,156
	r23.s64 = ctx.r1.s64 + 156;
	// addi r22,r1,160
	r22.s64 = ctx.r1.s64 + 160;
	// mr r25,r17
	r25.u64 = r17.u64;
	// cmplwi r24,0
	cr0.compare<uint32_t>(r24.u32, 0, xer);
	// beq 0x82467e28
	if (cr0.eq) goto loc_82467E28;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r21,r11,-17764
	r21.s64 = r11.s64 + -17764;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r20,r11,-17772
	r20.s64 = r11.s64 + -17772;
loc_82467BF4:
	// lwz r11,12(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// lwz r27,8(r24)
	r27.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82467c20
	if (cr0.eq) goto loc_82467C20;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,12
	cr6.compare<int32_t>(ctx.r9.s32, 12, xer);
	// bne cr6,0x82467c20
	if (!cr6.eq) goto loc_82467C20;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r24,r11
	r24.u64 = r11.u64;
loc_82467C20:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x82467c38
	if (cr6.eq) goto loc_82467C38;
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82467e1c
	if (cr0.eq) goto loc_82467E1C;
loc_82467C38:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82467e14
	if (cr6.eq) goto loc_82467E14;
	// lwz r28,24(r27)
	r28.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r30,48(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 48);
	// beq 0x82467c5c
	if (cr0.eq) goto loc_82467C5C;
	// lwz r29,16(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// b 0x82467c60
	goto loc_82467C60;
loc_82467C5C:
	// mr r29,r14
	r29.u64 = r14.u64;
loc_82467C60:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467c84
	if (cr0.eq) goto loc_82467C84;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82467c88
	goto loc_82467C88;
loc_82467C84:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
loc_82467C88:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r23)
	PPC_STORE_U32(r23.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82467ffc
	if (cr6.eq) goto loc_82467FFC;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467cb8
	if (cr0.eq) goto loc_82467CB8;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82467cbc
	goto loc_82467CBC;
loc_82467CB8:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
loc_82467CBC:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r22)
	PPC_STORE_U32(r22.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82467ffc
	if (cr6.eq) goto loc_82467FFC;
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82467d64
	if (cr0.eq) goto loc_82467D64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// beq 0x82467e78
	if (cr0.eq) goto loc_82467E78;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,8(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x82467ffc
	if (cr0.eq) goto loc_82467FFC;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x82467d24
	if (cr6.eq) goto loc_82467D24;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// stw r31,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r31.u32);
	// b 0x82467d64
	goto loc_82467D64;
loc_82467D24:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r4,20(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82462228
	sub_82462228(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x82467ffc
	if (cr0.eq) goto loc_82467FFC;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82462f30
	sub_82462F30(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467ffc
	if (cr0.eq) goto loc_82467FFC;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
loc_82467D64:
	// lwz r11,44(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 44);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82467dfc
	if (cr0.eq) goto loc_82467DFC;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82467e84
	if (!cr0.eq) goto loc_82467E84;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82467e84
	if (cr0.eq) goto loc_82467E84;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r4,20(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82462228
	sub_82462228(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x82467ffc
	if (cr0.eq) goto loc_82467FFC;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// mr. r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x82467ffc
	if (cr0.eq) goto loc_82467FFC;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r5,8(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82462f30
	sub_82462F30(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467ffc
	if (cr0.eq) goto loc_82467FFC;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
loc_82467DFC:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// lwz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// lwz r25,12(r25)
	r25.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r23,r11,12
	r23.s64 = r11.s64 + 12;
	// addi r22,r10,12
	r22.s64 = ctx.r10.s64 + 12;
	// b 0x82467e1c
	goto loc_82467E1C;
loc_82467E14:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82467e30
	if (cr6.eq) goto loc_82467E30;
loc_82467E1C:
	// lwz r24,12(r24)
	r24.u64 = PPC_LOAD_U32(r24.u32 + 12);
	// cmplwi r24,0
	cr0.compare<uint32_t>(r24.u32, 0, xer);
	// bne 0x82467bf4
	if (!cr0.eq) goto loc_82467BF4;
loc_82467E28:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x82467f74
	if (!cr6.eq) goto loc_82467F74;
loc_82467E30:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x82467f74
	if (!cr6.eq) goto loc_82467F74;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467ea4
	if (cr0.eq) goto loc_82467EA4;
	// cntlzw r11,r16
	r11.u64 = r16.u32 == 0 ? 32 : __builtin_clz(r16.u32);
	// mr r9,r19
	ctx.r9.u64 = r19.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r8,1
	ctx.r8.s64 = 1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,31
	ctx.r5.s64 = r11.s64 + 31;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82467ea8
	goto loc_82467EA8;
loc_82467E78:
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// b 0x82467e90
	goto loc_82467E90;
loc_82467E84:
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82467E90:
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// lwz r5,8(r19)
	ctx.r5.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x8245e998
	sub_8245E998(ctx, base);
	// b 0x82467ffc
	goto loc_82467FFC;
loc_82467EA4:
	// mr r31,r14
	r31.u64 = r14.u64;
loc_82467EA8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82467ffc
	if (cr6.eq) goto loc_82467FFC;
	// lwz r11,40(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82467edc
	if (cr6.eq) goto loc_82467EDC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq 0x82467ffc
	if (cr0.eq) goto loc_82467FFC;
loc_82467EDC:
	// lwz r11,148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82467f10
	if (cr0.eq) goto loc_82467F10;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-17784
	ctx.r6.s64 = r11.s64 + -17784;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x82467f14
	goto loc_82467F14;
loc_82467F10:
	// mr r11,r14
	r11.u64 = r14.u64;
loc_82467F14:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// beq cr6,0x82467ffc
	if (cr6.eq) goto loc_82467FFC;
	// lwz r10,156(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82459bf0
	sub_82459BF0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82468000
	if (cr0.eq) goto loc_82468000;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82460b10
	sub_82460B10(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468000
	if (cr0.eq) goto loc_82468000;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82468000
	goto loc_82468000;
loc_82467F74:
	// mr r8,r14
	ctx.r8.u64 = r14.u64;
	// mr r11,r17
	r11.u64 = r17.u64;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x82467f94
	if (cr6.eq) goto loc_82467F94;
loc_82467F84:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82467f84
	if (!cr0.eq) goto loc_82467F84;
loc_82467F94:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// bne cr6,0x82467fc4
	if (!cr6.eq) goto loc_82467FC4;
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// beq cr6,0x82467fb0
	if (cr6.eq) goto loc_82467FB0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r9,r11,14436
	ctx.r9.s64 = r11.s64 + 14436;
	// b 0x82467fb8
	goto loc_82467FB8;
loc_82467FB0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r9,r11,9120
	ctx.r9.s64 = r11.s64 + 9120;
loc_82467FB8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17828
	ctx.r6.s64 = r11.s64 + -17828;
	// b 0x82467fe8
	goto loc_82467FE8;
loc_82467FC4:
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// beq cr6,0x82467fd8
	if (cr6.eq) goto loc_82467FD8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r9,r11,14436
	ctx.r9.s64 = r11.s64 + 14436;
	// b 0x82467fe0
	goto loc_82467FE0;
loc_82467FD8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r9,r11,9120
	ctx.r9.s64 = r11.s64 + 9120;
loc_82467FE0:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17884
	ctx.r6.s64 = r11.s64 + -17884;
loc_82467FE8:
	// li r5,3013
	ctx.r5.s64 = 3013;
	// lwz r7,8(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 8);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82467FFC:
	// mr r31,r14
	r31.u64 = r14.u64;
loc_82468000:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x82468018
	if (!cr6.eq) goto loc_82468018;
loc_8246800C:
	// lwz r3,164(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// b 0x82468018
	goto loc_82468018;
loc_82468014:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82468018:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x8239bd10
	return;
}

__attribute__((alias("__imp__sub_82468020"))) PPC_WEAK_FUNC(sub_82468020);
PPC_FUNC_IMPL(__imp__sub_82468020) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcc8
	// stwu r1,-560(r1)
	ea = -560 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r17,r4
	r17.u64 = ctx.r4.u64;
	// mr r18,r6
	r18.u64 = ctx.r6.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8246861c
	if (cr6.eq) goto loc_8246861C;
	// lwz r11,4(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x8246861c
	if (!cr6.eq) goto loc_8246861C;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// beq cr6,0x8246861c
	if (cr6.eq) goto loc_8246861C;
	// lwz r11,4(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 4);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x8246861c
	if (!cr6.eq) goto loc_8246861C;
	// lwz r29,16(r17)
	r29.u64 = PPC_LOAD_U32(r17.u32 + 16);
	// li r16,0
	r16.s64 = 0;
	// addi r21,r5,16
	r21.s64 = ctx.r5.s64 + 16;
	// mr r31,r16
	r31.u64 = r16.u64;
	// mr r30,r16
	r30.u64 = r16.u64;
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// stw r16,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r16.u32);
	// stw r16,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r16.u32);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// stw r16,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r16.u32);
	// stw r16,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r16.u32);
	// bgt cr6,0x82468128
	if (cr6.gt) goto loc_82468128;
	// beq cr6,0x82468114
	if (cr6.eq) goto loc_82468114;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// beq cr6,0x82468100
	if (cr6.eq) goto loc_82468100;
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// beq cr6,0x824680ec
	if (cr6.eq) goto loc_824680EC;
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// beq cr6,0x824680dc
	if (cr6.eq) goto loc_824680DC;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// beq cr6,0x824680cc
	if (cr6.eq) goto loc_824680CC;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82468190
	if (!cr6.eq) goto loc_82468190;
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,15048
	r31.s64 = r11.s64 + 15048;
	// b 0x824680f8
	goto loc_824680F8;
loc_824680CC:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,11856
	r31.s64 = r11.s64 + 11856;
	// b 0x824680f8
	goto loc_824680F8;
loc_824680DC:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,7752
	r31.s64 = r11.s64 + 7752;
	// b 0x8246810c
	goto loc_8246810C;
loc_824680EC:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,4560
	r31.s64 = r11.s64 + 4560;
loc_824680F8:
	// li r30,14
	r30.s64 = 14;
	// b 0x82468190
	goto loc_82468190;
loc_82468100:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,456
	r31.s64 = r11.s64 + 456;
loc_8246810C:
	// li r30,18
	r30.s64 = 18;
	// b 0x82468190
	goto loc_82468190;
loc_82468114:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// li r30,12
	r30.s64 = 12;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,18240
	r31.s64 = r11.s64 + 18240;
	// b 0x82468190
	goto loc_82468190;
loc_82468128:
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x82468180
	if (cr6.eq) goto loc_82468180;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// beq cr6,0x82468170
	if (cr6.eq) goto loc_82468170;
	// cmpwi cr6,r11,39
	cr6.compare<int32_t>(r11.s32, 39, xer);
	// beq cr6,0x8246815c
	if (cr6.eq) goto loc_8246815C;
	// addi r11,r11,-51
	r11.s64 = r11.s64 + -51;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bgt cr6,0x82468190
	if (cr6.gt) goto loc_82468190;
	// lis r11,-32247
	r11.s64 = -2113339392;
	// li r30,2
	r30.s64 = 2;
	// addi r31,r11,-21208
	r31.s64 = r11.s64 + -21208;
	// b 0x82468190
	goto loc_82468190;
loc_8246815C:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// li r30,1
	r30.s64 = 1;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,20976
	r31.s64 = r11.s64 + 20976;
	// b 0x82468190
	goto loc_82468190;
loc_82468170:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,22120
	r31.s64 = r11.s64 + 22120;
	// b 0x8246818c
	goto loc_8246818C;
loc_82468180:
	// lis r11,-32247
	r11.s64 = -2113339392;
	// addi r11,r11,-21208
	r11.s64 = r11.s64 + -21208;
	// addi r31,r11,21208
	r31.s64 = r11.s64 + 21208;
loc_8246818C:
	// li r30,4
	r30.s64 = 4;
loc_82468190:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// li r5,255
	ctx.r5.s64 = 255;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8245b700
	sub_8245B700(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bne cr6,0x824681c4
	if (!cr6.eq) goto loc_824681C4;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3087
	ctx.r5.s64 = 3087;
	// addi r6,r11,-17596
	ctx.r6.s64 = r11.s64 + -17596;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// b 0x82468250
	goto loc_82468250;
loc_824681C4:
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// lwz r6,24(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// mr r8,r18
	ctx.r8.u64 = r18.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245d690
	sub_8245D690(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8246861c
	if (cr0.lt) goto loc_8246861C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82468260
	if (cr6.eq) goto loc_82468260;
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// lwz r6,24(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8245d690
	sub_8245D690(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8246861c
	if (cr0.lt) goto loc_8246861C;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r5,3088
	ctx.r5.s64 = 3088;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bne cr6,0x82468248
	if (!cr6.eq) goto loc_82468248;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// addi r6,r11,-17652
	ctx.r6.s64 = r11.s64 + -17652;
	// b 0x82468258
	goto loc_82468258;
loc_82468248:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17688
	ctx.r6.s64 = r11.s64 + -17688;
loc_82468250:
	// lwz r8,8(r21)
	ctx.r8.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
loc_82468258:
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x8246861c
	goto loc_8246861C;
loc_82468260:
	// lwz r20,144(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// addi r25,r1,152
	r25.s64 = ctx.r1.s64 + 152;
	// addi r24,r1,156
	r24.s64 = ctx.r1.s64 + 156;
	// mr r28,r18
	r28.u64 = r18.u64;
	// lwz r26,44(r20)
	r26.u64 = PPC_LOAD_U32(r20.u32 + 44);
	// cmplwi r26,0
	cr0.compare<uint32_t>(r26.u32, 0, xer);
	// beq 0x82468454
	if (cr0.eq) goto loc_82468454;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r23,r11,-17764
	r23.s64 = r11.s64 + -17764;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r22,r11,-17772
	r22.s64 = r11.s64 + -17772;
loc_8246828C:
	// lwz r11,12(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r10,r16
	ctx.r10.u64 = r16.u64;
	// lwz r27,8(r26)
	r27.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824682b8
	if (cr0.eq) goto loc_824682B8;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,12
	cr6.compare<int32_t>(ctx.r9.s32, 12, xer);
	// bne cr6,0x824682b8
	if (!cr6.eq) goto loc_824682B8;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r26,r11
	r26.u64 = r11.u64;
loc_824682B8:
	// lwz r29,24(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82468440
	if (cr6.eq) goto loc_82468440;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r30,48(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824682dc
	if (cr0.eq) goto loc_824682DC;
	// lwz r31,16(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// b 0x824682e0
	goto loc_824682E0;
loc_824682DC:
	// mr r31,r16
	r31.u64 = r16.u64;
loc_824682E0:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468304
	if (cr0.eq) goto loc_82468304;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82468308
	goto loc_82468308;
loc_82468304:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
loc_82468308:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r25)
	PPC_STORE_U32(r25.u32 + 0, ctx.r3.u32);
	// beq cr6,0x8246861c
	if (cr6.eq) goto loc_8246861C;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468338
	if (cr0.eq) goto loc_82468338;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8246833c
	goto loc_8246833C;
loc_82468338:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
loc_8246833C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,0(r24)
	PPC_STORE_U32(r24.u32 + 0, ctx.r3.u32);
	// beq cr6,0x8246861c
	if (cr6.eq) goto loc_8246861C;
	// lwz r11,44(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82468390
	if (cr0.eq) goto loc_82468390;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// beq 0x82468498
	if (cr0.eq) goto loc_82468498;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,8(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
loc_82468390:
	// lwz r11,44(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82468428
	if (cr0.eq) goto loc_82468428;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8245b478
	sub_8245B478(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824684a4
	if (!cr0.eq) goto loc_824684A4;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8245e550
	sub_8245E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824684a4
	if (cr0.eq) goto loc_824684A4;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r4,20(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x82462228
	sub_82462228(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x8246861c
	if (cr0.eq) goto loc_8246861C;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x82462478
	sub_82462478(ctx, base);
	// mr. r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x8246861c
	if (cr0.eq) goto loc_8246861C;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,8(r28)
	ctx.r5.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r4,27
	ctx.r4.s64 = 27;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x82462f30
	sub_82462F30(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246861c
	if (cr0.eq) goto loc_8246861C;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
loc_82468428:
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// lwz r28,12(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// addi r25,r11,12
	r25.s64 = r11.s64 + 12;
	// addi r24,r10,12
	r24.s64 = ctx.r10.s64 + 12;
	// b 0x82468448
	goto loc_82468448;
loc_82468440:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8246845c
	if (cr6.eq) goto loc_8246845C;
loc_82468448:
	// lwz r26,12(r26)
	r26.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// cmplwi r26,0
	cr0.compare<uint32_t>(r26.u32, 0, xer);
	// bne 0x8246828c
	if (!cr0.eq) goto loc_8246828C;
loc_82468454:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x824685c4
	if (!cr6.eq) goto loc_824685C4;
loc_8246845C:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x824685c4
	if (!cr6.eq) goto loc_824685C4;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824684c4
	if (cr0.eq) goto loc_824684C4;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,33
	ctx.r5.s64 = 33;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x824684c8
	goto loc_824684C8;
loc_82468498:
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// b 0x824684b0
	goto loc_824684B0;
loc_824684A4:
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
loc_824684B0:
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// lwz r5,8(r21)
	ctx.r5.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// bl 0x8245e998
	sub_8245E998(ctx, base);
	// b 0x8246861c
	goto loc_8246861C;
loc_824684C4:
	// mr r30,r16
	r30.u64 = r16.u64;
loc_824684C8:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8246861c
	if (cr6.eq) goto loc_8246861C;
	// lwz r11,40(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824684fc
	if (cr6.eq) goto loc_824684FC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq 0x8246861c
	if (cr0.eq) goto loc_8246861C;
loc_824684FC:
	// lwz r11,0(r17)
	r11.u64 = PPC_LOAD_U32(r17.u32 + 0);
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq 0x8246861c
	if (cr0.eq) goto loc_8246861C;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468548
	if (cr0.eq) goto loc_82468548;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-17784
	ctx.r6.s64 = r11.s64 + -17784;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246854c
	goto loc_8246854C;
loc_82468548:
	// mr r31,r16
	r31.u64 = r16.u64;
loc_8246854C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8246861c
	if (cr6.eq) goto loc_8246861C;
	// lwz r11,152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// lwz r11,156(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468590
	if (cr0.eq) goto loc_82468590;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-17712
	ctx.r6.s64 = r11.s64 + -17712;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x82468594
	goto loc_82468594;
loc_82468590:
	// mr r11,r16
	r11.u64 = r16.u64;
loc_82468594:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r11.u32);
	// beq cr6,0x8246861c
	if (cr6.eq) goto loc_8246861C;
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// stw r31,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r31.u32);
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// b 0x82468620
	goto loc_82468620;
loc_824685C4:
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// mr r11,r18
	r11.u64 = r18.u64;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x824685ec
	if (cr6.eq) goto loc_824685EC;
loc_824685D4:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x824685d4
	if (!cr0.eq) goto loc_824685D4;
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// beq cr6,0x824685f8
	if (cr6.eq) goto loc_824685F8;
loc_824685EC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r9,r11,14436
	ctx.r9.s64 = r11.s64 + 14436;
	// b 0x82468600
	goto loc_82468600;
loc_824685F8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r9,r11,9120
	ctx.r9.s64 = r11.s64 + 9120;
loc_82468600:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r21)
	ctx.r7.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// li r5,3013
	ctx.r5.s64 = 3013;
	// addi r6,r11,-17756
	ctx.r6.s64 = r11.s64 + -17756;
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_8246861C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82468620:
	// addi r1,r1,560
	ctx.r1.s64 = ctx.r1.s64 + 560;
	// b 0x8239bd18
	return;
}

__attribute__((alias("__imp__sub_82468628"))) PPC_WEAK_FUNC(sub_82468628);
PPC_FUNC_IMPL(__imp__sub_82468628) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce4
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82468694
	if (cr6.eq) goto loc_82468694;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82468694
	if (cr6.eq) goto loc_82468694;
	// addi r24,r29,16
	r24.s64 = r29.s64 + 16;
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r3,8(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// bl 0x823dee80
	sub_823DEE80(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x824686a0
	if (!cr0.lt) goto loc_824686A0;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r24)
	ctx.r7.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// li r5,3041
	ctx.r5.s64 = 3041;
	// addi r6,r11,-17564
	ctx.r6.s64 = r11.s64 + -17564;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82468694:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82468698:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8239bd34
	return;
loc_824686A0:
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// rlwinm r11,r11,0,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF0000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824686d4
	if (cr6.eq) goto loc_824686D4;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824686e8
	if (!cr6.eq) goto loc_824686E8;
	// subfic r11,r31,0
	xer.ca = r31.u32 <= 0;
	r11.s64 = 0 - r31.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// addi r27,r11,42
	r27.s64 = r11.s64 + 42;
	// b 0x824686ec
	goto loc_824686EC;
loc_824686D4:
	// subfic r11,r31,0
	xer.ca = r31.u32 <= 0;
	r11.s64 = 0 - r31.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// addi r27,r11,43
	r27.s64 = r11.s64 + 43;
	// b 0x824686ec
	goto loc_824686EC;
loc_824686E8:
	// lwz r27,128(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_824686EC:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468720
	if (cr0.eq) goto loc_82468720;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,34
	ctx.r5.s64 = 34;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82468724
	goto loc_82468724;
loc_82468720:
	// li r30,0
	r30.s64 = 0;
loc_82468724:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82468694
	if (cr6.eq) goto loc_82468694;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246875c
	if (cr0.eq) goto loc_8246875C;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x82468760
	goto loc_82468760;
loc_8246875C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82468760:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r3.u32);
	// beq cr6,0x82468694
	if (cr6.eq) goto loc_82468694;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x824094f0
	sub_824094F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r30)
	PPC_STORE_U32(r30.u32 + 32, ctx.r3.u32);
	// beq 0x82468694
	if (cr0.eq) goto loc_82468694;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x824679d0
	sub_824679D0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r30)
	PPC_STORE_U32(r30.u32 + 36, ctx.r3.u32);
	// beq 0x82468694
	if (cr0.eq) goto loc_82468694;
	// li r3,80
	ctx.r3.s64 = 80;
	// stw r25,44(r30)
	PPC_STORE_U32(r30.u32 + 44, r25.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824687d8
	if (cr0.eq) goto loc_824687D8;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x824687dc
	goto loc_824687DC;
loc_824687D8:
	// li r31,0
	r31.s64 = 0;
loc_824687DC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82468694
	if (cr6.eq) goto loc_82468694;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468814
	if (cr0.eq) goto loc_82468814;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x82468818
	goto loc_82468818;
loc_82468814:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82468818:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x82468694
	if (cr6.eq) goto loc_82468694;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246884c
	if (cr0.eq) goto loc_8246884C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82468850
	goto loc_82468850;
loc_8246884C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82468850:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq cr6,0x82468694
	if (cr6.eq) goto loc_82468694;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468880
	if (cr0.eq) goto loc_82468880;
	// mr r6,r24
	ctx.r6.u64 = r24.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x82468884
	goto loc_82468884;
loc_82468880:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82468884:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r3.u32);
	// beq cr6,0x82468694
	if (cr6.eq) goto loc_82468694;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82468698
	goto loc_82468698;
}

__attribute__((alias("__imp__sub_824688A8"))) PPC_WEAK_FUNC(sub_824688A8);
PPC_FUNC_IMPL(__imp__sub_824688A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824688EC"))) PPC_WEAK_FUNC(sub_824688EC);
PPC_FUNC_IMPL(__imp__sub_824688EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_824688F0"))) PPC_WEAK_FUNC(sub_824688F0);
PPC_FUNC_IMPL(__imp__sub_824688F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcf8
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r28.u32);
	// b 0x82468938
	goto loc_82468938;
loc_82468918:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x82468944
	if (cr6.eq) goto loc_82468944;
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beq cr6,0x82468944
	if (cr6.eq) goto loc_82468944;
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// beq cr6,0x82468944
	if (cr6.eq) goto loc_82468944;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
loc_82468938:
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82468918
	if (!cr0.eq) goto loc_82468918;
	// b 0x82468948
	goto loc_82468948;
loc_82468944:
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
loc_82468948:
	// clrlwi. r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824689b0
	if (!cr0.eq) goto loc_824689B0;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x82468974
	if (cr6.eq) goto loc_82468974;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3064
	ctx.r5.s64 = 3064;
	// addi r6,r11,-17480
	ctx.r6.s64 = r11.s64 + -17480;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x82468abc
	goto loc_82468ABC;
loc_82468974:
	// lis r12,26
	r12.s64 = 1703936;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r11,-32185
	r11.s64 = -2109276160;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// ori r12,r12,3
	r12.u64 = r12.u64 | 3;
	// stw r28,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r28.u32);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r7,r11,-30552
	ctx.r7.s64 = r11.s64 + -30552;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// and r4,r10,r12
	ctx.r4.u64 = ctx.r10.u64 & r12.u64;
	// bl 0x82418bc0
	sub_82418BC0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82468abc
	if (cr0.lt) goto loc_82468ABC;
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// b 0x82468af4
	goto loc_82468AF4;
loc_824689B0:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x823ed818
	sub_823ED818(ctx, base);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x82468a60
	if (!cr6.eq) goto loc_82468A60;
	// lis r12,26
	r12.s64 = 1703936;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// ori r12,r12,3
	r12.u64 = r12.u64 | 3;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// li r6,0
	ctx.r6.s64 = 0;
	// and r5,r11,r12
	ctx.r5.u64 = r11.u64 & r12.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x823f2870
	sub_823F2870(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82468ab4
	if (cr0.lt) goto loc_82468AB4;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x82409368
	sub_82409368(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x82468ab4
	if (cr0.eq) goto loc_82468AB4;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8239ce50
	sub_8239CE50(ctx, base);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82468a80
	if (cr6.eq) goto loc_82468A80;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r28.u32);
	// b 0x82468a80
	goto loc_82468A80;
loc_82468A60:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3201
	ctx.r5.s64 = 3201;
	// addi r6,r11,-17528
	ctx.r6.s64 = r11.s64 + -17528;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245ab70
	sub_8245AB70(ctx, base);
	// mr r30,r28
	r30.u64 = r28.u64;
	// mr r29,r28
	r29.u64 = r28.u64;
loc_82468A80:
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468aa8
	if (cr0.eq) goto loc_82468AA8;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r31,40
	ctx.r4.s64 = r31.s64 + 40;
	// bl 0x8240c9f0
	sub_8240C9F0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82468aac
	goto loc_82468AAC;
loc_82468AA8:
	// mr r30,r28
	r30.u64 = r28.u64;
loc_82468AAC:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82468ae8
	if (!cr6.eq) goto loc_82468AE8;
loc_82468AB4:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x823f0538
	sub_823F0538(ctx, base);
loc_82468ABC:
	// li r11,1
	r11.s64 = 1;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// beq cr6,0x82468ae0
	if (cr6.eq) goto loc_82468AE0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82468AE0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82468af4
	goto loc_82468AF4;
loc_82468AE8:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x823f0538
	sub_823F0538(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_82468AF4:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x8239bd48
	return;
}

__attribute__((alias("__imp__sub_82468AFC"))) PPC_WEAK_FUNC(sub_82468AFC);
PPC_FUNC_IMPL(__imp__sub_82468AFC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82468B00"))) PPC_WEAK_FUNC(sub_82468B00);
PPC_FUNC_IMPL(__imp__sub_82468B00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r25,0
	r25.s64 = 0;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r31,r25
	r31.u64 = r25.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// li r26,1
	r26.s64 = 1;
	// cmplwi cr6,r30,16
	cr6.compare<uint32_t>(r30.u32, 16, xer);
	// stw r31,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r31.u32);
	// ble cr6,0x82468b34
	if (!cr6.gt) goto loc_82468B34;
	// stw r26,72(r27)
	PPC_STORE_U32(r27.u32 + 72, r26.u32);
loc_82468B34:
	// lwz r11,72(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82469228
	if (!cr6.eq) goto loc_82469228;
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// subfic r9,r30,16
	xer.ca = r30.u32 <= 16;
	ctx.r9.s64 = 16 - r30.s64;
	// add r29,r11,r10
	r29.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// mtctr r30
	ctr.u64 = r30.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82468ba4
	if (cr6.eq) goto loc_82468BA4;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_82468B70:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82468bd4
	if (cr0.eq) goto loc_82468BD4;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r9,8(r27)
	PPC_STORE_U32(r27.u32 + 8, ctx.r9.u32);
	// stw r25,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r25.u32);
	// lwz r9,12(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// stw r9,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r9.u32);
	// stw r11,12(r27)
	PPC_STORE_U32(r27.u32 + 12, r11.u32);
	// bdnz 0x82468b70
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82468B70;
loc_82468BA4:
	// cmplwi cr6,r28,439
	cr6.compare<uint32_t>(r28.u32, 439, xer);
	// bgt cr6,0x8246af60
	if (cr6.gt) goto loc_8246AF60;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-25960
	r12.s64 = r12.s64 + -25960;
	// rlwinm r0,r28,1,0,30
	r0.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32185
	r12.s64 = -2109276160;
	// addi r12,r12,-29740
	r12.s64 = r12.s64 + -29740;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r28.u64) {
	case 0:
		goto loc_82468BF0;
	case 1:
		goto loc_82468C3C;
	case 2:
		goto loc_82468EC0;
	case 3:
		goto loc_82468C94;
	case 4:
		goto loc_82469A2C;
	case 5:
		goto loc_82468EC0;
	case 6:
		goto loc_82468EC0;
	case 7:
		goto loc_82468EC0;
	case 8:
		goto loc_82468EC0;
	case 9:
		goto loc_82468EC0;
	case 10:
		goto loc_82468EC0;
	case 11:
		goto loc_82468EC0;
	case 12:
		goto loc_82468EC0;
	case 13:
		goto loc_82468EC0;
	case 14:
		goto loc_82468CB0;
	case 15:
		goto loc_82468CD8;
	case 16:
		goto loc_82468D18;
	case 17:
		goto loc_82469C80;
	case 18:
		goto loc_82468D08;
	case 19:
		goto loc_82468D30;
	case 20:
		goto loc_82468D64;
	case 21:
		goto loc_82468EC0;
	case 22:
		goto loc_82468D98;
	case 23:
		goto loc_8246AF60;
	case 24:
		goto loc_82468E0C;
	case 25:
		goto loc_82468E28;
	case 26:
		goto loc_82468E54;
	case 27:
		goto loc_82468E74;
	case 28:
		goto loc_82468EA4;
	case 29:
		goto loc_8246AF60;
	case 30:
		goto loc_82468E0C;
	case 31:
		goto loc_82468E28;
	case 32:
		goto loc_82468E54;
	case 33:
		goto loc_82468EC0;
	case 34:
		goto loc_82468EB0;
	case 35:
		goto loc_82469A2C;
	case 36:
		goto loc_82468EC0;
	case 37:
		goto loc_82468EC8;
	case 38:
		goto loc_82468EF0;
	case 39:
		goto loc_82468F08;
	case 40:
		goto loc_82468F20;
	case 41:
		goto loc_82468F38;
	case 42:
		goto loc_82468F50;
	case 43:
		goto loc_82468F68;
	case 44:
		goto loc_82468F80;
	case 45:
		goto loc_82468F98;
	case 46:
		goto loc_82468FB0;
	case 47:
		goto loc_82468EC0;
	case 48:
		goto loc_82468FC8;
	case 49:
		goto loc_8246AF60;
	case 50:
		goto loc_8246AF60;
	case 51:
		goto loc_8246AF60;
	case 52:
		goto loc_82468EC0;
	case 53:
		goto loc_82468EB0;
	case 54:
		goto loc_82468FF0;
	case 55:
		goto loc_82469008;
	case 56:
		goto loc_82469020;
	case 57:
		goto loc_82469038;
	case 58:
		goto loc_82469090;
	case 59:
		goto loc_8246AF60;
	case 60:
		goto loc_8246AF60;
	case 61:
		goto loc_824690A8;
	case 62:
		goto loc_824690D8;
	case 63:
		goto loc_82469108;
	case 64:
		goto loc_8246911C;
	case 65:
		goto loc_82468EC0;
	case 66:
		goto loc_82469158;
	case 67:
		goto loc_82469180;
	case 68:
		goto loc_82468EC0;
	case 69:
		goto loc_82468EC0;
	case 70:
		goto loc_824691C8;
	case 71:
		goto loc_82469230;
	case 72:
		goto loc_824692A0;
	case 73:
		goto loc_824692D0;
	case 74:
		goto loc_82469300;
	case 75:
		goto loc_82468EC0;
	case 76:
		goto loc_82469330;
	case 77:
		goto loc_82468EC0;
	case 78:
		goto loc_82469344;
	case 79:
		goto loc_82469A2C;
	case 80:
		goto loc_82468EC0;
	case 81:
		goto loc_82468EC0;
	case 82:
		goto loc_82468EC0;
	case 83:
		goto loc_82468EC0;
	case 84:
		goto loc_82469358;
	case 85:
		goto loc_82469388;
	case 86:
		goto loc_824693A0;
	case 87:
		goto loc_824693B8;
	case 88:
		goto loc_824693D0;
	case 89:
		goto loc_824693E8;
	case 90:
		goto loc_824693E8;
	case 91:
		goto loc_82469400;
	case 92:
		goto loc_82469418;
	case 93:
		goto loc_82469430;
	case 94:
		goto loc_82469450;
	case 95:
		goto loc_82469464;
	case 96:
		goto loc_82469488;
	case 97:
		goto loc_824694A0;
	case 98:
		goto loc_824694C8;
	case 99:
		goto loc_82469508;
	case 100:
		goto loc_82469568;
	case 101:
		goto loc_824695C8;
	case 102:
		goto loc_82469628;
	case 103:
		goto loc_82469688;
	case 104:
		goto loc_824696E8;
	case 105:
		goto loc_82469748;
	case 106:
		goto loc_82469760;
	case 107:
		goto loc_82469778;
	case 108:
		goto loc_82469790;
	case 109:
		goto loc_824697A8;
	case 110:
		goto loc_824697C0;
	case 111:
		goto loc_82469808;
	case 112:
		goto loc_82469838;
	case 113:
		goto loc_82469868;
	case 114:
		goto loc_82469898;
	case 115:
		goto loc_824698C8;
	case 116:
		goto loc_824698E0;
	case 117:
		goto loc_82469910;
	case 118:
		goto loc_82469928;
	case 119:
		goto loc_82469970;
	case 120:
		goto loc_824699D0;
	case 121:
		goto loc_824699E8;
	case 122:
		goto loc_82469A54;
	case 123:
		goto loc_824697D8;
	case 124:
		goto loc_824697F0;
	case 125:
		goto loc_82469940;
	case 126:
		goto loc_82469AA8;
	case 127:
		goto loc_82469A90;
	case 128:
		goto loc_82469AC0;
	case 129:
		goto loc_824698F8;
	case 130:
		goto loc_82469AD8;
	case 131:
		goto loc_82469AF4;
	case 132:
		goto loc_82469B10;
	case 133:
		goto loc_82469B2C;
	case 134:
		goto loc_82469B44;
	case 135:
		goto loc_8246AF60;
	case 136:
		goto loc_8246AF60;
	case 137:
		goto loc_8246AF60;
	case 138:
		goto loc_82469A2C;
	case 139:
		goto loc_82469100;
	case 140:
		goto loc_82469B5C;
	case 141:
		goto loc_82469B70;
	case 142:
		goto loc_82468EC0;
	case 143:
		goto loc_82469B78;
	case 144:
		goto loc_82469B88;
	case 145:
		goto loc_82468EC0;
	case 146:
		goto loc_82468C94;
	case 147:
		goto loc_82469B98;
	case 148:
		goto loc_82469C00;
	case 149:
		goto loc_82469C7C;
	case 150:
		goto loc_82469C8C;
	case 151:
		goto loc_82469C8C;
	case 152:
		goto loc_82469C8C;
	case 153:
		goto loc_82469C8C;
	case 154:
		goto loc_82468EC0;
	case 155:
		goto loc_82469CA8;
	case 156:
		goto loc_82469A2C;
	case 157:
		goto loc_82468EC0;
	case 158:
		goto loc_82469CB8;
	case 159:
		goto loc_82469CE0;
	case 160:
		goto loc_82469D08;
	case 161:
		goto loc_82469D24;
	case 162:
		goto loc_82469D40;
	case 163:
		goto loc_82469D58;
	case 164:
		goto loc_82469D70;
	case 165:
		goto loc_82469D94;
	case 166:
		goto loc_82469A2C;
	case 167:
		goto loc_82469100;
	case 168:
		goto loc_82469A2C;
	case 169:
		goto loc_82468EC0;
	case 170:
		goto loc_82469DDC;
	case 171:
		goto loc_82468EC0;
	case 172:
		goto loc_82468C94;
	case 173:
		goto loc_82469C7C;
	case 174:
		goto loc_82469DE4;
	case 175:
		goto loc_82468EC0;
	case 176:
		goto loc_82468C94;
	case 177:
		goto loc_82468EC0;
	case 178:
		goto loc_82468EC0;
	case 179:
		goto loc_82468EC0;
	case 180:
		goto loc_82468EC0;
	case 181:
		goto loc_82468EC0;
	case 182:
		goto loc_82469A2C;
	case 183:
		goto loc_82468EC0;
	case 184:
		goto loc_82469E28;
	case 185:
		goto loc_82469E48;
	case 186:
		goto loc_82468EC0;
	case 187:
		goto loc_82468C94;
	case 188:
		goto loc_82469E60;
	case 189:
		goto loc_82468EC0;
	case 190:
		goto loc_82469E7C;
	case 191:
		goto loc_82469E98;
	case 192:
		goto loc_82468EC0;
	case 193:
		goto loc_82468C94;
	case 194:
		goto loc_82469EB4;
	case 195:
		goto loc_82469EC8;
	case 196:
		goto loc_82469EDC;
	case 197:
		goto loc_8246A02C;
	case 198:
		goto loc_82469F00;
	case 199:
		goto loc_8246A080;
	case 200:
		goto loc_8246A0AC;
	case 201:
		goto loc_82469A2C;
	case 202:
		goto loc_82469A2C;
	case 203:
		goto loc_82469100;
	case 204:
		goto loc_8246A0C0;
	case 205:
		goto loc_82469A2C;
	case 206:
		goto loc_82468EC0;
	case 207:
		goto loc_82468C94;
	case 208:
		goto loc_82469E28;
	case 209:
		goto loc_8246A0CC;
	case 210:
		goto loc_8246A0E4;
	case 211:
		goto loc_8246AF60;
	case 212:
		goto loc_8246AF60;
	case 213:
		goto loc_82468EC0;
	case 214:
		goto loc_82468EB0;
	case 215:
		goto loc_8246A118;
	case 216:
		goto loc_8246A168;
	case 217:
		goto loc_8246A1BC;
	case 218:
		goto loc_8246A1D4;
	case 219:
		goto loc_8246A1EC;
	case 220:
		goto loc_8246A204;
	case 221:
		goto loc_8246A21C;
	case 222:
		goto loc_8246A234;
	case 223:
		goto loc_8246A24C;
	case 224:
		goto loc_8246A264;
	case 225:
		goto loc_8246A280;
	case 226:
		goto loc_82468F68;
	case 227:
		goto loc_82468F80;
	case 228:
		goto loc_82468F98;
	case 229:
		goto loc_82468FB0;
	case 230:
		goto loc_82468EC0;
	case 231:
		goto loc_8246A298;
	case 232:
		goto loc_8246A340;
	case 233:
		goto loc_82469A2C;
	case 234:
		goto loc_82469100;
	case 235:
		goto loc_8246A418;
	case 236:
		goto loc_82469C7C;
	case 237:
		goto loc_82468EC0;
	case 238:
		goto loc_82468C94;
	case 239:
		goto loc_8246A42C;
	case 240:
		goto loc_82469A2C;
	case 241:
		goto loc_82469100;
	case 242:
		goto loc_8246A4AC;
	case 243:
		goto loc_8246A4C8;
	case 244:
		goto loc_82468EC0;
	case 245:
		goto loc_82468C94;
	case 246:
		goto loc_8246A51C;
	case 247:
		goto loc_8246AF60;
	case 248:
		goto loc_8246A4F4;
	case 249:
		goto loc_8246A504;
	case 250:
		goto loc_82469A2C;
	case 251:
		goto loc_82468EC0;
	case 252:
		goto loc_824691F8;
	case 253:
		goto loc_824691F8;
	case 254:
		goto loc_82469A2C;
	case 255:
		goto loc_82469100;
	case 256:
		goto loc_8246A5AC;
	case 257:
		goto loc_82469C7C;
	case 258:
		goto loc_82468EC0;
	case 259:
		goto loc_82468C94;
	case 260:
		goto loc_82469A2C;
	case 261:
		goto loc_8246A5B4;
	case 262:
		goto loc_8246A5C8;
	case 263:
		goto loc_8246A5D8;
	case 264:
		goto loc_8246A5E0;
	case 265:
		goto loc_8246A600;
	case 266:
		goto loc_8246A61C;
	case 267:
		goto loc_82468EC0;
	case 268:
		goto loc_82468EC0;
	case 269:
		goto loc_82468EC0;
	case 270:
		goto loc_8246A628;
	case 271:
		goto loc_8246A634;
	case 272:
		goto loc_8246A640;
	case 273:
		goto loc_82468EC0;
	case 274:
		goto loc_8246A64C;
	case 275:
		goto loc_8246A66C;
	case 276:
		goto loc_8246A6A0;
	case 277:
		goto loc_8246A6BC;
	case 278:
		goto loc_8246A6DC;
	case 279:
		goto loc_82468EC0;
	case 280:
		goto loc_8246A64C;
	case 281:
		goto loc_8246A66C;
	case 282:
		goto loc_8246A6F4;
	case 283:
		goto loc_8246A710;
	case 284:
		goto loc_8246A718;
	case 285:
		goto loc_8246A6A0;
	case 286:
		goto loc_8246A6BC;
	case 287:
		goto loc_8246A730;
	case 288:
		goto loc_8246A764;
	case 289:
		goto loc_8246A778;
	case 290:
		goto loc_8246A780;
	case 291:
		goto loc_8246A790;
	case 292:
		goto loc_8246A7A0;
	case 293:
		goto loc_8246A7BC;
	case 294:
		goto loc_8246A7D8;
	case 295:
		goto loc_8246A824;
	case 296:
		goto loc_82468EC0;
	case 297:
		goto loc_82468C94;
	case 298:
		goto loc_8246A838;
	case 299:
		goto loc_82469A2C;
	case 300:
		goto loc_8246A5B4;
	case 301:
		goto loc_82468EC0;
	case 302:
		goto loc_82469A2C;
	case 303:
		goto loc_82468EC0;
	case 304:
		goto loc_82469A2C;
	case 305:
		goto loc_82468EC0;
	case 306:
		goto loc_8246A840;
	case 307:
		goto loc_8246A85C;
	case 308:
		goto loc_82468EC0;
	case 309:
		goto loc_82468EC0;
	case 310:
		goto loc_82468EC0;
	case 311:
		goto loc_82468EC0;
	case 312:
		goto loc_82468EC0;
	case 313:
		goto loc_8246A878;
	case 314:
		goto loc_8246A938;
	case 315:
		goto loc_8246AA2C;
	case 316:
		goto loc_8246AA2C;
	case 317:
		goto loc_8246AA3C;
	case 318:
		goto loc_8246AA4C;
	case 319:
		goto loc_8246AA60;
	case 320:
		goto loc_82468EC0;
	case 321:
		goto loc_8246AA70;
	case 322:
		goto loc_8246AA70;
	case 323:
		goto loc_8246AA8C;
	case 324:
		goto loc_8246AAA4;
	case 325:
		goto loc_8246AAB8;
	case 326:
		goto loc_8246AAF8;
	case 327:
		goto loc_82468EC0;
	case 328:
		goto loc_82469A2C;
	case 329:
		goto loc_8246AB2C;
	case 330:
		goto loc_8246AB3C;
	case 331:
		goto loc_8246AB3C;
	case 332:
		goto loc_8246AB44;
	case 333:
		goto loc_8246AB74;
	case 334:
		goto loc_8246AB94;
	case 335:
		goto loc_8246ABAC;
	case 336:
		goto loc_8246ABD4;
	case 337:
		goto loc_8246ABDC;
	case 338:
		goto loc_82468EC0;
	case 339:
		goto loc_82468EC0;
	case 340:
		goto loc_82468EC0;
	case 341:
		goto loc_8246ABEC;
	case 342:
		goto loc_8246AC00;
	case 343:
		goto loc_8246AC14;
	case 344:
		goto loc_8246AC34;
	case 345:
		goto loc_8246AC3C;
	case 346:
		goto loc_82468EC0;
	case 347:
		goto loc_8246AC54;
	case 348:
		goto loc_8246AC5C;
	case 349:
		goto loc_8246AC64;
	case 350:
		goto loc_8246AC6C;
	case 351:
		goto loc_8246AC74;
	case 352:
		goto loc_8246AC7C;
	case 353:
		goto loc_82468EC0;
	case 354:
		goto loc_8246AC84;
	case 355:
		goto loc_82468EC0;
	case 356:
		goto loc_8246AC8C;
	case 357:
		goto loc_8246AC98;
	case 358:
		goto loc_8246ACA4;
	case 359:
		goto loc_82468EC0;
	case 360:
		goto loc_8246ACB0;
	case 361:
		goto loc_8246ACBC;
	case 362:
		goto loc_82468EC0;
	case 363:
		goto loc_8246ACC8;
	case 364:
		goto loc_8246ACD4;
	case 365:
		goto loc_82468EC0;
	case 366:
		goto loc_8246ACE0;
	case 367:
		goto loc_8246ACEC;
	case 368:
		goto loc_8246ACF8;
	case 369:
		goto loc_8246AD04;
	case 370:
		goto loc_82468EC0;
	case 371:
		goto loc_8246AD10;
	case 372:
		goto loc_8246AD1C;
	case 373:
		goto loc_82468EC0;
	case 374:
		goto loc_8246AD28;
	case 375:
		goto loc_82468EC0;
	case 376:
		goto loc_8246AD34;
	case 377:
		goto loc_82468EC0;
	case 378:
		goto loc_8246AD40;
	case 379:
		goto loc_82468EC0;
	case 380:
		goto loc_8246AD4C;
	case 381:
		goto loc_82468EC0;
	case 382:
		goto loc_8246AD58;
	case 383:
		goto loc_82468EC0;
	case 384:
		goto loc_8246AD7C;
	case 385:
		goto loc_8246AD88;
	case 386:
		goto loc_8246AD94;
	case 387:
		goto loc_8246ADA0;
	case 388:
		goto loc_8246ADAC;
	case 389:
		goto loc_8246ADB8;
	case 390:
		goto loc_8246ADC4;
	case 391:
		goto loc_8246ADD0;
	case 392:
		goto loc_8246ADDC;
	case 393:
		goto loc_8246ADE8;
	case 394:
		goto loc_8246ADF4;
	case 395:
		goto loc_82468EC0;
	case 396:
		goto loc_8246AD64;
	case 397:
		goto loc_8246AE00;
	case 398:
		goto loc_8246AE1C;
	case 399:
		goto loc_82469A2C;
	case 400:
		goto loc_82468EC0;
	case 401:
		goto loc_8246AE38;
	case 402:
		goto loc_82468EC0;
	case 403:
		goto loc_82468EC0;
	case 404:
		goto loc_82468EC0;
	case 405:
		goto loc_82468C94;
	case 406:
		goto loc_82468EC0;
	case 407:
		goto loc_82468EC0;
	case 408:
		goto loc_8246AE54;
	case 409:
		goto loc_82468EC0;
	case 410:
		goto loc_8246AEA8;
	case 411:
		goto loc_82468EC0;
	case 412:
		goto loc_8246AEC0;
	case 413:
		goto loc_82468EC0;
	case 414:
		goto loc_8246AED8;
	case 415:
		goto loc_82468EC0;
	case 416:
		goto loc_8246AEEC;
	case 417:
		goto loc_8246AEEC;
	case 418:
		goto loc_8246AEEC;
	case 419:
		goto loc_8246AEEC;
	case 420:
		goto loc_8246AF08;
	case 421:
		goto loc_8246AF08;
	case 422:
		goto loc_82469A2C;
	case 423:
		goto loc_82468EC0;
	case 424:
		goto loc_82468EC0;
	case 425:
		goto loc_8246AEEC;
	case 426:
		goto loc_8246AEEC;
	case 427:
		goto loc_8246AEEC;
	case 428:
		goto loc_8246AEEC;
	case 429:
		goto loc_8246AEEC;
	case 430:
		goto loc_8246AEEC;
	case 431:
		goto loc_8246AEEC;
	case 432:
		goto loc_82468EC0;
	case 433:
		goto loc_8246AF1C;
	case 434:
		goto loc_8246AEEC;
	case 435:
		goto loc_8246AEEC;
	case 436:
		goto loc_8246AEEC;
	case 437:
		goto loc_8246AF30;
	case 438:
		goto loc_8246AF48;
	case 439:
		goto loc_8246AF58;
	default:
		__builtin_unreachable();
	}
loc_82468BD4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,13028
	ctx.r6.s64 = r11.s64 + 13028;
loc_82468BDC:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
	// b 0x82469228
	goto loc_82469228;
loc_82468BF0:
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409b58
	sub_82409B58(ctx, base);
loc_82468C20:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82468c2c
	goto loc_82468C2C;
loc_82468C28:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82468C2C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_82468C30:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468C3C:
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r9,108(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// lwz r8,104(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 104);
	// lwz r7,100(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 100);
	// lwz r6,96(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 96);
	// lwz r5,92(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 92);
	// lwz r4,88(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + 88);
	// bl 0x82409b58
	sub_82409B58(ctx, base);
loc_82468C6C:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82468c78
	goto loc_82468C78;
loc_82468C74:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82468C78:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
loc_82468C88:
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
loc_82468C8C:
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468C94:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_82468C98:
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82409510
	sub_82409510(ctx, base);
loc_82468CA0:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_82468CA4:
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
loc_82468CA8:
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468CB0:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b240
	sub_8245B240(ctx, base);
loc_82468CC4:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// b 0x82468c8c
	goto loc_82468C8C;
loc_82468CD8:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245b240
	sub_8245B240(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
loc_82468D00:
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468D08:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r31,28(r27)
	PPC_STORE_U32(r27.u32 + 28, r31.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468D18:
	// lwz r11,28(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 28);
	// li r4,9
	ctx.r4.s64 = 9;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
loc_82468D24:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245acc8
	sub_8245ACC8(ctx, base);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468D30:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r4,7
	ctx.r4.s64 = 7;
loc_82468D38:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// bl 0x8245b118
	sub_8245B118(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
loc_82468D5C:
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r25.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468D64:
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r8,188(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245b118
	sub_8245B118(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// stw r25,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r25.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468D98:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468dc4
	if (cr0.eq) goto loc_82468DC4;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240a968
	sub_8240A968(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82468dc8
	goto loc_82468DC8;
loc_82468DC4:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82468DC8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468dec
	if (cr0.eq) goto loc_82468DEC;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// stw r31,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r31.u32);
	// b 0x82468df0
	goto loc_82468DF0;
loc_82468DEC:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_82468DF0:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82468c8c
	if (cr6.eq) goto loc_82468C8C;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e360
	sub_8245E360(ctx, base);
	// b 0x82469100
	goto loc_82469100;
loc_82468E0C:
	// lwz r11,16(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 16);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r10,16(r27)
	PPC_STORE_U32(r27.u32 + 16, ctx.r10.u32);
loc_82468E20:
	// stw r25,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r25.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468E28:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x824594e8
	sub_824594E8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x82468e44
	if (cr0.eq) goto loc_82468E44;
loc_82468E40:
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
loc_82468E44:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245b300
	sub_8245B300(ctx, base);
	// b 0x824691f8
	goto loc_824691F8;
loc_82468E54:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x824594e8
	sub_824594E8(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x82468e44
	if (cr0.eq) goto loc_82468E44;
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x82468e40
	goto loc_82468E40;
loc_82468E74:
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r4,8
	ctx.r4.s64 = 8;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245b118
	sub_8245B118(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// b 0x82468d00
	goto loc_82468D00;
loc_82468EA4:
	// lwz r8,188(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x82468d38
	goto loc_82468D38;
loc_82468EB0:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245e360
	sub_8245E360(ctx, base);
loc_82468EC0:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x82468c8c
	goto loc_82468C8C;
loc_82468EC8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,2
	ctx.r4.s64 = 2;
loc_82468EDC:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// bl 0x8240a968
	sub_8240A968(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_82468EF0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,64
	ctx.r4.s64 = 64;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468F08:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468F20:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468F38:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,256
	ctx.r4.s64 = 256;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468F50:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468F68:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lis r4,2
	ctx.r4.s64 = 131072;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468F80:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lis r4,4
	ctx.r4.s64 = 262144;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468F98:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lis r4,8
	ctx.r4.s64 = 524288;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468FB0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lis r4,16
	ctx.r4.s64 = 1048576;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82468FC8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240a968
	sub_8240A968(ctx, base);
	// b 0x82468c6c
	goto loc_82468C6C;
loc_82468FF0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,512
	ctx.r4.s64 = 512;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82469008:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,1024
	ctx.r4.s64 = 1024;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82469020:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,2048
	ctx.r4.s64 = 2048;
	// b 0x82468edc
	goto loc_82468EDC;
loc_82469038:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82469064
	if (cr0.eq) goto loc_82469064;
	// li r4,0
	ctx.r4.s64 = 0;
loc_8246904C:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,0
	ctx.r7.s64 = 0;
	// bl 0x8240a968
	sub_8240A968(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82469068
	goto loc_82469068;
loc_82469064:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82469068:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82469080
	if (cr0.eq) goto loc_82469080;
loc_8246907C:
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
loc_82469080:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82460a58
	sub_82460A58(ctx, base);
	// b 0x824691f8
	goto loc_824691F8;
loc_82469090:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r11,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, r11.u32);
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x8246907c
	goto loc_8246907C;
loc_824690A8:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x8240a968
	sub_8240A968(ctx, base);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82460a58
	sub_82460A58(ctx, base);
	// b 0x82468ec0
	goto loc_82468EC0;
loc_824690D8:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, r11.u32);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82460a58
	sub_82460A58(ctx, base);
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r25.u32);
loc_82469100:
	// lwz r31,180(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// b 0x82468ca8
	goto loc_82468CA8;
loc_82469108:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82461d08
	sub_82461D08(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246911C:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x82461d08
	sub_82461D08(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82409510
	sub_82409510(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82468c8c
	goto loc_82468C8C;
loc_82469158:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-16536
	ctx.r6.s64 = r11.s64 + -16536;
loc_82469170:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82468c6c
	goto loc_82468C6C;
loc_82469180:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691ac
	if (cr0.eq) goto loc_824691AC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-16536
	ctx.r6.s64 = r11.s64 + -16536;
loc_82469198:
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82409578
	sub_82409578(ctx, base);
loc_824691A4:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x824691b0
	goto loc_824691B0;
loc_824691AC:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_824691B0:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// b 0x82468ca4
	goto loc_82468CA4;
loc_824691C8:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82461280
	sub_82461280(ctx, base);
loc_824691F4:
	// lwz r31,128(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_824691F8:
	// lwz r11,76(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 76);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82469228
	if (!cr6.eq) goto loc_82469228;
	// lwz r3,12(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 12);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246af7c
	if (cr0.eq) goto loc_8246AF7C;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r11,12(r27)
	PPC_STORE_U32(r27.u32 + 12, r11.u32);
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r31.u32);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
loc_82469224:
	// stw r3,8(r27)
	PPC_STORE_U32(r27.u32 + 8, ctx.r3.u32);
loc_82469228:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x8239bd3c
	return;
loc_82469230:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824691f4
	if (!cr0.eq) goto loc_824691F4;
	// lwz r31,128(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x824691f8
	if (cr6.eq) goto loc_824691F8;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x824691f8
	if (cr6.eq) goto loc_824691F8;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,3005
	ctx.r5.s64 = 3005;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-16556
	ctx.r6.s64 = r11.s64 + -16556;
	// lwz r7,8(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x824691f8
	goto loc_824691F8;
loc_824692A0:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,32
	ctx.r9.s64 = 32;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// b 0x824691f4
	goto loc_824691F4;
loc_824692D0:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,128
	ctx.r9.s64 = 128;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// b 0x824691f4
	goto loc_824691F4;
loc_82469300:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,64
	ctx.r9.s64 = 64;
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,16
	ctx.r5.s64 = r11.s64 + 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82461280
	sub_82461280(ctx, base);
	// b 0x824691f4
	goto loc_824691F4;
loc_82469330:
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_82469338:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245e270
	sub_8245E270(ctx, base);
	// b 0x82469100
	goto loc_82469100;
loc_82469344:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82462150
	sub_82462150(ctx, base);
	// b 0x82468c6c
	goto loc_82468C6C;
loc_82469358:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,0
	ctx.r5.s64 = 0;
loc_8246936C:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
loc_82469374:
	// li r7,1
	ctx.r7.s64 = 1;
loc_82469378:
	// li r6,0
	ctx.r6.s64 = 0;
loc_8246937C:
	// li r9,0
	ctx.r9.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_82469388:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,5
	ctx.r5.s64 = 5;
	// b 0x8246936c
	goto loc_8246936C;
loc_824693A0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,11
	ctx.r5.s64 = 11;
	// b 0x8246936c
	goto loc_8246936C;
loc_824693B8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,12
	ctx.r5.s64 = 12;
	// b 0x8246936c
	goto loc_8246936C;
loc_824693D0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,13
	ctx.r5.s64 = 13;
	// b 0x8246936c
	goto loc_8246936C;
loc_824693E8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,9
	ctx.r5.s64 = 9;
	// b 0x8246936c
	goto loc_8246936C;
loc_82469400:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,16
	ctx.r5.s64 = 16;
	// b 0x8246936c
	goto loc_8246936C;
loc_82469418:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,20
	ctx.r5.s64 = 20;
	// b 0x8246936c
	goto loc_8246936C;
loc_82469430:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82469374
	goto loc_82469374;
loc_82469450:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82461fb8
	sub_82461FB8(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_82469464:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,4
	ctx.r7.s64 = 4;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x82469378
	goto loc_82469378;
loc_82469488:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82462070
	sub_82462070(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_824694A0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,23
	ctx.r5.s64 = 23;
loc_824694B4:
	// li r6,0
	ctx.r6.s64 = 0;
loc_824694B8:
	// li r7,1
	ctx.r7.s64 = 1;
loc_824694BC:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x8246937c
	goto loc_8246937C;
loc_824694C8:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824694ec
	if (!cr0.eq) goto loc_824694EC;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,24
	ctx.r5.s64 = 24;
	// b 0x824694b4
	goto loc_824694B4;
loc_824694EC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-16604
	ctx.r6.s64 = r11.s64 + -16604;
loc_824694F4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_824694F8:
	// addi r4,r27,40
	ctx.r4.s64 = r27.s64 + 40;
	// li r5,3086
	ctx.r5.s64 = 3086;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
	// b 0x824691f8
	goto loc_824691F8;
loc_82469508:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246953c
	if (cr0.eq) goto loc_8246953C;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82469540
	goto loc_82469540;
loc_8246953C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82469540:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_82469560:
	// li r5,25
	ctx.r5.s64 = 25;
	// b 0x824694b8
	goto loc_824694B8;
loc_82469568:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246959c
	if (cr0.eq) goto loc_8246959C;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x824695a0
	goto loc_824695A0;
loc_8246959C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_824695A0:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_824695C0:
	// li r5,26
	ctx.r5.s64 = 26;
	// b 0x824694b8
	goto loc_824694B8;
loc_824695C8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824695fc
	if (cr0.eq) goto loc_824695FC;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82469600
	goto loc_82469600;
loc_824695FC:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82469600:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_82469620:
	// li r5,27
	ctx.r5.s64 = 27;
	// b 0x824694b8
	goto loc_824694B8;
loc_82469628:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246965c
	if (cr0.eq) goto loc_8246965C;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82469660
	goto loc_82469660;
loc_8246965C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82469660:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_82469680:
	// li r5,28
	ctx.r5.s64 = 28;
	// b 0x824694b8
	goto loc_824694B8;
loc_82469688:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824696bc
	if (cr0.eq) goto loc_824696BC;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x824696c0
	goto loc_824696C0;
loc_824696BC:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_824696C0:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_824696E0:
	// li r5,29
	ctx.r5.s64 = 29;
	// b 0x824694b8
	goto loc_824694B8;
loc_824696E8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246971c
	if (cr0.eq) goto loc_8246971C;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82469720
	goto loc_82469720;
loc_8246971C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82469720:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_82469740:
	// li r5,30
	ctx.r5.s64 = 30;
	// b 0x824694b8
	goto loc_824694B8;
loc_82469748:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x82469560
	goto loc_82469560;
loc_82469760:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x824695c0
	goto loc_824695C0;
loc_82469778:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x82469620
	goto loc_82469620;
loc_82469790:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x82469680
	goto loc_82469680;
loc_824697A8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x824696e0
	goto loc_824696E0;
loc_824697C0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x82469740
	goto loc_82469740;
loc_824697D8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,33
	ctx.r5.s64 = 33;
	// b 0x824694b4
	goto loc_824694B4;
loc_824697F0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,38
	ctx.r5.s64 = 38;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469808:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246982c
	if (!cr0.eq) goto loc_8246982C;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,34
	ctx.r5.s64 = 34;
	// b 0x824694b4
	goto loc_824694B4;
loc_8246982C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-16688
	ctx.r6.s64 = r11.s64 + -16688;
	// b 0x824694f4
	goto loc_824694F4;
loc_82469838:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246985c
	if (!cr0.eq) goto loc_8246985C;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,35
	ctx.r5.s64 = 35;
	// b 0x824694b4
	goto loc_824694B4;
loc_8246985C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-16776
	ctx.r6.s64 = r11.s64 + -16776;
	// b 0x824694f4
	goto loc_824694F4;
loc_82469868:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246988c
	if (!cr0.eq) goto loc_8246988C;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,36
	ctx.r5.s64 = 36;
	// b 0x824694b4
	goto loc_824694B4;
loc_8246988C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-16864
	ctx.r6.s64 = r11.s64 + -16864;
	// b 0x824694f4
	goto loc_824694F4;
loc_82469898:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824698bc
	if (!cr0.eq) goto loc_824698BC;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,37
	ctx.r5.s64 = 37;
	// b 0x824694b4
	goto loc_824694B4;
loc_824698BC:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-16952
	ctx.r6.s64 = r11.s64 + -16952;
	// b 0x824694f4
	goto loc_824694F4;
loc_824698C8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,42
	ctx.r5.s64 = 42;
	// b 0x824694b4
	goto loc_824694B4;
loc_824698E0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,43
	ctx.r5.s64 = 43;
	// b 0x824694b4
	goto loc_824694B4;
loc_824698F8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,44
	ctx.r5.s64 = 44;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469910:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,45
	ctx.r5.s64 = 45;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469928:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,46
	ctx.r5.s64 = 46;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469940:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82469964
	if (!cr0.eq) goto loc_82469964;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,47
	ctx.r5.s64 = 47;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469964:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17012
	ctx.r6.s64 = r11.s64 + -17012;
	// b 0x824694f4
	goto loc_824694F4;
loc_82469970:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824699a4
	if (cr0.eq) goto loc_824699A4;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x824699a8
	goto loc_824699A8;
loc_824699A4:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_824699A8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
loc_824699C8:
	// li r5,39
	ctx.r5.s64 = 39;
	// b 0x824694b8
	goto loc_824694B8;
loc_824699D0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x824699c8
	goto loc_824699C8;
loc_824699E8:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r25,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r25.u32);
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82469a34
	if (!cr0.lt) goto loc_82469A34;
loc_82469A04:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// addi r4,r11,48
	ctx.r4.s64 = r11.s64 + 48;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82469a18
	if (!cr6.eq) goto loc_82469A18;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_82469A18:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3020
	ctx.r5.s64 = 3020;
	// addi r6,r11,-17040
	ctx.r6.s64 = r11.s64 + -17040;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_82469A2C:
	// mr r31,r25
	r31.u64 = r25.u64;
	// b 0x824691f8
	goto loc_824691F8;
loc_82469A34:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r7,128(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r5,31
	ctx.r5.s64 = 31;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x824694bc
	goto loc_824694BC;
loc_82469A54:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r25,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r25.u32);
	// bl 0x82460cb0
	sub_82460CB0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82469a04
	if (cr0.lt) goto loc_82469A04;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r7,128(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// li r5,32
	ctx.r5.s64 = 32;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x824694bc
	goto loc_824694BC;
loc_82469A90:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,48
	ctx.r5.s64 = 48;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469AA8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,49
	ctx.r5.s64 = 49;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469AC0:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,50
	ctx.r5.s64 = 50;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469AD8:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,51
	ctx.r5.s64 = 51;
	// b 0x824694b8
	goto loc_824694B8;
loc_82469AF4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,52
	ctx.r5.s64 = 52;
	// b 0x824694b8
	goto loc_824694B8;
loc_82469B10:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,53
	ctx.r5.s64 = 53;
	// b 0x824694b8
	goto loc_824694B8;
loc_82469B2C:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,40
	ctx.r5.s64 = 40;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469B44:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r5,41
	ctx.r5.s64 = 41;
	// b 0x824694b4
	goto loc_824694B4;
loc_82469B5C:
	// li r4,0
	ctx.r4.s64 = 0;
loc_82469B60:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82461f40
	sub_82461F40(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_82469B70:
	// lwz r4,184(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// b 0x82469b60
	goto loc_82469B60;
loc_82469B78:
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// b 0x82469338
	goto loc_82469338;
loc_82469B88:
	// li r4,1
	ctx.r4.s64 = 1;
loc_82469B8C:
	// li r5,0
	ctx.r5.s64 = 0;
loc_82469B90:
	// mr r31,r25
	r31.u64 = r25.u64;
	// b 0x82468d24
	goto loc_82468D24;
loc_82469B98:
	// lwz r31,180(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r30,r31
	r30.u64 = r31.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82468ca8
	if (cr6.eq) goto loc_82468CA8;
loc_82469BA8:
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x82469bf0
	if (!cr6.eq) goto loc_82469BF0;
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r10,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r10.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r4,72(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82469100
	if (cr0.eq) goto loc_82469100;
loc_82469BF0:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x82469ba8
	if (!cr0.eq) goto loc_82469BA8;
	// b 0x82469100
	goto loc_82469100;
loc_82469C00:
	// lwz r3,180(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82469c68
	if (cr6.eq) goto loc_82469C68;
loc_82469C10:
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x82469c58
	if (!cr6.eq) goto loc_82469C58;
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r10,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r10.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r4,72(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82469c64
	if (cr0.eq) goto loc_82469C64;
loc_82469C58:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// bne 0x82469c10
	if (!cr0.eq) goto loc_82469C10;
loc_82469C64:
	// lwz r3,180(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_82469C68:
	// lwz r4,184(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// bl 0x82409510
	sub_82409510(ctx, base);
loc_82469C70:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_82469C74:
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x82468d00
	goto loc_82468D00;
loc_82469C7C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82469C80:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ae40
	sub_8245AE40(ctx, base);
	// b 0x824691f8
	goto loc_824691F8;
loc_82469C8C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17052
	ctx.r6.s64 = r11.s64 + -17052;
	// b 0x82469170
	goto loc_82469170;
loc_82469CA8:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82409510
	sub_82409510(ctx, base);
	// b 0x824691a4
	goto loc_824691A4;
loc_82469CB8:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
loc_82469CD0:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8240cbb8
	sub_8240CBB8(ctx, base);
	// b 0x82468c6c
	goto loc_82468C6C;
loc_82469CE0:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691ac
	if (cr0.eq) goto loc_824691AC;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
loc_82469CF8:
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// bl 0x8240cbb8
	sub_8240CBB8(ctx, base);
	// b 0x824691a4
	goto loc_824691A4;
loc_82469D08:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82469D1C:
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82469cd0
	goto loc_82469CD0;
loc_82469D24:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691ac
	if (cr0.eq) goto loc_824691AC;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82469D38:
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82469cf8
	goto loc_82469CF8;
loc_82469D40:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// b 0x82469d1c
	goto loc_82469D1C;
loc_82469D58:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691ac
	if (cr0.eq) goto loc_824691AC;
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// b 0x82469d38
	goto loc_82469D38;
loc_82469D70:
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x8240ce18
	sub_8240CE18(ctx, base);
	// b 0x82468c6c
	goto loc_82468C6C;
loc_82469D94:
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82469dbc
	if (cr0.eq) goto loc_82469DBC;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8240ce18
	sub_8240CE18(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82469dc0
	goto loc_82469DC0;
loc_82469DBC:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82469DC0:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_82469DC4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// b 0x82469c74
	goto loc_82469C74;
loc_82469DDC:
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x82469b8c
	goto loc_82469B8C;
loc_82469DE4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245fe58
	sub_8245FE58(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_82469E28:
	// lwz r31,180(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_82469E2C:
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
loc_82469E30:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r10,24(r27)
	PPC_STORE_U32(r27.u32 + 24, ctx.r10.u32);
	// b 0x82468e20
	goto loc_82468E20;
loc_82469E48:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r3,176(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82409510
	sub_82409510(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// b 0x82469e2c
	goto loc_82469E2C;
loc_82469E60:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r7,188(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82466680
	sub_82466680(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_82469E7C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17064
	ctx.r6.s64 = r11.s64 + -17064;
	// b 0x82469170
	goto loc_82469170;
loc_82469E98:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691ac
	if (cr0.eq) goto loc_824691AC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17064
	ctx.r6.s64 = r11.s64 + -17064;
	// b 0x82469198
	goto loc_82469198;
loc_82469EB4:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82459f58
	sub_82459F58(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_82469EC8:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82459f58
	sub_82459F58(ctx, base);
	// b 0x82468cc4
	goto loc_82468CC4;
loc_82469EDC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82459f58
	sub_82459F58(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// b 0x82468ca4
	goto loc_82468CA4;
loc_82469F00:
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8246a02c
	if (cr6.eq) goto loc_8246A02C;
	// lwz r29,8(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x8246a02c
	if (cr0.eq) goto loc_8246A02C;
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r3,52
	ctx.r3.s64 = 52;
	// lwz r30,24(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// stw r11,28(r29)
	PPC_STORE_U32(r29.u32 + 28, r11.u32);
	// lwz r11,184(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// stw r26,76(r30)
	PPC_STORE_U32(r30.u32 + 76, r26.u32);
	// stw r11,48(r30)
	PPC_STORE_U32(r30.u32 + 48, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82469f4c
	if (cr0.eq) goto loc_82469F4C;
	// bl 0x8240bb40
	sub_8240BB40(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82469f50
	goto loc_82469F50;
loc_82469F4C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_82469F50:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// stw r3,64(r30)
	PPC_STORE_U32(r30.u32 + 64, ctx.r3.u32);
	// beq cr6,0x82469fc4
	if (cr6.eq) goto loc_82469FC4;
	// stw r26,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r26.u32);
	// li r3,80
	ctx.r3.s64 = 80;
	// lwz r11,108(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// lwz r11,108(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 108);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,108(r27)
	PPC_STORE_U32(r27.u32 + 108, r11.u32);
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82469fb4
	if (cr0.eq) goto loc_82469FB4;
	// addi r9,r27,40
	ctx.r9.s64 = r27.s64 + 40;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82469fb8
	goto loc_82469FB8;
loc_82469FB4:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_82469FB8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// stw r3,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r3.u32);
loc_82469FC4:
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r5,20(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// addi r4,r11,16
	ctx.r4.s64 = r11.s64 + 16;
	// b 0x8246a024
	goto loc_8246A024;
loc_82469FDC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82459368
	sub_82459368(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x8246a020
	if (cr0.eq) goto loc_8246A020;
loc_82469FEC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8246a014
	if (cr0.eq) goto loc_8246A014;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x8246a014
	if (!cr6.eq) goto loc_8246A014;
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// lwz r10,40(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8246a044
	if (cr6.eq) goto loc_8246A044;
loc_8246A014:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// bne 0x82469fec
	if (!cr0.eq) goto loc_82469FEC;
loc_8246A020:
	// lwz r5,32(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 32);
loc_8246A024:
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne 0x82469fdc
	if (!cr0.eq) goto loc_82469FDC;
loc_8246A02C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// bl 0x8245ae40
	sub_8245AE40(ctx, base);
	// stw r25,32(r27)
	PPC_STORE_U32(r27.u32 + 32, r25.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246A044:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r11,76(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 76);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246a070
	if (cr6.eq) goto loc_8246A070;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r7,8(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// li r5,3069
	ctx.r5.s64 = 3069;
	// addi r6,r11,-17088
	ctx.r6.s64 = r11.s64 + -17088;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245aaf8
	sub_8245AAF8(ctx, base);
loc_8246A070:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r26,76(r11)
	PPC_STORE_U32(r11.u32 + 76, r26.u32);
	// b 0x8246a02c
	goto loc_8246A02C;
loc_8246A080:
	// lwz r7,188(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_8246A090:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82467458
	sub_82467458(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// b 0x82469e30
	goto loc_82469E30;
loc_8246A0AC:
	// lwz r7,192(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x8246a090
	goto loc_8246A090;
loc_8246A0C0:
	// lwz r5,36(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 36);
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x82469b90
	goto loc_82469B90;
loc_8246A0CC:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82469064
	if (cr0.eq) goto loc_82469064;
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x8246904c
	goto loc_8246904C;
loc_8246A0E4:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r11,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, r11.u32);
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm. r11,r11,0,25,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x70;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82469080
	if (!cr0.eq) goto loc_82469080;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// ori r11,r11,16
	r11.u64 = r11.u64 | 16;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// b 0x82469080
	goto loc_82469080;
loc_8246A118:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a144
	if (cr0.eq) goto loc_8246A144;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240a968
	sub_8240A968(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a148
	goto loc_8246A148;
loc_8246A144:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A148:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// b 0x82468c8c
	goto loc_82468C8C;
loc_8246A168:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a194
	if (cr0.eq) goto loc_8246A194;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240a968
	sub_8240A968(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a198
	goto loc_8246A198;
loc_8246A194:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A198:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468eb0
	if (cr0.eq) goto loc_82468EB0;
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// stw r31,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r31.u32);
	// b 0x82468eb0
	goto loc_82468EB0;
loc_8246A1BC:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A1D4:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,32
	ctx.r4.s64 = 32;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A1EC:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,48
	ctx.r4.s64 = 48;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A204:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,80
	ctx.r4.s64 = 80;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A21C:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A234:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,8192
	ctx.r4.s64 = 8192;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A24C:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,16384
	ctx.r4.s64 = 16384;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A264:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lis r4,0
	ctx.r4.s64 = 0;
	// ori r4,r4,32768
	ctx.r4.u64 = ctx.r4.u64 | 32768;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A280:
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lis r4,1
	ctx.r4.s64 = 65536;
	// b 0x82468edc
	goto loc_82468EDC;
loc_8246A298:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a2c4
	if (cr0.eq) goto loc_8246A2C4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a2c8
	goto loc_8246A2C8;
loc_8246A2C4:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A2C8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a330
	if (cr0.eq) goto loc_8246A330;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a30c
	if (cr0.eq) goto loc_8246A30C;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x8246a310
	goto loc_8246A310;
loc_8246A30C:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_8246A310:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r4,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r4.u32);
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a330
	if (cr0.eq) goto loc_8246A330;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
loc_8246A330:
	// lwz r11,88(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 88);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,88(r27)
	PPC_STORE_U32(r27.u32 + 88, r11.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246A340:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a36c
	if (cr0.eq) goto loc_8246A36C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a370
	goto loc_8246A370;
loc_8246A36C:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A370:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a408
	if (cr0.eq) goto loc_8246A408;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a3b4
	if (cr0.eq) goto loc_8246A3B4;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x8246a3b8
	goto loc_8246A3B8;
loc_8246A3B4:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_8246A3B8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r4,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r4.u32);
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a408
	if (cr0.eq) goto loc_8246A408;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,20(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8246a408
	if (cr6.eq) goto loc_8246A408;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245af30
	sub_8245AF30(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8246a408
	if (!cr0.lt) goto loc_8246A408;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
loc_8246A408:
	// lwz r11,92(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 92);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,92(r27)
	PPC_STORE_U32(r27.u32 + 92, r11.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246A418:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245acc8
	sub_8245ACC8(ctx, base);
	// b 0x82469a2c
	goto loc_82469A2C;
loc_8246A42C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a458
	if (cr0.eq) goto loc_8246A458;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-17096
	ctx.r6.s64 = r11.s64 + -17096;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a45c
	goto loc_8246A45C;
loc_8246A458:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A45C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a4a0
	if (cr0.eq) goto loc_8246A4A0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r7,180(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,5
	ctx.r4.s64 = 5;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8240a050
	sub_8240A050(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x8246a4a4
	goto loc_8246A4A4;
loc_8246A4A0:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_8246A4A4:
	// stw r4,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r4.u32);
	// b 0x82469dc4
	goto loc_82469DC4;
loc_8246A4AC:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245acc8
	sub_8245ACC8(ctx, base);
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A4C0:
	// stw r25,80(r27)
	PPC_STORE_U32(r27.u32 + 80, r25.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246A4C8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r26,80(r27)
	PPC_STORE_U32(r27.u32 + 80, r26.u32);
	// mr r31,r25
	r31.u64 = r25.u64;
	// bl 0x8245ae40
	sub_8245AE40(ctx, base);
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x824691f8
	if (!cr6.eq) goto loc_824691F8;
	// b 0x8246a4c0
	goto loc_8246A4C0;
loc_8246A4F4:
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x824878b8
	sub_824878B8(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246A504:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8246a51c
	if (cr0.eq) goto loc_8246A51C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17156
	ctx.r6.s64 = r11.s64 + -17156;
	// b 0x824694f4
	goto loc_824694F4;
loc_8246A51C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a548
	if (cr0.eq) goto loc_8246A548;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22876
	ctx.r6.s64 = r11.s64 + -22876;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a54c
	goto loc_8246A54C;
loc_8246A548:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A54C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a588
	if (cr0.eq) goto loc_8246A588;
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8240c7b8
	sub_8240C7B8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x8246a58c
	goto loc_8246A58C;
loc_8246A588:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
loc_8246A58C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r4,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r4.u32);
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// b 0x82468d5c
	goto loc_82468D5C;
loc_8246A5AC:
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x82469b8c
	goto loc_82469B8C;
loc_8246A5B4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245a308
	sub_8245A308(ctx, base);
loc_8246A5C0:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x824691f8
	goto loc_824691F8;
loc_8246A5C8:
	// li r4,0
	ctx.r4.s64 = 0;
loc_8246A5CC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x824637e0
	sub_824637E0(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A5D8:
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x8246a5cc
	goto loc_8246A5CC;
loc_8246A5E0:
	// lwz r8,176(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82463da8
	sub_82463DA8(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A600:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// b 0x82469170
	goto loc_82469170;
loc_8246A61C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245a6e0
	sub_8245A6E0(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A628:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245a5d8
	sub_8245A5D8(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A634:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245a3c8
	sub_8245A3C8(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A640:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245a4d0
	sub_8245A4D0(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A64C:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,180(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82463da8
	sub_82463DA8(ctx, base);
	// b 0x82468ca0
	goto loc_82468CA0;
loc_8246A66C:
	// lwz r8,192(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r7,188(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_8246A680:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82463da8
	sub_82463DA8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r25,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, r25.u32);
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r25.u32);
	// stw r25,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r25.u32);
	// b 0x82469c80
	goto loc_82469C80;
loc_8246A6A0:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691ac
	if (cr0.eq) goto loc_824691AC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,32340
	ctx.r6.s64 = r11.s64 + 32340;
	// b 0x82469198
	goto loc_82469198;
loc_8246A6BC:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r8,184(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82463da8
	sub_82463DA8(ctx, base);
	// b 0x82469c70
	goto loc_82469C70;
loc_8246A6DC:
	// lwz r8,196(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lwz r7,192(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x8246a680
	goto loc_8246A680;
loc_8246A6F4:
	// li r7,0
	ctx.r7.s64 = 0;
loc_8246A6F8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_8246A704:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82463940
	sub_82463940(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A710:
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// b 0x8246a6f8
	goto loc_8246A6F8;
loc_8246A718:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_8246A724:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82463bb0
	sub_82463BB0(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A730:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r8,196(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lwz r7,192(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82463da8
	sub_82463DA8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r25,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, r25.u32);
	// stw r25,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, r25.u32);
	// stw r25,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, r25.u32);
	// stw r25,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, r25.u32);
	// b 0x82469c80
	goto loc_82469C80;
loc_8246A764:
	// li r7,0
	ctx.r7.s64 = 0;
loc_8246A768:
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x8246a704
	goto loc_8246A704;
loc_8246A778:
	// lwz r7,188(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// b 0x8246a768
	goto loc_8246A768;
loc_8246A780:
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x8246a724
	goto loc_8246A724;
loc_8246A790:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82460d58
	sub_82460D58(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A7A0:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240a808
	sub_8240A808(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246A7BC:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17172
	ctx.r6.s64 = r11.s64 + -17172;
	// b 0x82469170
	goto loc_82469170;
loc_8246A7D8:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a804
	if (cr0.eq) goto loc_8246A804;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17172
	ctx.r6.s64 = r11.s64 + -17172;
loc_8246A7F0:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a808
	goto loc_8246A808;
loc_8246A804:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A808:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ac60
	sub_8245AC60(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691f8
	if (cr0.eq) goto loc_824691F8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// b 0x82468c98
	goto loc_82468C98;
loc_8246A824:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245a7e0
	sub_8245A7E0(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246A838:
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x82469b8c
	goto loc_82469B8C;
loc_8246A840:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17184
	ctx.r6.s64 = r11.s64 + -17184;
	// b 0x82469170
	goto loc_82469170;
loc_8246A85C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x824691ac
	if (cr0.eq) goto loc_824691AC;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17184
	ctx.r6.s64 = r11.s64 + -17184;
	// b 0x82469198
	goto loc_82469198;
loc_8246A878:
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r30,r27,40
	r30.s64 = r27.s64 + 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a8b0
	if (cr0.eq) goto loc_8246A8B0;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a8b4
	goto loc_8246A8B4;
loc_8246A8B0:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A8B4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8246a8c4
	if (!cr6.eq) goto loc_8246A8C4;
loc_8246A8BC:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// b 0x8246a930
	goto loc_8246A930;
loc_8246A8C4:
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a8f4
	if (cr0.eq) goto loc_8246A8F4;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8246a8f8
	goto loc_8246A8F8;
loc_8246A8F4:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_8246A8F8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8246a8bc
	if (cr6.eq) goto loc_8246A8BC;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a9e0
	if (cr0.eq) goto loc_8246A9E0;
	// li r5,1
	ctx.r5.s64 = 1;
	// b 0x8246a9d0
	goto loc_8246A9D0;
loc_8246A91C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245d2e8
	sub_8245D2E8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
loc_8246A930:
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// b 0x82468c30
	goto loc_82468C30;
loc_8246A938:
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r30,r27,40
	r30.s64 = r27.s64 + 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a970
	if (cr0.eq) goto loc_8246A970;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c078
	sub_8240C078(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x8246a974
	goto loc_8246A974;
loc_8246A970:
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8246A974:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8246a8bc
	if (cr6.eq) goto loc_8246A8BC;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a9ac
	if (cr0.eq) goto loc_8246A9AC;
	// li r9,512
	ctx.r9.s64 = 512;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240adb8
	sub_8240ADB8(ctx, base);
	// b 0x8246a9b0
	goto loc_8246A9B0;
loc_8246A9AC:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_8246A9B0:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x8246a8bc
	if (cr6.eq) goto loc_8246A8BC;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a9e0
	if (cr0.eq) goto loc_8246A9E0;
	// li r5,0
	ctx.r5.s64 = 0;
loc_8246A9D0:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x8246a9e4
	goto loc_8246A9E4;
loc_8246A9E0:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_8246A9E4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// beq cr6,0x8246a8bc
	if (cr6.eq) goto loc_8246A8BC;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246aa1c
	if (cr0.eq) goto loc_8246AA1C;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// b 0x8246aa20
	goto loc_8246AA20;
loc_8246AA1C:
	// mr r11,r25
	r11.u64 = r25.u64;
loc_8246AA20:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8246a91c
	if (!cr6.eq) goto loc_8246A91C;
	// b 0x8246a8bc
	goto loc_8246A8BC;
loc_8246AA2C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245f120
	sub_8245F120(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AA3C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245f1e8
	sub_8245F1E8(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AA4C:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82462228
	sub_82462228(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AA60:
	// addi r4,r27,40
	ctx.r4.s64 = r27.s64 + 40;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245f340
	sub_8245F340(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AA70:
	// li r6,1
	ctx.r6.s64 = 1;
loc_8246AA74:
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82462478
	sub_82462478(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AA8C:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x824679d0
	sub_824679D0(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AAA4:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245bc60
	sub_8245BC60(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// b 0x82468c88
	goto loc_82468C88;
loc_8246AAB8:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82487798
	sub_82487798(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824691f8
	if (cr0.lt) goto loc_824691F8;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// addi r6,r11,16
	ctx.r6.s64 = r11.s64 + 16;
	// bl 0x8240c4d0
	sub_8240C4D0(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AAF8:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82487798
	sub_82487798(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824691f8
	if (cr0.lt) goto loc_824691F8;
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r9,128(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246AB2C:
	// lwz r4,180(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_8246AB30:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245fb48
	sub_8245FB48(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246AB3C:
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// b 0x8246ab30
	goto loc_8246AB30;
loc_8246AB44:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246ab68
	if (!cr0.eq) goto loc_8246AB68;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r7,0
	ctx.r7.s64 = 0;
	// b 0x8246ab88
	goto loc_8246AB88;
loc_8246AB68:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17240
	ctx.r6.s64 = r11.s64 + -17240;
	// b 0x824694f8
	goto loc_824694F8;
loc_8246AB74:
	// li r8,0
	ctx.r8.s64 = 0;
loc_8246AB78:
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
loc_8246AB84:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_8246AB88:
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82468628
	sub_82468628(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246AB94:
	// lwz r11,180(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r6,188(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r5,184(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// b 0x8246ab84
	goto loc_8246AB84;
loc_8246ABAC:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246abc8
	if (!cr0.eq) goto loc_8246ABC8;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245fd10
	sub_8245FD10(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246ABC8:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17304
	ctx.r6.s64 = r11.s64 + -17304;
	// b 0x824694f8
	goto loc_824694F8;
loc_8246ABD4:
	// li r8,1
	ctx.r8.s64 = 1;
	// b 0x8246ab78
	goto loc_8246AB78;
loc_8246ABDC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245fe58
	sub_8245FE58(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246ABEC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82462c68
	sub_82462C68(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AC00:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245f5c0
	sub_8245F5C0(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AC14:
	// li r4,45
	ctx.r4.s64 = 45;
loc_8246AC18:
	// li r6,0
	ctx.r6.s64 = 0;
loc_8246AC1C:
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,1
	ctx.r7.s64 = 1;
loc_8246AC24:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82462f30
	sub_82462F30(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AC34:
	// li r4,46
	ctx.r4.s64 = 46;
	// b 0x8246ac18
	goto loc_8246AC18;
loc_8246AC3C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82468020
	sub_82468020(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AC54:
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x8246ac18
	goto loc_8246AC18;
loc_8246AC5C:
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x8246ac18
	goto loc_8246AC18;
loc_8246AC64:
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x8246ac18
	goto loc_8246AC18;
loc_8246AC6C:
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x8246ac18
	goto loc_8246AC18;
loc_8246AC74:
	// li r4,6
	ctx.r4.s64 = 6;
	// b 0x8246ac18
	goto loc_8246AC18;
loc_8246AC7C:
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x8246ac18
	goto loc_8246AC18;
loc_8246AC84:
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x8246aa74
	goto loc_8246AA74;
loc_8246AC8C:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AC98:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ACA4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,10
	ctx.r4.s64 = 10;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ACB0:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,11
	ctx.r4.s64 = 11;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ACBC:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,12
	ctx.r4.s64 = 12;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ACC8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,13
	ctx.r4.s64 = 13;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ACD4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,14
	ctx.r4.s64 = 14;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ACE0:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,15
	ctx.r4.s64 = 15;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ACEC:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ACF8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,17
	ctx.r4.s64 = 17;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD04:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,18
	ctx.r4.s64 = 18;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD10:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,19
	ctx.r4.s64 = 19;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD1C:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,20
	ctx.r4.s64 = 20;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD28:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,21
	ctx.r4.s64 = 21;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD34:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,22
	ctx.r4.s64 = 22;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD40:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,23
	ctx.r4.s64 = 23;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD4C:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,24
	ctx.r4.s64 = 24;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD58:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,25
	ctx.r4.s64 = 25;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD64:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r6,184(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x82462798
	sub_82462798(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AD7C:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,27
	ctx.r4.s64 = 27;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD88:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,35
	ctx.r4.s64 = 35;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AD94:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,36
	ctx.r4.s64 = 36;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ADA0:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,37
	ctx.r4.s64 = 37;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ADAC:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,38
	ctx.r4.s64 = 38;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ADB8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,39
	ctx.r4.s64 = 39;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ADC4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,40
	ctx.r4.s64 = 40;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ADD0:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,41
	ctx.r4.s64 = 41;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ADDC:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,42
	ctx.r4.s64 = 42;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ADE8:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,43
	ctx.r4.s64 = 43;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246ADF4:
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,44
	ctx.r4.s64 = 44;
	// b 0x8246ac1c
	goto loc_8246AC1C;
loc_8246AE00:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17320
	ctx.r6.s64 = r11.s64 + -17320;
	// b 0x82469170
	goto loc_82469170;
loc_8246AE1C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246a804
	if (cr0.eq) goto loc_8246A804;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-17320
	ctx.r6.s64 = r11.s64 + -17320;
	// b 0x8246a7f0
	goto loc_8246A7F0;
loc_8246AE38:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c74
	if (cr0.eq) goto loc_82468C74;
	// lis r11,-32246
	r11.s64 = -2113273856;
	// addi r6,r11,-22544
	ctx.r6.s64 = r11.s64 + -22544;
	// b 0x82469170
	goto loc_82469170;
loc_8246AE54:
	// lwz r11,20(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 20);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8246ae94
	if (cr0.eq) goto loc_8246AE94;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x8246ae94
	if (!cr6.eq) goto loc_8246AE94;
	// lwz r10,180(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x8246ae7c
	if (!cr6.eq) goto loc_8246AE7C;
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
loc_8246AE7C:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,3081
	ctx.r5.s64 = 3081;
	// addi r6,r11,-17392
	ctx.r6.s64 = r11.s64 + -17392;
	// addi r4,r10,48
	ctx.r4.s64 = ctx.r10.s64 + 48;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245ab70
	sub_8245AB70(ctx, base);
loc_8246AE94:
	// lwz r6,176(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x8246ac24
	goto loc_8246AC24;
loc_8246AEA8:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// neg r11,r11
	r11.s64 = -r11.s64;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246AEC0:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// lfd f0,24(r31)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r31.u32 + 24);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfd f0,24(r31)
	PPC_STORE_U64(r31.u32 + 24, f0.u64);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246AED8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245d370
	sub_8245D370(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246AEEC:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82468c28
	if (cr0.eq) goto loc_82468C28;
	// addi r4,r27,40
	ctx.r4.s64 = r27.s64 + 40;
	// bl 0x824099d0
	sub_824099D0(ctx, base);
	// b 0x82468c20
	goto loc_82468C20;
loc_8246AF08:
	// lwz r31,176(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, r25.u32);
	// stw r11,36(r27)
	PPC_STORE_U32(r27.u32 + 36, r11.u32);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246AF1C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r4,176(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// bl 0x8245d4c0
	sub_8245D4C0(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246AF30:
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x823e2270
	sub_823E2270(ctx, base);
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// bl 0x823e52d0
	sub_823E52D0(ctx, base);
	// b 0x82469a2c
	goto loc_82469A2C;
loc_8246AF48:
	// li r4,0
	ctx.r4.s64 = 0;
loc_8246AF4C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x824688f0
	sub_824688F0(ctx, base);
	// b 0x8246a5c0
	goto loc_8246A5C0;
loc_8246AF58:
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x8246af4c
	goto loc_8246AF4C;
loc_8246AF60:
	// lis r11,-32246
	r11.s64 = -2113273856;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-17432
	ctx.r6.s64 = r11.s64 + -17432;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8245abe0
	sub_8245ABE0(ctx, base);
	// b 0x824691f8
	goto loc_824691F8;
loc_8246AF7C:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x824093b0
	sub_824093B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8246afa4
	if (cr0.eq) goto loc_8246AFA4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r5,8(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r6,r11,12976
	ctx.r6.s64 = r11.s64 + 12976;
	// bl 0x82409578
	sub_82409578(ctx, base);
	// b 0x8246afa8
	goto loc_8246AFA8;
loc_8246AFA4:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_8246AFA8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82469224
	if (!cr6.eq) goto loc_82469224;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,12944
	ctx.r6.s64 = r11.s64 + 12944;
	// b 0x82468bdc
	goto loc_82468BDC;
}

__attribute__((alias("__imp__sub_8246AFBC"))) PPC_WEAK_FUNC(sub_8246AFBC);
PPC_FUNC_IMPL(__imp__sub_8246AFBC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8246AFC0"))) PPC_WEAK_FUNC(sub_8246AFC0);
PPC_FUNC_IMPL(__imp__sub_8246AFC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bce0
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r24,0
	r24.s64 = 0;
	// addi r11,r31,1032
	r11.s64 = r31.s64 + 1032;
	// addi r22,r31,32
	r22.s64 = r31.s64 + 32;
	// li r25,-1
	r25.s64 = -1;
	// mr r30,r24
	r30.u64 = r24.u64;
	// stw r24,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r24.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// lis r11,-32247
	r11.s64 = -2113339392;
	// stw r24,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r24.u32);
	// addi r26,r11,23920
	r26.s64 = r11.s64 + 23920;
	// stw r25,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r25.u32);
	// lis r11,-32247
	r11.s64 = -2113339392;
	// stw r22,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r22.u32);
	// sth r24,0(r22)
	PPC_STORE_U16(r22.u32 + 0, r24.u16);
	// addi r27,r11,5120
	r27.s64 = r11.s64 + 5120;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r23,r11,12644
	r23.s64 = r11.s64 + 12644;
loc_8246B014:
	// rlwinm r29,r30,1,0,30
	r29.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r11,r26,-20384
	r11.s64 = r26.s64 + -20384;
	// lhax r11,r29,r11
	r11.s64 = int16_t(PPC_LOAD_U16(r29.u32 + r11.u32));
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246b108
	if (!cr0.eq) goto loc_8246B108;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x8246b04c
	if (!cr6.lt) goto loc_8246B04C;
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 3032);
	// bl 0x82463fc0
	sub_82463FC0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// bge 0x8246b04c
	if (!cr0.lt) goto loc_8246B04C;
	// stw r24,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r24.u32);
loc_8246B04C:
	// addi r11,r26,-18512
	r11.s64 = r26.s64 + -18512;
	// lhax r10,r29,r11
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(r29.u32 + r11.u32));
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8246b0d0
	if (cr0.eq) goto loc_8246B0D0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r10,7525
	cr6.compare<uint32_t>(ctx.r10.u32, 7525, xer);
	// bgt cr6,0x8246b0d0
	if (cr6.gt) goto loc_8246B0D0;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r9,r10,r26
	ctx.r9.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r26.u32));
	// cmpw cr6,r9,r11
	cr6.compare<int32_t>(ctx.r9.s32, r11.s32, xer);
	// bne cr6,0x8246b0d0
	if (!cr6.eq) goto loc_8246B0D0;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r9,r31,1030
	ctx.r9.s64 = r31.s64 + 1030;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x8246c554
	if (!cr6.lt) goto loc_8246C554;
	// addi r9,r27,3744
	ctx.r9.s64 = r27.s64 + 3744;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// lhax r30,r10,r9
	r30.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r9.u32));
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// sth r30,0(r11)
	PPC_STORE_U16(r11.u32 + 0, r30.u16);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r25,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r25.u32);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x8246b014
	if (!cr0.gt) goto loc_8246B014;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// b 0x8246b014
	goto loc_8246B014;
loc_8246B0D0:
	// addi r11,r27,1872
	r11.s64 = r27.s64 + 1872;
	// lhax r10,r29,r11
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(r29.u32 + r11.u32));
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8246c480
	if (cr0.eq) goto loc_8246C480;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r10,7525
	cr6.compare<uint32_t>(ctx.r10.u32, 7525, xer);
	// bgt cr6,0x8246c480
	if (cr6.gt) goto loc_8246C480;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r9,r10,r26
	ctx.r9.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r26.u32));
	// cmpw cr6,r9,r11
	cr6.compare<int32_t>(ctx.r9.s32, r11.s32, xer);
	// bne cr6,0x8246c480
	if (!cr6.eq) goto loc_8246C480;
	// addi r11,r27,3744
	r11.s64 = r27.s64 + 3744;
	// lhax r11,r10,r11
	r11.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r11.u32));
loc_8246B108:
	// rlwinm r30,r11,1,0,30
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r9,r27,-2440
	ctx.r9.s64 = r27.s64 + -2440;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,425
	cr6.compare<uint32_t>(r11.u32, 425, xer);
	// lhax r29,r30,r9
	r29.s64 = int16_t(PPC_LOAD_U16(r30.u32 + ctx.r9.u32));
	// rlwinm r28,r29,2,0,29
	r28.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r28,r10
	ctx.r10.s64 = ctx.r10.s64 - r28.s64;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// bgt cr6,0x8246c370
	if (cr6.gt) goto loc_8246C370;
	// lis r12,-32246
	r12.s64 = -2113273856;
	// addi r12,r12,-25080
	r12.s64 = r12.s64 + -25080;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32185
	r12.s64 = -2109276160;
	// addi r12,r12,-20132
	r12.s64 = r12.s64 + -20132;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_8246B15C;
	case 1:
		goto loc_8246B164;
	case 2:
		goto loc_8246B170;
	case 3:
		goto loc_8246B17C;
	case 4:
		goto loc_8246B188;
	case 5:
		goto loc_8246B190;
	case 6:
		goto loc_8246B19C;
	case 7:
		goto loc_8246B1A8;
	case 8:
		goto loc_8246B1B4;
	case 9:
		goto loc_8246B1C0;
	case 10:
		goto loc_8246B1CC;
	case 11:
		goto loc_8246B1D8;
	case 12:
		goto loc_8246B1E4;
	case 13:
		goto loc_8246B1F0;
	case 14:
		goto loc_8246B1FC;
	case 15:
		goto loc_8246B208;
	case 16:
		goto loc_8246B214;
	case 17:
		goto loc_8246B220;
	case 18:
		goto loc_8246B228;
	case 19:
		goto loc_8246B230;
	case 20:
		goto loc_8246B23C;
	case 21:
		goto loc_8246B248;
	case 22:
		goto loc_8246B254;
	case 23:
		goto loc_8246B260;
	case 24:
		goto loc_8246B26C;
	case 25:
		goto loc_8246B278;
	case 26:
		goto loc_8246B280;
	case 27:
		goto loc_8246B28C;
	case 28:
		goto loc_8246B298;
	case 29:
		goto loc_8246B2A4;
	case 30:
		goto loc_8246B2B0;
	case 31:
		goto loc_8246B2B8;
	case 32:
		goto loc_8246B2C0;
	case 33:
		goto loc_8246B2CC;
	case 34:
		goto loc_8246B2D8;
	case 35:
		goto loc_8246B2E4;
	case 36:
		goto loc_8246B2EC;
	case 37:
		goto loc_8246B2F4;
	case 38:
		goto loc_8246B2FC;
	case 39:
		goto loc_8246B304;
	case 40:
		goto loc_8246B30C;
	case 41:
		goto loc_8246B314;
	case 42:
		goto loc_8246B31C;
	case 43:
		goto loc_8246B324;
	case 44:
		goto loc_8246B32C;
	case 45:
		goto loc_8246B334;
	case 46:
		goto loc_8246B340;
	case 47:
		goto loc_8246B34C;
	case 48:
		goto loc_8246B358;
	case 49:
		goto loc_8246B364;
	case 50:
		goto loc_8246B36C;
	case 51:
		goto loc_8246B374;
	case 52:
		goto loc_8246B37C;
	case 53:
		goto loc_8246B388;
	case 54:
		goto loc_8246B394;
	case 55:
		goto loc_8246B3A0;
	case 56:
		goto loc_8246B3AC;
	case 57:
		goto loc_8246B3B8;
	case 58:
		goto loc_8246B3C4;
	case 59:
		goto loc_8246B3D0;
	case 60:
		goto loc_8246B3DC;
	case 61:
		goto loc_8246B3E8;
	case 62:
		goto loc_8246B3F4;
	case 63:
		goto loc_8246B400;
	case 64:
		goto loc_8246B40C;
	case 65:
		goto loc_8246B418;
	case 66:
		goto loc_8246B424;
	case 67:
		goto loc_8246B430;
	case 68:
		goto loc_8246B43C;
	case 69:
		goto loc_8246B448;
	case 70:
		goto loc_8246B454;
	case 71:
		goto loc_8246B460;
	case 72:
		goto loc_8246B46C;
	case 73:
		goto loc_8246B474;
	case 74:
		goto loc_8246B480;
	case 75:
		goto loc_8246B48C;
	case 76:
		goto loc_8246B498;
	case 77:
		goto loc_8246B4A4;
	case 78:
		goto loc_8246B4AC;
	case 79:
		goto loc_8246B4B4;
	case 80:
		goto loc_8246B4BC;
	case 81:
		goto loc_8246B4C4;
	case 82:
		goto loc_8246B4CC;
	case 83:
		goto loc_8246B4D4;
	case 84:
		goto loc_8246B4DC;
	case 85:
		goto loc_8246B4E4;
	case 86:
		goto loc_8246B4EC;
	case 87:
		goto loc_8246B4F4;
	case 88:
		goto loc_8246B500;
	case 89:
		goto loc_8246B508;
	case 90:
		goto loc_8246B514;
	case 91:
		goto loc_8246B51C;
	case 92:
		goto loc_8246B524;
	case 93:
		goto loc_8246B52C;
	case 94:
		goto loc_8246B534;
	case 95:
		goto loc_8246B53C;
	case 96:
		goto loc_8246B544;
	case 97:
		goto loc_8246B54C;
	case 98:
		goto loc_8246B554;
	case 99:
		goto loc_8246B560;
	case 100:
		goto loc_8246B56C;
	case 101:
		goto loc_8246B578;
	case 102:
		goto loc_8246B584;
	case 103:
		goto loc_8246B590;
	case 104:
		goto loc_8246B59C;
	case 105:
		goto loc_8246B5A4;
	case 106:
		goto loc_8246B5AC;
	case 107:
		goto loc_8246B5B4;
	case 108:
		goto loc_8246B5BC;
	case 109:
		goto loc_8246B5C4;
	case 110:
		goto loc_8246B5CC;
	case 111:
		goto loc_8246B5D4;
	case 112:
		goto loc_8246B5DC;
	case 113:
		goto loc_8246B5E4;
	case 114:
		goto loc_8246B5EC;
	case 115:
		goto loc_8246B5F4;
	case 116:
		goto loc_8246B5FC;
	case 117:
		goto loc_8246B604;
	case 118:
		goto loc_8246B610;
	case 119:
		goto loc_8246B618;
	case 120:
		goto loc_8246B620;
	case 121:
		goto loc_8246B628;
	case 122:
		goto loc_8246B634;
	case 123:
		goto loc_8246B640;
	case 124:
		goto loc_8246B64C;
	case 125:
		goto loc_8246B658;
	case 126:
		goto loc_8246B664;
	case 127:
		goto loc_8246B66C;
	case 128:
		goto loc_8246B674;
	case 129:
		goto loc_8246B680;
	case 130:
		goto loc_8246B68C;
	case 131:
		goto loc_8246B698;
	case 132:
		goto loc_8246B6A4;
	case 133:
		goto loc_8246B6B0;
	case 134:
		goto loc_8246B6BC;
	case 135:
		goto loc_8246B6C4;
	case 136:
		goto loc_8246B6D0;
	case 137:
		goto loc_8246B6DC;
	case 138:
		goto loc_8246B6E8;
	case 139:
		goto loc_8246B6F4;
	case 140:
		goto loc_8246B6FC;
	case 141:
		goto loc_8246B708;
	case 142:
		goto loc_8246B714;
	case 143:
		goto loc_8246B720;
	case 144:
		goto loc_8246B72C;
	case 145:
		goto loc_8246B738;
	case 146:
		goto loc_8246B744;
	case 147:
		goto loc_8246B74C;
	case 148:
		goto loc_8246B758;
	case 149:
		goto loc_8246B764;
	case 150:
		goto loc_8246B770;
	case 151:
		goto loc_8246B77C;
	case 152:
		goto loc_8246B788;
	case 153:
		goto loc_8246B794;
	case 154:
		goto loc_8246B7A0;
	case 155:
		goto loc_8246B7AC;
	case 156:
		goto loc_8246B7B8;
	case 157:
		goto loc_8246B7C4;
	case 158:
		goto loc_8246B7D0;
	case 159:
		goto loc_8246B7D8;
	case 160:
		goto loc_8246B7E4;
	case 161:
		goto loc_8246B7EC;
	case 162:
		goto loc_8246B7F8;
	case 163:
		goto loc_8246B804;
	case 164:
		goto loc_8246B80C;
	case 165:
		goto loc_8246B818;
	case 166:
		goto loc_8246B824;
	case 167:
		goto loc_8246B830;
	case 168:
		goto loc_8246B83C;
	case 169:
		goto loc_8246B848;
	case 170:
		goto loc_8246B854;
	case 171:
		goto loc_8246B860;
	case 172:
		goto loc_8246B86C;
	case 173:
		goto loc_8246B874;
	case 174:
		goto loc_8246B880;
	case 175:
		goto loc_8246B88C;
	case 176:
		goto loc_8246B898;
	case 177:
		goto loc_8246B8A4;
	case 178:
		goto loc_8246B8B0;
	case 179:
		goto loc_8246B8BC;
	case 180:
		goto loc_8246B8C8;
	case 181:
		goto loc_8246B8D4;
	case 182:
		goto loc_8246B8E0;
	case 183:
		goto loc_8246B8EC;
	case 184:
		goto loc_8246B8F8;
	case 185:
		goto loc_8246B900;
	case 186:
		goto loc_8246B90C;
	case 187:
		goto loc_8246B918;
	case 188:
		goto loc_8246B924;
	case 189:
		goto loc_8246B930;
	case 190:
		goto loc_8246B93C;
	case 191:
		goto loc_8246B948;
	case 192:
		goto loc_8246B954;
	case 193:
		goto loc_8246B960;
	case 194:
		goto loc_8246B96C;
	case 195:
		goto loc_8246B974;
	case 196:
		goto loc_8246B97C;
	case 197:
		goto loc_8246B988;
	case 198:
		goto loc_8246B994;
	case 199:
		goto loc_8246B9A0;
	case 200:
		goto loc_8246B9AC;
	case 201:
		goto loc_8246B9B8;
	case 202:
		goto loc_8246B9C4;
	case 203:
		goto loc_8246B9D0;
	case 204:
		goto loc_8246B9DC;
	case 205:
		goto loc_8246B9E8;
	case 206:
		goto loc_8246B9F0;
	case 207:
		goto loc_8246B9F8;
	case 208:
		goto loc_8246BA00;
	case 209:
		goto loc_8246BA08;
	case 210:
		goto loc_8246BA10;
	case 211:
		goto loc_8246BA18;
	case 212:
		goto loc_8246BA20;
	case 213:
		goto loc_8246BA28;
	case 214:
		goto loc_8246BA30;
	case 215:
		goto loc_8246BA38;
	case 216:
		goto loc_8246BA40;
	case 217:
		goto loc_8246BA48;
	case 218:
		goto loc_8246BA50;
	case 219:
		goto loc_8246BA5C;
	case 220:
		goto loc_8246BA68;
	case 221:
		goto loc_8246BA74;
	case 222:
		goto loc_8246BA80;
	case 223:
		goto loc_8246BA8C;
	case 224:
		goto loc_8246BA94;
	case 225:
		goto loc_8246BA9C;
	case 226:
		goto loc_8246BAA8;
	case 227:
		goto loc_8246BAB4;
	case 228:
		goto loc_8246BAC0;
	case 229:
		goto loc_8246BACC;
	case 230:
		goto loc_8246BAD8;
	case 231:
		goto loc_8246BAE0;
	case 232:
		goto loc_8246BAE8;
	case 233:
		goto loc_8246BAF4;
	case 234:
		goto loc_8246BB00;
	case 235:
		goto loc_8246BB0C;
	case 236:
		goto loc_8246BB18;
	case 237:
		goto loc_8246BB20;
	case 238:
		goto loc_8246BB2C;
	case 239:
		goto loc_8246BB34;
	case 240:
		goto loc_8246BB3C;
	case 241:
		goto loc_8246BB48;
	case 242:
		goto loc_8246BB54;
	case 243:
		goto loc_8246BB60;
	case 244:
		goto loc_8246BB6C;
	case 245:
		goto loc_8246BB78;
	case 246:
		goto loc_8246BB84;
	case 247:
		goto loc_8246BB90;
	case 248:
		goto loc_8246BB98;
	case 249:
		goto loc_8246BBA0;
	case 250:
		goto loc_8246BBA8;
	case 251:
		goto loc_8246BBB0;
	case 252:
		goto loc_8246BBBC;
	case 253:
		goto loc_8246BBC8;
	case 254:
		goto loc_8246BBD4;
	case 255:
		goto loc_8246BBE0;
	case 256:
		goto loc_8246BBEC;
	case 257:
		goto loc_8246BBF8;
	case 258:
		goto loc_8246BC04;
	case 259:
		goto loc_8246BC10;
	case 260:
		goto loc_8246BC1C;
	case 261:
		goto loc_8246BC24;
	case 262:
		goto loc_8246BC2C;
	case 263:
		goto loc_8246BC38;
	case 264:
		goto loc_8246BC44;
	case 265:
		goto loc_8246BC4C;
	case 266:
		goto loc_8246BC58;
	case 267:
		goto loc_8246BC60;
	case 268:
		goto loc_8246BC6C;
	case 269:
		goto loc_8246BC78;
	case 270:
		goto loc_8246BC84;
	case 271:
		goto loc_8246BC8C;
	case 272:
		goto loc_8246BC98;
	case 273:
		goto loc_8246BCA4;
	case 274:
		goto loc_8246BCB0;
	case 275:
		goto loc_8246BCB8;
	case 276:
		goto loc_8246BCC0;
	case 277:
		goto loc_8246BCC8;
	case 278:
		goto loc_8246BCD4;
	case 279:
		goto loc_8246BCE0;
	case 280:
		goto loc_8246BCEC;
	case 281:
		goto loc_8246BCF8;
	case 282:
		goto loc_8246BD04;
	case 283:
		goto loc_8246BD10;
	case 284:
		goto loc_8246BD1C;
	case 285:
		goto loc_8246BD28;
	case 286:
		goto loc_8246BD34;
	case 287:
		goto loc_8246BD40;
	case 288:
		goto loc_8246BD4C;
	case 289:
		goto loc_8246BD58;
	case 290:
		goto loc_8246BD64;
	case 291:
		goto loc_8246BD70;
	case 292:
		goto loc_8246BD7C;
	case 293:
		goto loc_8246BD88;
	case 294:
		goto loc_8246BD94;
	case 295:
		goto loc_8246BDA0;
	case 296:
		goto loc_8246BDAC;
	case 297:
		goto loc_8246BDB4;
	case 298:
		goto loc_8246BDC0;
	case 299:
		goto loc_8246BDCC;
	case 300:
		goto loc_8246BDD8;
	case 301:
		goto loc_8246BDE4;
	case 302:
		goto loc_8246BDF0;
	case 303:
		goto loc_8246BDF8;
	case 304:
		goto loc_8246BE00;
	case 305:
		goto loc_8246BE0C;
	case 306:
		goto loc_8246BE18;
	case 307:
		goto loc_8246BE20;
	case 308:
		goto loc_8246BE2C;
	case 309:
		goto loc_8246BE34;
	case 310:
		goto loc_8246BE40;
	case 311:
		goto loc_8246BE48;
	case 312:
		goto loc_8246BE50;
	case 313:
		goto loc_8246BE5C;
	case 314:
		goto loc_8246BE68;
	case 315:
		goto loc_8246BE74;
	case 316:
		goto loc_8246BE80;
	case 317:
		goto loc_8246BE88;
	case 318:
		goto loc_8246BE94;
	case 319:
		goto loc_8246BEA0;
	case 320:
		goto loc_8246BEAC;
	case 321:
		goto loc_8246BEB8;
	case 322:
		goto loc_8246BEC4;
	case 323:
		goto loc_8246BED0;
	case 324:
		goto loc_8246BEDC;
	case 325:
		goto loc_8246BEE8;
	case 326:
		goto loc_8246BEF4;
	case 327:
		goto loc_8246BF00;
	case 328:
		goto loc_8246BF0C;
	case 329:
		goto loc_8246BF18;
	case 330:
		goto loc_8246BF24;
	case 331:
		goto loc_8246BF30;
	case 332:
		goto loc_8246BF3C;
	case 333:
		goto loc_8246BF48;
	case 334:
		goto loc_8246BF54;
	case 335:
		goto loc_8246BF60;
	case 336:
		goto loc_8246BF6C;
	case 337:
		goto loc_8246BF78;
	case 338:
		goto loc_8246BF84;
	case 339:
		goto loc_8246BF90;
	case 340:
		goto loc_8246BF9C;
	case 341:
		goto loc_8246BFA8;
	case 342:
		goto loc_8246BFB4;
	case 343:
		goto loc_8246BFC0;
	case 344:
		goto loc_8246BFCC;
	case 345:
		goto loc_8246BFD8;
	case 346:
		goto loc_8246BFE4;
	case 347:
		goto loc_8246BFF0;
	case 348:
		goto loc_8246BFFC;
	case 349:
		goto loc_8246C008;
	case 350:
		goto loc_8246C014;
	case 351:
		goto loc_8246C020;
	case 352:
		goto loc_8246C02C;
	case 353:
		goto loc_8246C038;
	case 354:
		goto loc_8246C044;
	case 355:
		goto loc_8246C050;
	case 356:
		goto loc_8246C05C;
	case 357:
		goto loc_8246C068;
	case 358:
		goto loc_8246C074;
	case 359:
		goto loc_8246C080;
	case 360:
		goto loc_8246C08C;
	case 361:
		goto loc_8246C098;
	case 362:
		goto loc_8246C0A4;
	case 363:
		goto loc_8246C0B0;
	case 364:
		goto loc_8246C0BC;
	case 365:
		goto loc_8246C0C8;
	case 366:
		goto loc_8246C0D4;
	case 367:
		goto loc_8246C0E0;
	case 368:
		goto loc_8246C0EC;
	case 369:
		goto loc_8246C0F8;
	case 370:
		goto loc_8246C104;
	case 371:
		goto loc_8246C110;
	case 372:
		goto loc_8246C11C;
	case 373:
		goto loc_8246C128;
	case 374:
		goto loc_8246C134;
	case 375:
		goto loc_8246C140;
	case 376:
		goto loc_8246C14C;
	case 377:
		goto loc_8246C158;
	case 378:
		goto loc_8246C164;
	case 379:
		goto loc_8246C170;
	case 380:
		goto loc_8246C17C;
	case 381:
		goto loc_8246C188;
	case 382:
		goto loc_8246C194;
	case 383:
		goto loc_8246C1A0;
	case 384:
		goto loc_8246C1AC;
	case 385:
		goto loc_8246C1B8;
	case 386:
		goto loc_8246C1C4;
	case 387:
		goto loc_8246C1D0;
	case 388:
		goto loc_8246C1DC;
	case 389:
		goto loc_8246C1E8;
	case 390:
		goto loc_8246C1F4;
	case 391:
		goto loc_8246C200;
	case 392:
		goto loc_8246C20C;
	case 393:
		goto loc_8246C218;
	case 394:
		goto loc_8246C224;
	case 395:
		goto loc_8246C230;
	case 396:
		goto loc_8246C23C;
	case 397:
		goto loc_8246C244;
	case 398:
		goto loc_8246C250;
	case 399:
		goto loc_8246C25C;
	case 400:
		goto loc_8246C268;
	case 401:
		goto loc_8246C274;
	case 402:
		goto loc_8246C280;
	case 403:
		goto loc_8246C28C;
	case 404:
		goto loc_8246C298;
	case 405:
		goto loc_8246C2A4;
	case 406:
		goto loc_8246C2B0;
	case 407:
		goto loc_8246C2BC;
	case 408:
		goto loc_8246C2C8;
	case 409:
		goto loc_8246C2D0;
	case 410:
		goto loc_8246C2DC;
	case 411:
		goto loc_8246C2E8;
	case 412:
		goto loc_8246C2F0;
	case 413:
		goto loc_8246C2F8;
	case 414:
		goto loc_8246C300;
	case 415:
		goto loc_8246C308;
	case 416:
		goto loc_8246C310;
	case 417:
		goto loc_8246C318;
	case 418:
		goto loc_8246C320;
	case 419:
		goto loc_8246C32C;
	case 420:
		goto loc_8246C338;
	case 421:
		goto loc_8246C340;
	case 422:
		goto loc_8246C348;
	case 423:
		goto loc_8246C350;
	case 424:
		goto loc_8246C358;
	case 425:
		goto loc_8246C360;
	default:
		__builtin_unreachable();
	}
loc_8246B15C:
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B164:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B170:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B17C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B188:
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B190:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B19C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,6
	ctx.r4.s64 = 6;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B1A8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B1B4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B1C0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,12
	ctx.r4.s64 = 12;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B1CC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B1D8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,10
	ctx.r4.s64 = 10;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B1E4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,11
	ctx.r4.s64 = 11;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B1F0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,13
	ctx.r4.s64 = 13;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B1FC:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,14
	ctx.r4.s64 = 14;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B208:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,15
	ctx.r4.s64 = 15;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B214:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,18
	ctx.r4.s64 = 18;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B220:
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B228:
	// li r4,17
	ctx.r4.s64 = 17;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B230:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,19
	ctx.r4.s64 = 19;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B23C:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,20
	ctx.r4.s64 = 20;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B248:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,21
	ctx.r4.s64 = 21;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B254:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,22
	ctx.r4.s64 = 22;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B260:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,25
	ctx.r4.s64 = 25;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B26C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,26
	ctx.r4.s64 = 26;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B278:
	// li r4,24
	ctx.r4.s64 = 24;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B280:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,27
	ctx.r4.s64 = 27;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B28C:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,28
	ctx.r4.s64 = 28;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B298:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,31
	ctx.r4.s64 = 31;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B2A4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,32
	ctx.r4.s64 = 32;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B2B0:
	// li r4,30
	ctx.r4.s64 = 30;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B2B8:
	// li r4,35
	ctx.r4.s64 = 35;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B2C0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,36
	ctx.r4.s64 = 36;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B2CC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,33
	ctx.r4.s64 = 33;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B2D8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,34
	ctx.r4.s64 = 34;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B2E4:
	// li r4,37
	ctx.r4.s64 = 37;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B2EC:
	// li r4,38
	ctx.r4.s64 = 38;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B2F4:
	// li r4,39
	ctx.r4.s64 = 39;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B2FC:
	// li r4,40
	ctx.r4.s64 = 40;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B304:
	// li r4,41
	ctx.r4.s64 = 41;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B30C:
	// li r4,42
	ctx.r4.s64 = 42;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B314:
	// li r4,43
	ctx.r4.s64 = 43;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B31C:
	// li r4,44
	ctx.r4.s64 = 44;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B324:
	// li r4,45
	ctx.r4.s64 = 45;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B32C:
	// li r4,46
	ctx.r4.s64 = 46;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B334:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,47
	ctx.r4.s64 = 47;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B340:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,48
	ctx.r4.s64 = 48;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B34C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,52
	ctx.r4.s64 = 52;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B358:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,53
	ctx.r4.s64 = 53;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B364:
	// li r4,54
	ctx.r4.s64 = 54;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B36C:
	// li r4,55
	ctx.r4.s64 = 55;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B374:
	// li r4,56
	ctx.r4.s64 = 56;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B37C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,57
	ctx.r4.s64 = 57;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B388:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,58
	ctx.r4.s64 = 58;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B394:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,61
	ctx.r4.s64 = 61;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B3A0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,62
	ctx.r4.s64 = 62;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B3AC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,63
	ctx.r4.s64 = 63;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B3B8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,64
	ctx.r4.s64 = 64;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B3C4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,65
	ctx.r4.s64 = 65;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B3D0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,66
	ctx.r4.s64 = 66;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B3DC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,67
	ctx.r4.s64 = 67;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B3E8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,68
	ctx.r4.s64 = 68;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B3F4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,69
	ctx.r4.s64 = 69;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B400:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,70
	ctx.r4.s64 = 70;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B40C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,71
	ctx.r4.s64 = 71;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B418:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,72
	ctx.r4.s64 = 72;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B424:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,73
	ctx.r4.s64 = 73;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B430:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,74
	ctx.r4.s64 = 74;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B43C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,75
	ctx.r4.s64 = 75;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B448:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,76
	ctx.r4.s64 = 76;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B454:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,77
	ctx.r4.s64 = 77;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B460:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,78
	ctx.r4.s64 = 78;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B46C:
	// li r4,79
	ctx.r4.s64 = 79;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B474:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,80
	ctx.r4.s64 = 80;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B480:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,81
	ctx.r4.s64 = 81;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B48C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,82
	ctx.r4.s64 = 82;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B498:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,83
	ctx.r4.s64 = 83;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B4A4:
	// li r4,84
	ctx.r4.s64 = 84;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4AC:
	// li r4,85
	ctx.r4.s64 = 85;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4B4:
	// li r4,86
	ctx.r4.s64 = 86;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4BC:
	// li r4,87
	ctx.r4.s64 = 87;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4C4:
	// li r4,88
	ctx.r4.s64 = 88;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4CC:
	// li r4,89
	ctx.r4.s64 = 89;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4D4:
	// li r4,90
	ctx.r4.s64 = 90;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4DC:
	// li r4,91
	ctx.r4.s64 = 91;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4E4:
	// li r4,92
	ctx.r4.s64 = 92;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4EC:
	// li r4,93
	ctx.r4.s64 = 93;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B4F4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,94
	ctx.r4.s64 = 94;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B500:
	// li r4,95
	ctx.r4.s64 = 95;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B508:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,96
	ctx.r4.s64 = 96;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B514:
	// li r4,97
	ctx.r4.s64 = 97;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B51C:
	// li r4,98
	ctx.r4.s64 = 98;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B524:
	// li r4,99
	ctx.r4.s64 = 99;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B52C:
	// li r4,100
	ctx.r4.s64 = 100;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B534:
	// li r4,101
	ctx.r4.s64 = 101;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B53C:
	// li r4,102
	ctx.r4.s64 = 102;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B544:
	// li r4,103
	ctx.r4.s64 = 103;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B54C:
	// li r4,104
	ctx.r4.s64 = 104;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B554:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,105
	ctx.r4.s64 = 105;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B560:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,106
	ctx.r4.s64 = 106;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B56C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,107
	ctx.r4.s64 = 107;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B578:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,108
	ctx.r4.s64 = 108;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B584:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,109
	ctx.r4.s64 = 109;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B590:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,110
	ctx.r4.s64 = 110;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B59C:
	// li r4,123
	ctx.r4.s64 = 123;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5A4:
	// li r4,124
	ctx.r4.s64 = 124;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5AC:
	// li r4,111
	ctx.r4.s64 = 111;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5B4:
	// li r4,112
	ctx.r4.s64 = 112;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5BC:
	// li r4,113
	ctx.r4.s64 = 113;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5C4:
	// li r4,114
	ctx.r4.s64 = 114;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5CC:
	// li r4,115
	ctx.r4.s64 = 115;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5D4:
	// li r4,116
	ctx.r4.s64 = 116;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5DC:
	// li r4,129
	ctx.r4.s64 = 129;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5E4:
	// li r4,117
	ctx.r4.s64 = 117;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5EC:
	// li r4,118
	ctx.r4.s64 = 118;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5F4:
	// li r4,125
	ctx.r4.s64 = 125;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B5FC:
	// li r4,119
	ctx.r4.s64 = 119;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B604:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,120
	ctx.r4.s64 = 120;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B610:
	// li r4,126
	ctx.r4.s64 = 126;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B618:
	// li r4,127
	ctx.r4.s64 = 127;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B620:
	// li r4,128
	ctx.r4.s64 = 128;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B628:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,130
	ctx.r4.s64 = 130;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B634:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,131
	ctx.r4.s64 = 131;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B640:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,132
	ctx.r4.s64 = 132;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B64C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,121
	ctx.r4.s64 = 121;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B658:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,122
	ctx.r4.s64 = 122;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B664:
	// li r4,134
	ctx.r4.s64 = 134;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B66C:
	// li r4,133
	ctx.r4.s64 = 133;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B674:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,138
	ctx.r4.s64 = 138;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B680:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,139
	ctx.r4.s64 = 139;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B68C:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,140
	ctx.r4.s64 = 140;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B698:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,141
	ctx.r4.s64 = 141;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B6A4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,142
	ctx.r4.s64 = 142;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B6B0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,143
	ctx.r4.s64 = 143;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B6BC:
	// li r4,144
	ctx.r4.s64 = 144;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B6C4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,145
	ctx.r4.s64 = 145;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B6D0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,146
	ctx.r4.s64 = 146;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B6DC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,147
	ctx.r4.s64 = 147;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B6E8:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,148
	ctx.r4.s64 = 148;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B6F4:
	// li r4,149
	ctx.r4.s64 = 149;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B6FC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,150
	ctx.r4.s64 = 150;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B708:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,151
	ctx.r4.s64 = 151;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B714:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,152
	ctx.r4.s64 = 152;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B720:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,153
	ctx.r4.s64 = 153;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B72C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,154
	ctx.r4.s64 = 154;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B738:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,155
	ctx.r4.s64 = 155;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B744:
	// li r4,156
	ctx.r4.s64 = 156;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B74C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,157
	ctx.r4.s64 = 157;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B758:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,158
	ctx.r4.s64 = 158;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B764:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,159
	ctx.r4.s64 = 159;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B770:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,160
	ctx.r4.s64 = 160;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B77C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,161
	ctx.r4.s64 = 161;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B788:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,162
	ctx.r4.s64 = 162;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B794:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,163
	ctx.r4.s64 = 163;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B7A0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,164
	ctx.r4.s64 = 164;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B7AC:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,165
	ctx.r4.s64 = 165;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B7B8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,166
	ctx.r4.s64 = 166;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B7C4:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,167
	ctx.r4.s64 = 167;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B7D0:
	// li r4,168
	ctx.r4.s64 = 168;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B7D8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,169
	ctx.r4.s64 = 169;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B7E4:
	// li r4,170
	ctx.r4.s64 = 170;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B7EC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,171
	ctx.r4.s64 = 171;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B7F8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,172
	ctx.r4.s64 = 172;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B804:
	// li r4,173
	ctx.r4.s64 = 173;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B80C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,174
	ctx.r4.s64 = 174;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B818:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,175
	ctx.r4.s64 = 175;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B824:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,176
	ctx.r4.s64 = 176;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B830:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,177
	ctx.r4.s64 = 177;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B83C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,178
	ctx.r4.s64 = 178;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B848:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,179
	ctx.r4.s64 = 179;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B854:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,180
	ctx.r4.s64 = 180;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B860:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,181
	ctx.r4.s64 = 181;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B86C:
	// li r4,182
	ctx.r4.s64 = 182;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B874:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,183
	ctx.r4.s64 = 183;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B880:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,184
	ctx.r4.s64 = 184;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B88C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,185
	ctx.r4.s64 = 185;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B898:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,186
	ctx.r4.s64 = 186;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B8A4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,187
	ctx.r4.s64 = 187;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B8B0:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,188
	ctx.r4.s64 = 188;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B8BC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,189
	ctx.r4.s64 = 189;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B8C8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,190
	ctx.r4.s64 = 190;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B8D4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,191
	ctx.r4.s64 = 191;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B8E0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,192
	ctx.r4.s64 = 192;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B8EC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,193
	ctx.r4.s64 = 193;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B8F8:
	// li r4,194
	ctx.r4.s64 = 194;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B900:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,195
	ctx.r4.s64 = 195;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B90C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,196
	ctx.r4.s64 = 196;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B918:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,197
	ctx.r4.s64 = 197;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B924:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,198
	ctx.r4.s64 = 198;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B930:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,199
	ctx.r4.s64 = 199;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B93C:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,200
	ctx.r4.s64 = 200;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B948:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,201
	ctx.r4.s64 = 201;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B954:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,202
	ctx.r4.s64 = 202;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B960:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,203
	ctx.r4.s64 = 203;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B96C:
	// li r4,204
	ctx.r4.s64 = 204;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B974:
	// li r4,205
	ctx.r4.s64 = 205;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B97C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,206
	ctx.r4.s64 = 206;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B988:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,207
	ctx.r4.s64 = 207;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B994:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,208
	ctx.r4.s64 = 208;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B9A0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,209
	ctx.r4.s64 = 209;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B9AC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,210
	ctx.r4.s64 = 210;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B9B8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,213
	ctx.r4.s64 = 213;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B9C4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,214
	ctx.r4.s64 = 214;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B9D0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,215
	ctx.r4.s64 = 215;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B9DC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,216
	ctx.r4.s64 = 216;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246B9E8:
	// li r4,217
	ctx.r4.s64 = 217;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B9F0:
	// li r4,218
	ctx.r4.s64 = 218;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246B9F8:
	// li r4,219
	ctx.r4.s64 = 219;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA00:
	// li r4,220
	ctx.r4.s64 = 220;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA08:
	// li r4,221
	ctx.r4.s64 = 221;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA10:
	// li r4,222
	ctx.r4.s64 = 222;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA18:
	// li r4,223
	ctx.r4.s64 = 223;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA20:
	// li r4,224
	ctx.r4.s64 = 224;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA28:
	// li r4,225
	ctx.r4.s64 = 225;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA30:
	// li r4,226
	ctx.r4.s64 = 226;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA38:
	// li r4,227
	ctx.r4.s64 = 227;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA40:
	// li r4,228
	ctx.r4.s64 = 228;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA48:
	// li r4,229
	ctx.r4.s64 = 229;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA50:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,230
	ctx.r4.s64 = 230;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BA5C:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,231
	ctx.r4.s64 = 231;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BA68:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,232
	ctx.r4.s64 = 232;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BA74:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,233
	ctx.r4.s64 = 233;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BA80:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,234
	ctx.r4.s64 = 234;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BA8C:
	// li r4,235
	ctx.r4.s64 = 235;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA94:
	// li r4,236
	ctx.r4.s64 = 236;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BA9C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,237
	ctx.r4.s64 = 237;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BAA8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,238
	ctx.r4.s64 = 238;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BAB4:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,239
	ctx.r4.s64 = 239;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BAC0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,240
	ctx.r4.s64 = 240;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BACC:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,241
	ctx.r4.s64 = 241;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BAD8:
	// li r4,242
	ctx.r4.s64 = 242;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BAE0:
	// li r4,243
	ctx.r4.s64 = 243;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BAE8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,244
	ctx.r4.s64 = 244;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BAF4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,245
	ctx.r4.s64 = 245;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB00:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,246
	ctx.r4.s64 = 246;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB0C:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,248
	ctx.r4.s64 = 248;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB18:
	// li r4,250
	ctx.r4.s64 = 250;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BB20:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,251
	ctx.r4.s64 = 251;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB2C:
	// li r4,252
	ctx.r4.s64 = 252;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BB34:
	// li r4,253
	ctx.r4.s64 = 253;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BB3C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,409
	ctx.r4.s64 = 409;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB48:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,410
	ctx.r4.s64 = 410;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB54:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,411
	ctx.r4.s64 = 411;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB60:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,412
	ctx.r4.s64 = 412;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB6C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,413
	ctx.r4.s64 = 413;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB78:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,414
	ctx.r4.s64 = 414;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB84:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,415
	ctx.r4.s64 = 415;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BB90:
	// li r4,416
	ctx.r4.s64 = 416;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BB98:
	// li r4,417
	ctx.r4.s64 = 417;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BBA0:
	// li r4,418
	ctx.r4.s64 = 418;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BBA8:
	// li r4,419
	ctx.r4.s64 = 419;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BBB0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,306
	ctx.r4.s64 = 306;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BBBC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,307
	ctx.r4.s64 = 307;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BBC8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,308
	ctx.r4.s64 = 308;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BBD4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,309
	ctx.r4.s64 = 309;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BBE0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,310
	ctx.r4.s64 = 310;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BBEC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,311
	ctx.r4.s64 = 311;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BBF8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,312
	ctx.r4.s64 = 312;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC04:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,254
	ctx.r4.s64 = 254;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC10:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,255
	ctx.r4.s64 = 255;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC1C:
	// li r4,256
	ctx.r4.s64 = 256;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BC24:
	// li r4,257
	ctx.r4.s64 = 257;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BC2C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,258
	ctx.r4.s64 = 258;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC38:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,259
	ctx.r4.s64 = 259;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC44:
	// li r4,260
	ctx.r4.s64 = 260;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BC4C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,261
	ctx.r4.s64 = 261;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC58:
	// li r4,262
	ctx.r4.s64 = 262;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BC60:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,263
	ctx.r4.s64 = 263;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC6C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,264
	ctx.r4.s64 = 264;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC78:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,265
	ctx.r4.s64 = 265;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC84:
	// li r4,266
	ctx.r4.s64 = 266;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BC8C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,267
	ctx.r4.s64 = 267;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BC98:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,268
	ctx.r4.s64 = 268;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BCA4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,269
	ctx.r4.s64 = 269;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BCB0:
	// li r4,270
	ctx.r4.s64 = 270;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BCB8:
	// li r4,271
	ctx.r4.s64 = 271;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BCC0:
	// li r4,272
	ctx.r4.s64 = 272;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BCC8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,273
	ctx.r4.s64 = 273;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BCD4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,274
	ctx.r4.s64 = 274;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BCE0:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,275
	ctx.r4.s64 = 275;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BCEC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,276
	ctx.r4.s64 = 276;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BCF8:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,277
	ctx.r4.s64 = 277;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD04:
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,278
	ctx.r4.s64 = 278;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD10:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,279
	ctx.r4.s64 = 279;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD1C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,280
	ctx.r4.s64 = 280;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD28:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,281
	ctx.r4.s64 = 281;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD34:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,282
	ctx.r4.s64 = 282;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD40:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,283
	ctx.r4.s64 = 283;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD4C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,284
	ctx.r4.s64 = 284;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD58:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,285
	ctx.r4.s64 = 285;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD64:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,286
	ctx.r4.s64 = 286;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD70:
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,287
	ctx.r4.s64 = 287;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD7C:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,288
	ctx.r4.s64 = 288;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD88:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,289
	ctx.r4.s64 = 289;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BD94:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,290
	ctx.r4.s64 = 290;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BDA0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,291
	ctx.r4.s64 = 291;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BDAC:
	// li r4,292
	ctx.r4.s64 = 292;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BDB4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,293
	ctx.r4.s64 = 293;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BDC0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,294
	ctx.r4.s64 = 294;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BDCC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,295
	ctx.r4.s64 = 295;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BDD8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,296
	ctx.r4.s64 = 296;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BDE4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,297
	ctx.r4.s64 = 297;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BDF0:
	// li r4,298
	ctx.r4.s64 = 298;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BDF8:
	// li r4,299
	ctx.r4.s64 = 299;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BE00:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,300
	ctx.r4.s64 = 300;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE0C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,301
	ctx.r4.s64 = 301;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE18:
	// li r4,302
	ctx.r4.s64 = 302;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BE20:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,303
	ctx.r4.s64 = 303;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE2C:
	// li r4,304
	ctx.r4.s64 = 304;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BE34:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,305
	ctx.r4.s64 = 305;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE40:
	// li r4,313
	ctx.r4.s64 = 313;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BE48:
	// li r4,314
	ctx.r4.s64 = 314;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BE50:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,315
	ctx.r4.s64 = 315;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE5C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,316
	ctx.r4.s64 = 316;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE68:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,317
	ctx.r4.s64 = 317;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE74:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,318
	ctx.r4.s64 = 318;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE80:
	// li r4,319
	ctx.r4.s64 = 319;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246BE88:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,320
	ctx.r4.s64 = 320;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BE94:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,321
	ctx.r4.s64 = 321;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BEA0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,322
	ctx.r4.s64 = 322;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BEAC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,323
	ctx.r4.s64 = 323;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BEB8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,324
	ctx.r4.s64 = 324;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BEC4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,325
	ctx.r4.s64 = 325;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BED0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,326
	ctx.r4.s64 = 326;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BEDC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,327
	ctx.r4.s64 = 327;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BEE8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,328
	ctx.r4.s64 = 328;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BEF4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,329
	ctx.r4.s64 = 329;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF00:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,330
	ctx.r4.s64 = 330;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF0C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,331
	ctx.r4.s64 = 331;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF18:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,332
	ctx.r4.s64 = 332;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF24:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,333
	ctx.r4.s64 = 333;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF30:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,334
	ctx.r4.s64 = 334;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF3C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,335
	ctx.r4.s64 = 335;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF48:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,336
	ctx.r4.s64 = 336;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF54:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,337
	ctx.r4.s64 = 337;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF60:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,338
	ctx.r4.s64 = 338;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF6C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,339
	ctx.r4.s64 = 339;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF78:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,340
	ctx.r4.s64 = 340;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF84:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,341
	ctx.r4.s64 = 341;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF90:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,342
	ctx.r4.s64 = 342;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BF9C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,343
	ctx.r4.s64 = 343;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BFA8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,344
	ctx.r4.s64 = 344;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BFB4:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,345
	ctx.r4.s64 = 345;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BFC0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,346
	ctx.r4.s64 = 346;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BFCC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,347
	ctx.r4.s64 = 347;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BFD8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,348
	ctx.r4.s64 = 348;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BFE4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,349
	ctx.r4.s64 = 349;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BFF0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,350
	ctx.r4.s64 = 350;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246BFFC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,351
	ctx.r4.s64 = 351;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C008:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,352
	ctx.r4.s64 = 352;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C014:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,353
	ctx.r4.s64 = 353;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C020:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,354
	ctx.r4.s64 = 354;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C02C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,355
	ctx.r4.s64 = 355;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C038:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,356
	ctx.r4.s64 = 356;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C044:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,357
	ctx.r4.s64 = 357;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C050:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,358
	ctx.r4.s64 = 358;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C05C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,359
	ctx.r4.s64 = 359;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C068:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,360
	ctx.r4.s64 = 360;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C074:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,361
	ctx.r4.s64 = 361;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C080:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,362
	ctx.r4.s64 = 362;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C08C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,363
	ctx.r4.s64 = 363;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C098:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,364
	ctx.r4.s64 = 364;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C0A4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,365
	ctx.r4.s64 = 365;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C0B0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,366
	ctx.r4.s64 = 366;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C0BC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,367
	ctx.r4.s64 = 367;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C0C8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,368
	ctx.r4.s64 = 368;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C0D4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,369
	ctx.r4.s64 = 369;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C0E0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,370
	ctx.r4.s64 = 370;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C0EC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,371
	ctx.r4.s64 = 371;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C0F8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,372
	ctx.r4.s64 = 372;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C104:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,373
	ctx.r4.s64 = 373;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C110:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,374
	ctx.r4.s64 = 374;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C11C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,375
	ctx.r4.s64 = 375;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C128:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,376
	ctx.r4.s64 = 376;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C134:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,377
	ctx.r4.s64 = 377;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C140:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,378
	ctx.r4.s64 = 378;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C14C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,379
	ctx.r4.s64 = 379;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C158:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,380
	ctx.r4.s64 = 380;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C164:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,381
	ctx.r4.s64 = 381;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C170:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,382
	ctx.r4.s64 = 382;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C17C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,395
	ctx.r4.s64 = 395;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C188:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,396
	ctx.r4.s64 = 396;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C194:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,383
	ctx.r4.s64 = 383;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C1A0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,384
	ctx.r4.s64 = 384;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C1AC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,385
	ctx.r4.s64 = 385;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C1B8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,386
	ctx.r4.s64 = 386;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C1C4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,387
	ctx.r4.s64 = 387;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C1D0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,388
	ctx.r4.s64 = 388;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C1DC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,389
	ctx.r4.s64 = 389;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C1E8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,390
	ctx.r4.s64 = 390;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C1F4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,391
	ctx.r4.s64 = 391;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C200:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,392
	ctx.r4.s64 = 392;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C20C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,393
	ctx.r4.s64 = 393;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C218:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,394
	ctx.r4.s64 = 394;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C224:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,397
	ctx.r4.s64 = 397;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C230:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,398
	ctx.r4.s64 = 398;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C23C:
	// li r4,399
	ctx.r4.s64 = 399;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C244:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,400
	ctx.r4.s64 = 400;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C250:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,401
	ctx.r4.s64 = 401;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C25C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,402
	ctx.r4.s64 = 402;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C268:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,403
	ctx.r4.s64 = 403;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C274:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,404
	ctx.r4.s64 = 404;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C280:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,405
	ctx.r4.s64 = 405;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C28C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,406
	ctx.r4.s64 = 406;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C298:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,407
	ctx.r4.s64 = 407;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C2A4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,408
	ctx.r4.s64 = 408;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C2B0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,420
	ctx.r4.s64 = 420;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C2BC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,421
	ctx.r4.s64 = 421;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C2C8:
	// li r4,422
	ctx.r4.s64 = 422;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C2D0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,423
	ctx.r4.s64 = 423;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C2DC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,424
	ctx.r4.s64 = 424;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C2E8:
	// li r4,425
	ctx.r4.s64 = 425;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C2F0:
	// li r4,426
	ctx.r4.s64 = 426;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C2F8:
	// li r4,427
	ctx.r4.s64 = 427;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C300:
	// li r4,428
	ctx.r4.s64 = 428;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C308:
	// li r4,429
	ctx.r4.s64 = 429;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C310:
	// li r4,430
	ctx.r4.s64 = 430;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C318:
	// li r4,431
	ctx.r4.s64 = 431;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C320:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,432
	ctx.r4.s64 = 432;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C32C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,433
	ctx.r4.s64 = 433;
	// b 0x8246c368
	goto loc_8246C368;
loc_8246C338:
	// li r4,434
	ctx.r4.s64 = 434;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C340:
	// li r4,435
	ctx.r4.s64 = 435;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C348:
	// li r4,436
	ctx.r4.s64 = 436;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C350:
	// li r4,437
	ctx.r4.s64 = 437;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C358:
	// li r4,438
	ctx.r4.s64 = 438;
	// b 0x8246c364
	goto loc_8246C364;
loc_8246C360:
	// li r4,439
	ctx.r4.s64 = 439;
loc_8246C364:
	// li r5,0
	ctx.r5.s64 = 0;
loc_8246C368:
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 3032);
	// bl 0x82468b00
	sub_82468B00(ctx, base);
loc_8246C370:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r27,-3296
	ctx.r8.s64 = r27.s64 + -3296;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// subf r10,r28,r9
	ctx.r10.s64 = ctx.r9.s64 - r28.s64;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lha r11,0(r11)
	r11.s64 = int16_t(PPC_LOAD_U16(r11.u32 + 0));
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// lhax r10,r30,r8
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(r30.u32 + ctx.r8.u32));
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8246c40c
	if (!cr0.eq) goto loc_8246C40C;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8246c40c
	if (!cr6.eq) goto loc_8246C40C;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r10,66
	ctx.r10.s64 = 66;
	// li r30,66
	r30.s64 = 66;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// sth r10,0(r11)
	PPC_STORE_U16(r11.u32 + 0, ctx.r10.u16);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x8246c3f8
	if (!cr6.lt) goto loc_8246C3F8;
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 3032);
	// bl 0x82463fc0
	sub_82463FC0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// bge 0x8246c3f8
	if (!cr0.lt) goto loc_8246C3F8;
	// stw r24,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r24.u32);
loc_8246C3F8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8246b014
	if (!cr6.eq) goto loc_8246B014;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8246c568
	goto loc_8246C568;
loc_8246C40C:
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r27,3456
	ctx.r10.s64 = r27.s64 + 3456;
	// lhax r10,r9,r10
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r10.u32));
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8246c448
	if (cr0.eq) goto loc_8246C448;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// cmplwi cr6,r10,7525
	cr6.compare<uint32_t>(ctx.r10.u32, 7525, xer);
	// bgt cr6,0x8246c448
	if (cr6.gt) goto loc_8246C448;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r8,r10,r26
	ctx.r8.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r26.u32));
	// cmpw cr6,r8,r11
	cr6.compare<int32_t>(ctx.r8.s32, r11.s32, xer);
	// bne cr6,0x8246c448
	if (!cr6.eq) goto loc_8246C448;
	// addi r11,r27,3744
	r11.s64 = r27.s64 + 3744;
	// lhax r30,r10,r11
	r30.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r11.u32));
	// b 0x8246c44c
	goto loc_8246C44C;
loc_8246C448:
	// lhax r30,r9,r27
	r30.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + r27.u32));
loc_8246C44C:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r10,r31,1030
	ctx.r10.s64 = r31.s64 + 1030;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8246c554
	if (!cr6.lt) goto loc_8246C554;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// sth r30,0(r11)
	PPC_STORE_U16(r11.u32 + 0, r30.u16);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
loc_8246C46C:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x8246b014
	goto loc_8246B014;
loc_8246C480:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8246c4a4
	if (!cr6.eq) goto loc_8246C4A4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// bl 0x8245d5f8
	sub_8245D5F8(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_8246C4A4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x8246c540
	if (!cr6.lt) goto loc_8246C540;
	// li r11,3
	r11.s64 = 3;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_8246C4B8:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r11,r26,-18512
	r11.s64 = r26.s64 + -18512;
	// lha r10,0(r9)
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + 0));
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r11,r10,r11
	r11.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + r11.u32));
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8246c4f0
	if (cr0.eq) goto loc_8246C4F0;
	// addi r10,r11,256
	ctx.r10.s64 = r11.s64 + 256;
	// cmplwi cr6,r10,7525
	cr6.compare<uint32_t>(ctx.r10.u32, 7525, xer);
	// bgt cr6,0x8246c4f0
	if (cr6.gt) goto loc_8246C4F0;
	// rlwinm r11,r10,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r11,r26
	r11.u64 = PPC_LOAD_U16(r11.u32 + r26.u32);
	// cmplwi cr6,r11,256
	cr6.compare<uint32_t>(r11.u32, 256, xer);
	// beq cr6,0x8246c510
	if (cr6.eq) goto loc_8246C510;
loc_8246C4F0:
	// cmplw cr6,r9,r22
	cr6.compare<uint32_t>(ctx.r9.u32, r22.u32, xer);
	// ble cr6,0x8246c564
	if (!cr6.gt) goto loc_8246C564;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r10,r9,-2
	ctx.r10.s64 = ctx.r9.s64 + -2;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// b 0x8246c4b8
	goto loc_8246C4B8;
loc_8246C510:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r9,r31,1030
	ctx.r9.s64 = r31.s64 + 1030;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x8246c554
	if (!cr6.lt) goto loc_8246C554;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r27,3744
	ctx.r9.s64 = r27.s64 + 3744;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// lhax r30,r10,r9
	r30.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r9.u32));
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// sth r30,0(r11)
	PPC_STORE_U16(r11.u32 + 0, r30.u16);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// b 0x8246c46c
	goto loc_8246C46C;
loc_8246C540:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246c564
	if (cr6.eq) goto loc_8246C564;
	// stw r25,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r25.u32);
	// b 0x8246b014
	goto loc_8246B014;
loc_8246C554:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,13060
	ctx.r4.s64 = r11.s64 + 13060;
	// bl 0x8245d5f8
	sub_8245D5F8(ctx, base);
loc_8246C564:
	// li r3,1
	ctx.r3.s64 = 1;
loc_8246C568:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8239bd30
	return;
}

__attribute__((alias("__imp__sub_8246C570"))) PPC_WEAK_FUNC(sub_8246C570);
PPC_FUNC_IMPL(__imp__sub_8246C570) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x8239bcec
	// stwu r1,-3184(r1)
	ea = -3184 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// lis r4,8
	ctx.r4.s64 = 524288;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// li r3,-1
	ctx.r3.s64 = -1;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// lis r4,3
	ctx.r4.s64 = 196608;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x8246c5d4
	if (!cr6.eq) goto loc_8246C5D4;
	// lis r29,-30602
	r29.s64 = -2005532672;
	// ori r29,r29,2156
	r29.u64 = r29.u64 | 2156;
	// b 0x8246c6a8
	goto loc_8246C6A8;
loc_8246C5D4:
	// stw r30,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r30.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r27,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r27.u32);
	// li r27,1
	r27.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r26,116(r31)
	PPC_STORE_U32(r31.u32 + 116, r26.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// stw r30,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r30.u32);
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// stw r30,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r30.u32);
	// stw r27,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r27.u32);
	// stw r30,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r30.u32);
	// stw r30,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r30.u32);
	// stw r30,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r30.u32);
	// stw r30,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r30.u32);
	// stw r30,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r30.u32);
	// stw r30,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r30.u32);
	// stw r30,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r30.u32);
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// stw r30,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r30.u32);
	// bl 0x823e2270
	sub_823E2270(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x8246c6a8
	if (cr0.lt) goto loc_8246C6A8;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8245acc8
	sub_8245ACC8(ctx, base);
	// li r5,3036
	ctx.r5.s64 = 3036;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8239cd50
	sub_8239CD50(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r31,3112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 3112, r31.u32);
	// bl 0x8246afc0
	sub_8246AFC0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8246c678
	if (cr0.eq) goto loc_8246C678;
	// stw r27,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r27.u32);
loc_8246C678:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x823e52d0
	sub_823E52D0(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// blt 0x8246c6a8
	if (cr0.lt) goto loc_8246C6A8;
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8246c6a8
	if (!cr6.eq) goto loc_8246C6A8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r30,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r30.u32);
loc_8246C6A8:
	// bl 0x823b4cf0
	sub_823B4CF0(ctx, base);
	// lis r4,11
	ctx.r4.s64 = 720896;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// ori r4,r4,31
	ctx.r4.u64 = ctx.r4.u64 | 31;
	// bl 0x823b4b58
	sub_823B4B58(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bge cr6,0x8246c6cc
	if (!cr6.lt) goto loc_8246C6CC;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x8246c6e8
	goto loc_8246C6E8;
loc_8246C6CC:
	// lwz r11,72(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 72);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8246c6e4
	if (cr6.eq) goto loc_8246C6E4;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x8246c6e8
	goto loc_8246C6E8;
loc_8246C6E4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8246C6E8:
	// addi r1,r1,3184
	ctx.r1.s64 = ctx.r1.s64 + 3184;
	// b 0x8239bd3c
	return;
}

__attribute__((alias("__imp__sub_8246C6F0"))) PPC_WEAK_FUNC(sub_8246C6F0);
PPC_FUNC_IMPL(__imp__sub_8246C6F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// bl 0x8242e4f0
	sub_8242E4F0(ctx, base);
	// lis r11,-32246
	r11.s64 = -2113273856;
	// stw r30,344(r31)
	PPC_STORE_U32(r31.u32 + 344, r30.u32);
	// lis r10,-32139
	ctx.r10.s64 = -2106261504;
	// lis r9,-32139
	ctx.r9.s64 = -2106261504;
	// addi r11,r11,-16512
	r11.s64 = r11.s64 + -16512;
	// addi r10,r10,-6280
	ctx.r10.s64 = ctx.r10.s64 + -6280;
	// addi r9,r9,-5992
	ctx.r9.s64 = ctx.r9.s64 + -5992;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r10,244(r31)
	PPC_STORE_U32(r31.u32 + 244, ctx.r10.u32);
	// stw r9,248(r31)
	PPC_STORE_U32(r31.u32 + 248, ctx.r9.u32);
	// stw r8,552(r31)
	PPC_STORE_U32(r31.u32 + 552, ctx.r8.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

